[
  {
    "objectID": "hw/hw-01.html",
    "href": "hw/hw-01.html",
    "title": "Homework 1",
    "section": "",
    "text": "(see Gradescope for any updates on due dates)"
  },
  {
    "objectID": "hw/hw-01.html#due-1159pm-tues-sept-12",
    "href": "hw/hw-01.html#due-1159pm-tues-sept-12",
    "title": "Homework 1",
    "section": "",
    "text": "(see Gradescope for any updates on due dates)"
  },
  {
    "objectID": "hw/hw-01.html#rstudio",
    "href": "hw/hw-01.html#rstudio",
    "title": "Homework 1",
    "section": "RStudio",
    "text": "RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not, first install the latest version of R here: https://cran.rstudio.com (remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "hw/hw-01.html#r-knitr",
    "href": "hw/hw-01.html#r-knitr",
    "title": "Homework 1",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the .Rnw format to type up this lab report. To get started see basics about knitr."
  },
  {
    "objectID": "hw/hw-01.html#getting-started-with-github-classroom",
    "href": "hw/hw-01.html#getting-started-with-github-classroom",
    "title": "Homework 1",
    "section": "Getting started with Github Classroom",
    "text": "Getting started with Github Classroom\nGo to Github classroom to accept the invitation to create a repository for this assignment at HW1\nThis will create a private repo in the STA702-F23 organization on Github with your github user name. Note: You may receive an email invitation to join STA702-F23 on your behalf.\nHit refresh, to see the link for the repo, and then click on it to go to the STA702-F23 organization in Github.\nFollow the instructions in the README in your repo and in the hw1.Rnw file to complete the assignment and push to GitHub. If you encounter issues with Gradescope submission, it is critical that you have pushed your final assignment to GitHub by the due date to validate timestamps."
  },
  {
    "objectID": "hw/hw-01.html#gradescope-submission",
    "href": "hw/hw-01.html#gradescope-submission",
    "title": "Homework 1",
    "section": "Gradescope Submission",
    "text": "Gradescope Submission\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github and upload the pdf to Gradescope here: https://www.gradescope.com/courses/585736/assignments\nMake sure to knit to pdf; ask the TA about knitting to pdf if you cannot figure it out. Be sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "hw/hw-01.html#grading",
    "href": "hw/hw-01.html#grading",
    "title": "Homework 1",
    "section": "Grading",
    "text": "Grading\nTotal: 20 points."
  },
  {
    "objectID": "hw/hw-03.html",
    "href": "hw/hw-03.html",
    "title": "Homework 3",
    "section": "",
    "text": "Please see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-03.html#due-1159pm-tues-sept-26",
    "href": "hw/hw-03.html#due-1159pm-tues-sept-26",
    "title": "Homework 3",
    "section": "",
    "text": "Please see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-03.html#rstudio",
    "href": "hw/hw-03.html#rstudio",
    "title": "Homework 3",
    "section": "RStudio",
    "text": "RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not, first install the latest version of R here: https://cran.rstudio.com (remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "hw/hw-03.html#r-knitr",
    "href": "hw/hw-03.html#r-knitr",
    "title": "Homework 3",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the .Rnw format to type up this lab report. To get started see basics about knitr."
  },
  {
    "objectID": "hw/hw-03.html#getting-started-with-github-classroom",
    "href": "hw/hw-03.html#getting-started-with-github-classroom",
    "title": "Homework 3",
    "section": "Getting started with Github Classroom",
    "text": "Getting started with Github Classroom\nGo to Github classroom to accept the invitation to create a repository for this assignment at HW3 - this will create a private repo in the STA702-F23 organization on Github with your github user name. Note: You may receive an email invitation to join STA702-F23 on your behalf.\nHit refresh, to see the link for the repo, and then click on it to go to the STA702-F23 organization in Github.\nFollow the instructions in the README in your repo and in the hw*.Rnw file to complete the assignment and push to GitHub. If you encounter issues with Gradescope submission, it is critical that you have pushed your final assignment to GitHub by the due date to validate timestamps."
  },
  {
    "objectID": "hw/hw-03.html#gradescope-submission",
    "href": "hw/hw-03.html#gradescope-submission",
    "title": "Homework 3",
    "section": "Gradescope Submission",
    "text": "Gradescope Submission\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github and upload the pdf to Gradescope here: https://www.gradescope.com/courses/585736/assignments\nMake sure to knit to pdf; ask the TA about knitting to pdf if you cannot figure it out. Be sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "hw/hw-03.html#grading",
    "href": "hw/hw-03.html#grading",
    "title": "Homework 3",
    "section": "Grading",
    "text": "Grading\nTotal: 20 points."
  },
  {
    "objectID": "labs/lab-00-getting-started.html#rrstudio",
    "href": "labs/lab-00-getting-started.html#rrstudio",
    "title": "Lab 0: Getting Started with R and Sweave/Knitr",
    "section": "R/RStudio",
    "text": "R/RStudio\nYou all should have R and RStudio installed on your computers or feel free to use the Department servers. If you want a local version of RStudion, first install the latest version of R here: https://cran.rstudio.com (remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system. You may also need to install git as well."
  },
  {
    "objectID": "labs/lab-00-getting-started.html#github",
    "href": "labs/lab-00-getting-started.html#github",
    "title": "Lab 0: Getting Started with R and Sweave/Knitr",
    "section": "Github",
    "text": "Github\nCreate a github account if you do not have one here https://github.com"
  },
  {
    "objectID": "labs/lab-00-getting-started.html#r-sweave",
    "href": "labs/lab-00-getting-started.html#r-sweave",
    "title": "Lab 0: Getting Started with R and Sweave/Knitr",
    "section": "R Sweave",
    "text": "R Sweave\nYou are required to use R Sweave/knitr to type up HW and lab reports. Don’t worry we will guide you along the way!"
  },
  {
    "objectID": "labs/lab-00-getting-started.html#gradescope",
    "href": "labs/lab-00-getting-started.html#gradescope",
    "title": "Lab 0: Getting Started with R and Sweave/Knitr",
    "section": "Gradescope",
    "text": "Gradescope\nYou MUST submit the final pdf file to the course site on Gradescope. Make sure to knit to pdf and to submit under the right assignment entry."
  },
  {
    "objectID": "labs/lab-04.html#rrstudio",
    "href": "labs/lab-04.html#rrstudio",
    "title": "Lab 4: Metropolis Random Walk Algorithms",
    "section": "R/RStudio",
    "text": "R/RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not and want to use your own computer, first install the latest version of R here: https://cran.rstudio.com remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "labs/lab-04.html#r-knitr",
    "href": "labs/lab-04.html#r-knitr",
    "title": "Lab 4: Metropolis Random Walk Algorithms",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the Rnw format to type up this lab report. To get started see basics about knitr. Make sure to knit to pdf ; ask the TA about knitting to pdf if you cannot figure it out."
  },
  {
    "objectID": "labs/lab-04.html#github-classroom",
    "href": "labs/lab-04.html#github-classroom",
    "title": "Lab 4: Metropolis Random Walk Algorithms",
    "section": "Github Classroom",
    "text": "Github Classroom\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github by the due date."
  },
  {
    "objectID": "labs/lab-04.html#gradescope",
    "href": "labs/lab-04.html#gradescope",
    "title": "Lab 4: Metropolis Random Walk Algorithms",
    "section": "Gradescope",
    "text": "Gradescope\nYou must upload the final pdf from your Github repo to Gradescope.\nBe sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": " Syllabus",
    "section": "",
    "text": "When in doubt about anything at all, ask questions!!!\n\nPrerequisites\nALL students are expected to be familiar with all the topics covered within the required prerequisites to be in this course. That is - mathematical statistics and probability, linear algebra, and multivariate calculus. Students are also expected to be familiar with R and are encouraged to learn LaTeX during the course.\n\n\nWorkload\nWork hours will include time spent going through the preassigned readings, attending lectures and lab sessions, and doing all graded work.\n\n\nGraded Work\nGraded work for the course will consist of homework assignments, lab exercises, two midterms and a final exam. Regrade requests for problem sets and lab exercises must be done via Gradescope AT MOST 24 hours after grades are released! Regrade requests for quizzes, midterm, and final exams must be done via Gradescope AT MOST 12 hours after grades are released! Always write in complete sentences and show your steps.\nStudents’ final grades will be determined as shown below:\n\nComponent Percentage\n\n\nComponent\nPercentage\n\n\n\n\nHomework\n20%\n\n\nMidterm\n20%\n\n\nMidterm II\n20%\n\n\nLab exercises\n10%\n\n\nParticipation\n5%\n\n\nFinal Exam\n25%\n\n\n\nThere are no make-ups for any of the graded work except for medical or familial emergencies or for reasons approved by the instructor BEFORE the due date. See the instructor in advance of relevant due dates to discuss possible alternatives.\nGrades may be curved at the end of the semester. Cumulative averages of 90% – 100% are guaranteed at least an A-, 80% – 89% at least a B-, and 70% – 79% at least a C-, however the exact ranges for letter grades will be determined at the end of the course.\n\n\nDescriptions of graded work\n\nProblem sets\nHomework will be handed out on a weekly basis. They will be based on both the lectures and labs and will be announced every Thursday or Friday – be sure to check the website regularly! Also, please note that any work that is not legible by the instructor or TAs will not be graded (given a score of 0). Every write-up must be clearly written in full sentences and clear English. Any assignment that is completely unclear to the instructors and/or TAs, may result in a grade of a 0. For programming exercises, we will be using R/knitr with \\(\\LaTeX\\) for preparing assignments using github classroom for data analysis.\nEach student MUST write up and turn in her or his own answers. You are encouraged to talk to each other regarding homework problems or to the instructor/TA. However, the write-up, solution, and code must be entirely your own work. No sharing of solutions or code! The assignments must be submitted on Gradescope under Assignments. Note that you will not be able to make online submissions after the due date, so be sure to submit before or by the Gradescope-specified deadline. You may resubmit, so when in doubt submit work early. In certain situations if there are issues with submissions, the TA may review your GitHub repository prior to the due date.\nSolutions will be curated from student solutions with proper attribution. Every week the TAs will select a representative correct solution for the assigned problems and put them together into one solutions set with each answer being attributed to the student who wrote it. If you would like to OPT OUT of having your homework solutions used for the class solutions, please let the Instructor and TAs know in advance.\nFinally, your lowest homework score will be dropped!\n\n\nLab exercises\nThe objective of the lab assignments is to give you more hands-on experience with Bayesian data analysis. Attend the lab session and learn a concept or two and some R from the TA, and then work on the computational part of the problem sets. Each lab assignment should be submitted in timely fashion. You are REQUIRED to use R/knitr (or R/Rmarkdown in some cases).\n\n\nMidterm Exams\nThere will be two inclass midterm exams. Detailed instructions on the midterm will be made available later but please check dates on the calendar well in advance!\n\n\nFinal Exam\nThere will be a final exam after the reading week. If you miss any quiz or the midterm, your grade will depend more on the final exam score since there are no make-up exams. You cannot miss the final exam! Please check the important dates on the homepage for the date and time of the final before making plans to return home at the end of the semester. Detailed instructions on the final will be made available later.\n\n\n\nLate Submission Policy\n\nno late submission of homework or lab assignments, however we will drop the lowest score in each.\n\n\n\nCourse Topics\n\nBasics of Bayesian Models\nLoss Functions, Inference and Decision Making\nPredictive Distributions\nPredictive Distributions and Model Checking\nBayesian Hypothesis Testing\nMultiple Testing\nMCMC (Gibbs & Metropolis Hastings Algorithms)\nBayesian Generalized Linear Models\nHiearchical Modeling and Random Effects\nHamiltonian Monte Carlo\nNonParametric Bayes\n\nFor a detailed day-by-day list of topics, please refer to the Course Schedule\n\n\nAcademic integrity\nDuke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, respect, and accountability. Citizens of this community commit to reflect upon and uphold these principles in all academic and nonacademic endeavors, and to protect and promote a culture of integrity.\nRemember the Duke Community Standard that you have agreed to abide by:\n\nTo uphold the Duke Community Standard:\n\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\nCheating or plagiarism on any graded assessments, lying about an illness or absence and other forms of academic dishonesty are a breach of trust with classmates and faculty, violate the Duke Community Standard, and will not be tolerated. Such incidences will result in a 0 grade for all parties involved. Additionally, there may be penalties to your final class grade along with being reported to the Office of Student Conduct. Review the academic dishonesty policies at https://studentaffairs.duke.edu/conduct/z-policies/academic-dishonesty.\n\n\nDiversity & Inclusiveness\nThis course is designed so that students from all backgrounds and perspectives all feel welcome both in and out of class. Please feel free to talk to me (in person or via email) if you do not feel well-served by any aspect of this class, or if some aspect of class is not welcoming or accessible to you. My goal is for you to succeed in this course, therefore, let me know immediately if you feel you are struggling with any part of the course more than you know how to manage. Doing so will not affect your grades, but it will allow me to provide the resources to help you succeed in the course.\n\n\nDisability Statement\nStudents with disabilities who believe that they may need accommodations in the class are encouraged to contact the Student Disabilities Access Office at 919-668-1267 or disabilities@aas.duke.edu as soon as possible to better ensure that such accommodations are implemented in a timely fashion.\n\n\nOther Information\nIt can be a lot more pleasant oftentimes to get one-on-one answers and help. Make use of the teaching team’s office hours, we’re here to help! Do not hesitate to talk to me during office hours or by appointment to discuss a problem set or any aspect of the course. Questions related to course assignments and honesty policy should be directed to me. When the teaching team has announcements for you we will send an email to your Duke email address. Be sure to check your email daily.\nMost of the course components will be held in person, but occasionally may need to be held online using Zoom meetings. If you have any concerns, issues or challenges, let the instructor know as soon as possible. Also, all students are strongly encouraged to rely on the forums in Sakai, for interacting among yourself and asking other students questions. You can also ask the instructor or the TAs questions on there and we will try to respond as soon as possible. If you experience any technical issues with joining or using the forums, let the instructor know.\n\n\nProfessionalism\nTry as much as possible to refrain from texting or using your computer for anything other than coursework during class and labs. Again, the more engaged you are, the quicker you will be able to get through the materials. You are responsible for everything covered in the lecture videos, lecture notes/slides, and in the assigned readings."
  },
  {
    "objectID": "reading/02-reading.html",
    "href": "reading/02-reading.html",
    "title": "Lecture 2: Optimal Bayesian Point and Interval Estimation",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 3.1.2: Confidence regions\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 2.3: Summarizing posterior inference\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\nChapter 2 (skip Section 2.4 for now) Decision-Theoretic Foundations\nSection 4.1: Bayesian inference\nSection 4.2: Bayesian Decision Theory\nSection 5.5: Confidence regions"
  },
  {
    "objectID": "reading/02-reading.html#readings",
    "href": "reading/02-reading.html#readings",
    "title": "Lecture 2: Optimal Bayesian Point and Interval Estimation",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 3.1.2: Confidence regions\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 2.3: Summarizing posterior inference\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\nChapter 2 (skip Section 2.4 for now) Decision-Theoretic Foundations\nSection 4.1: Bayesian inference\nSection 4.2: Bayesian Decision Theory\nSection 5.5: Confidence regions"
  },
  {
    "objectID": "reading/05-reading.html",
    "href": "reading/05-reading.html",
    "title": "Lecture 5: Introduction to Hierarchical Models",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 8.2: Comparing multiple groups\nSection 8.3: The hierarchical normal model\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 5.2: Exchangeability and setting up hierarchical models\nSection 5.3: Fully Bayesian analysis of conjugate hierarchical models\nSection 5.4: Estimating exchangeable parameters for a normal model\nSection 5.7: Weakly informative priors for hierarchical variance parameters\nSection 11.2 Metropolis and Metropolis-Hastings algorithms\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/05-reading.html#readings",
    "href": "reading/05-reading.html#readings",
    "title": "Lecture 5: Introduction to Hierarchical Models",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 8.2: Comparing multiple groups\nSection 8.3: The hierarchical normal model\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 5.2: Exchangeability and setting up hierarchical models\nSection 5.3: Fully Bayesian analysis of conjugate hierarchical models\nSection 5.4: Estimating exchangeable parameters for a normal model\nSection 5.7: Weakly informative priors for hierarchical variance parameters\nSection 11.2 Metropolis and Metropolis-Hastings algorithms\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/07-reading.html",
    "href": "reading/07-reading.html",
    "title": "Lecture 7: Adaptive Metropolis & Metropolis-Hastings",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 10.4: Metropolis, Metropolis-Hastings and Gibbs\nSection 10.5: Combining the Metropolis and Gibbs algorithm\nSection 10.6: Discussion and further references\nChapter 6: Posterior approximation with the Gibbs sampler\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 11.2: Metropolis and Metropolis-Hastings algorithms\nSection 11.4: Inference and assessing convergence\nSection 11.6: Example\nSection 11.7: Bibliographic note\n\nAn Adaptive Metropolis Algoritm by Heikki Haario, Eero Saksman, Johanna Tamminen (2001)\nExamples of Adaptive Metropolis by Gareth O. Roberts & Jeffrey S. Rosenthal (2009) Journal of Computational and Graphical Statistics, 18:2, 349-367, DOI: 10.1198/ jcgs.2009.06134\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/07-reading.html#readings",
    "href": "reading/07-reading.html#readings",
    "title": "Lecture 7: Adaptive Metropolis & Metropolis-Hastings",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 10.4: Metropolis, Metropolis-Hastings and Gibbs\nSection 10.5: Combining the Metropolis and Gibbs algorithm\nSection 10.6: Discussion and further references\nChapter 6: Posterior approximation with the Gibbs sampler\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 11.2: Metropolis and Metropolis-Hastings algorithms\nSection 11.4: Inference and assessing convergence\nSection 11.6: Example\nSection 11.7: Bibliographic note\n\nAn Adaptive Metropolis Algoritm by Heikki Haario, Eero Saksman, Johanna Tamminen (2001)\nExamples of Adaptive Metropolis by Gareth O. Roberts & Jeffrey S. Rosenthal (2009) Journal of Computational and Graphical Statistics, 18:2, 349-367, DOI: 10.1198/ jcgs.2009.06134\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/04-reading.html",
    "href": "reading/04-reading.html",
    "title": "Lecture 4: Predictive Checks",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nChapter 4: Monte Carlo Approximations\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nChapter 6: Model Checking"
  },
  {
    "objectID": "reading/04-reading.html#readings",
    "href": "reading/04-reading.html#readings",
    "title": "Lecture 4: Predictive Checks",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nChapter 4: Monte Carlo Approximations\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nChapter 6: Model Checking"
  },
  {
    "objectID": "reading/04-reading.html#optional",
    "href": "reading/04-reading.html#optional",
    "title": "Lecture 4: Predictive Checks",
    "section": "Optional",
    "text": "Optional\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\n2.6 Criticisms and alternatives\n6.2.2 Monte Carlo methods"
  },
  {
    "objectID": "reading/04-reading.html#recommended",
    "href": "reading/04-reading.html#recommended",
    "title": "Lecture 4: Predictive Checks",
    "section": "Recommended",
    "text": "Recommended\nBayarri, M. and Berger, J. (2000). P-values for composite null models. Journal of the American Statistical Association, 95(452):1127–1142\nBerger, J (2003) Could Fisher, Jeffreys and Neyman Have Agreed on Testing? Statistical Science, 18:1-12."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": " Schedule",
    "section": "",
    "text": "Please refresh often in case links/content has been updated\n\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n      Week\n      Date\n      Lesson\n      Reading\n      Slides\n      Labs\n      HW\n    \n  \n  \n    WEEK 1\n\nTues, Aug 29\n\nLecture 0: Course Overview and Introduction\n\n\n\n \n\n\n\n\n    \nThur, Aug 31\n\nLecture 1: Basics of Bayesian Inference\n\n\n\n \n\n\n\n    \nFri, Sept 1\n\nLab 1: R and Monte Carlo Review\n\n\n\n\n\n\n    WEEK 2\n\nTues, Sept 5\n\nLecture 2: Loss Functions & Summaries\n\n\n\n \n\n\n hw-01\n\n    \nThur, Sept 7\n\nLecture 3: Normal Model & Predictive Distributions\n\n\n\n \n\n\n\n    \nFri, Sept 8\n\nLab 2: Beta-Binomial Model and Introduction to stan\n\n\n\n\n\n\n    WEEK 3\n\nTues, Sept 12\n\nLecture 4: Predictive Checks\n\n\n\n \n\n\n hw-02\n\n    \nThur, Sept 14\n\nLecture 5: Introduction to Hierarchical Models, EB & Metropolis\n\n\n\n \n\n\n\n    \nFri, Sept 15\n\nLab 3: Posterior Predictive Checks\n\n\n\n\n\n\n    WEEK 4\n\nTues, Sept 19\n\nLecture 6: Metropolis Algorithm & Stochastic Sampling\n\n\n\n \n\n\n hw-03\n\n    \nThur, Sept 21\n\nLecture 7: Diagnostics and Adaptive Metropolis\n\n\n\n \n\n\n\n    \nFri, Sept 22\n\nLab 4: Metropolis Hastings\n\n\n\n\n\n\n    WEEK 5\n\nTues, Sept 26\n\nLecture 8: Metropolis-Hastings and Gibbs\n\n\n\n \n\n\n hw-04\n\n    \nThur, Sept 28\n\nLecture 9: Data Augmentation\n\n\n\n \n\n\n\n    \nFri, Sept 29\n\nLab 5:  Gibbs, DA and Adaptive Metropolis\n\n\n\n\n\n    WEEK 6\n\nTues, Oct 3\n\nLecture 10: Missing Data\n\n\n\n\n hw-05\n\n    \nThu, Oct 5\n\nLecture 11: Hypothesis Testing\n\n\n\n\n\n    \nFri, Oct 6\n\nLab 6: Hypothesis & Multiple Testing\n\n\n\n\n\n    WEEK 7\n\nTue, Oct 10\n\nLec 12: Multiple Testing and Hierachical Models\n\n\n\n\n hw-06\n\n    \nThu, Oct 12\n\nLec 13: Bayesian Multiple Testing and Hierachical Models\n\n\n\n\n\n    \nFri, Oct 13\n\nLab: Review\n\n\n\n\n\n    WEEK 8\n\nTue, Oct 17\n\nNO CLASS FALL BREAK\n\n\n\n\n\n    \nThur, Oct 19\n\nMidterm 1\n\n\n\n\n\n    \nFri, Oct 20\n\nLab 7: Variable Selection\n\n\n\n\n hw-07\n\n    WEEK 9\n\nTue, Oct 24\n\nLec 14: Bayesian Linear Regression\n\n\n\n\n\n    \nThur, Oct 26\n\nLec 15: Priors in Bayesian Linear Regression\n\n\n\n\n\n    \nFri, Oct 27\n\nLab 7: Variable Selection\n\n\n\n\n\n    WEEK 10\n\nTues, Oct 31\n\nLec 16: Bayesian Variable Selection and Model Averaging\n\n\n \n\n\n\n    \nThur, Nov 2\n\nLec 17: Bayesian Variable Selection and Model Averaging\n\n\n\n\n\n    \nFri, Nov 3\n\nLab: Q&A\n\n\n\n\n\n    Week 11\n\nTues, Nov 7\n\nLec 18:\n\n\n\n\n hw-08\n\n    \nThurs, Nov 9\n\nLec 19:  Outliers\n\n\n\n\n\n    \nFri, Nov 10\n\nLab 8: Review\n\n\n\n\n\n    Week 12\n\nTues, Nov 14\n\nMidterm II\n\n\n\n\n hw-09\n\n    \nThurs, Nov 16\n\nLec 20: Random Effects\n\n\n\n\n\n    \nFri, Nov 17\n\nLab 9\n\n\n\n\n\n    Week 12\n\nTues, Nov 21\n\nLec 21: Mixed Effects Models\n\n\n\n\n hw-10\n\n    \nThurs, Nov 23\n\nThanksgiving Break - No Class \n\n\n\n\n\n    Week 13\n\nTues, Nov 28\n\nHMC\n\n\n\n\n hw-11\n\n    \nThur, Nov 30\n\nBARK: NonParametric Regression\n\n\n\n\n\n    \nFri, Dec 1\n\nLab 10\n\n\n\n\n\n    Week 14\n\n\nReading Period\n\n\n\n\n\n    Finals Period\n\nSat, Dec 16 2pm-5pm (in classroom)"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#normal-means-model",
    "href": "resources/slides/05-hierarchical-models.html#normal-means-model",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Normal Means Model",
    "text": "Normal Means Model\n\nSuppose we have normal data with \\[Y_i \\mid \\mu_i, \\sigma^2 \\overset{ind}{\\sim} \\textsf{N}(\\mu_i, \\sigma^2)\\]\nseparate mean for each observation!\nQuestion: How can we possibly hope to estimate all these \\(\\mu_i\\)? One \\(y_i\\) per \\(\\mu_i\\) and \\(n\\) observations!\nNaive estimator: just consider only using \\(y_i\\) in estimating and not the other observations.\nMLE \\(\\hat{\\mu}_i = y_i\\)\nHierarchical Viewpoint: Let’s borrow information from other observations!"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#motivation",
    "href": "resources/slides/05-hierarchical-models.html#motivation",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Motivation",
    "text": "Motivation\n\n\n \n \n\nExample \\(y_i\\) is difference in gene expression for the \\(i^{\\text{th}}\\) gene between cancer and control lines\nmay be natural to think that the \\(\\mu_i\\) arise from some common distribution, \\(\\mu_i \\overset{iid}{\\sim} g\\)\nunbiased but high variance estimators of \\(\\mu_i\\) based on one observation!"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#low-variability",
    "href": "resources/slides/05-hierarchical-models.html#low-variability",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Low Variability",
    "text": "Low Variability\n\n\nlittle variation in \\(\\mu_i\\)s so a better estimate might be \\(\\bar{y}\\)\nNot forced to choose either - what about some weighted average between \\(y_i\\) and \\(\\bar{y}\\)?"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#simple-example",
    "href": "resources/slides/05-hierarchical-models.html#simple-example",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Simple Example",
    "text": "Simple Example\n\nData Model \\[Y_i \\mid \\mu_i, \\sigma^2 \\overset{ind}{\\sim} \\textsf{N}(\\mu_i, \\sigma^2)\\]\nMeans Model \\[\\mu_i \\mid \\mu, \\sigma^2_\\mu \\overset{iid}{\\sim} \\textsf{N}(\\mu, \\sigma^2_{\\mu})\\]\nnot necessarily a prior!\nNow estimate \\(\\mu_i\\) (let \\(\\phi = 1/\\sigma^2\\) and \\(\\phi_{\\mu} = 1/\\sigma^2_\\mu\\))\nCalculate the “posterior” \\(\\mu_i \\mid y_i, \\mu, \\phi, \\phi_\\mu\\)"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#hiearchical-estimates",
    "href": "resources/slides/05-hierarchical-models.html#hiearchical-estimates",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Hiearchical Estimates",
    "text": "Hiearchical Estimates\n\nPosterior: \\(\\mu_i \\mid y_i, \\mu, \\phi, \\phi_\\mu \\overset{ind}{\\sim} \\textsf{N}(\\tilde{\\mu}_i, 1/\\tilde{\\phi}_\\mu)\\)\nestimator of \\(\\mu_i\\) weighted average of data and population parameter \\(\\mu\\) \\[\\tilde{\\mu}_i = \\frac{\\phi_\\mu \\mu + \\phi y_i}\n                        {\\phi_\\mu + \\phi} \\qquad \\qquad \\tilde{\\phi}_\\mu = \\phi + \\phi_\\mu\\]\nif \\(\\phi_\\mu\\) is large relative to \\(\\phi\\) all of the \\(\\mu_i\\) are close together and benefit by borrowing information\nin limit as \\(\\sigma^2_\\mu \\to 0\\) or \\(\\phi_\\mu \\to \\infty\\) we have \\(\\tilde{\\mu}_i = \\mu\\) (all means are the same)\nif \\(\\phi_\\mu\\) is small relative to \\(\\phi\\) little borrowing of information\nin the limit as \\(\\phi_\\mu \\to 0\\) we have \\(\\tilde{\\mu}_i = y_i\\)"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#bayes-estimators-and-bias",
    "href": "resources/slides/05-hierarchical-models.html#bayes-estimators-and-bias",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Bayes Estimators and Bias",
    "text": "Bayes Estimators and Bias\n\nNote: you often benefit from a hierarchical model, even if its not obvious that the \\(\\mu_i\\) are related!\nThe MLE for the \\(\\mu_i\\) is just the sample \\(y_i\\).\n\\(y_i\\) is unbiased for \\(\\mu_i\\) but can have high variability!\nthe posterior mean is actually biased.\nUsually through the weighting of the sample data and prior, Bayes procedures have the tendency to pull the estimate of \\(\\mu_i\\) toward the prior or provide shrinkage to the mean.\n\n\n\n\n\n\n\n\nQuestion\n\n\nWhy would we ever want to do this? Why not just stick with the MLE?\n\n\n\n\nMSE or Bias-Variance Tradeoff"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#modern-relevance",
    "href": "resources/slides/05-hierarchical-models.html#modern-relevance",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Modern Relevance",
    "text": "Modern Relevance\n\nThe fact that a biased estimator would do a better job in many estimation/prediction problems can be proven rigorously, and is referred to as Stein’s paradox.\nStein’s result implies, in particular, that the sample mean is an inadmissible estimator of the mean of a multivariate normal distribution in more than two dimensions i.e. there are other estimators that will come closer to the true value in expectation.\nIn fact, these are Bayes point estimators (the posterior expectation of the parameter \\(\\mu_i\\)).\nMost of what we do now in high-dimensional statistics is develop biased estimators that perform better than unbiased ones.\nExamples: lasso regression, ridge regression, various kinds of hierarchical Bayesian models, etc."
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#population-parameters",
    "href": "resources/slides/05-hierarchical-models.html#population-parameters",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Population Parameters",
    "text": "Population Parameters\n\nwe don’t know \\(\\mu\\) (or \\(\\sigma^2\\) and \\(\\sigma^2_\\mu\\) for that matter)\nFind marginal likelihood \\(\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu)\\) by integrating out \\(\\mu_i\\) with respect to \\(g\\) \\[\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu) \\propto \\prod_{i = 1}^n\n\\int \\textsf{N}(y_i; \\mu_i, \\sigma^2)  \\textsf{N}(\\mu_i; \\mu, \\sigma^2_\\mu) \\, d \\mu_i\\]\nProduct of predictive distributions for \\(Y_i \\mid \\mu, \\sigma^2, \\sigma^2_\\mu \\overset{iid}{\\sim} \\textsf{N}(\\mu, \\sigma^2 + \\sigma^2_\\mu)\\)\n\\[\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu) \\propto \\prod_{i = 1}^n (\\sigma^2 + \\sigma^2_\\mu)^{-1/2} \\exp \\left\\{ - \\frac{1}{2} \\frac{\\left(y_i - \\mu \\right)^2}{\\sigma^2 + \\sigma^2_\\mu }\\right\\}\\]\nFind MLE’s"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#mles",
    "href": "resources/slides/05-hierarchical-models.html#mles",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "MLEs",
    "text": "MLEs\n\\[\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu) \\propto  (\\sigma^2 + \\sigma^2_\\mu)^{-n/2} \\exp\\left\\{ - \\frac{1}{2} \\sum_{i=1}^n\\frac{\\left(y_i - \\mu \\right)^2}{\\sigma^2 + \\sigma^2_\\mu }\\right\\}\\]\n\nMLE of \\(\\mu\\): \\(\\hat{\\mu} = \\bar{y}\\)\nCan we say anything about \\(\\sigma^2_\\mu\\)? or \\(\\sigma^2\\) individually?\nMLE of \\(\\sigma^2 + \\sigma^2_\\mu\\) is \\[\\widehat{\\sigma^2 + \\sigma^2_\\mu} = \\frac{\\sum(y_i - \\bar{y})^2}{n}\\]\nAssume \\(\\sigma^2\\) is known (say 1) \\[\\hat{\\sigma}^2_\\mu = \\frac{\\sum(y_i - \\bar{y})^2}{n} - 1\\]"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#empirical-bayes-estimates",
    "href": "resources/slides/05-hierarchical-models.html#empirical-bayes-estimates",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Empirical Bayes Estimates",
    "text": "Empirical Bayes Estimates\n\nplug in estimates of hyperparameters into the prior and pretend they are known\nresulting estimates are known as Empirical Bayes\nEstimates of variances may be negative - constrain to 0 on the boundary\nunderestimates uncertainty\nFully Bayes would put a prior on the unknowns"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#bayes-and-hierarchical-models",
    "href": "resources/slides/05-hierarchical-models.html#bayes-and-hierarchical-models",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Bayes and Hierarchical Models",
    "text": "Bayes and Hierarchical Models\n\nWe know the conditional posterior distribution of \\(\\mu_i\\) given the other parameters, lets work with the marginal likelihood \\(\\cal{L}(\\theta)\\)\nneed a prior \\(\\pi(\\theta)\\) for unknown parameters are \\(\\theta = (\\mu, \\sigma^2, \\sigma^2_\\mu)\\) (details later)\nPosterior \\[\\pi(\\theta \\mid y) = \\frac{\\pi(\\theta) \\cal{L}(\\theta)}\n{\\int_\\Theta \\pi(\\theta) \\cal{L}(\\theta) \\, d\\theta} =\n\\frac{\\pi(\\theta) \\cal{L}(\\theta)}\n{m(y)}\\]\nProblems: Except for simple cases (conjugate models) \\(m(y)\\) is not available analytically"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#large-sample-approximations",
    "href": "resources/slides/05-hierarchical-models.html#large-sample-approximations",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Large Sample Approximations",
    "text": "Large Sample Approximations\n\nAppeal to BvM (Bayesian Central Limit Theorem) and approximate \\(\\pi(\\theta \\mid y)\\) with a Gaussian distribution centered at the posterior mode \\(\\hat{\\theta}\\) and asymptotic covariance matrix \\[V_\\theta = \\left[- \\frac{\\partial^2}{\\partial \\theta \\partial \\theta^T} \\left\\{\\log(\\pi(\\theta)) + \\log(\\cal{L}(\\theta)) \\right\\} \\right]^{-1}\\]\nrelated to Laplace approximation to integral (also large sample)\nUse normal approximation to find \\(\\textsf{E}[h(\\theta) \\mid y]\\)\nIntegral may not exist in closed form (non-linear functions)\nuse numerical quadrature (doesn’t scale up)\nStochastic methods of integration"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#stochastic-integration",
    "href": "resources/slides/05-hierarchical-models.html#stochastic-integration",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Stochastic Integration",
    "text": "Stochastic Integration\n\nStochastic integration \\[\\textsf{E}[h(\\theta) \\mid y] =  \\int_\\Theta h(\\theta) \\pi(\\theta \\mid y) \\, d\\theta \\approx \\frac{1}{T}\\sum_{t=1}^{T} h(\\theta^{(t)}) \\qquad \\theta^{(t)} \\sim \\pi(\\theta \\mid y)\\]\nwhat if we can’t sample from the \\(\\pi(\\theta \\mid y)\\) but can sample from some distribution \\(q()\\) \\[\\textsf{E}[h(\\theta) \\mid y] =  \\int_\\Theta h(\\theta) \\frac{\\pi(\\theta \\mid y)}{q(\\theta)} q(\\theta)\\, d\\theta \\approx \\frac{1}{T}\\sum_{t=1}^{T} h(\\theta^{(t)}) \\frac{\\pi(\\theta^{(t)} \\mid y)} {q(\\theta^{(t)})} \\qquad\\] where \\(\\theta^{(t)} \\sim q(\\theta)\\)\nWithout the \\(m(y)\\) in \\(\\pi(\\theta \\mid y)\\) we just have \\(\\pi(\\theta \\mid y) \\propto \\pi(\\theta) \\cal{L}(\\theta)\\)\nuse twice for numerator and denominator"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#important-sampling-estimate",
    "href": "resources/slides/05-hierarchical-models.html#important-sampling-estimate",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Important Sampling Estimate",
    "text": "Important Sampling Estimate\n\nEstimate of \\(m(y)\\) \\[m(y) \\approx \\frac{1}{T} \\sum_{t=1}^{T}  \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})} \\qquad \\theta^{(t)} \\sim q(\\theta)\\]\nRatio estimator of \\(\\textsf{E}[h(\\theta) \\mid y]\\) \\[\\textsf{E}[h(\\theta) \\mid y] \\approx \\frac{\\sum_{t=1}^{T} h(\\theta^{(t)}) \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}}\n{ \\sum_{t=1}^{T}  \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}}\n\\qquad \\theta^{(t)} \\sim q(\\theta)\\]\nWeighted average with importance weights \\(w(\\theta^{(t)}) \\propto \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}\\) \\[\\textsf{E}[h(\\theta) \\mid y] \\approx \\sum_{t=1}^{T} h(\\theta^{(t)}) w(\\theta^{(t)})/\\sum_{t=1}^T w(\\theta^{(t)}) \\qquad \\theta^{(t)} \\sim q(\\theta)\\]"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#issues",
    "href": "resources/slides/05-hierarchical-models.html#issues",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Issues",
    "text": "Issues\n\nif \\(q()\\) puts too little mass in regions with high posterior density, we can have some extreme weights\noptimal case is that \\(q()\\) is as close as possible to the posterior so that all weights are constant\nEstimate may have large variance\nProblems with finding a good \\(q()\\) in high dimensions \\((d &gt; 20)\\) or with skewed distributions"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#markov-chain-monte-carlo-mcmc",
    "href": "resources/slides/05-hierarchical-models.html#markov-chain-monte-carlo-mcmc",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Markov Chain Monte Carlo (MCMC)",
    "text": "Markov Chain Monte Carlo (MCMC)\n\nTypically \\(\\pi(\\theta)\\) and \\(\\cal{L}(\\theta)\\) are easy to evaluate\n\n\n\n\n\n\n\n\nQuestion\n\n\nHow do we draw samples only using evaluations of the prior and likelihood in higher dimensional settings?\n\n\n\n\nconstruct a Markov chain \\(\\theta^{(t)}\\) in such a way the the stationary distribution of the Markov chain is the posterior distribution \\(\\pi(\\theta \\mid y)\\)! \\[\\theta^{(0)} \\overset{k}{\\longrightarrow} \\theta^{(1)} \\overset{k}{\\longrightarrow} \\theta^{(2)} \\cdots\\]\n\\(k_t(\\theta^{(t-1)} ; \\theta^{(t)})\\) transition kernel\ninitial state \\(\\theta^{(0)}\\)\nchoose some nice \\(k_t\\) such that \\(\\theta^{(t)} \\to \\pi(\\theta \\mid y)\\) as \\(t \\to \\infty\\)\nbiased samples initially but get closer to the target\nMetropolis Algorithm (1950’s)"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#stochastic-sampling-intuition",
    "href": "resources/slides/05-hierarchical-models.html#stochastic-sampling-intuition",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Stochastic Sampling Intuition",
    "text": "Stochastic Sampling Intuition\n\nFrom a sampling perspective, we need to have a large sample or group of values, \\(\\theta^{(1)}, \\ldots, \\theta^{(S)}\\) from \\(\\pi(\\theta \\mid y)\\) whose empirical distribution approximates \\(\\pi(\\theta \\mid y)\\).\nfor any two sets \\(A\\) and \\(B\\), we want \\[\\frac{\\dfrac{\\# \\theta^{(s)} \\in A}{S}}{\\dfrac{\\# \\theta^{(s)} \\in B}{S} } = \\dfrac{\\# \\theta^{(s)} \\in A}{\\# \\theta^{(s)} \\in B} \\approx \\dfrac{\\pi(\\theta \\in A \\mid  y)}{\\pi(\\theta \\in B \\mid  y)}\\]\nSuppose we have a working group \\(\\theta^{(1)}, \\ldots, \\theta^{(s)}\\) at iteration \\(s\\), and need to add a new value \\(\\theta^{(s+1)}\\).\nConsider a candidate value \\(\\theta^\\star\\) that is close to \\(\\theta^{(s)}\\)\nShould we set \\(\\theta^{(s+1)} = \\theta^\\star\\) or not?"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#posterior-ratio.",
    "href": "resources/slides/05-hierarchical-models.html#posterior-ratio.",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Posterior Ratio.",
    "text": "Posterior Ratio.\nlook at the ratio \\[\n\\begin{split}\nM & = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)} = \\frac{\\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y)} } {\\dfrac{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}{p(y)}}\\\\\n\\\\\n&  = \\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}\n\\end{split}\n\\]\n\ndoes not depend on the marginal likelihood we don’t know!"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#metropolis-algorithm",
    "href": "resources/slides/05-hierarchical-models.html#metropolis-algorithm",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Metropolis algorithm",
    "text": "Metropolis algorithm\n\nIf \\(M &gt; 1\\)\n\nIntuition: \\(\\theta^{(s)}\\) is already a part of the density we desire and the density at \\(\\theta^\\star\\) is even higher than the density at \\(\\theta^{(s)}\\).\nAction: set \\(\\theta^{(s+1)} = \\theta^\\star\\)\n\nIf \\(M &lt; 1\\),\n\nIntuition: relative frequency of values in our group \\(\\theta^{(1)}, \\ldots, \\theta^{(s)}\\) “equal” to \\(\\theta^\\star\\) should be \\(\\approx M = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)}\\).\nFor every \\(\\theta^{(s)}\\), include only a fraction of an instance of \\(\\theta^\\star\\).\nAction: set \\(\\theta^{(s+1)} = \\theta^\\star\\) with probability \\(M\\) and \\(\\theta^{(s+1)} = \\theta^{(s)}\\) with probability \\(1-M\\)."
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#proposal-distribution",
    "href": "resources/slides/05-hierarchical-models.html#proposal-distribution",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Proposal Distribution",
    "text": "Proposal Distribution\n\nWhere should the proposed value \\(\\theta^\\star\\) come from?\nSample \\(\\theta^\\star\\) close to the current value \\(\\theta^{(s)}\\) using a symmetric proposal distribution \\(\\theta^\\star \\sim q(\\theta^\\star \\mid \\theta^{(s)})\\)\n\\(q()\\) is actually a “family of proposal distributions”, indexed by the specific value of \\(\\theta^{(s)}\\).\nHere, symmetric means that \\(q(\\theta^\\star \\mid \\theta^{(s)}) = q(\\theta^{(s)} \\mid \\theta^\\star)\\).\nCommon choice \\[\\textsf{N}(\\theta^\\star; \\theta^{(s)}, \\delta^2 \\Sigma)\\] with \\(\\Sigma\\) based on the approximate \\(\\textsf{Cov}(\\theta \\mid y)\\) and \\(\\delta = 2.44/\\text{dim}(\\theta)\\) or \\[\\text{Unif}(\\theta^\\star; \\theta^{(s)} - \\delta, \\theta^{(s)} + \\delta)\\]"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#metropolis-algorithm-recap",
    "href": "resources/slides/05-hierarchical-models.html#metropolis-algorithm-recap",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Metropolis Algorithm Recap",
    "text": "Metropolis Algorithm Recap\nThe algorithm proceeds as follows:\n\nGiven \\(\\theta^{(1)}, \\ldots, \\theta^{(s)}\\), generate a candidate value \\(\\theta^\\star \\sim q(\\theta^\\star \\mid \\theta^{(s)})\\).\nCompute the acceptance ratio \\[\\begin{split}\nM & = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)} = \\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}.\n\\end{split}\\]\nSet \\[\\begin{eqnarray*}\n\\theta^{(s+1)} = \\left\\{ \\begin{array}{ll}\n\\theta^\\star & \\quad \\text{with probability} \\quad \\text{min}(M,1) \\\\\n\\theta^{(s)} & \\quad \\text{with probability} \\quad 1 - \\text{min}(M,1) \\\\\n\\end{array} \\right.\n\\end{eqnarray*}\\] equivalent to sampling \\(u \\sim U(0,1)\\) independently and setting \\[\\begin{eqnarray*}\n\\theta^{(s+1)} = \\left\\{ \\begin{array}{ll}\n\\theta^\\star & \\quad \\text{if} \\quad u &lt; M \\\\\n\\theta^{(s)} & \\quad \\text{if} \\quad \\text{otherwise} \\\\\n\\end{array} \\right. .\n\\end{eqnarray*}\n\\]"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#notes",
    "href": "resources/slides/05-hierarchical-models.html#notes",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Notes",
    "text": "Notes\n\nAcceptance probability is \\[M = \\min \\left\\{ 1, \\frac{\\pi(\\theta^\\star) \\cal{L}(\\theta^\\star)}\n                         {\\pi(\\theta^{(s)}) \\cal{L}(\\theta^{(s)})}\\right\\}\\]\nratio of posterior densities where normalizing constant cancels!\nThe Metropolis chain ALWAYS moves to the proposed \\(\\theta^\\star\\) at iteration \\(s+1\\) if \\(\\theta^\\star\\) has higher target density than the current \\(\\theta^{(s)}\\).\nSometimes, it also moves to a \\(\\theta^\\star\\) value with lower density in proportion to the density value itself.\nThis leads to a random, Markov process that naturally explores the space according to the probability defined by \\(\\pi(\\theta \\mid y)\\), and hence generates a sequence that, while dependent, eventually represents draws from \\(\\pi(\\theta \\mid y)\\) (stationary distribution of the Markov Chain).\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/template.html",
    "href": "resources/slides/template.html",
    "title": "STA 702 Fall 2023",
    "section": "",
    "text": "subtitle: “STA 702: Lecture ?” title: “template” author: “Merlise Clyde” institute: “Duke University” format: revealjs: theme: [simple, custom.scss] slide-number: true incremental: true scrollable: false controls: true fragments: true preview-links: auto logo: ../../img/icon.png footer: https://sta702-F23.github.io/website/ chalkboard: boardmarker-width: 1 chalk-width: 2 chalk-effect: 0 embed-resources: false html-math-method: method: mathjax url: “https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js”\neditor: markdown: wrap: 72 execute: echo: false"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#metropolis-hastings-mh",
    "href": "resources/slides/08-gibbs.html#metropolis-hastings-mh",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Metropolis-Hastings (MH)",
    "text": "Metropolis-Hastings (MH)\n\nMetropolis requires that the proposal distribution be symmetric\nHastings (1970) generalizes Metropolis algorithms to allow asymmetric proposals - aka Metropolis-Hastings or MH \\(q(\\theta^* \\mid \\theta^{(s)})\\) does not need to be the same as \\(q(\\theta^{(s)} \\mid \\theta^*)\\)\npropose \\(\\theta^* \\mid \\theta^{(s)} \\sim q(\\theta^* \\mid \\theta^{(s)})\\)\nAcceptance probability \\[\\min \\left\\{ 1, \\frac{\\pi(\\theta^*) \\cal{L}(\\theta^*)/q(\\theta^* \\mid \\theta^{(s)})}\n{\\pi(\\theta^{(s)}) \\cal{L}(\\theta^{(s)})/q( \\theta^{(s)} \\mid \\theta^*)} \\right\\}\\]\nadjustment for asymmetry in acceptance ratio is key to ensuring convergence to stationary distribution!"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#special-cases",
    "href": "resources/slides/08-gibbs.html#special-cases",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Special cases",
    "text": "Special cases\n\nMetropolis\nIndependence chain\nGibbs samplers\nMetropolis-within-Gibbs\ncombinations of the above!"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#independence-chain",
    "href": "resources/slides/08-gibbs.html#independence-chain",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Independence Chain",
    "text": "Independence Chain\n\nsuppose we have a good approximation \\(\\tilde{\\pi}(\\theta \\mid y)\\) to \\(\\pi(\\theta \\mid y)\\)\nDraw \\(\\theta^* \\sim \\tilde{\\pi}(\\theta \\mid y)\\) without conditioning on \\(\\theta^{(s)}\\)\nacceptance probability \\[\\min \\left\\{ 1, \\frac{\\pi(\\theta^*) \\cal{L}(\\theta^*)/\\tilde{\\pi}(\\theta^* \\mid \\theta^{(s)})}\n{\\pi(\\theta^{(s)}) \\cal{L}(\\theta^{(s)})/\\tilde{\\pi}( \\theta^{(s)} \\mid \\theta^*)} \\right\\}\\]\nwhat happens if the approximation is really accurate?\nprobability of acceptance is \\(\\approx 1\\)\nImportant caveat for convergence: tails of the proposalr should be at least as heavy as the tails of the posterior (Tweedie 1994)\nReplace Gaussian by a Student-t with low degrees of freedom\ntransformations of \\(\\theta\\) to imporove approximation"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#blocked-metropolis-hastings",
    "href": "resources/slides/08-gibbs.html#blocked-metropolis-hastings",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Blocked Metropolis-Hastings",
    "text": "Blocked Metropolis-Hastings\nSo far all algorithms update all of the parameters simultaneously\n\nconvenient to break problems in to \\(K\\) blocks and update them separately\n\\(\\theta = (\\theta_{[1]}, \\ldots, \\theta_{[K]}) = (\\theta_1, \\ldots, \\theta_p)\\)\nAt iteration \\(s\\), for \\(k = 1, \\ldots, K\\) Cycle thru blocks: (fixed order or random order)\n\npropose \\(\\theta^*_{[k]} \\sim q_k(\\theta_{[k]} \\mid \\theta_{[&lt;k]}^{(s)}, \\theta_{[&gt;k]}^{(s-1)})\\)\nset \\(\\theta_{[k]}^{(s)} = \\theta^*_{[k]}\\) with probability \\[\\min \\left\\{ 1, \\frac{\n\\pi(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^*,\n  \\theta_{[&gt;k]}^{(s-1)})\n\\cal{L}(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^*,\n     \\theta_{[&gt;k]}^{(s-1)})/\nq_k(\\theta_{[k]}^* \\mid \\theta_{[&lt;k]}^{(s)},    \n\\theta_{[&gt;k]}^{(s-1)})}\n{\\pi(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^{(s-1)},\n  \\theta_{[&gt;k]}^{(s-1)})\n\\cal{L}(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^{(s-1)},\n     \\theta_{[&gt;k]}^{(s-1)})/\nq_k(\\theta_{[k]}^{(s-1)} \\mid \\theta_{[&lt;k]}^{(s)},    \n\\theta_{[&gt;k]}^{(s-1)})} \\right\\}\\]"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#gibbs-sampler",
    "href": "resources/slides/08-gibbs.html#gibbs-sampler",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Gibbs Sampler",
    "text": "Gibbs Sampler\n\nThe Gibbs Sampler is special case of Blocked MH\nproposal distribution \\(q_k\\) for the \\(k\\)th block is the full conditional distribution for \\(\\theta_{[k]}\\) \\[\\begin{split}\n\\pi(\\theta_{[k]} \\mid \\theta_{[-k]}, y) & = \\frac{\\pi(\\theta_{[k]} , \\theta_{[-k]} \\mid y)}{ \\pi(\\theta_{[-k]} \\mid y))} \\propto \\pi(\\theta_{[k]} , \\theta_{[-k]} \\mid y)\\\\\n\\   & \\propto \\cal{L}(\\theta_{[k]} , \\theta_{[-k]})\\pi(\\theta_{[k]} , \\theta_{[-k]})\n\\end{split}\\]\nAcceptance probability \\[\\min \\left\\{ 1, \\frac{\n\\pi(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^*,\n      \\theta_{[&gt;k]}^{(s-1)})\n\\cal{L}(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^*,\n         \\theta_{[&gt;k]}^{(s-1)})/\nq_k(\\theta_{[k]}^* \\mid \\theta_{[&lt;k]}^{(s)},    \n     \\theta_{[&gt;k]}^{(s-1)})}\n{\\pi(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^{(s-1)},\n      \\theta_{[&gt;k]}^{(s-1)})\n\\cal{L}(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^{(s-1)},\n         \\theta_{[&gt;k]}^{(s-1)})/\nq_k(\\theta_{[k]}^{(s-1)} \\mid \\theta_{[&lt;k]}^{(s)},    \n     \\theta_{[&gt;k]}^{(s-1)})} \\right\\}\\]\nNote normalizing constant in the proposal ratio cancels out and terms simplify so that acceptance probability is always 1!\neven though joint distribution is messy, full conditionals may be (conditionally) conjugate and easy to sample from!"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#univariate-normal-example",
    "href": "resources/slides/08-gibbs.html#univariate-normal-example",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Univariate Normal Example",
    "text": "Univariate Normal Example\nModel \\[\\begin{align*}\nY_i \\mid \\mu, \\sigma^2 & \\overset{iid}{\\sim} \\textsf{N}(\\mu, 1/\\phi) \\\\\n\\mu & \\sim \\textsf{N}(\\mu_0, 1/\\tau_0) \\\\\n\\phi & \\sim  \\textsf{Gamma}(a/2, b/2)\n\\end{align*}\\]\n\nJoint prior is a product of independent Normal-Gamma\nIs \\(\\pi(\\mu, \\phi \\mid y_1, \\ldots, y_n)\\) also a Normal-Gamma family?"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#full-conditional-for-the-mean",
    "href": "resources/slides/08-gibbs.html#full-conditional-for-the-mean",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Full Conditional for the Mean",
    "text": "Full Conditional for the Mean\nThe full conditional distributions \\(\\mu \\mid \\phi, y_1, \\ldots, y_n\\) \\[\\begin{align*}\n\\mu & \\mid \\phi, y_1, \\ldots, y_n \\sim \\textsf{N}(\\hat{\\mu}, 1/\\tau_n) \\\\\n\\hat{\\mu} & = \\frac{\\tau_0 \\mu_0  + n \\phi \\bar{y}}{\\tau_0 + n \\phi} \\\\\n\\tau_n & = \\tau_0 + n \\phi\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#full-conditional-for-the-precision",
    "href": "resources/slides/08-gibbs.html#full-conditional-for-the-precision",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Full Conditional for the Precision",
    "text": "Full Conditional for the Precision\n\nFull conditional for \\(\\phi\\) \\[\\begin{align*}\n\\phi  \\mid \\mu, y_1, \\ldots, y_n & \\sim \\textsf{Gamma}( a_n/2, b_n/2) \\\\\na_n & = a + n \\\\\nb_n & = b + \\sum_i (y_i - \\mu)^2\n\\end{align*}\\]\n\n\n\\[\\textsf{E}[\\phi \\mid \\mu, y_1, \\ldots, y_n] = \\frac{(a + n)/2}{(b + \\sum_i (y_i - \\mu)^2 )/2}\\]\n\nWhat happens with a non-informative prior i.e \\(a = b = \\epsilon\\) as \\(\\epsilon \\to 0\\)?\n\n\n\n\n\n\n\n\n\nProper full conditionals with improper priors do not ensure proper joint posterior!"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#normal-linear-regression-example",
    "href": "resources/slides/08-gibbs.html#normal-linear-regression-example",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Normal Linear Regression Example",
    "text": "Normal Linear Regression Example\n\nModel \\[\\begin{align*}\nY_i \\mid \\beta, \\phi & \\overset{iid}{\\sim} \\textsf{N}(x_i^T\\beta, 1/\\phi) \\\\\nY \\mid \\beta, \\phi & \\sim \\textsf{N}(X \\beta, \\phi^{-1} I_n) \\\\\n\\beta & \\sim \\textsf{N}(b_0, \\Phi_0^{-1}) \\\\\n\\phi & \\sim \\textsf{Gamma}(v_0/2, s_0/2)\n\\end{align*}\\]\n\\(x_i\\) is a \\(p \\times 1\\) vector of predictors and \\(X\\) is \\(n \\times p\\) matrix\n\\(\\beta\\) is a \\(p \\times 1\\) vector of coefficients\n\\(\\Phi_0\\) is a \\(p \\times p\\) prior precision matrix\nMultivariate Normal density for \\(\\beta\\) \\[\\pi(\\beta \\mid b_0, \\Phi_0) = \\frac{|\\Phi_0|^{1/2}}{(2 \\pi)^{p/2}}\\exp\\left\\{- \\frac{1}{2}(\\beta - b_0)^T \\Phi_0 (\\beta - b_0)  \\right\\}\\] Note: stopped here 9/26/23 ## Full Conditional for \\(\\beta\\) {.smaller}\n\n\\[\\begin{align*}\n\\beta & \\mid \\phi, y_1, \\ldots, y_n \\sim \\textsf{N}(b_n, \\Phi_n^{-1}) \\\\\nb_n & =  (\\Phi_0 + \\phi X^TX)^{-1}(\\Phi_0 b_0  +  \\phi X^TX \\hat{\\beta})\\\\\n\\Phi_n & = \\Phi_0 + \\phi X^TX\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#derivation-continued",
    "href": "resources/slides/08-gibbs.html#derivation-continued",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Derivation continued",
    "text": "Derivation continued"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#full-conditional-for-phi",
    "href": "resources/slides/08-gibbs.html#full-conditional-for-phi",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Full Conditional for \\(\\phi\\)",
    "text": "Full Conditional for \\(\\phi\\)\n\\[\\phi \\mid \\beta, y_1, \\ldots, y_n \\sim \\textsf{Gamma}\\left(\\frac{v_0 + n}{2}, \\frac{s_0 + \\sum_i(y_i - x^T_i \\beta)^2}{2}\\right)\\]"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#choice-of-prior-precision",
    "href": "resources/slides/08-gibbs.html#choice-of-prior-precision",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Choice of Prior Precision",
    "text": "Choice of Prior Precision\n\nNon-Informative \\(\\Phi_0 \\to 0\\)\nFormal Posterior given \\(\\phi\\) \\[\\beta \\mid \\phi, y_1, \\ldots, y_n \\sim \\textsf{N}(\\hat{\\beta}, \\phi^{-1} (X^TX)^{-1})\\]\nneeds \\(X^TX\\) to be full rank for distribution to be unique"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#invariance-and-choice-of-meanprecision",
    "href": "resources/slides/08-gibbs.html#invariance-and-choice-of-meanprecision",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Invariance and Choice of Mean/Precision",
    "text": "Invariance and Choice of Mean/Precision\n\nthe model in vector form \\(Y \\mid \\beta, \\phi \\sim \\textsf{N}_n (X\\beta, \\phi^{-1} I_n)\\)\nWhat if we transform the mean \\(X\\beta = X H H^{-1} \\beta\\) with new \\(X\\) matrix \\(\\tilde{X} = X H\\) where \\(H\\) is \\(p \\times p\\) and invertible and coefficients \\(\\tilde{\\beta} = H^{-1} \\beta\\).\nobtain the posterior for \\(\\tilde{\\beta}\\) using \\(Y\\) and \\(\\tilde{X}\\)\n\\[ Y \\mid  \\tilde{\\beta}, \\phi \\sim \\textsf{N}_n (\\tilde{X}\\tilde{\\beta}, \\phi^{-1} I_n)\\]\nsince \\(\\tilde{X} \\tilde{\\beta} = X H \\tilde{\\beta} = X \\beta\\) invariance suggests that the posterior for \\(\\beta\\) and \\(H \\tilde{\\beta}\\) should be the same\nplus the posterior of \\(H^{-1} \\beta\\) and \\(\\tilde{\\beta}\\) should be the same\n\n\n\n\n\n\n\n\nExercise for the Energetic Student\n\n\nWith some linear algebra, show that this is true for a normal prior if \\(b_0 = 0\\) and \\(\\Phi_0\\) is \\(k X^TX\\) for some \\(k\\)"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#zellners-g-prior",
    "href": "resources/slides/08-gibbs.html#zellners-g-prior",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Zellner’s g-prior",
    "text": "Zellner’s g-prior\n\nPopular choice is to take \\(k = \\phi/g\\) which is a special case of Zellner’s g-prior \\[\\beta \\mid \\phi, g \\sim \\textsf{N}\\left(0, \\frac{g}{\\phi} (X^TX)^{-1}\\right)\\]\nFull conditional \\[\\beta \\mid \\phi, g \\sim \\textsf{N}\\left(\\frac{g}{1 + g} \\hat{\\beta}, \\frac{1}{\\phi} \\frac{g}{1 + g} (X^TX)^{-1}\\right)\\]\none parameter \\(g\\) controls shrinkage\nif \\(\\phi \\sim \\textsf{Gamma}(v_0/2, s_0/2)\\) then posterior is \\[\\phi \\mid y_1, \\ldots, y_n \\sim \\textsf{Gamma}(v_n/2, s_n/2)\\]\nConjugate so we could skip Gibbs sampling and sample directly from gamma and then conditional normal!"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#ridge-regression",
    "href": "resources/slides/08-gibbs.html#ridge-regression",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Ridge Regression",
    "text": "Ridge Regression\n\nIf \\(X^TX\\) is nearly singular, certain elements of \\(\\beta\\) or (linear combinations of \\(\\beta\\)) may have huge variances under the \\(g\\)-prior (or flat prior) as the MLEs are highly unstable!\nRidge regression protects against the explosion of variances and ill-conditioning with the conjugate priors: \\[\\beta \\mid \\phi \\sim \\textsf{N}(0, \\frac{1}{\\phi \\lambda} I_p)\\]\nPosterior for \\(\\beta\\) (conjugate case) \\[\\beta \\mid \\phi, \\lambda, y_1, \\ldots, y_n \\sim\n\\textsf{N}\\left((\\lambda I_p + X^TX)^{-1} X^T Y,  \\frac{1}{\\phi}(\\lambda I_p + X^TX)^{-1}\n\\right)\\]"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#bayes-regression",
    "href": "resources/slides/08-gibbs.html#bayes-regression",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Bayes Regression",
    "text": "Bayes Regression\n\nPosterior mean (or mode) given \\(\\lambda\\) is biased, but can show that there always is a value of \\(\\lambda\\) where the frequentist’s expected squared error loss is smaller for the Ridge estimator than MLE!\nrelated to penalized maximum likelihood estimation\nChoice of \\(\\lambda\\)\nBayes Regression and choice of \\(\\Phi_0\\) in general is a very important problem and provides the foundation for many variations on shrinkage estimators, variable selection, hierarchical models, nonparameteric regression and more!\nBe sure that you can derive the full conditional posteriors for \\(\\beta\\) and \\(\\phi\\) as well as the joint posterior in the conjugate case!"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#comments",
    "href": "resources/slides/08-gibbs.html#comments",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Comments",
    "text": "Comments\n\nWhy don’t we treat each individual \\(\\beta_j\\) as a separate block?\nGibbs always accepts, but can mix slowly if parameters in different blocks are highly correlated!\nUse block sizes in Gibbs that are as big as possible to improve mixing (proven faster convergence)\nCollapse the sampler by integrating out as many parameters as possible (as long as resulting sampler has good mixing)\ncan use Gibbs steps and (adaptive) Metropolis Hastings steps together\nIntroduce latent variables (data augmentation) to allow Gibbs steps (Next class)\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#ingredients",
    "href": "resources/slides/01-basics-of-bayes.html#ingredients",
    "title": "Basics of Bayesian Statistics",
    "section": "Ingredients",
    "text": "Ingredients\n\nPrior Distribution \\(\\pi(\\theta)\\) for unknown \\(\\theta\\)\nLikelihood Function \\({\\cal{L}}(\\theta \\mid y ) \\propto p(y \\mid \\theta)\\) (sampling model)\nPosterior Distribution \\[\\pi(\\theta | y) = \\frac{\\pi(\\theta)p(y \\mid \\theta)}{\\int_{\\Theta}\\pi({\\theta})p(y\\mid {\\theta}) \\textrm{d}{\\theta}} = \\frac{\\pi(\\theta)p(y\\mid\\theta)}{p(y)}\\]\nLoss Function Depends on what you want to report; estimate of \\(\\theta\\), predict future \\(Y_{n+1}\\), etc"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#posterior-depends-on-likelihoods",
    "href": "resources/slides/01-basics-of-bayes.html#posterior-depends-on-likelihoods",
    "title": "Basics of Bayesian Statistics",
    "section": "Posterior Depends on Likelihoods",
    "text": "Posterior Depends on Likelihoods\n\nLikelihood function is defined up to a consant \\[c \\, {\\cal{L}}(\\theta \\mid Y) =  p(y \\mid \\theta) \\]\nBayes’ Rule \\[\\pi(\\theta | y) = \\frac{\\pi(\\theta)p(y \\mid \\theta)}{\\int_{\\Theta}\\pi({\\theta})p(y\\mid {\\theta}) \\textrm{d}{\\theta}} =\n\\frac{\\pi(\\theta)c {\\cal{L}}(\\theta \\mid y)}{\\int_{\\Theta}\\pi({\\theta})c{\\cal{L}}(\\theta \\mid y) \\textrm{d}{\\theta}}  =\n\\frac{\\pi(\\theta){\\cal{L}}(\\theta \\mid y)}{m(y)}\\]\n\\(m(y)\\) is proportional to the marginal distribution of data\n\\[m(y) = \\int_{\\Theta}\\pi({\\theta}){\\cal{L}}(\\theta \\mid y) \\textrm{d}{\\theta}\\]\nmarginal likelihood of this model or “evidence”\n\n\nNote: the marginal likelihood and maximized likelihood are very different!"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#binomial-example",
    "href": "resources/slides/01-basics-of-bayes.html#binomial-example",
    "title": "Basics of Bayesian Statistics",
    "section": "Binomial Example",
    "text": "Binomial Example\n\nBinomial sampling \\(Y \\mid n, \\theta \\sim \\textsf{Binomial}(n, \\theta)\\)\nProbability Mass Function \\[p(y \\mid \\theta) = {n \\choose y} \\theta^y(1-\\theta)^{n-y}\\]\nLikelihood \\(\\cal{L}(\\theta ) = \\theta^y(1-\\theta)^{n-y}\\)\nMLE \\(\\hat{\\theta}\\) of Binomial is \\(\\bar{y} = y/n\\) proportion of successes\nRecall Derivation!"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#marginal-likelihood",
    "href": "resources/slides/01-basics-of-bayes.html#marginal-likelihood",
    "title": "Basics of Bayesian Statistics",
    "section": "Marginal Likelihood",
    "text": "Marginal Likelihood\n\\[m(y) = \\int_\\Theta \\cal{L}(\\theta)  \\pi(\\theta) \\textrm{d}\\theta=  \\int_\\Theta \\theta^y(1-\\theta)^{n-y} \\pi(\\theta) \\textrm{d}\\theta\\]\n“Averaging” of likelihood over prior \\(\\pi(\\theta) = 1\\)"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#binomial-example-1",
    "href": "resources/slides/01-basics-of-bayes.html#binomial-example-1",
    "title": "Basics of Bayesian Statistics",
    "section": "Binomial Example",
    "text": "Binomial Example\n\nPrior \\(\\theta \\sim \\textsf{U}(0,1)\\) or \\(\\pi(\\theta) = 1, \\quad \\textrm{for } \\theta \\in (0,1)\\)\nMarginal \\(m(y) = \\int_0^1 \\theta^y(1-\\theta)^{n-y}\\, 1 \\,\\textrm{d}\\theta\\)\nSpecial function known as the beta function - see Rudin \\[{B}(a, b) =  \\int_0^1 \\theta^{a - 1}(1-\\theta)^{b - 1} \\,\\textrm{d}\\theta \\]\nPosterior Distribution \\[\\pi(\\theta \\mid y ) = \\frac{ \\theta^{(y+1)-1} (1-\\theta)^{(n - y +1) -1}}{B(y + 1,n - y + 1)}\\]\n\n\n\\[\\theta \\mid y \\sim \\textsf{Beta}(y + 1, n - y + 1) \\]"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#beta-prior-distributions",
    "href": "resources/slides/01-basics-of-bayes.html#beta-prior-distributions",
    "title": "Basics of Bayesian Statistics",
    "section": "Beta Prior Distributions",
    "text": "Beta Prior Distributions\n\\(\\textsf{Beta}(a, b)\\) is a probability density function (pdf) on (0,1),\n\n\\[\\pi(\\theta) = \\frac{1}{B(a,b)} \\theta^{a-1} (1-\\theta)^{b -1}\\]\n\nUse the kernel trick to find the posterior \\[\\pi(\\theta \\mid y) \\propto \\cal{L}(\\theta \\mid y) \\pi(\\theta)\\]\nWrite down likelihood and prior (ignore constants wrt \\(\\theta\\))\nRecognize kernel of density\nFigure out normalizing constant/distribution"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#try-it",
    "href": "resources/slides/01-basics-of-bayes.html#try-it",
    "title": "Basics of Bayesian Statistics",
    "section": "Try it!",
    "text": "Try it!"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#prior-to-posterior-updating-binomial-data",
    "href": "resources/slides/01-basics-of-bayes.html#prior-to-posterior-updating-binomial-data",
    "title": "Basics of Bayesian Statistics",
    "section": "Prior to Posterior Updating Binomial Data",
    "text": "Prior to Posterior Updating Binomial Data\n\nPrior \\(\\textsf{Beta}(a, b)\\)\nPosterior \\(\\textsf{Beta}(a + y, b + n - y)\\)\nConjugate prior & posterior distribution are in the same family of distributions, (Beta)\nSimple updating of information from the prior to posterior\n\n\\(a + b\\) “prior sample size” (number of trials in a hypothetical experiment)\n\\(a\\) “number of successes”\n\\(b\\) “number of failures”\n\nprior elicitation (process of choosing the prior hyperparamters) based on historic or imaginary data"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#summaries-properties",
    "href": "resources/slides/01-basics-of-bayes.html#summaries-properties",
    "title": "Basics of Bayesian Statistics",
    "section": "Summaries & Properties",
    "text": "Summaries & Properties\n\nFor \\(\\theta \\sim \\textsf{Beta}(a,b)\\) let \\(a + b = n_0\\) “prior sample size”\nPrior mean \\[\\textsf{E}[\\theta] = \\frac{a}{a+b}  \\equiv \\theta_0 \\]\nPosterior mean \\[\\textsf{E}[\\theta \\mid y ] = \\frac{a + y }{a+b +n}  \\equiv \\tilde{\\theta} \\]\nRewrite with MLE \\(\\hat{\\theta} = \\bar{y} = \\frac{y}{n}\\) and prior mean \\[\\textsf{E}[\\theta \\mid y ] = \\frac{a + y }{a+b +n}  \n= \\frac{n_0}{n_0 + n} \\theta_0  + \\frac{n}{n_0 + n} \\hat{\\theta}\\]\nWeighted average of prior mean and MLE where weight for \\(\\theta_0 \\propto n_0\\) and weight for \\(\\hat{\\theta} \\propto n\\)"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#properties",
    "href": "resources/slides/01-basics-of-bayes.html#properties",
    "title": "Basics of Bayesian Statistics",
    "section": "Properties",
    "text": "Properties\n\nPosterior mean \\[\\tilde{\\theta} = \\frac{n_0}{n_0 + n} \\theta_0  + \\frac{n}{n_0 + n} \\hat{\\theta}\\]\nin finite samples we get shrinkage: posterior mean pulls the MLE toward the prior mean; amount depends on prior sample size \\(n_0\\) and data sample size \\(n\\)\nregularization effect to reduce Mean Squared Error for estimation with small sample sizes and noisy data\n\nintroduces some bias (in the frequentist sense) due to prior mean \\(\\theta_0\\)\nreduces variance (bias-variance trade-off)\n\nhelpful in the Binomial case, when sample size is small or \\(\\theta_{\\text{true}} \\approx 0\\) (rare events) and \\(\\hat{\\theta} = 0\\) (inbalanced categorical data)\nas we get more information from the data \\(n \\to \\infty\\) we have \\(\\tilde{\\theta} \\to \\hat{\\theta}\\) and consistency ! As \\(n \\to \\infty, \\textsf{E}[\\tilde{\\theta}] \\to \\theta_{\\text{true}}\\)"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#some-possible-prior-densities",
    "href": "resources/slides/01-basics-of-bayes.html#some-possible-prior-densities",
    "title": "Basics of Bayesian Statistics",
    "section": "Some possible prior densities",
    "text": "Some possible prior densities"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#prior-choice",
    "href": "resources/slides/01-basics-of-bayes.html#prior-choice",
    "title": "Basics of Bayesian Statistics",
    "section": "Prior Choice",
    "text": "Prior Choice\n\nIs the uniform prior \\(\\textsf{Beta}(1,1)\\) non-informative?\n\nNo- if \\(y = 0\\) (or \\(n\\)) sparse/rare events saying that we have a prior “historical” sample with 1 success and 1 failure ( \\(a = 1\\) and \\(b = 1\\) ) can be very informative\n\nWhat about a uniform prior on the log odds? \\(\\eta \\equiv \\log\\left( \\frac{\\theta} {1 - \\theta} \\right)\\)? \\[\\pi(\\eta) \\propto 1, \\qquad \\eta \\in \\mathbb{R}\\]\n\nIs this a proper prior distribution?\nwhat would be induced measure for \\(\\theta\\)?\nFind Jacobian (exercise!) \\[\\pi(\\theta) \\propto \\theta^{-1} (1 - \\theta)^{-1}, \\qquad \\theta \\in (0,1)\\]\nlimiting case of a Beta \\(a \\to 0\\) and \\(b \\to 0\\) (Haldane’s prior)"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#formal-bayes",
    "href": "resources/slides/01-basics-of-bayes.html#formal-bayes",
    "title": "Basics of Bayesian Statistics",
    "section": "Formal Bayes",
    "text": "Formal Bayes\n\nuse of improper prior and turn the Bayesian crank\ncalculate \\(m(y)\\) and renormalize likelihood times “improper prior” if \\(m(y)\\) is finite\nformal posterior is \\(\\textsf{Beta}(y, n-y)\\) and reasonable only if \\(y \\neq 0\\) or \\(y \\neq n\\) as \\(B(0, -)\\) and \\(B(-, 0)\\) (normalizing constant) are undefined!\nno shrinkage \\(\\textsf{E}[\\theta \\mid y] = \\frac{y}{n} = \\tilde{\\theta} = \\hat{\\theta}\\)"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#invariance",
    "href": "resources/slides/01-basics-of-bayes.html#invariance",
    "title": "Basics of Bayesian Statistics",
    "section": "Invariance",
    "text": "Invariance\n\nJeffreys argues that priors should be invariant to transformations to be non-informative. . . . i.e. if we reparameterize with \\(\\theta = h(\\rho)\\) then the rule should be that \\[\\pi_\\theta(\\theta) = \\left|\\frac{ d \\rho} {d \\theta}\\right| \\pi_\\rho(h^{-1}(\\theta))\\]\nJefferys’ rule is to pick \\(\\pi(\\rho) \\propto (I(\\rho))^{1/2}\\)\nExpected Fisher Information for \\(\\rho\\) \\[ I(\\rho) = - \\textsf{E} \\left[ \\frac {d^2 \\log ({\\cal{L}}(\\rho))} {d^2 \\rho} \\right]\\]\nFor the Binomial example \\(\\pi(\\theta) \\propto \\theta^{-1/2} (1 - \\theta)^{-1/2}\\)\nThus Jefferys’ prior is a \\(\\textsf{Beta}(1/2, 1/2)\\)"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#why",
    "href": "resources/slides/01-basics-of-bayes.html#why",
    "title": "Basics of Bayesian Statistics",
    "section": "Why ?",
    "text": "Why ?\nChain Rule!\n\nFind Jefferys’ prior for \\(\\theta\\) where \\(Y \\sim \\textsf{Ber}(\\theta)\\)\nFind information matrix \\(I(\\rho)\\) for \\(\\rho = \\rho(\\theta)\\) from \\(I(\\theta)\\)\nShow that the prior satisfies the invariance property!\nFind Jeffreys’ prior for \\(\\rho = \\log(\\frac{\\theta}{1 - \\theta})\\)\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#example-from-last-class",
    "href": "resources/slides/07-adaptive-metropolis.html#example-from-last-class",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Example from Last Class",
    "text": "Example from Last Class\n\nMarginal Likelihood \\[\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu) \\propto (\\sigma^2 + \\sigma^2_\\mu)^{-n/2} \\exp \\left\\{ - \\frac{1}{2} \\frac{\\sum_{i=1}^n\\left(y_i - \\mu \\right)^2}{\\sigma^2 + \\sigma^2_\\mu }\\right\\}\\]\nPriors with \\(\\sigma^2 = 1\\): \\(p(\\mu) \\propto 1\\) and \\(\\sigma_\\mu \\sim \\textsf{Cauchy}^+(0,1)\\) independent of \\(\\mu\\)\nSymmetric proposal for \\(\\mu\\) and \\(\\sigma_\\tau\\)\nIndependent normals centered at current values of \\(\\mu\\) and \\(\\sigma_\\mu\\) with covariance \\(\\frac{2.38^2}{d} \\textsf{Cov}(\\theta)\\) where \\(d = 2\\) (the dimension of \\(\\theta\\) )\n\\(\\delta^2 = 2.38^2/d\\) optimal for multivariate normal target Roberts, Gelman, and Gilks (1997) with acceptance rate ranging from 40% to 23.4% (as \\(d \\to \\infty\\))"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#convergence-diagnostics",
    "href": "resources/slides/07-adaptive-metropolis.html#convergence-diagnostics",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Convergence diagnostics",
    "text": "Convergence diagnostics\n\nDiagnostics available to help decide on number of burn-in & collected samples.\nNote: no definitive tests of convergence but you should do as many diagnostics as you can, on all parameters in your model.\nWith “experience”, visual inspection of trace plots perhaps most useful approach.\nThere are a number of useful automated tests in R.\nCAUTION: diagnostics cannot guarantee that a chain has converged, but they can indicate it has not converged."
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#diagnostics-in-r",
    "href": "resources/slides/07-adaptive-metropolis.html#diagnostics-in-r",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Diagnostics in R",
    "text": "Diagnostics in R\n\nThe most popular package for MCMC diagnostics in R is coda.\ncoda uses a special MCMC format so you must always convert your posterior matrix into an MCMC object.\nFor the example, we have the following in R.\n\n\n\n#library(coda)\ntheta.mcmc &lt;- mcmc(theta,start=1) #no burn-in (simple problem!)"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#diagnostics-in-r-1",
    "href": "resources/slides/07-adaptive-metropolis.html#diagnostics-in-r-1",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Diagnostics in R",
    "text": "Diagnostics in R\n\nsummary(theta.mcmc)\n\n\nIterations = 1:10000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n             Mean     SD Naive SE Time-series SE\nmu       -0.07977 0.1046 0.001046       0.002839\nsigma_mu  0.17550 0.1273 0.001273       0.004397\n\n2. Quantiles for each variable:\n\n              2.5%     25%      50%      75%  97.5%\nmu       -0.283420 -0.1508 -0.08193 -0.00848 0.1337\nsigma_mu  0.007995  0.0758  0.15024  0.25228 0.4693\n\n\n\nThe naive SE is the standard error of the mean, which captures simulation error of the mean rather than the posterior uncertainty.\nThe time-series SE adjusts the naive SE for autocorrelation."
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#effective-sample-size",
    "href": "resources/slides/07-adaptive-metropolis.html#effective-sample-size",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Effective Sample Size",
    "text": "Effective Sample Size\n\nThe effective sample size translates the number of MCMC samples \\(S\\) into an equivalent number of independent samples.\nIt is defined as \\[\\textrm{ESS} = \\dfrac{S}{1 + 2 \\sum_k \\rho_k},\\]\n\\(S\\) is the sample size and \\(\\rho_k\\) is the lag \\(k\\) autocorrelation.\nFor our data, we have\n\n\n\neffectiveSize(theta.mcmc)\n\n       mu  sigma_mu \n1356.6495  838.2613 \n\n\n\nSo our 10,000 samples are equivalent to 1356.6 independent samples for \\(\\mu\\) and 838.3 independent samples for \\(\\sigma_\\mu\\)."
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#trace-plot-for-mean",
    "href": "resources/slides/07-adaptive-metropolis.html#trace-plot-for-mean",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Trace plot for mean",
    "text": "Trace plot for mean"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#trace-plot-for-sigma_mu",
    "href": "resources/slides/07-adaptive-metropolis.html#trace-plot-for-sigma_mu",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Trace plot for \\(\\sigma_\\mu\\)",
    "text": "Trace plot for \\(\\sigma_\\mu\\)\n\nOK (be careful of scaling in plots!)"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#autocorrelation",
    "href": "resources/slides/07-adaptive-metropolis.html#autocorrelation",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Autocorrelation",
    "text": "Autocorrelation\n\nAnother way to evaluate convergence is to look at the autocorrelation between draws of our Markov chain.\nThe lag \\(k\\) autocorrelation, \\(\\rho_k\\), is the correlation between each draw and its \\(k\\)th lag, defined as \\[\\rho_k = \\dfrac{\\sum_{s=1}^{S-k}(\\theta_s - \\bar{\\theta})(\\theta_{s+k} - \\bar{\\theta})}{\\sum_{s=1}^{S-k}(\\theta_s - \\bar{\\theta})^2}\\]\nWe expect the autocorrelation to decrease as \\(k\\) increases.\nIf autocorrelation remains high as \\(k\\) increases, we have slow mixing due to the inability of the sampler to move around the space well."
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#autocorrelation-for-mean",
    "href": "resources/slides/07-adaptive-metropolis.html#autocorrelation-for-mean",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Autocorrelation for mean",
    "text": "Autocorrelation for mean\n\nSo-So"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#autocorrelation-for-variance",
    "href": "resources/slides/07-adaptive-metropolis.html#autocorrelation-for-variance",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Autocorrelation for variance",
    "text": "Autocorrelation for variance\n\nworse"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#gelman-rubin",
    "href": "resources/slides/07-adaptive-metropolis.html#gelman-rubin",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Gelman-Rubin",
    "text": "Gelman-Rubin\nGelman & Rubin suggested a diagnostic \\(R\\) based on taking separate chains with dispersed initial values to test convergence"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#gelman-rubin-diagnostic",
    "href": "resources/slides/07-adaptive-metropolis.html#gelman-rubin-diagnostic",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Gelman-Rubin Diagnostic",
    "text": "Gelman-Rubin Diagnostic\n\nRun m &gt; 2 chains of length 2S from overdispersed starting values.\nDiscard the first S draws in each chain.\nCalculate the pooled within-chain variance \\(W\\) and between-chain variance \\(B\\). \\[R = \\frac{\\frac{S-1}{S} W + \\frac{1}{S} B }{W}\\]\nnumerator and denominator are both unbiased estimates of the variance if the two chains have converged\n\notherwise \\(W\\) is an underestimate (hasn’t explored enough)\nnumerator will overestimate as \\(B\\) is too large (overdispersed starting points)\n\nAs \\(S \\to \\infty\\) and \\(B \\to 0\\), \\(R \\to 1\\)\nversion in R is slightly different"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#gelman-rubin-diagnostic-1",
    "href": "resources/slides/07-adaptive-metropolis.html#gelman-rubin-diagnostic-1",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Gelman-Rubin Diagnostic",
    "text": "Gelman-Rubin Diagnostic\n\ntheta.mcmc = mcmc.list(mcmc(theta1, start=5000), mcmc(theta2, start=5000))\ngelman.diag(theta.mcmc)\n\nPotential scale reduction factors:\n\n         Point est. Upper C.I.\nmu                1          1\nsigma_mu          1          1\n\nMultivariate psrf\n\n1\n\n\n\nValues of \\(R &gt; 1.1\\) suggest lack of convergence\nLooks OK\nSee also gelman.plot"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#geweke-statistic",
    "href": "resources/slides/07-adaptive-metropolis.html#geweke-statistic",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Geweke statistic",
    "text": "Geweke statistic\n\nGeweke proposed taking two non-overlapping parts of a single Markov chain (usually the first 10% and the last 50%) and comparing the mean of both parts, using a difference of means test\nThe null hypothesis would be that the two parts of the chain are from the same distribution.\nThe test statistic is a z-score with standard errors adjusted for autocorrelation, and if the p-value is significant for a variable, you need more draws.\nOutput in R is the Z score"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#geweke-diagnostic",
    "href": "resources/slides/07-adaptive-metropolis.html#geweke-diagnostic",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Geweke Diagnostic",
    "text": "Geweke Diagnostic\n\ngeweke.diag(theta.mcmc)\n\n[[1]]\n\nFraction in 1st window = 0.1\nFraction in 2nd window = 0.5 \n\n      mu sigma_mu \n -0.7779   0.7491 \n\n\n[[2]]\n\nFraction in 1st window = 0.1\nFraction in 2nd window = 0.5 \n\n      mu sigma_mu \n  0.4454   0.6377 \n\n\n\nThe output is the z-score itself (not the p-value)."
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#practical-advice-on-diagnostics",
    "href": "resources/slides/07-adaptive-metropolis.html#practical-advice-on-diagnostics",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Practical advice on diagnostics",
    "text": "Practical advice on diagnostics\n\nThere are more tests we can use: Raftery and Lewis diagnostic, Heidelberger and Welch, etc.\nThe Gelman-Rubin approach is quite appealing in using multiple chains\nGeweke (and Heidelberger and Welch) sometimes reject even when the trace plots look good.\nOverly sensitive to minor departures from stationarity that do not impact inferences.\nMost common method of assessing convergence is visual examination of trace plots."
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#improving-results",
    "href": "resources/slides/07-adaptive-metropolis.html#improving-results",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Improving Results",
    "text": "Improving Results\n\nmore iterations and multiple chains\nthinning to reduce correlations and increase ESS\nchange the proposal distribution \\(q\\)\nadaptive Metropolis to tune \\(q\\)"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#proposal-distribution",
    "href": "resources/slides/07-adaptive-metropolis.html#proposal-distribution",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Proposal Distribution",
    "text": "Proposal Distribution\n\nCommon choice \\[\\textsf{N}(\\theta^\\star; \\theta^{(s)}, \\delta^2 \\Sigma)\\]\nrough estimate of \\(\\Sigma\\) based on the asymptotic Gaussian approximation \\(\\textsf{Cov}(\\theta \\mid y)\\) and \\(\\delta = 2.38/\\sqrt{\\text{dim}(\\theta)}\\)\nfind the MAP estimate (posterior mode) \\(\\hat{\\theta}\\)\ntake \\[\\Sigma =  \\left[-\n  \\frac{\\partial^2 \\log(\\cal{L}(\\theta)) + \\log(\\pi(\\theta))}\n   {\\partial \\theta \\partial \\theta^T} \\right]^{-1}_{\\theta = \\hat{\\theta}}\\]\nignore prior and use inverse of Fisher Information (covariance of MLE)"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#learn-covariance-in-proposal",
    "href": "resources/slides/07-adaptive-metropolis.html#learn-covariance-in-proposal",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Learn Covariance in Proposal?",
    "text": "Learn Covariance in Proposal?\n\nCan we learn the proposal distribution?\nad hoc?\n\nrun an initial MCMC for an initial tuning phase (e.g. 1000 samples) with a fixed \\(\\delta\\) and estimate \\(\\Sigma(\\theta)\\) from samples.\n\nrun more to tweak \\(\\delta\\) to get acceptance rate between \\(23\\%-40\\%\\).\nfix the kernel for final run\n\nMCMC doesn’t allow you to use the full history of the chain \\(\\theta^{(1)}, \\ldots, \\theta^{(s)}\\) in constructing the proposal distributions as it violates the Markov assumption\neven with no further “learning”, no guarantee we will converge to posterior!\nmore elegant approach - formal adaptive Metropolis\n\nkeep adapting the entire time!\n\n\n\n\n\n\n\n\n\nad hoc adaptation may mess up convergence !"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#adaptive-mcmc",
    "href": "resources/slides/07-adaptive-metropolis.html#adaptive-mcmc",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Adaptive MCMC",
    "text": "Adaptive MCMC\n\nrun RWM with a Gaussian proposal for a fixed number of iterations for \\(s &lt; s_0\\)\nestimate of covariance at state \\(s\\) \\[\\Sigma^{(s)} = \\frac{1}{s}\\left(\\sum_{i=1}^s \\theta^{(i)} {\\theta^{(i)}}^T -\ns \\bar{\\theta}^{(s)} {\\bar{\\theta}^{(s)}}^T\\right)\\]\nproposal for \\(s &gt; s_0\\) with \\(\\delta = 2.38/\\sqrt{d}\\) \\[\\theta^* \\sim \\textsf{N}(\\theta^{(s)}, \\delta^2 (\\Sigma^{(s)} + \\epsilon I_d))\\]\n\\(\\epsilon &gt; 0\\) insures covariance is positive definite\nif \\(s_0\\) is too large will take longer for adaptation to be seen\nneed conditions for vanishing adaptation e.g. that the proposal depends less and less on recent states in the chain - see Roberts & Rosenthal (2009)for examples and other conditions"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#example-again",
    "href": "resources/slides/07-adaptive-metropolis.html#example-again",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Example again",
    "text": "Example again\n\n\n\n\n\n\n\n\n\nAcceptance rate now around 30-35 % of 10,000 iterations!\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#normal-linear-regression-example",
    "href": "resources/slides/09-data-augmentation.html#normal-linear-regression-example",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Normal Linear Regression Example",
    "text": "Normal Linear Regression Example\n\nModel \\[\\begin{align*}\nY_i \\mid \\beta, \\phi & \\overset{  ind}{\\sim} \\textsf{N}(x_i^T\\beta, 1/\\phi) \\\\\nY \\mid \\beta, \\phi & \\sim \\textsf{N}(X \\beta, \\phi^{-1} I_n) \\\\\n\\beta & \\sim \\textsf{N}(b_0, \\Phi_0^{-1}) \\\\\n\\phi & \\sim \\textsf{Gamma}(v_0/2, s_0/2)\n\\end{align*}\\]\n\\(x_i\\) is a \\(p \\times 1\\) vector of predictors and \\(X\\) is \\(n \\times p\\) matrix\n\\(\\beta\\) is a \\(p \\times 1\\) vector of coefficients\n\\(\\Phi_0\\) is a \\(p \\times p\\) prior precision matrix\nMultivariate Normal density for \\(\\beta\\) \\[\\pi(\\beta \\mid b_0, \\Phi_0) = \\frac{|\\Phi_0|^{1/2}}{(2 \\pi)^{p/2}}\\exp\\left\\{- \\frac{1}{2}(\\beta - b_0)^T \\Phi_0 (\\beta - b_0)  \\right\\}\\]"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#full-conditional-for-beta",
    "href": "resources/slides/09-data-augmentation.html#full-conditional-for-beta",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Full Conditional for \\(\\beta\\)",
    "text": "Full Conditional for \\(\\beta\\)\n\\[\\begin{align*}\n\\beta & \\mid \\phi, y_1, \\ldots, y_n \\sim \\textsf{N}(b_n, \\Phi_n^{-1}) \\\\\nb_n & =  (\\Phi_0 + \\phi X^TX)^{-1}(\\Phi_0 b_0  +  \\phi X^TX \\hat{\\beta})\\\\\n\\Phi_n & = \\Phi_0 + \\phi X^TX\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#derivation-continued",
    "href": "resources/slides/09-data-augmentation.html#derivation-continued",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Derivation continued",
    "text": "Derivation continued"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#full-conditional-for-phi",
    "href": "resources/slides/09-data-augmentation.html#full-conditional-for-phi",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Full Conditional for \\(\\phi\\)",
    "text": "Full Conditional for \\(\\phi\\)\n\\[\\phi \\mid \\beta, y_1, \\ldots, y_n \\sim \\textsf{Gamma}\\left(\\frac{v_0 + n}{2}, \\frac{s_0 + \\sum_i(y_i - x^T_i \\beta)^2}{2}\\right)\\]"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#choice-of-prior-precision",
    "href": "resources/slides/09-data-augmentation.html#choice-of-prior-precision",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Choice of Prior Precision",
    "text": "Choice of Prior Precision\n\nNon-Informative \\(\\Phi_0 \\to 0\\)\nFormal Posterior given \\(\\phi\\) \\[\\beta \\mid \\phi, y_1, \\ldots, y_n \\sim \\textsf{N}(\\hat{\\beta}, \\phi^{-1} (X^TX)^{-1})\\]\nneeds \\(X^TX\\) to be full rank for distribution to be unique!"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#binary-regression",
    "href": "resources/slides/09-data-augmentation.html#binary-regression",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Binary Regression",
    "text": "Binary Regression\n\\[Y_i \\mid \\beta \\sim \\textsf{Ber}(p(x_i^T \\beta))\\] where \\(\\Pr(Y_i = 1 \\mid \\beta) = p(x_i^T \\beta))\\) and linear predictor \\(x_i^T\\beta = \\lambda_i\\)\n\nlink function for binary regression is any 1-1 function \\(g\\) that will map \\((0,1) \\to \\mathbb{R}\\), i.e. \\(g(p(\\lambda)) = \\lambda\\)\nlogistic regression uses the logit link\n\\[\\log\\left(\\frac{p(\\lambda_i)}{1 - p(\\lambda_i) }\\right) = x_i^T \\beta = \\lambda_i\\]\nprobit link \\[p(x_i^T \\beta) = \\Phi(x_i^T \\beta)\\]\n\\(\\Phi()\\) is the Normal cdf"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#likelihood-and-posterior",
    "href": "resources/slides/09-data-augmentation.html#likelihood-and-posterior",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Likelihood and Posterior",
    "text": "Likelihood and Posterior\nLikelihood: \\[\\cal{L}(\\beta) \\propto \\prod_{i = 1}^n \\Phi(x_i^T \\beta)^{y_i} (1 - \\Phi(x^T_i \\beta))^{1 - y_i}\\]\n\nprior \\(\\beta \\sim \\textsf{N}_p(b_0, \\Phi_0)\\)\nposterior \\(\\pi(\\beta) \\propto \\pi(\\beta) \\cal{L}(\\beta)\\)\nHow to approximate the posterior?\n\nasymptotic Normal approximation\nMH with Independence chain or adaptive Metropolis\nstan (Hamiltonian Monte Carlo)\nGibbs ?\n\nseemingly no, but there is a trick!"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#data-augmentation",
    "href": "resources/slides/09-data-augmentation.html#data-augmentation",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Data Augmentation",
    "text": "Data Augmentation\n\nConsider an augmented posterior \\[\\pi(\\beta, Z \\mid y) \\propto \\pi(\\beta) \\pi(Z \\mid \\beta) \\pi(y \\mid Z, \\theta)\\]\nIF we choose \\(\\pi(Z \\mid \\beta)\\) and \\(\\pi(y \\mid Z, \\theta)\\) carefully, we can carry out Gibbs and get samples of \\(\\pi(\\beta \\mid y)\\) !\ndesired marginal of joint augmented posterior \\[\\pi(\\beta \\mid y) = \\int_{\\cal{Z}} \\pi(\\beta, z \\mid y) \\, dz\\]\nWe have to choose latent prior and sampling model such that \\[p(y \\mid \\beta) = \\int_{\\cal{Z}}  \\pi(z \\mid \\beta) \\pi(y \\mid \\beta, z) \\, dz\\]\ncomplete data likelihood \\(\\pi(z \\mid \\beta) \\pi(y \\mid \\beta, z)\\)"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#augmentation-strategy",
    "href": "resources/slides/09-data-augmentation.html#augmentation-strategy",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Augmentation Strategy",
    "text": "Augmentation Strategy\nSet\n\n\\(y_i = 1_{(Z_i &gt; 0)}\\) i.e. ( \\(y_i = 1\\) if \\(Z_i &gt; 0\\) )\n\\(y_i = 1_{(Z_i &lt; 0)}\\) i.e. ( \\(y_i = 0\\) if \\(Z_i &lt; 0\\) )\n\\(Z_i = x_i^T \\beta + \\epsilon_i \\qquad \\epsilon_i \\overset{iid}{\\sim} \\textsf{N(0,1)}\\)\nRelationship to probit model: \\[\\begin{align*}\\Pr(y = 1 \\mid \\beta) & = P(Z_i &gt; 0 \\mid \\beta) \\\\\n& = P(Z_i - x_i^T \\beta &gt; -x^T\\beta) \\\\\n& = P(\\epsilon_i &gt; -x^T\\beta) \\\\\n& =  1 - \\Phi(-x^T_i \\beta) \\\\\n& =  \\Phi(x^T_i \\beta)\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#augmented-posterior-gibbs",
    "href": "resources/slides/09-data-augmentation.html#augmented-posterior-gibbs",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Augmented Posterior & Gibbs",
    "text": "Augmented Posterior & Gibbs\n\ntwo block Gibbs sampler \\(\\theta_{[1]} = \\beta\\) and \\(\\theta_{[2]} = (Z_1, \\ldots, Z_n)^T\\) \\[\\begin{align*}\\pi(& Z_1,  \\ldots, Z_n,  \\, \\beta \\mid y) \\propto \\\\\n& \\textsf{N}(\\beta; b_0, \\phi_0)  \\left\\{\\prod_{i=1}^n \\textsf{N}(Z_i; x_i^T\\beta, 1)\\right\\} \\left\\{  \\prod_{i=1}^n y_i 1_{(Z_i &gt; 0)} + (1 - y_i)1_{(Z_i &lt; 0)}\\right\\}\n\\end{align*}\\]\nfull conditional for \\(\\beta\\) given \\(Z_i\\)’s based on Normal-Normal regression \\[\\beta \\mid Z_1, \\ldots, Z_n, y_1, \\ldots, y_n \\sim \\textsf{N}(b_n, \\Phi_n)\\]\nFull conditional for latent \\(Z_i\\) (product of independent dist’s) \\[\\begin{align*}\n\\pi(Z_i \\mid \\beta, Z_{[-i]}, y_1, \\ldots, y_n)  & \\propto\n\\textsf{N}(Z_i; x_i^T \\beta, 1)1_{(Z_i &gt; 0)} \\text{   if  } y_1 = 1 \\\\\n\\pi(Z_i \\mid \\beta, Z_{[-i]}, y_1, \\ldots, y_n)  & \\propto\n\\textsf{N}(Z_i; x_i^T \\beta, 1)1_{(Z_i &lt; 0) }\\text{   if  } y_1 = 0 \\\\\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#truncated-sampling",
    "href": "resources/slides/09-data-augmentation.html#truncated-sampling",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Truncated Sampling",
    "text": "Truncated Sampling\n\n\n\nUse inverse cdf method for cdf \\(F\\)\nIf \\(U\\sim U(0,1)\\) set \\(X = F^{-1}(U)\\)\nif \\(X \\in (a, b)\\), Draw \\(X \\sim U(F(a),F(b))\\) and set \\(X = F^{-1}(u)\\)"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#truncated-normal-sampling",
    "href": "resources/slides/09-data-augmentation.html#truncated-normal-sampling",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Truncated Normal Sampling",
    "text": "Truncated Normal Sampling\n\n\n\nsample from independent truncated normal distributions for full conditional for \\(Z_i\\)\nif \\(Y_i = 1\\) then \\(Z_i \\sim \\textsf{Normal}(x_i^T\\beta, 1) I(0, \\infty)\\)\nstandard truncated normal \\(\\tilde{Z} = Z_i - x_i^T \\beta \\in (-x_i^T \\beta, \\infty)\\)\n\n\nGenerate \\(U \\sim \\textsf{Uniform}(\\Phi(-x_i^T\\beta), \\Phi(\\infty))\\)\nSet \\(\\tilde{z} = \\Phi^{-1}(U)\\) (Standard truncated normal)\nShift \\(Z_i = x_i^T \\beta + \\tilde{z}\\)\n\n\n\n\n\n\n\n\n\n\n\n\nU = 0.69, \\(Z_i = x_i^T \\beta + \\Phi^{-1}(U)\\) = 0.99"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#comments-on-gibbs",
    "href": "resources/slides/09-data-augmentation.html#comments-on-gibbs",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Comments on Gibbs",
    "text": "Comments on Gibbs\n\nWhy don’t we treat each individual \\(\\theta_j\\) as a separate block?\nGibbs always accepts, but can mix slowly if parameters in different blocks are highly correlated!\nUse block sizes in Gibbs that are as big as possible to improve mixing (proven faster convergence)\nCollapse the sampler by integrating out as many parameters as possible (as long as resulting sampler has good mixing)\ncan use Gibbs steps and (adaptive) Metropolis Hastings steps together\nlatent variables may allow Gibbs steps, but not always better compared to MH!"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#data-augmentation-in-general",
    "href": "resources/slides/09-data-augmentation.html#data-augmentation-in-general",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Data Augmentation in General",
    "text": "Data Augmentation in General\nDA is a broader than a computational trick allowing Gibbs sampling\n\nrandom effects or latent variable modeling i.e we introduce latent variables to simplify dependence structure modelling\nModeling heavy tailed distributions for priors or errors in robust regression as mixtures of normals\noutliesr\nvariable selection\nmissing data\nNext class:\n\nMultivariate Normal data\n\nWishart and inverse-Wishart distributions\nmissing data\n\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html#bayesian-statistical-modeling-and-data-analysis",
    "href": "index.html#bayesian-statistical-modeling-and-data-analysis",
    "title": "STA 702 Fall 2023",
    "section": "Bayesian Statistical Modeling and Data Analysis",
    "text": "Bayesian Statistical Modeling and Data Analysis\n\nCourse Overview\nThis course provides an introduction to Bayesian statistics targeted towards building a foundation for later research in developing models appropriate to complex data applications and to methodology research developing new modeling/inferential frameworks and algorithms. Topics include the basic foundations of Bayesian inferences – prior distributions, likelihood functions, posterior distributions, loss functions, and Bayes estimators/decisions with illustration in simple cases. Posterior computation in non-conjugate models with Markov chain Monte Carlo (MCMC) algorithms in addition to approximations to posteriors based on Laplace and variational approaches will be covered. We will build (and critique) models for a variety of data types and structures including regression, classification, and dependent data, hierarchical models for the borrowing of information, and methods for dealing with model uncertainty. Throughout we will discuss the difference between classical and Bayesian paradigms as well as advantages/disadvantages of Bayes. Time permitting we will discuss generalized Bayes.\n\n\nLearning Objectives\nBy the end of this course, students should be able to\n\nUnderstand the basics of Bayesian inference, that is, be able to define likelihood functions, prior distributions, posterior distributions, prior predictive distributions and posterior predictive distributions.\nDerive posterior distributions, prior predictive distributions and posterior predictive distributions, for common likelihood-prior combinations of distributions.\nInterpret the results of fitted models and conduct checks to ascertain that the models have converged.\nUse the Bayesian methods and models covered in class to analyze real data sets.\nAssess the adequacy of Bayesian models to any given data and make a decision on what to do in cases when certain models are not appropriate for a given data set."
  },
  {
    "objectID": "index.html#course-info",
    "href": "index.html#course-info",
    "title": "STA 702 Fall 2023",
    "section": "Course Info",
    "text": "Course Info\n\nInstructional Team and Office Hours\n\n\n\nRole\nName\nEmail\nOffice Hours\nLocation\n\n\n\n\nInstructor\nDr Merlise Clyde\n\nMon 9:00- 10:00, Thur 130-2:30  or by appointment (I have lots of 30 minute gaps!) \n223E Old Chem\n\n\nTA\nRick Presman\n\nMon 3:00 - 4:00, Fri 9:00-10:00\n203B Old Chem\n\n\n\n\n\nMeeting Times\n\nLecture\n   Tuesdays and Thursdays (10:05am - 11:20am)\n   Perkins LINK 060 (Classroom 1)\n\n\nLabs\n   Fridays (11:45pm - 1:00pm)\n   Perkins LINK 060 (Classroom 1)\n\n\nZoom meetings\nOccasionally we may need to meet over Zoom for class/lab or Office hours. The easiest way for you to join the different Zoom meetings is to log in to Sakai, go to the “Zoom meetings” tab, and click “Upcoming Meetings”. For the recordings (for lecture/lab and discussion sessions were recorded), also log in to Sakai, go to the “Zoom meetings” tab, and click “Cloud Recordings”. Those will be available few minutes after the sessions.\n\n\n\nTexts\n\n\n\n \nTitle\nAuthor(s)\nPublisher\n\n\n\n\n\nA First Course in Bayesian Statistical Methods\nPeter D. Hoff, 2009\nSpringer\n\n\n\nBayesian Data Analysis (Third Edition)\nAndrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\nChapman and Hall/CRC\n\n\n\nAll books are available available online from Duke library. See the Resources tab for additional links\n\n\nMaterials\nLecture notes and slides, and assigned readings will be posted on the course website. Homework and Lab Assignments will be posted on Github \n\n\nImportant Dates\n\n\n\n \n \n\n\n\n\nTues, Aug 29\nClasses begin\n\n\nFri, Sept 8\nDrop/Add ends\n\n\nFriday, Oct 13\nMidterm I (tentative)\n\n\nSat - Tues, Oct 14 - 17\nFall Break\n\n\nTues, Nov 20\nMidterm II (tentative)\n\n\nFriday, Dec 1\nGraduate Classes End\n\n\nDec 2 - Dec 12\nGraduate Reading Period\n\n\nSat, Dec 16\nFinal Exam (Perkins 060 2:00-5:00pm)\n\n\n\n\n\nGreen Classroom\n This course has achieved Duke’s Green Classroom Certification. The certification indicates that the faculty member teaching this course has taken significant steps to green the delivery of this course. Your faculty member has completed a checklist indicating their common practices in areas of this course that have an environmental impact, such as paper and energy consumption. Some common practices implemented by faculty to reduce the environmental impact of their course include allowing electronic submission of assignments, providing online readings and turning off lights and electronics in the classroom when they are not in use. The eco-friendly aspects of course delivery may vary by faculty, by course and throughout the semester. Learn more at https://sustainability.duke.edu/action/certification.\n\n\nAcknowledgement\nThis web page contains materials developed or adapted by Dr. Alexander Volfovsky, Dr. David B. Dunson, Dr. Rebecca Carter Steorts and Dr Michael Akande."
  },
  {
    "objectID": "resources/slides/00-course-overview.html#what-is-this-course-about",
    "href": "resources/slides/00-course-overview.html#what-is-this-course-about",
    "title": "Welcome to STA 702",
    "section": "What is this course about?",
    "text": "What is this course about?\n\nLearn the foundations and theory of Bayesian inference in the context of several models.\nUse Bayesian models to answer inferential questions.\nApply the models to several different problems.\nUnderstand the advantages/disadvantages of Bayesian methods vs classical methods\n\n\n\n A Bayesian version will usually make things better…\n– Andrew Gelman."
  },
  {
    "objectID": "resources/slides/00-course-overview.html#instructional-team",
    "href": "resources/slides/00-course-overview.html#instructional-team",
    "title": "Welcome to STA 702",
    "section": "Instructional Team",
    "text": "Instructional Team\nInstructor: Dr Merlise Clyde\n   clyde@duke.edu     223 Old Chemistry     https://www2.stat.duke.edu/~clyde \n\n \nTeaching Assistant: Rick Presman\n   rick.presman@duke.edu\n \n   See course website for Office Hours, Policies and more!"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#prerequisites",
    "href": "resources/slides/00-course-overview.html#prerequisites",
    "title": "Welcome to STA 702",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nrandom variables, common families of probability distribution functions and expectations\nconditional distributions\ntransformations of random variables and change of variables\nprinciples of statistical inference (likelihoods)\nsampling distributions and hypothesis testing\nconcepts of convergence\n\n\nReview Chapters 1 to 5 of the Casella and Berger book"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#computing",
    "href": "resources/slides/00-course-overview.html#computing",
    "title": "Welcome to STA 702",
    "section": "Computing",
    "text": "Computing\n\nLabs/HW will involve computing in R!\nWrite your own MCMC samplers and run code long enough to show convergence\nYou can learn R on the fly\n\nsee Resources Tab on website\nmaterials from 2023 Bootcamp/Orientation"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#grading-policies",
    "href": "resources/slides/00-course-overview.html#grading-policies",
    "title": "Welcome to STA 702",
    "section": "Grading Policies",
    "text": "Grading Policies\n\n5% class\n20% HW\n10% Lab\n20% Midterm I\n20% Midterm II\n25% Final\nNo Late Submissions for HW/Lab; Drop the lowest score\nYou are encouraged to discuss assignments, but copying others work is considered a misconduct violation and will result in a 0 on the assignment\nConfirm that you have access to Sakai, Gradescope, and GitHub"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#course-structure-and-policies",
    "href": "resources/slides/00-course-overview.html#course-structure-and-policies",
    "title": "Welcome to STA 702",
    "section": "Course structure and policies",
    "text": "Course structure and policies\n\nSee the Syllabus\nMake use of the teaching team’s office hours, we’re here to help!\nDo not hesitate to come to my office hours or you can also make an appointment to discuss a homework problem or any aspect of the course.\nPlease make sure to check your email daily for announcements\nUse the  Reporting an issue link to report broken links or missing content"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#important-dates",
    "href": "resources/slides/00-course-overview.html#important-dates",
    "title": "Welcome to STA 702",
    "section": "Important Dates",
    "text": "Important Dates\n\n\n\n \n \n\n\n\n\nTues, Aug 29\nClasses begin\n\n\nFri, Sept 8\nDrop/Add ends\n\n\nFriday, Oct 13\nMidterm I (tentative)\n\n\nSat - Tues, Oct 14 - 17\nFall Break\n\n\nTues, Nov 20\nMidterm II (tentative)\n\n\nFriday, Dec 1\nGraduate Classes End\n\n\nDec 2 - Dec 12\nGraduate Reading Period\n\n\nSat, Dec 16\nFinal Exam (Perkins 060 2:00-5:00pm)\n\n\n\n\nSee Class Schedule for slides, readings, HW, Labs, etc"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#topics",
    "href": "resources/slides/00-course-overview.html#topics",
    "title": "Welcome to STA 702",
    "section": "Topics",
    "text": "Topics\n\nBasics of Bayesian Models\nLoss Functions, Inference and Decision Making\nPredictive Distributions\nPredictive Distributions and Model Checking\nBayesian Hypothesis Testing\nMultiple Testing\nMCMC (Gibbs & Metropolis Hastings Algorithms)\nModel Uncertainty/Model Choice\nBayesian Generalized Linear Models\nHiearchical Modeling and Random Effects\nHamiltonian Monte Carlo\nNonparametric Bayes Regression"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#basics-of-bayesian-inference",
    "href": "resources/slides/00-course-overview.html#basics-of-bayesian-inference",
    "title": "Welcome to STA 702",
    "section": "Basics of Bayesian inference",
    "text": "Basics of Bayesian inference\nGenerally (unless otherwise stated), in this course, we will use the following notation. Let\n\n\\(Y\\) is a random variable from some probability distribution \\(p(y \\mid \\theta)\\)\n\\(\\mathcal{Y}\\) be the sample space (possible outcomes for \\(Y\\))\n\\(y\\) is the observed data\n\\(\\theta\\) is the unknown parameter of interest\n\\(\\Theta\\) be the parameter space\ne.g. \\(Y \\sim \\textsf{Ber}(\\theta)\\) where \\(\\theta = \\Pr(Y = 1)\\)"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#frequentist-inference",
    "href": "resources/slides/00-course-overview.html#frequentist-inference",
    "title": "Welcome to STA 702",
    "section": "Frequentist inference",
    "text": "Frequentist inference\n\nGiven data \\(y\\), how would we estimate the population parameter \\(\\theta\\)?\n\nMaximum likelihood estimate (MLE)\nMethod of moments\nand so on…\n\nFrequentist MLE finds the one value of \\(\\theta\\) that maximizes the likelihood\nTypically uses large sample (asymptotic) theory to obtain confidence intervals and do hypothesis testing."
  },
  {
    "objectID": "resources/slides/00-course-overview.html#what-are-bayesian-methods",
    "href": "resources/slides/00-course-overview.html#what-are-bayesian-methods",
    "title": "Welcome to STA 702",
    "section": "What are Bayesian methods?",
    "text": "What are Bayesian methods?\n\nBayesian methods are data analysis tools derived from the principles of Bayesian inference and provide\n\nparameter estimates with good statistical properties;\nparsimonious descriptions of observed data;\npredictions for missing data and forecasts of future data with full uncertainty quantification; and\na computational framework for model estimation, selection, decision making and validation.\nbuilds on likelihood inference"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#bayes-theorem",
    "href": "resources/slides/00-course-overview.html#bayes-theorem",
    "title": "Welcome to STA 702",
    "section": "Bayes’ theorem",
    "text": "Bayes’ theorem\n\nLet’s take a step back and quickly review the basic form of Bayes’ theorem.\nSuppose there are some events \\(A\\) and B having probabilities \\(\\Pr(A)\\) and \\(\\Pr(B)\\).\nBayes’ rule gives the relationship between the marginal probabilities of A and B and the conditional probabilities.\nIn particular, the basic form of Bayes’ rule or Bayes’ theorem is \\[\\Pr(A | B) = \\frac{\\Pr(A \\ \\textrm{and} \\ B)}{\\Pr(B)} = \\frac{\\Pr(B|A)\\Pr(A)}{\\Pr(B)}\\]\n\\(\\Pr(A)\\) = marginal probability of event \\(A\\), \\(\\Pr(B | A)\\) = conditional probability of event \\(B\\) given event \\(A\\), and so on.\n“reverses the conditioning” e.g. Probability of Covid given a negative test versus probability of a negative test given Covid"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#bayes-rule-more-generally",
    "href": "resources/slides/00-course-overview.html#bayes-rule-more-generally",
    "title": "Welcome to STA 702",
    "section": "Bayes’ Rule more generally",
    "text": "Bayes’ Rule more generally\n\nFor each \\(\\theta \\in \\Theta\\), specify a prior distribution \\(p(\\theta)\\) or \\(\\pi(\\theta)\\), describing our beliefs about \\(\\theta\\) being the true population parameter.\nFor each \\(\\theta \\in \\Theta\\) and \\(y \\in \\mathcal{Y}\\), specify a sampling distribution \\(p(y|\\theta)\\), describing our belief that the data we see \\(y\\) is the outcome of a study with true parameter \\(\\theta\\).  Likelihood \\(L(\\theta|y)\\) proportional to \\(p(y|\\theta)\\)\nAfter observing the data \\(y\\), for each \\(\\theta \\in \\Theta\\), update the prior distribution to a posterior distribution \\(p(\\theta | y)\\) or \\(\\pi(\\theta | y)\\), describing our “updated” belief about \\(\\theta\\) being the true population parameter.\n\n\nGetting from Step 1 to 3? Bayes’ rule!\n\\[p(\\theta | y) = \\frac{p(\\theta)p(y|\\theta)}{\\int_{\\Theta}p(\\tilde{\\theta})p(y| \\tilde{\\theta}) \\textrm{d}\\tilde{\\theta}} = \\frac{p(\\theta)p(y|\\theta)}{p(y)}\\] where \\(p(y)\\) obtained by Law of Total Probability"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#notes-on-prior-distributions",
    "href": "resources/slides/00-course-overview.html#notes-on-prior-distributions",
    "title": "Welcome to STA 702",
    "section": "Notes on prior distributions",
    "text": "Notes on prior distributions\nMany types of priors may be of interest. These may\n\nrepresent our own beliefs;\nrepresent beliefs of a variety of people with differing prior opinions; or\nassign probability more or less evenly over a large region of the parameter space\ndesigned to provide good frequentist behavior when little is known"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#notes-on-prior-distributions-1",
    "href": "resources/slides/00-course-overview.html#notes-on-prior-distributions-1",
    "title": "Welcome to STA 702",
    "section": "Notes on prior distributions",
    "text": "Notes on prior distributions\n\nSubjective Bayes: a prior should accurately quantify some individual’s beliefs about \\(\\theta\\)\nObjective Bayes: the prior should be chosen to produce a procedure with “good” operating characteristics without including subjective prior knowledge\nWeakly informative: prior centered in a plausible region but not overly-informative, as there is a tendency to be over confident about one’s beliefs\nEmpirical Bayes: uses the data to estimate the prior, then pretends it was known\nPractical Bayes: Combination"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#notes-on-prior-distributions-2",
    "href": "resources/slides/00-course-overview.html#notes-on-prior-distributions-2",
    "title": "Welcome to STA 702",
    "section": "Notes on prior distributions",
    "text": "Notes on prior distributions\n\nThe prior quantifies ‘your’ initial uncertainty in \\(\\theta\\) before you observe new data (new information) - this may be necessarily subjective & summarizes experience in a field or prior research.\nEven if the prior is not “perfect”, placing higher probability in a ballpark of the truth leads to better performance.\nHence, it is very seldom the case that a weakly informative prior is not preferred over no prior. (Model selection is one case where one needs to be careful!)\nOne (very important) role of the prior is to stabilize estimates (shrinkage) in the presence of limited data."
  },
  {
    "objectID": "resources/slides/00-course-overview.html#next-steps",
    "href": "resources/slides/00-course-overview.html#next-steps",
    "title": "Welcome to STA 702",
    "section": "Next Steps",
    "text": "Next Steps\nWork on Lab 0\nFinally, here are some readings to entertain you. Make sure to glance through them within the next week. See Course Resources\n\nEfron, B., 1986. Why isn’t everyone a Bayesian?. The American Statistician, 40(1), pp. 1-5.\nGelman, A., 2008. Objections to Bayesian statistics. Bayesian Analysis, 3(3), pp. 445-449.\nDiaconis, P., 1977. Finite forms of de Finetti’s theorem on exchangeability. Synthese, 36(2), pp. 271-281.\nGelman, A., Meng, X. L. and Stern, H., 1996. Posterior predictive assessment of model fitness via realized discrepancies. Statistica sinica, pp. 733-760. 5. Dunson, D. B., 2018. Statistics in the big data era: Failures of the machine. Statistics & Probability Letters, 136, pp. 4-9.\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#last-class-normal-means-model",
    "href": "resources/slides/06-metropolis.html#last-class-normal-means-model",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Last Class: Normal Means Model",
    "text": "Last Class: Normal Means Model\n\nData Model \\(Y_i \\mid \\mu_i, \\sigma^2 \\overset{ind}{\\sim} \\textsf{N}(\\mu_i, \\sigma^2)\\)\nMeans Model \\(\\mu_i \\mid \\mu, \\sigma^2_\\mu \\overset{iid}{\\sim} \\textsf{N}(\\mu, \\sigma^2_{\\mu})\\)$\nFound marginal likelihood \\(\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu)\\) by integrating out \\(\\mu_i\\) with respect to \\(g\\) \\[\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu) \\propto (\\sigma^2 + \\sigma^2_\\mu)^{-n/2} \\exp \\left\\{ - \\frac{1}{2} \\frac{\\sum_{i=1}^n\\left(y_i - \\mu \\right)^2}{\\sigma^2 + \\sigma^2_\\mu }\\right\\}\\]\nPosterior for \\(\\theta = \\mu, \\sigma^2_\\mu\\) with \\(\\sigma^2 = 1\\) \\[\\pi(\\theta \\mid y) = \\frac{\\pi(\\theta) \\cal{L}(\\theta)}\n{\\int_\\Theta \\pi(\\theta) \\cal{L}(\\theta) \\, d\\theta} =\n\\frac{\\pi(\\theta) \\cal{L}(\\theta)}\n{m(y)}\\]\nwhile we can integrate out \\(\\mu\\), no closed form for posterior of \\(\\sigma^2_\\mu\\) given \\(\\sigma^2\\)"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#important-sampling-estimate",
    "href": "resources/slides/06-metropolis.html#important-sampling-estimate",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Important Sampling Estimate",
    "text": "Important Sampling Estimate\n\nEstimate of \\(m(y)\\) \\[m(y) \\approx \\frac{1}{T} \\sum_{t=1}^{T}  \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})} \\qquad \\theta^{(t)} \\sim q(\\theta)\\]\nRatio estimator of \\(\\textsf{E}[h(\\theta) \\mid y]\\) \\[\\textsf{E}[h(\\theta) \\mid y] \\approx \\frac{\\sum_{t=1}^{T} h(\\theta^{(t)}) \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}}\n{ \\sum_{t=1}^{T}  \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}}\n\\qquad \\theta^{(t)} \\sim q(\\theta)\\]\nWeighted average with importance weights \\(w(\\theta^{(t)}) \\propto \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}\\) \\[\\textsf{E}[h(\\theta) \\mid y] \\approx \\sum_{t=1}^{T} h(\\theta^{(t)}) w(\\theta^{(t)})/\\sum_{t=1}^T w(\\theta^{(t)}) \\qquad \\theta^{(t)} \\sim q(\\theta)\\]"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#issues",
    "href": "resources/slides/06-metropolis.html#issues",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Issues",
    "text": "Issues\n\nif \\(q()\\) puts too little mass in regions with high posterior density, we can have some extreme weights\noptimal case is that \\(q()\\) is as close as possible to the posterior so that all weights are constant\nEstimate may have large variance\nProblems with finding a good \\(q()\\) in high dimensions \\((d &gt; 20)\\) or with skewed distributions"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#markov-chain-monte-carlo-mcmc",
    "href": "resources/slides/06-metropolis.html#markov-chain-monte-carlo-mcmc",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Markov Chain Monte Carlo (MCMC)",
    "text": "Markov Chain Monte Carlo (MCMC)\n\nTypically \\(\\pi(\\theta)\\) and \\(\\cal{L}(\\theta)\\) are easy to evaluate\n\n\n\n\n\n\n\n\nQuestion\n\n\nHow do we draw samples only using evaluations of the prior and likelihood in higher dimensional settings?\n\n\n\n\nconstruct a Markov chain \\(\\theta^{(t)}\\) in such a way the the stationary distribution of the Markov chain is the posterior distribution \\(\\pi(\\theta \\mid y)\\)! \\[\\theta^{(0)} \\overset{k}{\\longrightarrow} \\theta^{(1)} \\overset{k}{\\longrightarrow} \\theta^{(2)} \\cdots\\]\n\\(k_t(\\theta^{(t-1)} ; \\theta^{(t)})\\) transition kernel\ninitial state \\(\\theta^{(0)}\\)\nchoose some nice \\(k_t\\) such that \\(\\theta^{(t)} \\to \\pi(\\theta \\mid y)\\) as \\(t \\to \\infty\\)\nbiased samples initially but get closer to the target\nMetropolis Algorithm (1950’s)"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#stochastic-sampling-intuition",
    "href": "resources/slides/06-metropolis.html#stochastic-sampling-intuition",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Stochastic Sampling Intuition",
    "text": "Stochastic Sampling Intuition\n\nFrom a sampling perspective, we need to have a large sample or group of values, \\(\\theta^{(1)}, \\ldots, \\theta^{(S)}\\) from \\(\\pi(\\theta \\mid y)\\) whose empirical distribution approximates \\(\\pi(\\theta \\mid y)\\).\nfor any two sets \\(A\\) and \\(B\\), we want \\[\\frac{\\dfrac{\\# \\theta^{(s)} \\in A}{S}}{\\dfrac{\\# \\theta^{(s)} \\in B}{S} } = \\dfrac{\\# \\theta^{(s)} \\in A}{\\# \\theta^{(s)} \\in B} \\approx \\dfrac{\\pi(\\theta \\in A \\mid  y)}{\\pi(\\theta \\in B \\mid  y)}\\]\nSuppose we have a working group \\(\\theta^{(1)}, \\ldots, \\theta^{(s)}\\) at iteration \\(s\\), and need to add a new value \\(\\theta^{(s+1)}\\).\nConsider a candidate value \\(\\theta^\\star\\) that is close to \\(\\theta^{(s)}\\)\nShould we set \\(\\theta^{(s+1)} = \\theta^\\star\\) or not?"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#posterior-ratio",
    "href": "resources/slides/06-metropolis.html#posterior-ratio",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Posterior Ratio",
    "text": "Posterior Ratio\nlook at the ratio \\[\n\\begin{split}\nM & = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)} = \\frac{\\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y)} } {\\dfrac{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}{p(y)}}\\\\\n\\\\\n&  = \\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}\n\\end{split}\n\\]\n\ndoes not depend on the marginal likelihood we don’t know!"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#metropolis-algorithm",
    "href": "resources/slides/06-metropolis.html#metropolis-algorithm",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Metropolis Algorithm",
    "text": "Metropolis Algorithm\n\nIf \\(M &gt; 1\\)\n\nIntuition: \\(\\theta^{(s)}\\) is already a part of the density we desire and the density at \\(\\theta^\\star\\) is even higher than the density at \\(\\theta^{(s)}\\).\nAction: set \\(\\theta^{(s+1)} = \\theta^\\star\\)\n\nIf \\(M &lt; 1\\),\n\nIntuition: relative frequency of values in our group \\(\\theta^{(1)}, \\ldots, \\theta^{(s)}\\) “equal” to \\(\\theta^\\star\\) should be \\(\\approx M = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)}\\).\nFor every \\(\\theta^{(s)}\\), include only a fraction of an instance of \\(\\theta^\\star\\).\nAction: set \\(\\theta^{(s+1)} = \\theta^\\star\\) with probability \\(M\\) and \\(\\theta^{(s+1)} = \\theta^{(s)}\\) with probability \\(1-M\\)."
  },
  {
    "objectID": "resources/slides/06-metropolis.html#proposal-distribution",
    "href": "resources/slides/06-metropolis.html#proposal-distribution",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Proposal Distribution",
    "text": "Proposal Distribution\n\nWhere should the proposed value \\(\\theta^\\star\\) come from?\nSample \\(\\theta^\\star\\) close to the current value \\(\\theta^{(s)}\\) using a symmetric proposal distribution \\(\\theta^\\star \\sim q(\\theta^\\star \\mid \\theta^{(s)})\\)\n\\(q()\\) is actually a “family of proposal distributions”, indexed by the specific value of \\(\\theta^{(s)}\\).\nHere, symmetric means that \\(q(\\theta^\\star \\mid \\theta^{(s)}) = q(\\theta^{(s)} \\mid \\theta^\\star)\\).\nCommon choice \\[\\textsf{N}(\\theta^\\star; \\theta^{(s)}, \\delta^2 \\Sigma)\\] with \\(\\Sigma\\) based on the approximate \\(\\textsf{Cov}(\\theta \\mid y)\\) and \\(\\delta^2 = 2.38^2/\\text{dim}(\\theta)\\) or \\[\\text{Unif}(\\theta^\\star; \\theta^{(s)} - \\delta, \\theta^{(s)} + \\delta)\\]"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#metropolis-algorithm-recap",
    "href": "resources/slides/06-metropolis.html#metropolis-algorithm-recap",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Metropolis Algorithm Recap",
    "text": "Metropolis Algorithm Recap\nThe algorithm proceeds as follows:\n\nGiven \\(\\theta^{(1)}, \\ldots, \\theta^{(s)}\\), generate a candidate value \\(\\theta^\\star \\sim q(\\theta^\\star \\mid \\theta^{(s)})\\).\nCompute the acceptance ratio \\[\\begin{split}\nM & = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)} = \\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}.\n\\end{split}\\]\nSet \\[\\begin{eqnarray*}\n\\theta^{(s+1)} = \\left\\{ \\begin{array}{ll}\n\\theta^\\star & \\quad \\text{with probability} \\quad \\text{min}(M,1) \\\\\n\\theta^{(s)} & \\quad \\text{with probability} \\quad 1 - \\text{min}(M,1) \\\\\n\\end{array} \\right.\n\\end{eqnarray*}\\] equivalent to sampling \\(u \\sim U(0,1)\\) independently and setting \\[\\begin{eqnarray*}\n\\theta^{(s+1)} = \\left\\{ \\begin{array}{ll}\n\\theta^\\star & \\quad \\text{if} \\quad u &lt; M \\\\\n\\theta^{(s)} & \\quad \\text{if} \\quad \\text{otherwise} \\\\\n\\end{array} \\right. .\n\\end{eqnarray*}\n\\]"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#notes",
    "href": "resources/slides/06-metropolis.html#notes",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Notes",
    "text": "Notes\n\nAcceptance probability is \\[M = \\min \\left\\{ 1, \\frac{\\pi(\\theta^\\star) \\cal{L}(\\theta^\\star)}\n                         {\\pi(\\theta^{(s)}) \\cal{L}(\\theta^{(s)})}\\right\\}\\]\nratio of posterior densities where normalizing constant cancels!\nThe Metropolis chain ALWAYS moves to the proposed \\(\\theta^\\star\\) at iteration \\(s+1\\) if \\(\\theta^\\star\\) has higher target density than the current \\(\\theta^{(s)}\\).\nSometimes, it also moves to a \\(\\theta^\\star\\) value with lower density in proportion to the density value itself.\nThis leads to a random, Markov process that naturally explores the space according to the probability defined by \\(\\pi(\\theta \\mid y)\\), and hence generates a sequence that, while dependent, eventually represents draws from \\(\\pi(\\theta \\mid y)\\) (stationary distribution of the Markov Chain)."
  },
  {
    "objectID": "resources/slides/06-metropolis.html#summarizing-samples",
    "href": "resources/slides/06-metropolis.html#summarizing-samples",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Summarizing Samples",
    "text": "Summarizing Samples\n\nOnce we obtain the samples, then we are back to using Monte Carlo approximations for quantities of interest!\nwe can approximate posterior means, quantiles, and other quantities of interest using the empirical distribution of our sampled values.\neasy to compute the posterior distribution of nonlinear functions of parameters! \\[\\psi^{(s)} = g(\\theta^{(s)})\\]\nsome posterior summaries are hard to calculate based on samples \\(\\{ \\theta^{(s)}\\}\\)\n\nmode/MAP (at least for continuous)\nmarginal likelihood \\(m(y) = \\int \\pi(\\theta) p(y \\mid \\theta)\\, d\\theta\\)"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#convergence",
    "href": "resources/slides/06-metropolis.html#convergence",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Convergence",
    "text": "Convergence\nWe will not cover the convergence theory behind Metropolis chains in detail, but …\n\nThe Markov process generated under this procedure is ergodic (irreducible and aperiodic) and has a unique limiting distribution (stationary distribution)\n\nergodicity means that the chain can move anywhere at each step, which is ensured, if \\(q(\\theta^\\star \\mid \\theta^{(s)}) &gt; 0\\) everywhere!\n\nBy construction, Metropolis chains are reversible, so that \\(\\pi(\\theta \\mid y)\\) is the stationary distribution\n\nThink of reversibility as being equivalent to symmetry of the joint density of two consecutive \\(\\theta^{(s)}\\) and \\(\\theta^{(s+1)}\\) in the stationary process (which we get by using a symmetric proposal distribution)\ndetailed balance"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#example",
    "href": "resources/slides/06-metropolis.html#example",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Example",
    "text": "Example\nPriors with \\(\\sigma^2 = 1\\): \\[p(\\mu) \\propto 1\\]\n\nUse a \\(\\textsf{Cauchy}(0,1)\\) prior on \\(\\sigma_\\mu\\) independent of \\(\\mu\\) and\nSymmetric proposal for \\(\\mu\\) and \\(\\sigma_\\tau\\)?\nTry independent normals \\(\\frac{2.38^2}{d} \\textsf{Cov}(\\theta)\\) where \\(d\\) is the dimension of \\(\\theta\\) (d = 2)"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#samples",
    "href": "resources/slides/06-metropolis.html#samples",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Samples",
    "text": "Samples\n\n\nOverall Acceptance probability is 0.6 out of 10^{4} samples\nGoal is around 0.44 in 1 dimension to 0.23 in higher dimensions"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#tuning",
    "href": "resources/slides/06-metropolis.html#tuning",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Tuning",
    "text": "Tuning\n\nSampled values are correlated\nCorrelation between samples can be adjusted by selecting an optimal \\(\\delta\\) (i.e., spread of the distribution) in the proposal distribution\n\\(\\delta\\) too small leads to \\(M \\approx 1\\) for most proposed values, a high acceptance rate, but very small moves, leading to highly correlated chain.\n\\(\\delta\\) too large can get “stuck” because \\(\\theta^\\star\\) may be very far away from high density regions, leading to a very low acceptance rate and again high correlation in the Markov chain.\nBurn-in and thinning can help!"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#burn-in",
    "href": "resources/slides/06-metropolis.html#burn-in",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Burn-in",
    "text": "Burn-in\n\nConvergence occurs regardless of our starting point (in theory), so we can usually pick any reasonable values in the parameter space as a starting point.\nMay take a long time to reach high density regions\nOver representation of low density samples given finite iterations\nGenerally, we throw out a certain number of the first draws, known as the burn-in, as an attempt to make our draws closer to the stationary distribution and less dependent on any single set of starting values.\nHowever, we don’t know exactly when convergence occurs, so it is not always clear how much burn-in we would need.\nIf you run long enough you should not need to discard any samples! (ergodicity)"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#example-1",
    "href": "resources/slides/06-metropolis.html#example-1",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#convergence-diagnostics",
    "href": "resources/slides/06-metropolis.html#convergence-diagnostics",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Convergence diagnostics",
    "text": "Convergence diagnostics\n\nDiagnostics available to help decide on number of burn-in & collected samples.\nNote: no definitive tests of convergence but you should do as many diagnostics as you can, on all parameters in your model.\nWith “experience”, visual inspection of trace plots perhaps most useful approach.\nThere are a number of useful automated tests in R.\nCAUTION: diagnostics cannot guarantee that a chain has converged, but they can indicate it has not converged."
  },
  {
    "objectID": "resources/slides/06-metropolis.html#diagnostics-in-r",
    "href": "resources/slides/06-metropolis.html#diagnostics-in-r",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Diagnostics in R",
    "text": "Diagnostics in R\n\nThe most popular package for MCMC diagnostics in R is coda.\ncoda uses a special MCMC format so you must always convert your posterior matrix into an MCMC object.\nFor the example, we have the following in R.\n\n\n\n#library(coda)\ntheta.mcmc &lt;- mcmc(theta,start=1) #no burn-in (simple problem!)"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#diagnostics-in-r-1",
    "href": "resources/slides/06-metropolis.html#diagnostics-in-r-1",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Diagnostics in R",
    "text": "Diagnostics in R\n\nsummary(theta.mcmc)\n\n\nIterations = 1:10000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n             Mean     SD Naive SE Time-series SE\nmu       -0.07977 0.1046 0.001046       0.002839\nsigma_mu  0.17550 0.1273 0.001273       0.004397\n\n2. Quantiles for each variable:\n\n              2.5%     25%      50%      75%  97.5%\nmu       -0.283420 -0.1508 -0.08193 -0.00848 0.1337\nsigma_mu  0.007995  0.0758  0.15024  0.25228 0.4693\n\n\n\nThe naive SE is the standard error of the mean, which captures simulation error of the mean rather than the posterior uncertainty.\nThe time-series SE adjusts the naive SE for autocorrelation."
  },
  {
    "objectID": "resources/slides/06-metropolis.html#effective-sample-size.",
    "href": "resources/slides/06-metropolis.html#effective-sample-size.",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Effective sample size.",
    "text": "Effective sample size.\n\nThe effective sample size translates the number of MCMC samples \\(S\\) into an equivalent number of independent samples.\nIt is defined as \\[\\textrm{ESS} = \\dfrac{S}{1 + 2 \\sum_k \\rho_k},\\]\n\\(S\\) is the sample size and \\(\\rho_k\\) is the lag \\(k\\) autocorrelation.\nFor our data, we have\n\n\n\neffectiveSize(theta.mcmc)\n\n       mu  sigma_mu \n1356.6495  838.2613 \n\n\n\nSo our 10,000 samples are equivalent to 1356.6 independent samples for \\(\\mu\\) and 838.3 independent samples for \\(\\sigma_\\mu\\)."
  },
  {
    "objectID": "resources/slides/06-metropolis.html#trace-plot-for-mean",
    "href": "resources/slides/06-metropolis.html#trace-plot-for-mean",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Trace plot for mean",
    "text": "Trace plot for mean"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#trace-plot-for-sigma_mu",
    "href": "resources/slides/06-metropolis.html#trace-plot-for-sigma_mu",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Trace plot for \\(\\sigma_\\mu\\)",
    "text": "Trace plot for \\(\\sigma_\\mu\\)\n\nOK (be careful of scaling in plots!)"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#autocorrelation",
    "href": "resources/slides/06-metropolis.html#autocorrelation",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Autocorrelation",
    "text": "Autocorrelation\n\nAnother way to evaluate convergence is to look at the autocorrelation between draws of our Markov chain.\nThe lag \\(k\\) autocorrelation, \\(\\rho_k\\), is the correlation between each draw and its \\(k\\)th lag, defined as \\[\\rho_k = \\dfrac{\\sum_{s=1}^{S-k}(\\theta_s - \\bar{\\theta})(\\theta_{s+k} - \\bar{\\theta})}{\\sum_{s=1}^{S-k}(\\theta_s - \\bar{\\theta})^2}\\]\nWe expect the autocorrelation to decrease as \\(k\\) increases.\nIf autocorrelation remains high as \\(k\\) increases, we have slow mixing due to the inability of the sampler to move around the space well."
  },
  {
    "objectID": "resources/slides/06-metropolis.html#autocorrelation-for-mean",
    "href": "resources/slides/06-metropolis.html#autocorrelation-for-mean",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Autocorrelation for mean",
    "text": "Autocorrelation for mean\n\nSo-So"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#autocorrelation-for-variance",
    "href": "resources/slides/06-metropolis.html#autocorrelation-for-variance",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Autocorrelation for variance",
    "text": "Autocorrelation for variance\n\nworse"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#gelman-rubin",
    "href": "resources/slides/06-metropolis.html#gelman-rubin",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Gelman-Rubin",
    "text": "Gelman-Rubin\nGelman & Rubin suggested a diagnostic \\(R\\) based on taking separate chains with dispersed initial values to test convergence"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#gelman-rubin-diagnostic",
    "href": "resources/slides/06-metropolis.html#gelman-rubin-diagnostic",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Gelman-Rubin Diagnostic",
    "text": "Gelman-Rubin Diagnostic\n\nRun m &gt; 2 chains of length 2S from overdispersed starting values.\nDiscard the first S draws in each chain.\nCalculate the pooled within-chain variance \\(W\\) and between-chain variance \\(B\\). \\[R = \\frac{\\frac{S-1}{S} W + \\frac{1}{S} B }{W}\\]\nnumerator and denominator are both unbiased estimates of the variance if the two chains have converged\n\notherwise \\(W\\) is an underestimate (hasn’t explored enough)\nnumerator will overestimate as \\(B\\) is too large (overdispersed starting points)\n\nAs \\(S \\to \\infty\\) and \\(B \\to 0\\), \\(R \\to 1\\)\nversion in R is slightly different"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#gelman-rubin-diagnostic-1",
    "href": "resources/slides/06-metropolis.html#gelman-rubin-diagnostic-1",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Gelman-Rubin Diagnostic",
    "text": "Gelman-Rubin Diagnostic\n\ntheta.mcmc = mcmc.list(mcmc(theta1, start=5000), mcmc(theta2, start=5000))\ngelman.diag(theta.mcmc)\n\nPotential scale reduction factors:\n\n         Point est. Upper C.I.\nmu                1          1\nsigma_mu          1          1\n\nMultivariate psrf\n\n1\n\n\n\nValues of \\(R &gt; 1.1\\) suggest lack of convergence\nLooks OK\nSee also gelman.plot"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#geweke-statistic",
    "href": "resources/slides/06-metropolis.html#geweke-statistic",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Geweke statistic",
    "text": "Geweke statistic\n\nGeweke proposed taking two non-overlapping parts of a single Markov chain (usually the first 10% and the last 50%) and comparing the mean of both parts, using a difference of means test\nThe null hypothesis would be that the two parts of the chain are from the same distribution.\nThe test statistic is a z-score with standard errors adjusted for autocorrelation, and if the p-value is significant for a variable, you need more draws.\nOutput in R is the Z score"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#geweke-diagnostic",
    "href": "resources/slides/06-metropolis.html#geweke-diagnostic",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Geweke Diagnostic",
    "text": "Geweke Diagnostic\n\nThe output is the z-score itself (not the p-value).\n\n\ngeweke.diag(theta.mcmc)\n\n[[1]]\n\nFraction in 1st window = 0.1\nFraction in 2nd window = 0.5 \n\n      mu sigma_mu \n -0.7779   0.7491 \n\n\n[[2]]\n\nFraction in 1st window = 0.1\nFraction in 2nd window = 0.5 \n\n      mu sigma_mu \n  0.4454   0.6377"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#practical-advice-on-diagnostics",
    "href": "resources/slides/06-metropolis.html#practical-advice-on-diagnostics",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Practical advice on diagnostics",
    "text": "Practical advice on diagnostics\n\nThere are more tests we can use: Raftery and Lewis diagnostic, Heidelberger and Welch, etc.\nThe Gelman-Rubin approach is quite appealing in using multiple chains\nGeweke (and Heidelberger and Welch) sometimes reject even when the trace plots look good.\nOverly sensitive to minor departures from stationarity that do not impact inferences.\nMost common method of assessing convergence is visual examination of trace plots."
  },
  {
    "objectID": "resources/slides/06-metropolis.html#improving",
    "href": "resources/slides/06-metropolis.html#improving",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Improving",
    "text": "Improving\n\nmore iterations and multiple chains\nthinning to reduce correlations and increase ESS e.g. if autocorrelation drops to near zero at say lag 5, keep every 5th draw\nchange the proposal distribution \\(q\\)\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#outline",
    "href": "resources/slides/03-normal-predictive-distributions.html#outline",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Outline",
    "text": "Outline\n\nNormal Model\nPredictive Distributions\nPrior Predictive; useful for prior elicitation\nPosterior Predictive; predicting/forecasting future events\nComparing Estimators"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#normal-model-setup",
    "href": "resources/slides/03-normal-predictive-distributions.html#normal-model-setup",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Normal Model Setup",
    "text": "Normal Model Setup\n\nSuppose we have independent observations \\[\\mathbf{y} = (y_1,y_2,\\ldots,y_n)^T\\] where each \\(Y_i \\mid \\theta, \\sigma^2 \\stackrel{iid}{\\sim} \\textsf{N}(\\theta, \\sigma^2)\\)\nWe will see that it is more convenient to work with \\(\\tau = 1/\\sigma^2\\) (precision)\nreparameterizing the model for the data we have \\[Y_i \\mid \\theta, \\tau  \\sim \\mathcal{N}(\\theta, \\tau^{-1})\\]\nfor simplicity we will treat \\(\\tau\\) as known initially.\nNeed to specify a prior for \\(\\theta\\) on \\(\\mathbb{R}\\)"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#prior-for-a-normal-mean",
    "href": "resources/slides/03-normal-predictive-distributions.html#prior-for-a-normal-mean",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Prior for a Normal Mean",
    "text": "Prior for a Normal Mean\n\nNatural choice is a Normal/Gaussian distribution (Conjugate prior) \\[\\theta \\sim \\textsf{N}(\\theta_0, 1/\\tau_0)\\]\n\\(\\theta_0\\) is the prior mean - best guess for \\(\\theta\\) using information other than \\(\\mathbf{y}\\)\n\\(\\tau_0\\) is the prior precision and expresses our certainty about this guess\none notion of non-informative is to let \\(\\tau_0 \\to 0\\)\nbetter justification is as Jeffreys’ prior (uniform measure)\n\\(\\pi(\\theta) \\propto 1\\)\nparameterization invariant and invariant to location/scale changes in the data (group invariance)\n\n\n\n\n\n\n\n\nExercise for the Energetic Student\n\n\nYou should be able to derive Jeffreys prior!"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#posterior-distribution-1-observaton",
    "href": "resources/slides/03-normal-predictive-distributions.html#posterior-distribution-1-observaton",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Posterior Distribution (1 observaton)",
    "text": "Posterior Distribution (1 observaton)\n\nPosterior \\[p(\\theta \\mid y) \\propto \\exp\\left\\{- \\frac 1 2 [\\tau (y - \\theta) ^2 + \\tau_0(\\theta - \\theta_0) ^2 \\right\\} \\, d\\theta\\]\nQuadratic in exponential term: \\(\\tau_0(\\theta - \\theta_0)^2 = \\tau_0 \\theta^2 - 2 \\tau_0 \\theta_0 \\theta + \\tau_0 \\theta_0^2\\)\n\nExpand quadratics, regroup and read off precision from quadtric term in \\(\\theta\\) and mean from linear term in \\(\\theta\\)\n\nposterior precision is the sum of prior precision and data precision \\(\\tau_0 + \\tau\\)\nposterior mean \\(\\hat{\\theta} = \\frac{\\tau_0} {\\tau_0 + \\tau} \\theta_0 + \\frac{\\tau}{\\tau_0 + \\tau} y\\); precision weighted average of prior mean and MLE\nconjugate family updating \\(\\theta \\mid y \\sim \\textsf{N} \\left(\\hat{\\theta}, \\frac{1}{\\tau_0 + \\tau} \\right)\\)"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#marginal-distribution",
    "href": "resources/slides/03-normal-predictive-distributions.html#marginal-distribution",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Marginal Distribution",
    "text": "Marginal Distribution\n\nRecall that the marginal distribution is \\[p({y}) = p(y_1,\\ldots,y_n) = \\int_\\Theta p(y_1,\\ldots,y_n \\mid \\theta) \\pi(\\theta)\\, d\\theta\\]\nthis is also called the prior predictive distribution and is independent of any unknown parameters\nWe may care about making predictions before we even see any data.\nThis is often useful as a way to see if the sampling distribution or prior we have chosen is appropriate, after integrating out all unknown parameters."
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#prior-predictive-for-a-single-case",
    "href": "resources/slides/03-normal-predictive-distributions.html#prior-predictive-for-a-single-case",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Prior Predictive for a Single Case",
    "text": "Prior Predictive for a Single Case\n\\[\\begin{split} p(y) & \\propto \\int_\\mathbb{R} p(y \\mid \\theta) \\pi(\\theta) \\, d\\theta \\\\\n& \\propto \\int_\\mathbb{R}\\exp\\left\\{- \\frac 1 2 \\tau (y - \\theta) ^2 \\right\\} \\exp\\left\\{-  \\frac 1 2 \\tau_0(\\theta - \\theta_0) ^2 \\right\\} \\, d\\theta\n\\end{split}\\]\n\n\n\nIntegration\n\nExpand quadratics in exp terms\nGroup terms with \\(\\theta^2\\) and \\(\\theta\\)\nRead off posterior precision and\nposterior mean\nComplete the square\nIntegrate out \\(\\theta\\) to obtain marginal!\n\n\n\nLinear combinations of Normals are Normal! \\[Y \\stackrel{D}{=} \\theta + \\epsilon, \\quad \\epsilon \\sim N(0, 1/\\tau) \\quad \\theta \\sim N(\\theta_0, 1/\\tau_0)\\]\nFind Mean of sum\nFind Variance of sum\nMarginal \\(Y \\sim N(\\theta_0, 1/\\tau_0 + 1/\\tau)\\)"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#prior-predictive",
    "href": "resources/slides/03-normal-predictive-distributions.html#prior-predictive",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Prior Predictive",
    "text": "Prior Predictive\n\nmarginal distribution for \\(Y\\) (prior predictive) \\[Y \\sim \\textsf{N}\\left(\\theta_0, \\frac{1}{\\tau_0} + \\frac{1}{\\tau}\\right) \\text{ or } \\textsf{N}(\\theta_0, \\sigma^2 + \\sigma^2_0)\\]\ntwo sources of variability: data variability and prior variability\nuseful to think about observable quantities when choosing the prior\nsample directly from the prior predictive and assess whether the samples are consistent with our prior knowledge\nif not, go back and modify the prior & repeat\nsequential substitution sampling (repeat \\(T\\) times)\n\ndraw \\(\\theta^{(t)} \\sim \\pi(\\theta)\\)\ndraw \\(y^{(t)} \\mid \\theta^{(t)} \\sim p(y \\mid \\theta^{(t)})\\)\n\ntakes into account uncertain about \\(\\theta\\) and variability in \\(Y\\)!"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#posterior-updating",
    "href": "resources/slides/03-normal-predictive-distributions.html#posterior-updating",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Posterior Updating",
    "text": "Posterior Updating\n\nSequential updating using the previous result as our prior!\nNew prior after seeing 1 observation is \\[\\textsf{N}(\\theta_1, 1/\\tau_1)\\]\nprior mean weighted average \\[\\theta_1 \\equiv \\frac{\\tau_0 \\theta_0 + \\tau y_1}{\\tau_0 + \\tau_1}\\]\nprior precision after 1 observation \\[\\tau_1 \\equiv \\tau_0 + \\tau\\]\nprior variance is now \\(\\sigma^2_1 = 1/\\tau_1\\)"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#posterior-predictive-for-y_2-given-y_1",
    "href": "resources/slides/03-normal-predictive-distributions.html#posterior-predictive-for-y_2-given-y_1",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Posterior Predictive for \\(y_2\\) given \\(y_1\\)",
    "text": "Posterior Predictive for \\(y_2\\) given \\(y_1\\)\n\nConditional \\(p(y_2 \\mid y_1) = p(y_2, y_1)/p(y_1)\\) (Hard way!)\nUse latent variable representation \\[p(y_2 \\mid y_1) = \\int_\\Theta \\frac{p(y_2, \\mid \\theta) p( y_1 \\mid \\theta ) \\pi(\\theta) \\, d\\theta}{p(y_1)}\\]\nsimplify to previous problem and use results \\[p(y_2 \\mid y_1) =  \\int_\\Theta p(y_2 \\mid \\theta) \\pi(\\theta \\mid y_1) \\, d\\theta\\]\n(Posterior) Predictive \\[Y_2 \\mid y_1 \\sim \\textsf{N}(\\theta_1, \\sigma^2 + \\sigma^2_1)\\]"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#iterated-expectations",
    "href": "resources/slides/03-normal-predictive-distributions.html#iterated-expectations",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Iterated Expectations",
    "text": "Iterated Expectations\nBased on expressions we have an exponential of a quadratic in \\(y_2\\) so know that distribution is Gaussian\n\nFind the mean and variance using iterated expectations:\nmean \\[\\textsf{E}[Y_2 \\mid y_1] = \\textsf{E}_{\\theta \\mid y_1}[\\textsf{E}_{Y_2 \\mid y_1, \\theta} [Y_2 \\mid y_1, \\theta] \\mid y_1]\\]\nConditional Variance \\(\\textsf{Var}[Y_2 \\mid y_1]\\)\nIterated expectations (prove!) \\[\\textsf{Var}[Y_2  \\mid y_1] = \\textsf{E}_{\\theta \\mid y_1}[\\textsf{Var}_{Y_2 \\mid y_1, \\theta} [Y_2 \\mid y_1, \\theta] \\mid y_1] + \\textsf{Var}_{\\theta \\mid y_1}[\\textsf{E}_{Y_2 \\mid y_1, \\theta} [Y_2 \\mid y_1, \\theta] \\mid y_1]\\]"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#updated-posterior-for-theta",
    "href": "resources/slides/03-normal-predictive-distributions.html#updated-posterior-for-theta",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Updated Posterior for \\(\\theta\\)",
    "text": "Updated Posterior for \\(\\theta\\)\n\\[p(\\theta \\mid y_1, y_2) \\propto p(y_2 \\mid \\theta) p(y_1 \\mid \\theta) \\pi(\\theta)\\]\n\\[p(\\theta \\mid y_1, y_2) \\propto  p(y_2 \\mid \\theta) p(\\theta \\mid y_1)\\]\n\nApply previous updating rules\n\nnew posterior mean \\[\\theta_2 = \\frac{\\tau_1 \\theta_1  + \\tau y_2}{\\tau_1 + \\tau} = \\frac{\\tau_0 \\theta_0 + 2 \\tau \\bar{y}}\n{\\tau_0 + 2 \\tau}\\]\nnew precision \\[ \\tau_2 = \\tau_1 + \\tau = \\tau_0 + 2 \\tau\\]"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#after-n-observations",
    "href": "resources/slides/03-normal-predictive-distributions.html#after-n-observations",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "After \\(n\\) observations",
    "text": "After \\(n\\) observations\n\nPosterior for \\(\\theta\\) \\[\\theta \\mid y_1, \\ldots, y_n \\sim \\textsf{N}\\left( \\frac{\\tau_0 \\theta_0 + n \\tau \\bar{y}}\n{\\tau_0 + n \\tau}, \\frac{1}{ \\tau_0 + n \\tau} \\right)\\]\nPosterior Predictive Distribution for \\(Y_{n+1}\\) \\[Y_{n+1} \\mid y_1, \\ldots, y_n \\sim \\textsf{N}\\left( \\frac{\\tau_0 \\theta_0 + n \\tau \\bar{y}}\n{\\tau_0 + n \\tau}, \\frac{1}{\\tau} + \\frac{1}{ \\tau_0 + n \\tau} \\right)\\]\nShrinkage of the MLE to the prior mean\nMore accurate estimation of \\(\\theta\\) as \\(n \\to \\infty\\) (reducible error)\nCannot reduce the error for prediction \\(Y_{n+1}\\) due to \\(\\sigma^2\\)\npredictive distribution for a next observation given everything we know - prior and likelihood"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#results-with-jeffreys-prior",
    "href": "resources/slides/03-normal-predictive-distributions.html#results-with-jeffreys-prior",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Results with Jeffreys’ Prior",
    "text": "Results with Jeffreys’ Prior\n\nWhat if \\(\\tau_0 \\to 0\\)? (or \\(\\sigma^2_0 \\to \\infty\\))\nPrior predictive \\(\\textsf{N}(\\theta_0, \\sigma^2_0 + \\sigma^2 )\\) (not proper in the limit)\nPosterior for \\(\\theta\\) (formal posterior) \\[\\theta \\mid y_1, \\ldots, y_n \\sim \\textsf{N}\\left( \\frac{\\tau_0 \\theta_0 + n \\tau \\bar{y}}\n{\\tau_0 + n \\tau}, \\frac{1}{ \\tau_0 + n \\tau} \\right)\\]\n\n\n\\[\\to  \\qquad \\theta \\mid y_1, \\ldots, y_n \\sim \\textsf{N}\\left( \\bar{y},\n\\frac{1}{n \\tau} \\right)\\]\n\nRecovers the MLE as the posterior mode!\nPosterior variance of \\(\\theta = \\sigma^2/n\\) (same as variance of the MLE)"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#posterior-predictive-distribution",
    "href": "resources/slides/03-normal-predictive-distributions.html#posterior-predictive-distribution",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Posterior Predictive Distribution",
    "text": "Posterior Predictive Distribution\n\nPosterior predictive distribution for \\(Y_{n+1}\\) \\[Y_{n+1} \\mid y_1, \\ldots, y_n \\sim \\textsf{N}\\left( \\frac{\\tau_0 \\theta_0 + n \\tau \\bar{y}}\n{\\tau_0 + n \\tau}, \\frac{1}{\\tau} + \\frac{1}{ \\tau_0 + n \\tau} \\right)\\]\nUnder Jeffreys’ prior \\[Y_{n+1} \\mid y_1, \\ldots, y_n \\sim \\textsf{N}\\left( \\bar{y}, \\sigma^2 (1 + \\frac{1}{n} )\\right)\\]\nCaptures extra uncertainty due to not knowing \\(\\theta\\) (compared to plug-in approach where we plug in MLE in sampling model!"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#comparing-estimators",
    "href": "resources/slides/03-normal-predictive-distributions.html#comparing-estimators",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Comparing Estimators",
    "text": "Comparing Estimators\n\nExpected loss (from frequentist perspective) of using Bayes Estimator\nPosterior mean is optimal under squared error loss (min Bayes Risk) [also absolute error loss]\nCompute Mean Square Error (or Expected Average Loss) \\[\\textsf{E}_{\\bar{y} \\mid \\theta}\\left[\\left(\\hat{\\theta} - \\theta \\right)^2 \\mid \\theta \\right]\\]\n\n\n\\[ = \\textsf{Bias}(\\hat{\\theta})^2 + \\textsf{Var}(\\hat{\\theta})\\]\n\nFor the MLE \\(\\bar{Y}\\) this is just the variance of \\(\\bar{Y}\\) or \\(\\sigma^2/n\\)"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#mse-for-bayes",
    "href": "resources/slides/03-normal-predictive-distributions.html#mse-for-bayes",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "MSE for Bayes",
    "text": "MSE for Bayes\n\nFrequentist Risk \\[\\textsf{E}_{\\bar{y} \\mid \\theta}\\left[\\left(\\hat{\\theta} - \\theta \\right)^2 \\mid \\theta \\right] = \\textsf{MSE} =  \\textsf{Bias}(\\hat{\\theta})^2 + \\textsf{Var}(\\hat{\\theta})\\]\nBias of Bayes Estimate \\[\\textsf{E}_{\\bar{Y} \\mid \\theta}\\left[ \\frac{\\tau_0 \\theta_0 + \\tau n \\bar{Y}}\n{\\tau_0  + \\tau n}\\right] =\n\\frac{\\tau_0(\\theta_0 - \\theta)}{\\tau_0 + \\tau n}\\]\nVariance \\[\\textsf{Var}\\left(\\frac{\\tau_0 \\theta_0 + \\tau n \\bar{Y}}{\\tau_0 + \\tau n} - \\theta  \\mid \\theta \\right)  = \\frac{\\tau n}{(\\tau_0 + \\tau n)^2}\\]\n(Frequentist) expected Loss when truth is \\(\\theta\\) \\[\\textsf{MSE} = \\frac{\\tau_0^2(\\theta - \\theta_0)^2 + \\tau n}{(\\tau_0 + \\tau n)^2}\\]"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#plot",
    "href": "resources/slides/03-normal-predictive-distributions.html#plot",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Plot",
    "text": "Plot\nBehavior ?"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#updating-with-n-observations",
    "href": "resources/slides/03-normal-predictive-distributions.html#updating-with-n-observations",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Updating with \\(n\\) Observations",
    "text": "Updating with \\(n\\) Observations\n\nCan update sequentially as before -or-\nWe can use the \\(\\cal{L}(\\theta)\\) based on \\(n\\) observations and repeat completing the square with the original prior \\(\\theta \\sim \\textsf{N}(\\theta_0, 1/\\tau_0)\\)\nsame answer!\nThe likelihood for \\(\\theta\\) is proportional to the sampling model \\[p(y \\mid \\theta,\\tau)  =\n\\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi}} \\tau^{\\frac{1}{2}}  \\exp{\\left\\{-\\frac{1}{2} \\tau (y_i-\\theta)^2\\right\\}}\\]\n\n\n\n\n\n\n\n\nExercise\n\n\nRewrite in terms of sufficient statistics!"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#exercises-for-practice",
    "href": "resources/slides/03-normal-predictive-distributions.html#exercises-for-practice",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Exercises for Practice",
    "text": "Exercises for Practice\n\n\n\n\n\n\nExercise 1\n\n\nUse \\(\\cal{L}(\\theta)\\) based on \\(n\\) observations and \\(\\pi(\\theta)\\) to find \\(\\pi(\\theta \\mid y_1, \\ldots, y_n)\\) based on the sufficient statistics\n\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\nUse \\(\\pi(\\theta \\mid y_1, \\ldots, y_n)\\) to find the posterior predictive distribution for \\(Y_{n+1}\\)"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#simplification",
    "href": "resources/slides/03-normal-predictive-distributions.html#simplification",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Simplification",
    "text": "Simplification\n\\[\\begin{split}\n\\cal{L}(\\theta) & \\propto \\tau^{\\frac{n}{2}} \\ \\exp\\left\\{-\\frac{1}{2} \\tau \\sum_{i=1}^n (y_i-\\theta)^2\\right\\}\\\\\n& \\propto \\tau^{\\frac{n}{2}} \\ \\exp\\left\\{-\\frac{1}{2} \\tau \\sum_{i=1}^n \\left[ (y_i-\\bar{y}) - (\\theta - \\bar{y}) \\right]^2 \\right\\}\\\\\n\\\\\n& \\propto \\tau^{\\frac{n}{2}} \\ \\exp\\left\\{-\\frac{1}{2} \\tau \\left[ \\sum_{i=1}^n (y_i-\\bar{y})^2 + \\sum_{i=1}^n(\\theta - \\bar{y})^2 \\right] \\right\\}\\\\\n& \\propto \\tau^{\\frac{n}{2}} \\ \\exp\\left\\{-\\frac{1}{2} \\tau \\left[ \\sum_{i=1}^n (y_i-\\bar{y})^2 + n(\\theta - \\bar{y})^2 \\right] \\right\\}\\\\\n& \\propto \\tau^{\\frac{n}{2}} \\ \\exp\\left\\{-\\frac{1}{2} \\tau s^2(n-1) \\right\\} \\ \\exp\\left\\{-\\frac{1}{2} \\tau n(\\theta - \\bar{y})^2 \\right\\}\n\\end{split}\\]\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/14-bayes-regression.html#conjugate-versus-semi-conjugate-normal-linear-regression-example",
    "href": "resources/slides/14-bayes-regression.html#conjugate-versus-semi-conjugate-normal-linear-regression-example",
    "title": "Lecture 14: Bayesian Regression",
    "section": "Conjugate versus Semi-Conjugate Normal Linear Regression Example",
    "text": "Conjugate versus Semi-Conjugate Normal Linear Regression Example\n\nSemi-Conjugate Model \\[\\begin{align*}\nY \\mid \\beta, \\phi & \\sim \\textsf{N}(X \\beta, \\phi^{-1} I_n) \\\\\n\\beta & \\sim \\textsf{N}(b_0, \\Phi_0^{-1}) \\\\\n\\phi & \\sim \\textsf{Gamma}(v_0/2, s_0/2)\n\\end{align*}\\]\nConjugate Normal-Gamma Model (Joint Posterior is also Normal-Gamma ) \\[\\begin{align*}\nY \\mid \\beta, \\phi & \\sim \\textsf{N}(X \\beta, \\phi^{-1} I_n) \\\\\n\\beta \\mid \\phi & \\sim \\textsf{N}(b_0, \\phi^{-1}\\Phi_0^{-1}) \\\\\n\\phi & \\sim \\textsf{Gamma}(v_0/2, s_0/2)\n\\end{align*}\\]\nConditional Normal for \\(\\beta \\mid \\phi, Y\\) and \\(\\phi \\mid Y\\) is Gamma (Show!)"
  },
  {
    "objectID": "resources/slides/14-bayes-regression.html#invariance-and-choice-of-meanprecision",
    "href": "resources/slides/14-bayes-regression.html#invariance-and-choice-of-meanprecision",
    "title": "Lecture 14: Bayesian Regression",
    "section": "Invariance and Choice of Mean/Precision",
    "text": "Invariance and Choice of Mean/Precision\n\nthe model in vector form \\(Y \\mid \\beta, \\phi \\sim \\textsf{N}_n (X\\beta, \\phi^{-1} I_n)\\)\nWhat if we transform the mean \\(X\\beta = X H H^{-1} \\beta\\) with new \\(X\\) matrix \\(\\tilde{X} = X H\\) where \\(H\\) is \\(p \\times p\\) and invertible and coefficients \\(\\tilde{\\beta} = H^{-1} \\beta\\).\nobtain the posterior for \\(\\tilde{\\beta}\\) using \\(Y\\) and \\(\\tilde{X}\\)\n\\[ Y \\mid  \\tilde{\\beta}, \\phi \\sim \\textsf{N}_n (\\tilde{X}\\tilde{\\beta}, \\phi^{-1} I_n)\\]\nsince \\(\\tilde{X} \\tilde{\\beta} = X H \\tilde{\\beta} = X \\beta\\) invariance suggests that the posterior for \\(\\beta\\) and \\(H \\tilde{\\beta}\\) should be the same\nplus the posterior of \\(H^{-1} \\beta\\) and \\(\\tilde{\\beta}\\) should be the same\n\n\n\n\n\n\n\n\nExercise for the Energetic Student\n\n\nWith some linear algebra, show that this is true for a normal prior if \\(b_0 = 0\\) and \\(\\Phi_0\\) is \\(k X^TX\\) for some \\(k\\)"
  },
  {
    "objectID": "resources/slides/14-bayes-regression.html#zellners-g-prior",
    "href": "resources/slides/14-bayes-regression.html#zellners-g-prior",
    "title": "Lecture 14: Bayesian Regression",
    "section": "Zellner’s g-prior",
    "text": "Zellner’s g-prior\n\nPopular choice is to take \\(k = \\phi/g\\) which is a special case of Zellner’s g-prior \\[\\beta \\mid \\phi, g \\sim \\textsf{N}\\left(0, \\frac{g}{\\phi} (X^TX)^{-1}\\right)\\]\nFull conditional \\[\\beta \\mid \\phi, g \\sim \\textsf{N}\\left(\\frac{g}{1 + g} \\hat{\\beta}, \\frac{1}{\\phi} \\frac{g}{1 + g} (X^TX)^{-1}\\right)\\]\none parameter \\(g\\) controls shrinkage\nif \\(\\phi \\sim \\textsf{Gamma}(v_0/2, s_0/2)\\) then posterior is \\[\\phi \\mid y_1, \\ldots, y_n \\sim \\textsf{Gamma}(v_n/2, s_n/2)\\]\nConjugate so we could skip Gibbs sampling and sample directly from gamma and then conditional normal!"
  },
  {
    "objectID": "resources/slides/14-bayes-regression.html#ridge-regression",
    "href": "resources/slides/14-bayes-regression.html#ridge-regression",
    "title": "Lecture 14: Bayesian Regression",
    "section": "Ridge Regression",
    "text": "Ridge Regression\n\nIf \\(X^TX\\) is nearly singular, certain elements of \\(\\beta\\) or (linear combinations of \\(\\beta\\)) may have huge variances under the \\(g\\)-prior (or flat prior) as the MLEs are highly unstable!\nRidge regression protects against the explosion of variances and ill-conditioning with the conjugate priors: \\[\\beta \\mid \\phi \\sim \\textsf{N}(0, \\frac{1}{\\phi \\lambda} I_p)\\]\nPosterior for \\(\\beta\\) (conjugate case) \\[\\beta \\mid \\phi, \\lambda, y_1, \\ldots, y_n \\sim\n\\textsf{N}\\left((\\lambda I_p + X^TX)^{-1} X^T Y,  \\frac{1}{\\phi}(\\lambda I_p + X^TX)^{-1}\n\\right)\\]"
  },
  {
    "objectID": "resources/slides/14-bayes-regression.html#bayes-regression",
    "href": "resources/slides/14-bayes-regression.html#bayes-regression",
    "title": "Lecture 14: Bayesian Regression",
    "section": "Bayes Regression",
    "text": "Bayes Regression\n\nPosterior mean (or mode) given \\(\\lambda\\) is biased, but can show that there always is a value of \\(\\lambda\\) where the frequentist’s expected squared error loss is smaller for the Ridge estimator than MLE!\nrelated to penalized maximum likelihood estimation\nChoice of \\(\\lambda\\)\nBayes Regression and choice of \\(\\Phi_0\\) in general is a very important problem and provides the foundation for many variations on shrinkage estimators, variable selection, hierarchical models, nonparameteric regression and more!\nBe sure that you can derive the full conditional posteriors for \\(\\beta\\) and \\(\\phi\\) as well as the joint posterior in the conjugate case!\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#last-time",
    "href": "resources/slides/02-loss-functions.html#last-time",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Last Time …",
    "text": "Last Time …\n\nIntroduction to “ingredients” of Bayesian analysis\nIllustrated a simple Beta-Binomial conjugate example\nPosterior \\(\\pi(\\theta \\mid y)\\) is a \\(\\textsf{Beta}(a + y, b + n - y )\\)\n\n\nToday …\n\nan introduction to loss functions\nBayes Risk\noptimal decisions and estimators"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#bayes-estimate",
    "href": "resources/slides/02-loss-functions.html#bayes-estimate",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Bayes estimate",
    "text": "Bayes estimate\n\nAs we’ve seen by now, having posterior distributions instead of one-number summaries is great for capturing uncertainty.\nThat said, it is still very appealing to have simple summaries, especially when dealing with clients or collaborators from other fields, who desire one.\n\nWhat if we want to produce a single “best” estimate of \\(\\theta\\)?\nWhat if we want to produce an interval estimate \\((\\theta_L, \\theta_U )\\)?\n\n\n\nThese would provide alternatives to the frequentist MLEs and confidence intervals"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#heuristically",
    "href": "resources/slides/02-loss-functions.html#heuristically",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Heuristically",
    "text": "Heuristically\n\n\n\n\n\n\n\n\n\n“best” estimate of \\(\\theta\\) is the maximum a posteriori estimate (MAP) or posterior mode\n\nwhat do we really mean by “best”?\n\nfind an interval such that \\(P(\\theta \\in ( \\theta_L, \\theta_U ) \\mid y) = 1- \\alpha\\)\n\nlots of intervals that satisfy this! which one is “best”?"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#loss-functions-for-estimators",
    "href": "resources/slides/02-loss-functions.html#loss-functions-for-estimators",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Loss Functions for Estimators",
    "text": "Loss Functions for Estimators\nIntroduce loss functions for decision making about what to report!\n\na loss function provides a summary for how bad an estimator \\(\\hat{\\theta}\\) is relative to the “true” value of \\(\\theta\\)\nSquared error loss \\((L2)\\)\n\\[l(\\theta, \\hat{\\theta}) = (\\hat{\\theta} - \\theta)^2\\]\nAbsolute error loss \\((L1)\\) \\[l(\\theta, \\hat{\\theta}) = |\\hat{\\theta} - \\theta|\\]\n\n\nBut how do we deal with the fact that we do not know \\(\\theta\\)?"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#bayes-risk",
    "href": "resources/slides/02-loss-functions.html#bayes-risk",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Bayes Risk",
    "text": "Bayes Risk\n\nBayes risk is defined as the expected loss of using \\(\\hat{\\theta}\\) averaging over the posterior distribution. \\[ R(\\hat{\\theta}) = \\textsf{E}_{\\pi(\\theta \\mid y)} [l(\\theta, \\hat{\\theta}) ]\\]\nthe Bayes optimal estimate \\(\\hat{\\theta}\\) is the estimator that has the lowest posterior expected loss or Bayes Risk\nDepends on choice of loss function\nFrequentist risk also exists for evaluating a given estimator under true value of \\(\\theta\\) \\[\\textsf{E}_{p(y \\mid \\theta_{\\textrm{true}})} [l(\\theta_{\\textrm{true}} , \\hat{\\theta}) )]\\]"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#squared-error-loss",
    "href": "resources/slides/02-loss-functions.html#squared-error-loss",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Squared Error Loss",
    "text": "Squared Error Loss\nA common choice for point estimation is squared error loss:\n\\[R(\\hat{\\theta}) = \\textsf{E}_{\\pi(\\theta \\mid y)} [l(\\theta, \\hat{\\theta}) ] = \\int_\\Theta (\\hat{\\theta} - \\theta)^2 \\pi(\\theta \\mid y) \\, d\\theta\\]\n\n\n\n\n\n\n\nLet’s work it out!\n\n\nExpand, take expectations of \\(R(\\hat{\\theta})\\) with respect to \\(\\theta\\) and factor as a quadratic to find the minimizer (or take derivatives)"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#steps",
    "href": "resources/slides/02-loss-functions.html#steps",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Steps",
    "text": "Steps\n\\[R(\\hat{\\theta}) = \\int_\\Theta (\\hat{\\theta}^2 - 2 \\hat{\\theta} \\theta + \\theta^2) \\pi(\\theta \\mid y) \\, d \\theta\\]\n\n\\[R(\\hat{\\theta}) = \\hat{\\theta}^2 - 2 \\hat{\\theta} \\int_\\Theta \\theta \\pi(\\theta \\mid y) \\, d\\theta +  \\int_\\Theta \\theta^2  \\pi(\\theta \\mid y) \\, d\\theta\\]\n\n\n\\[R(\\hat{\\theta}) = \\hat{\\theta}^2 - 2 \\hat{\\theta} \\textsf{E}[\\theta \\mid y] + \\textsf{E}[\\theta^2 \\mid y]\\]\n\n\n\\[R(\\hat{\\theta}) = \\hat{\\theta}^2 - 2 \\hat{\\theta} \\textsf{E}[\\theta \\mid y] +  \\textsf{E}[\\theta \\mid y]^2 - \\textsf{E}[\\theta \\mid y]^2 +  \\textsf{E}[\\theta^2 \\mid y]\\]\n\n\nQuadratic in \\(\\hat{\\theta}\\) minimized when \\(\\hat{\\theta} = \\textsf{E}[\\theta \\mid y]\\)\n\\(\\Rightarrow\\) posterior mean is the Bayes optimal estimator for \\(\\theta\\) under squared error loss\n\nIn the beta-binomial case for example, the optimal Bayes estimate under squared error loss is \\(\\hat{\\theta} = \\frac{a+y}{a+b+n}\\)"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#what-about-other-loss-functions",
    "href": "resources/slides/02-loss-functions.html#what-about-other-loss-functions",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "What about other loss functions?",
    "text": "What about other loss functions?\n\nClearly, squared error is only one possible loss function. An alternative is absolute loss, which has \\[l(\\theta, \\hat{\\theta})  = |\\theta - \\hat{\\theta}|\\]\nAbsolute loss places less of a penalty on large deviations & the resulting Bayes estimate is the posterior median.\nMedian is actually relatively easy to estimate.\nRecall that for a continuous random variable \\(Y\\) with cdf \\(F\\), the median of the distribution is the value \\(z\\), which satisfies \\[F(z) = \\Pr(Y\\leq z) = \\dfrac{1}{2}= \\Pr(Y\\geq z) = 1-F(z)\\]\nAs long as we know how to evaluate the CDF of the distribution we have, we can solve for \\(z\\)."
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#beta-binomial",
    "href": "resources/slides/02-loss-functions.html#beta-binomial",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Beta-Binomial",
    "text": "Beta-Binomial\n\nFor the beta-binomial model, the CDF of the beta posterior can be written as \\[F(z) = \\Pr(\\theta\\leq z | y) = \\int^z_0 \\textrm{Beta}(\\theta| a+y, b+n-y) d\\theta.\\]\nThen, if \\(\\hat{\\theta}\\) is the median, we have that \\(F(\\hat{\\theta}) = 0.5\\)\nTo solve for \\(\\hat{\\theta}\\), apply the inverse CDF \\[\\hat{\\theta} = F^{-1}(0.5)\\]\nIn R, that’s simply\n\n\n\nqbeta(0.5,a+y,b+n-y)\n\n\nFor other distributions, switch out the beta."
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#loss-functions-in-general",
    "href": "resources/slides/02-loss-functions.html#loss-functions-in-general",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Loss Functions in General",
    "text": "Loss Functions in General\n\nA loss function \\(l(\\theta, \\delta(y) )\\) is a function of the parameter \\(\\theta\\) and \\(\\delta(y)\\) based on just the data \\(y\\)\nFor example, \\(\\delta(y) = \\bar{y}\\) can be the decision to use the sample mean to estimate \\(\\theta\\), the true population mean.\n\\(l(\\theta, \\delta(y) )\\) determines the penalty for making the decision \\(\\delta(y)\\), if \\(\\theta\\) is the true parameter or state of nature; the loss function characterizes the price paid for errors.\nBayes optimal estimator or action is the estimator/action that minimizes the expected posterior loss marginalizing out any unknowns over posterior/predictive distribution."
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#map-estimator",
    "href": "resources/slides/02-loss-functions.html#map-estimator",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "MAP Estimator",
    "text": "MAP Estimator\n\nWhat about the MAP estimator? Is it an optimal Bayes estimator & under what choice of loss function?\n\\(L_\\infty\\) loss: \\[R_{\\infty}(\\hat{\\theta}) = \\lim_{p \\to \\infty} \\int_\\Theta (\\theta - \\hat{\\theta})^p \\pi(\\theta \\mid y) \\, d \\theta\\]\nEssentially saying that we need the estimator to be right on the truth or the error blows up!\nIs this a reasonable loss function?"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#interval-estimates",
    "href": "resources/slides/02-loss-functions.html#interval-estimates",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Interval Estimates",
    "text": "Interval Estimates\nRecall that a frequentist confidence interval \\([l(y), \\ u(y)]\\) has 95% frequentist coverage for a population parameter \\(\\theta\\) if, before we collect the data, \\[\\Pr[l(y) &lt; \\theta &lt; u(y) | \\theta] = 0.95.\\]\n\nThis means that 95% of the time, our constructed interval will cover the true parameter, and 5% of the time it won’t.\nThere is NOT a 95% chance your interval covers the true parameter once you have collected the data.\nIn any given sample, you don’t know whether you’re in the lucky 95% or the unlucky 5%. You just know that either the interval covers the parameter, or it doesn’t (useful, but not too helpful clearly).\nOften based on aysmptotics i.e use a Wald or other type of frequentist asymptotic interval \\(\\hat{\\theta} \\pm 1.96 \\,\\text{se}(\\hat{\\theta})\\)"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#bayesian-intervals",
    "href": "resources/slides/02-loss-functions.html#bayesian-intervals",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Bayesian Intervals",
    "text": "Bayesian Intervals\n\nWe want a Bayesian alternative to confidence intervals for some pre-specified value of \\(\\alpha\\)\nAn interval \\([l(y), \\ u(y)]\\) has \\(1 - \\alpha\\) 100% Bayesian coverage for \\(\\theta\\) if \\[\\Pr(\\theta \\in [l(y), \\ u(y)] \\mid y) = 1 - \\alpha\\]\nThis describes our information about where \\(\\theta\\) lies after we observe the data.\nFantastic! This is actually the interpretation people want to give to the frequentist confidence interval.\nBayesian interval estimates are often generally called credible intervals or credible sets.\n\n\nHow to choose \\([l(y), \\ u(y)]\\)?"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#bayesian-equal-tail-interval",
    "href": "resources/slides/02-loss-functions.html#bayesian-equal-tail-interval",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Bayesian Equal Tail Interval",
    "text": "Bayesian Equal Tail Interval\n\nThe easiest way to obtain a Bayesian interval estimate is to use posterior quantiles with equal tail areas. Often when researchers refer to a credible interval, this is what they mean.\nTo make a \\(100 \\times (1-\\alpha)%\\) equi-tail quantile-based credible interval, find numbers (quantiles) \\(\\theta_{\\alpha/2} &lt; \\theta_{1-\\alpha/2}\\) such that\n\n\\(\\Pr(\\theta &lt; \\theta_{\\alpha/2} \\mid y) = \\dfrac{\\alpha}{2}\\); and\n\\(\\Pr(\\theta &gt; \\theta_{1-\\alpha/2} \\mid y) = \\dfrac{\\alpha}{2}\\).\n\n\n\nConvenient conceptually and easy as we just take the \\(\\alpha/2\\) and \\(1 - \\alpha/2\\) quantiles of \\(\\pi(\\theta \\mid y)\\) as \\(l(y)\\) and \\(u(y)\\), respectively."
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#beta-binomial-equal-tailed-interval",
    "href": "resources/slides/02-loss-functions.html#beta-binomial-equal-tailed-interval",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Beta-Binomial Equal-tailed Interval",
    "text": "Beta-Binomial Equal-tailed Interval\n\n95% Equal -Tail Area interval is \\((0.02, 0.41)\\)"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#monte-carlo-version",
    "href": "resources/slides/02-loss-functions.html#monte-carlo-version",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Monte Carlo Version",
    "text": "Monte Carlo Version\n\nSuppose we don’t have \\(\\pi(\\theta \\mid y)\\) is a simple form, but we do have samples \\(\\theta_1, \\ldots, \\theta_T\\) from \\(\\pi(\\theta \\mid y)\\)\nWe can use these samples to obtain Monte Carlo (MC) estimates of posterior summaries \\[\\hat{\\theta} = \\textsf{E}[\\theta \\mid y] \\approx \\frac{1}{T} \\sum_{t= 1}^T \\theta_t\\]\nwhat about MC quantile estimates?\nFind the 2.5th and 97.5th percentile from the empirical distribution\n\n\n\ntheta = rbeta(1000, a + y, b + n - y)\nquantile(theta, c(0.025, 0.975))\n\n      2.5%      97.5% \n0.02141993 0.39572970"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#equal-tail-interval",
    "href": "resources/slides/02-loss-functions.html#equal-tail-interval",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Equal-Tail Interval",
    "text": "Equal-Tail Interval\n\nNote there are values of \\(\\theta\\) outside the quantile-based credible interval, with higher density than some values inside the interval."
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#hpd-region",
    "href": "resources/slides/02-loss-functions.html#hpd-region",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "HPD Region",
    "text": "HPD Region\n\nA \\(100 \\times (1-\\alpha)%\\) highest posterior density (HPD) region is a subset \\(s(y)\\) of the parameter space \\(\\Theta\\) such that\n\n\\(\\Pr(\\theta \\in s(y) \\mid y) = 1-\\alpha\\); and\nIf \\(\\theta_a \\in s(y)\\) and \\(\\theta_b \\notin s(y)\\), then \\(p(\\theta_a \\mid y) &gt; p(\\theta_b \\mid y)\\) (highest density set)\n\n\\(\\Rightarrow\\) All points in a HPD region have higher posterior density than points outside the region.\nThe basic idea is to gradually move a horizontal line down across the density, including in the HPD region all values of \\(\\theta\\) with a density above the horizontal line.\nStop moving the line down when the posterior probability of the values of \\(\\theta\\) in the region reaches \\(1-\\alpha\\)."
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#simulation-based-using-the-coda-package",
    "href": "resources/slides/02-loss-functions.html#simulation-based-using-the-coda-package",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Simulation Based using the coda Package",
    "text": "Simulation Based using the coda Package\n\n\n\n\n\n\n\n\n \n \n\nlibrary(coda)\nHPDinterval(as.mcmc(theta))\n\n           lower     upper\nvar1 0.005930904 0.3669906\nattr(,\"Probability\")\n[1] 0.95"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#properties-of-hpd-sets",
    "href": "resources/slides/02-loss-functions.html#properties-of-hpd-sets",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Properties of HPD Sets",
    "text": "Properties of HPD Sets\n\nShortest length interval (or volume) for the given coverage\nEquivalent to Equal-Tail Intervals if the posterior is unimodal and symmetric\nMay not be an interval if the posterior distribution is multi-modal\nIn general, not invariant under monotonic transformations of \\(\\theta\\). (Why?)\nMore computationally intensive to solve exactly!\n\n\n\n\n\n\n\n\nSee “The Bayesian Choice” by Christian Robert Section 5.5.5 for more info on Loss Functions for Interval Estimation"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#connections-between-bayes-and-mle-based-frequentist-inference",
    "href": "resources/slides/02-loss-functions.html#connections-between-bayes-and-mle-based-frequentist-inference",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Connections between Bayes and MLE Based Frequentist Inference",
    "text": "Connections between Bayes and MLE Based Frequentist Inference\nBerstein von Mises (BvM) Theorems) aka Bayesian Central Limit Theorems\n\nexamine limiting form of the posterior distribution \\(\\pi(\\theta \\mid y)\\) as \\(n \\to \\infty\\)\n\\(\\pi(\\theta \\mid y)\\) goes to a Gaussian under regularity conditions\n\ncentered at the MLE\nvariance given by the inverse of the Expected Fisher Information (var of MLE)\n\nThe most important implication of the BvM is that Bayesian inference is asymptotically correct from a frequentist point of view\nUsed to justify Normal Approximations to the posterior distribution (eg Laplace approximations)"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#model-misspecification",
    "href": "resources/slides/02-loss-functions.html#model-misspecification",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Model Misspecification ?",
    "text": "Model Misspecification ?\n\nWe might have chosen a bad sampling model/likelihood\nposterior still converges to a Gaussian centered at the MLE under the misspecified model, but wrong variance\n95% Bayesian credible sets do not have correct frequentist coverage\nSee Klein & van der Vaart for more rigorous treatment if interested\nparametric model is “close” to the true data-generating process\nmodel diagnostics & changing the model can reduce the gap between model we are using and the true data generating process\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#uses-of-posterior-predictive",
    "href": "resources/slides/04-predictive-checks.html#uses-of-posterior-predictive",
    "title": "Prior/Posterior Checks",
    "section": "Uses of Posterior Predictive",
    "text": "Uses of Posterior Predictive\n\nPlot the entire density or summarize\nAvailable analytically for conjugate families\nMonte Carlo Approximation \\[p(y_{n+1} \\mid y_1, \\ldots y_n) \\approx \\frac 1 T \\sum_{t = 1}^T  p(y_{n+1} \\mid \\theta^{(t)})\\] where \\(\\theta^{(t)} \\sim \\pi(\\theta \\mid y_1, \\ldots y_n)\\) for \\(t = 1, \\ldots, T\\)\nT samples from the posterior distribution\nEmpirical Estimates & Quantiles from Monte Carlo Samples"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#models",
    "href": "resources/slides/04-predictive-checks.html#models",
    "title": "Prior/Posterior Checks",
    "section": "Models",
    "text": "Models\n\nSo far this all assumes we have a correct sampling model and a “reasonable” prior distrbution\nGeorge Box: All models are wrong but some are useful\n“Useful” \\(\\rightarrow\\) model provides a good approximation; there aren’t clear aspects of the data that are ignored or misspecified\nhow can we decide if a model is misspecified and needs to change?"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#example",
    "href": "resources/slides/04-predictive-checks.html#example",
    "title": "Prior/Posterior Checks",
    "section": "Example",
    "text": "Example\n\nPoisson model \\[Y_i  \\mid \\theta \\stackrel{iid}{\\sim }\\textsf{Poisson}(\\theta) \\qquad i = 1, \\ldots, n\\]\nHow might our model be misspecified?\n\nPoisson assumes that \\(\\textsf{E}(Y_i) = \\textsf{Var}(Y_i) = \\theta\\)\nit’s very common for data to be over-dispersed \\(\\textsf{E}(Y_i) &lt; \\textsf{Var}(Y_i)\\)\nignored additional structure in the data, i.e. data are not iid\nzero-inflation many more zero values than consistent with the poisson model"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#posterior-predictive-checks",
    "href": "resources/slides/04-predictive-checks.html#posterior-predictive-checks",
    "title": "Prior/Posterior Checks",
    "section": "Posterior Predictive Checks",
    "text": "Posterior Predictive Checks\n\nGuttman (1967), Rubin (1984) proposed the use of Posterior Predictive Checks (PPC)] for model criticism; further developed by Gelman et al (1996)\nthe spirit of posterior predictive checks is that “If my model is good, then its posterior predictive distribution will generate data that look like my oberved data”\n\\(y^{\\text{obs}}\\) is the observed data\n\\(y^{\\text{rep}}\\) is a new dataset sampled from the posterior predictive \\(p(y^{\\text{rep}} \\mid y^{\\text{obs}})\\) of size \\(n\\) (same size as the observed)\nUse a diagnostic statistic \\(d(y)\\) to capture some feature of the data that the model may fail to capture, say variance\ncompare \\(d(y^{\\text{obs}})\\) to the reference distribution of \\(d(y^{\\text{rep}})\\)\nUse Posterior Predictive P-value as a summary \\[ p_{PPC} = P(d(y^{\\text{obs}}) &gt; d(y^{\\text{rep}}) \\mid y^{\\text{obs}})\n\\]"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#formally",
    "href": "resources/slides/04-predictive-checks.html#formally",
    "title": "Prior/Posterior Checks",
    "section": "Formally",
    "text": "Formally\n\nchoose a “diagnostic statistic” \\(d(\\cdot)\\) that captures some summary of the data, e.g. \\(\\textsf{Var}(y)\\) for over-dispersion, where large values of the statistic would be surprising if the model were correct.\n\\(d(y^{\\text{obs}}) \\equiv d_{\\textrm{obs}}\\) value of statistic in observed data\n\\(d(y^{\\text{rep}}_t) \\equiv d_{\\textrm{pred}}\\) value of statistic for the \\(t\\)th random dataset drawn from the posterior predictive distribution\n\nGenerate \\(\\theta_t \\stackrel{iid}{\\sim}p(\\theta \\mid y^{\\textrm{obs}})\\)\nGenerate \\(y^{\\textrm{rep}_t} \\mid \\theta_t \\stackrel{iid}{\\sim} p(y \\mid \\theta_t)\\)\nCalculate \\(d(y^{\\text{rep}}_t)\\)\n\nplot posterior predictive distribution of \\(d(y^{\\text{rep}}_t)\\) and add \\(d_{\\textrm{obs}}\\)\nHow extreme is \\(t_{\\textrm{obs}}\\) compared to the distribution of \\(d(y^{\\text{rep}})\\)?\ncompute p-value \\(p_{PPC} = \\frac 1 T \\sum_t I(d(y^{\\text{obs}}) &gt; d(y^{\\text{rep}}_t))\\)"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#example-with-over-dispersion",
    "href": "resources/slides/04-predictive-checks.html#example-with-over-dispersion",
    "title": "Prior/Posterior Checks",
    "section": "Example with Over Dispersion",
    "text": "Example with Over Dispersion\n\n\n\nn = 100; phi = 1; mu = 5\ntheta.t = rgamma(n,phi,phi/mu)\ny = rpois(n, theta.t)\na = 1; b = 1;\nt.obs = var(y)\n\nnT = 10000\nt.pred = rep(NA, nT)\nfor (t in 1:nT) {\n  theta.post = rgamma(1, a + sum(y),\n                         b + n)\n  y.pred = rpois(n, theta.post)\n  t.pred[t] = var(y.pred)\n}\n\nhist(t.pred, \n     xlim = range(c(t.pred, t.obs)),\n     xlab=\"var\", \n     main=\"Posterior Predictive Distribution\")\n\nabline(v = t.obs, col=\"red\")"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#zero-inflated-distribution",
    "href": "resources/slides/04-predictive-checks.html#zero-inflated-distribution",
    "title": "Prior/Posterior Checks",
    "section": "Zero Inflated Distribution",
    "text": "Zero Inflated Distribution\n\n\n\n\n\n\n\n\n\n\n\n\nR Code to generate zero inflated\n\nn = 1000\nmu = 5; phi = 1\ntheta.t = rgamma(n,phi,phi/mu)\nz = rbinom(n, 1, .90)\ny = rpois(n, theta.t)*z\n\n\nLet the \\(d()\\) be the proportion of zeros in the sample \\[\\begin{aligned}\nd(y) & = \\frac{\\sum_{i = 1}^{n}1(y_i = 0)}{n} \\\\\n   & = 0.24\n\\end{aligned}\\]"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#posterior-predictive-distribution",
    "href": "resources/slides/04-predictive-checks.html#posterior-predictive-distribution",
    "title": "Prior/Posterior Checks",
    "section": "Posterior Predictive Distribution",
    "text": "Posterior Predictive Distribution"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#posterior-predictive-p-values-ppps",
    "href": "resources/slides/04-predictive-checks.html#posterior-predictive-p-values-ppps",
    "title": "Prior/Posterior Checks",
    "section": "Posterior Predictive p-values (PPPs)",
    "text": "Posterior Predictive p-values (PPPs)\n\np-value is probability of seeing something as extreme or more so under a hypothetical “null” model\nfrom a frequentist perspect, one appealing property of p-values is that they should be uniformally distributed under the “null” model\nPPPs advocated by Gelman & Rubin in papers and BDA are not valid p-values generally. They are do not have a uniform distribution under the hypothesis that the model is correctly specified\nthe PPPs tend to be concentrated around 0.5, tend not to reject (conservative)\ntheoretical reason for the incorrect distribution is due to double use of the data\nDO NOT USE as a formal test! use as a diagnostic plot to see how model might fall flat, but be cautious!"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#example-bivariate-normal",
    "href": "resources/slides/04-predictive-checks.html#example-bivariate-normal",
    "title": "Prior/Posterior Checks",
    "section": "Example: Bivariate Normal",
    "text": "Example: Bivariate Normal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPPP = 0.52\nWhat’s happening?"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#problems-with-ppc",
    "href": "resources/slides/04-predictive-checks.html#problems-with-ppc",
    "title": "Prior/Posterior Checks",
    "section": "Problems with PPC",
    "text": "Problems with PPC\n\nBayarri & Berger (2000) provides more discussion about why PPP are not always calibrated\nDouble use of the data; \\(Y^{\\text{rep}}\\) depends on the observed diagnostic in last case\nBayarri & Berger propose partial predictive p-values and conditional predictive p-values that avoid double use of the data by “removing” the contribution of \\(d_{\\text{obs}}\\) to the posterior for \\(\\theta\\) or conditioning on a statistic, such as the MLE of \\(\\theta\\)\nheuristically, need the diagnostic to be independent of posterior for \\(\\theta\\) (asymptoptically) under the assumed model\nnot always easy to find!\nMoran et al (2022) propose a workaround to avoid double use of the data by spliting the data \\(y_{\\text{obs}}, y_{\\text{new}}\\), use \\(y_{\\text{obs}}\\), to learn \\(\\theta\\) and the other to calculate \\(d_{\\textrm{new}}\\)\ncan be calculated via simulation easily"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#pop-pc-of-moran-et-al",
    "href": "resources/slides/04-predictive-checks.html#pop-pc-of-moran-et-al",
    "title": "Prior/Posterior Checks",
    "section": "POP-PC of Moran et al",
    "text": "POP-PC of Moran et al\n\n\nPOP-PPC = 0.35"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#modeling-over-dispersion",
    "href": "resources/slides/04-predictive-checks.html#modeling-over-dispersion",
    "title": "Prior/Posterior Checks",
    "section": "Modeling Over-Dispersion",
    "text": "Modeling Over-Dispersion\n\nOriginal Model \\(Y_i \\mid \\theta \\sim \\textsf{Poisson}(\\theta)\\)\ncause of overdispersion is variation in the rate \\[ Y_i \\mid \\theta_i \\sim \\textsf{Poisson}(\\theta_i)\\]\nmodel variation via prior \\[\\theta_i \\sim \\pi_\\theta()\\]\n\\(\\pi_\\theta()\\) characterizes variation in the rate parameter across inviduals\nSimple Two Stage Hierarchical Model"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#modeling-perspectives",
    "href": "resources/slides/04-predictive-checks.html#modeling-perspectives",
    "title": "Prior/Posterior Checks",
    "section": "Modeling Perspectives",
    "text": "Modeling Perspectives\n\n\n\nstart with a simple model\n\n\nask if there are surprises through Posterior Checks\nneed calibrated diagnostic(s) with good power\nneed these to work even if starting model is relatively complex\nother informal diagnostics (residuals)\nremodel if needed based on departures\nBayesian meaning?\n\n\n\nstart with a fairly complex model or models\n\n\nshrinkage to prevent overfitting\nformal tests for simplifying models\nmethods to combine multiple models to express uncertaity\nproperties"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#example-1",
    "href": "resources/slides/04-predictive-checks.html#example-1",
    "title": "Prior/Posterior Checks",
    "section": "Example",
    "text": "Example\n\\[\\theta_i \\sim \\textsf{Gamma}(\\phi \\mu, \\phi)\\]\n\nFind pmf for \\(Y_i \\mid \\mu, \\phi\\)\nFind \\(\\textsf{E}[Y_i \\mid \\mu, \\phi]\\) and \\(\\textsf{Var}[Y_i \\mid \\mu, \\phi]\\)\nHomework: \\[\\theta_i \\sim \\textsf{Gamma}(\\phi, \\phi/\\mu)\\]\nCan either of these model zero-inflation?\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": " Resources",
    "section": "",
    "text": "Supplementary Textbooks\nThese textbooks are great resources for some of the topics we will cover. You do not need to buy them, but you may be able to borrow them from Duke library should you need extra reading materials, besides the class slides and main textbooks.\n\nDoing Bayesian Data Analysis in brms and the tidyverse\nStatistical rethinking with brms, ggplot2, and the tidyverse: Second edition\nAlbert, J. (2009), “Bayesian Computation with R (Second Edition).”\nBolstad, W. M. and Curran, J. M. (2016), “Introduction to Bayesian Statistics (Third Edition).”\n\n\n\nR and R Markdown Resources\nR Markdown can be used to create high quality reports and presentations with embedded chunks of R code. You are required to use R Markdown to type up your lab reports. R Markdown would also be my personal favorite for typing up your homework assignments for this course, but you are welcome to use any word processor of your choice for those. To learn more about R Markdown and for other resources for programming in R, see the links below.\n\nR for Data Science (by Hadley Wickham & Garrett Grolemund)\nIntroduction to R Markdown (Article by Garrett Grolemund)\nIntroduction to R Markdown (Slides by Andrew Cho)\nR Markdown Cheat Sheet\nData Visualization with ggplot2 Cheat Sheet\nOther Useful Cheat Sheets\nA very (very!) basic R Markdown template\n\n\n\nLaTeX\nYou may also use LaTeX to type up your assignments. You may find it easier to create your TeX and LaTeX documents using online editors such as Overleaf (simply create a free account and you are good to go!). However, that need not be the case. If you prefer to create them locally/offline on your personal computers, you will need to download a TeX distribution (the most popular choices are MiKTeX for Windows and MacTeX for macOS) plus an editor (I personally prefer TeXstudio but feel free to download any editor of your choice). Follow the links below for some options, and to also learn how to use LaTeX.\n\nLearn LaTeX in 30 minutes\nChoosing a LaTeX Compiler.\n\n\n\nInteresting Articles\nI will add articles I find interesting below. These are articles I find useful as supplementary readings for topics covered in class, or as good sources that cover concepts I think you should know, but which we may not have time to cover. I strongly suggest you find time to (at the very least) take a “quick peek” at each article.\n\nEfron, B., 1986. Why isn’t everyone a Bayesian?. The American Statistician, 40(1), pp. 1-5.\nGelman, A., 2008. Objections to Bayesian statistics. Bayesian Analysis, 3(3), pp. 445-449.\nDiaconis, P., 1977. Finite forms of de Finetti’s theorem on exchangeability. Synthese, 36(2), pp. 271-281.\nGelman, A., Meng, X. L. and Stern, H., 1996. Posterior predictive assessment of model fitness via realized discrepancies. Statistica sinica, pp. 733-760.\nDunson, D. B., 2018. Statistics in the big data era: Failures of the machine. Statistics & Probability Letters, 136, pp. 4-9."
  },
  {
    "objectID": "reading/00-reading.html",
    "href": "reading/00-reading.html",
    "title": "Lecture 0: Readings to Pique Your Interest",
    "section": "",
    "text": "These are articles I find useful as supplementary readings for topics covered in class, or as good sources that cover concepts I think you should know, but which we may not have time to cover. I strongly suggest you find time to (at the very least) take a “quick peek” at each article.\n\nEfron, B., 1986. Why isn’t everyone a Bayesian?. The American Statistician, 40(1), pp. 1-5.\nGelman, A., 2008. Objections to Bayesian statistics. Bayesian Analysis, 3(3), pp. 445-449.\nDiaconis, P., 1977. Finite forms of de Finetti’s theorem on exchangeability. Synthese, 36(2), pp. 271-281.\nGelman, A., Meng, X. L. and Stern, H., 1996. Posterior predictive assessment of model fitness via realized discrepancies. Statistica sinica, pp. 733-760.\nDunson, D. B., 2018. Statistics in the big data era: Failures of the machine. Statistics & Probability Letters, 136, pp. 4-9."
  },
  {
    "objectID": "reading/00-reading.html#readings",
    "href": "reading/00-reading.html#readings",
    "title": "Lecture 0: Readings to Pique Your Interest",
    "section": "",
    "text": "These are articles I find useful as supplementary readings for topics covered in class, or as good sources that cover concepts I think you should know, but which we may not have time to cover. I strongly suggest you find time to (at the very least) take a “quick peek” at each article.\n\nEfron, B., 1986. Why isn’t everyone a Bayesian?. The American Statistician, 40(1), pp. 1-5.\nGelman, A., 2008. Objections to Bayesian statistics. Bayesian Analysis, 3(3), pp. 445-449.\nDiaconis, P., 1977. Finite forms of de Finetti’s theorem on exchangeability. Synthese, 36(2), pp. 271-281.\nGelman, A., Meng, X. L. and Stern, H., 1996. Posterior predictive assessment of model fitness via realized discrepancies. Statistica sinica, pp. 733-760.\nDunson, D. B., 2018. Statistics in the big data era: Failures of the machine. Statistics & Probability Letters, 136, pp. 4-9."
  },
  {
    "objectID": "reading/08-reading.html",
    "href": "reading/08-reading.html",
    "title": "Lecture 8: Gibbs Sampling, Blocked Samplers and Metropolis Hastings",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nChapter 6: Posterior approximation with the Gibbs sampler\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\nSection 10.4: Metropolis, Metropolis-Hastings and Gibbs\nSection 10.5: Combining the Metropolis and Gibbs algorithm\nSection 10.6: Discussion and further references\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 11.1: Gibbs sampler\nSection 11.2: Metropolis and Metropolis-Hastings algorithms\nSection 11.3: Using Gibbs and Metropolis as building blocks\nSection 11.7: Bibliographic note\nSection 14.1: Conditional modeling\nSection 14.2: Bayesian analysis of the classical regression model\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/08-reading.html#readings",
    "href": "reading/08-reading.html#readings",
    "title": "Lecture 8: Gibbs Sampling, Blocked Samplers and Metropolis Hastings",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nChapter 6: Posterior approximation with the Gibbs sampler\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\nSection 10.4: Metropolis, Metropolis-Hastings and Gibbs\nSection 10.5: Combining the Metropolis and Gibbs algorithm\nSection 10.6: Discussion and further references\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 11.1: Gibbs sampler\nSection 11.2: Metropolis and Metropolis-Hastings algorithms\nSection 11.3: Using Gibbs and Metropolis as building blocks\nSection 11.7: Bibliographic note\nSection 14.1: Conditional modeling\nSection 14.2: Bayesian analysis of the classical regression model\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/06-reading.html",
    "href": "reading/06-reading.html",
    "title": "Lecture 6: Introduction to Metropolis Algorithms and Diagnostics",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 10.1: Generalized linear models\n\nSection 10.2: The Metropolis algorithm\nSection 10.3: The Metropolis algorithm for Poisson regression\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 11.2 Metropolis and Metropolis-Hastings algorithms\nSection 11.4 Inference and Assessing Convergence\nSection 11.5 Effective number of simulations\nSection 11.6 Example\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\nSee also Dunson, D. & Johndrow, J. (2020) The Hastings algorithm at fifty. Biometrika,107: pp. 1–23"
  },
  {
    "objectID": "reading/06-reading.html#readings",
    "href": "reading/06-reading.html#readings",
    "title": "Lecture 6: Introduction to Metropolis Algorithms and Diagnostics",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 10.1: Generalized linear models\n\nSection 10.2: The Metropolis algorithm\nSection 10.3: The Metropolis algorithm for Poisson regression\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 11.2 Metropolis and Metropolis-Hastings algorithms\nSection 11.4 Inference and Assessing Convergence\nSection 11.5 Effective number of simulations\nSection 11.6 Example\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\nSee also Dunson, D. & Johndrow, J. (2020) The Hastings algorithm at fifty. Biometrika,107: pp. 1–23"
  },
  {
    "objectID": "reading/03-reading.html",
    "href": "reading/03-reading.html",
    "title": "Lecture 3: Normal Models and Predictive Distributions",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 5.1: The normal model\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 2.5: Normal Distribution with Known Variance (page 39)"
  },
  {
    "objectID": "reading/03-reading.html#readings",
    "href": "reading/03-reading.html#readings",
    "title": "Lecture 3: Normal Models and Predictive Distributions",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 5.1: The normal model\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 2.5: Normal Distribution with Known Variance (page 39)"
  },
  {
    "objectID": "reading/01-reading.html",
    "href": "reading/01-reading.html",
    "title": "Lecture 1: Basics of Bayesian inference",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 1: Introduction and examples\nSection 3.1: The binomial model\nSection 3.4: Discussion and further references\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin:\n\nSection 1.1: The three steps of Bayesian data analysis\nSection 1.2: General notation for statistical inference\nSection 1.3: Bayesian inference\nSection 1.9: Computation and software\nSection 1.10: Bayesian inference in applied statistics\nSection 2.1: Estimating a probability from binomial data\nSection 2.2: Posterior as compromise between data and prior information\nSection 2.4: Informative prior distributions"
  },
  {
    "objectID": "reading/01-reading.html#readings",
    "href": "reading/01-reading.html#readings",
    "title": "Lecture 1: Basics of Bayesian inference",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 1: Introduction and examples\nSection 3.1: The binomial model\nSection 3.4: Discussion and further references\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin:\n\nSection 1.1: The three steps of Bayesian data analysis\nSection 1.2: General notation for statistical inference\nSection 1.3: Bayesian inference\nSection 1.9: Computation and software\nSection 1.10: Bayesian inference in applied statistics\nSection 2.1: Estimating a probability from binomial data\nSection 2.2: Posterior as compromise between data and prior information\nSection 2.4: Informative prior distributions"
  },
  {
    "objectID": "reading/01-reading.html#optional",
    "href": "reading/01-reading.html#optional",
    "title": "Lecture 1: Basics of Bayesian inference",
    "section": "Optional",
    "text": "Optional\n\nBayesian Computation with R (Second Edition) by Jim Albert:\n\nSection 2: Introduction to Bayesian thinking"
  },
  {
    "objectID": "labs/lab-02-beta-binomial.html#rrstudio",
    "href": "labs/lab-02-beta-binomial.html#rrstudio",
    "title": "Lab 2: Beta-Binomial Model and Introduction to stan",
    "section": "R/RStudio",
    "text": "R/RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not and want to use your own computer, first install the latest version of R here: https://cran.rstudio.com remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "labs/lab-02-beta-binomial.html#r-knitr",
    "href": "labs/lab-02-beta-binomial.html#r-knitr",
    "title": "Lab 2: Beta-Binomial Model and Introduction to stan",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the Rnw format to type up this lab report. To get started see basics about knitr. Make sure to knit to pdf ; ask the TA about knitting to pdf if you cannot figure it out."
  },
  {
    "objectID": "labs/lab-02-beta-binomial.html#github-classroom",
    "href": "labs/lab-02-beta-binomial.html#github-classroom",
    "title": "Lab 2: Beta-Binomial Model and Introduction to stan",
    "section": "Github Classroom",
    "text": "Github Classroom\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github by the due date."
  },
  {
    "objectID": "labs/lab-02-beta-binomial.html#gradescope",
    "href": "labs/lab-02-beta-binomial.html#gradescope",
    "title": "Lab 2: Beta-Binomial Model and Introduction to stan",
    "section": "Gradescope",
    "text": "Gradescope\nYou must upload the final pdf from your Github repo to Gradescope.\nBe sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "labs/lab-01-r-review.html#rrstudio",
    "href": "labs/lab-01-r-review.html#rrstudio",
    "title": "Lab 1: R Review and Monte Carlo",
    "section": "R/RStudio",
    "text": "R/RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not and want to use your own computer, first install the latest version of R here: https://cran.rstudio.com remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "labs/lab-01-r-review.html#r-knitr",
    "href": "labs/lab-01-r-review.html#r-knitr",
    "title": "Lab 1: R Review and Monte Carlo",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the Rnw format to type up this lab report. To get started see basics about knitr. Make sure to knit to pdf ; ask the TA about knitting to pdf if you cannot figure it out."
  },
  {
    "objectID": "labs/lab-01-r-review.html#github-classroom",
    "href": "labs/lab-01-r-review.html#github-classroom",
    "title": "Lab 1: R Review and Monte Carlo",
    "section": "Github Classroom",
    "text": "Github Classroom\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github by the due date."
  },
  {
    "objectID": "labs/lab-01-r-review.html#gradescope",
    "href": "labs/lab-01-r-review.html#gradescope",
    "title": "Lab 1: R Review and Monte Carlo",
    "section": "Gradescope",
    "text": "Gradescope\nYou must upload the final pdf from your Github repo to Gradescope.\nBe sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "labs/lab-03.html#rrstudio",
    "href": "labs/lab-03.html#rrstudio",
    "title": "Lab 3: Posterior Predictive Checks",
    "section": "R/RStudio",
    "text": "R/RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not and want to use your own computer, first install the latest version of R here: https://cran.rstudio.com remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "labs/lab-03.html#r-knitr",
    "href": "labs/lab-03.html#r-knitr",
    "title": "Lab 3: Posterior Predictive Checks",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the Rnw format to type up this lab report. To get started see basics about knitr. Make sure to knit to pdf ; ask the TA about knitting to pdf if you cannot figure it out."
  },
  {
    "objectID": "labs/lab-03.html#github-classroom",
    "href": "labs/lab-03.html#github-classroom",
    "title": "Lab 3: Posterior Predictive Checks",
    "section": "Github Classroom",
    "text": "Github Classroom\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github by the due date."
  },
  {
    "objectID": "labs/lab-03.html#gradescope",
    "href": "labs/lab-03.html#gradescope",
    "title": "Lab 3: Posterior Predictive Checks",
    "section": "Gradescope",
    "text": "Gradescope\nYou must upload the final pdf from your Github repo to Gradescope.\nBe sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "hw/hw-02.html",
    "href": "hw/hw-02.html",
    "title": "Homework 2",
    "section": "",
    "text": "Please see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-02.html#due-1159pm-tues-sept-19",
    "href": "hw/hw-02.html#due-1159pm-tues-sept-19",
    "title": "Homework 2",
    "section": "",
    "text": "Please see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-02.html#rstudio",
    "href": "hw/hw-02.html#rstudio",
    "title": "Homework 2",
    "section": "RStudio",
    "text": "RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not, first install the latest version of R here: https://cran.rstudio.com (remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "hw/hw-02.html#r-knitr",
    "href": "hw/hw-02.html#r-knitr",
    "title": "Homework 2",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the .Rnw format to type up this lab report. To get started see basics about knitr."
  },
  {
    "objectID": "hw/hw-02.html#getting-started-with-github-classroom",
    "href": "hw/hw-02.html#getting-started-with-github-classroom",
    "title": "Homework 2",
    "section": "Getting started with Github Classroom",
    "text": "Getting started with Github Classroom\nGo to Github classroom to accept the invitation to create a repository for this assignment at HW2\nThis will create a private repo in the STA702-F23 organization on Github with your github user name. Note: You may receive an email invitation to join STA702-F23 on your behalf.\nHit refresh, to see the link for the repo, and then click on it to go to the STA702-F23 organization in Github.\nFollow the instructions in the README in your repo and in the hw*.Rnw file to complete the assignment and push to GitHub. If you encounter issues with Gradescope submission, it is critical that you have pushed your final assignment to GitHub by the due date to validate timestamps."
  },
  {
    "objectID": "hw/hw-02.html#gradescope-submission",
    "href": "hw/hw-02.html#gradescope-submission",
    "title": "Homework 2",
    "section": "Gradescope Submission",
    "text": "Gradescope Submission\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github and upload the pdf to Gradescope here: https://www.gradescope.com/courses/585736/assignments\nMake sure to knit to pdf; ask the TA about knitting to pdf if you cannot figure it out. Be sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "hw/hw-02.html#grading",
    "href": "hw/hw-02.html#grading",
    "title": "Homework 2",
    "section": "Grading",
    "text": "Grading\nTotal: 20 points."
  }
]