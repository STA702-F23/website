[
  {
    "objectID": "resources/slides/10-missing-data.html#introduction-to-missing-data",
    "href": "resources/slides/10-missing-data.html#introduction-to-missing-data",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Introduction to Missing Data",
    "text": "Introduction to Missing Data\n\nMissing data/nonresponse is fairly common in real data.\n\nFailure to respond to survey question\nSubject misses some clinic visits out of all possible\nOnly subset of subjects asked certain questions\n\nposterior computation usually depends on the data through \\(\\mathcal{p}(Y \\mid X, \\theta)\\), which can be difficult to compute (at least directly) when some of the \\(y_i\\) (multivariate \\(Y\\)) or \\(x^T_i\\) values are missing.\nMost software packages often throw away all subjects with incomplete data (can lead to bias and precision loss).\nSome individuals impute missing values with a mean or some other fixed value (ignores uncertainty).\nImputing missing data is actually quite natural in the Bayesian context."
  },
  {
    "objectID": "resources/slides/10-missing-data.html#missing-data-mechanisms",
    "href": "resources/slides/10-missing-data.html#missing-data-mechanisms",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Missing data mechanisms",
    "text": "Missing data mechanisms\n\nData are said to be missing completely at random (MCAR) if the reason for missingness does not depend on the values of the observed data or missing data.\nFor example, suppose\n\nyou handed out a double-sided survey questionnaire of 20 questions to a sample of participants;\nquestions 1-15 were on the first page but questions 16-20 were at the back; and\nsome of the participants did not respond to questions 16-20.\n\nThen, the values for questions 16-20 for those people who did not respond would be MCAR if they simply did not realize the pages were double-sided; they had no reason to ignore those questions.\nThis is rarely plausible in practice!"
  },
  {
    "objectID": "resources/slides/10-missing-data.html#missing-data-mechanisms-1",
    "href": "resources/slides/10-missing-data.html#missing-data-mechanisms-1",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Missing Data Mechanisms",
    "text": "Missing Data Mechanisms\n\nData are said to be missing at random (MAR) if, conditional on the values of the observed data, the reason for missingness does not depend on the missing data.\nUsing our previous example, suppose\n\nquestions 1-15 include demographic information such as age and education;\nquestions 16-20 include income related questions; and\nonce again, some participants did not respond to questions 16-20.\n\nThen, the values for questions 16-20 for those people who did not respond would be MAR if younger people are more likely not to respond to those income related questions than old people, where age is observed for all participants. (missingness reason must be independent of income)\nThis is the most commonly assumed mechanism in practice!"
  },
  {
    "objectID": "resources/slides/10-missing-data.html#missing-data-mechanisms-2",
    "href": "resources/slides/10-missing-data.html#missing-data-mechanisms-2",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Missing data mechanisms",
    "text": "Missing data mechanisms\n\nData are said to be missing not at random (MNAR or NMAR) if the reason for missingness depends on the actual values of the missing (unobserved) data.\nsuppose again that\nquestions 1-15 include demographic information such as age and education;\nquestions 16-20 include income related questions; and\nonce again, some of the participants did not respond to questions 16-20.\nThen, the values for questions 16-20 for those people who did not respond would be MNAR if people who earn more money are less likely to respond to those income related questions than those with lower incomes.\nThis is usually the case in real data, but analysis can be complex!"
  },
  {
    "objectID": "resources/slides/10-missing-data.html#multivariate-formulation",
    "href": "resources/slides/10-missing-data.html#multivariate-formulation",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Multivariate Formulation",
    "text": "Multivariate Formulation\n\nConsider the multivariate data scenario with \\(\\boldsymbol{Y}_i = (\\boldsymbol{Y}_1,\\ldots,\\boldsymbol{Y}_n)^T\\), where \\(\\boldsymbol{Y}_i = (Y_{i1},\\ldots,Y_{ip})^T\\), for \\(i = 1,\\ldots, n\\).\nFor now, we will assume the multivariate normal model as the sampling model, so that each \\(p\\) dimensional \\(\\boldsymbol{Y}_i = (Y_{i1},\\ldots,Y_{ip})^T \\sim \\mathcal{N}_p(\\boldsymbol{\\theta}, \\Sigma)\\). \\[p(\\boldsymbol{Y}_i \\mid \\boldsymbol{\\theta}, \\Sigma) = \\frac{|\\Sigma|^{-1/2}}{(2\\pi)^{p/2}} \\exp\\left\\{ -\\frac{1}{2} (\\boldsymbol{Y} - \\boldsymbol{\\theta})^T \\Sigma^{-1} (\\boldsymbol{Y} - \\boldsymbol{\\theta}) \\right\\}\\]\nSuppose now that \\(\\boldsymbol{Y}\\) contains missing values.\nWe can separate \\(\\boldsymbol{Y}\\) into the observed and missing parts so that for for each individual, \\[\\boldsymbol{Y}_i = (\\boldsymbol{Y}_{i,obs},\\boldsymbol{Y}_{i,mis})\\]"
  },
  {
    "objectID": "resources/slides/10-missing-data.html#mathematical-formulation",
    "href": "resources/slides/10-missing-data.html#mathematical-formulation",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Mathematical Formulation",
    "text": "Mathematical Formulation\n\nLet\n\n\\(j\\) index variables (where \\(i\\) already indexes individuals),\n\\(r_{ij} = 1\\) when \\(y_{ij}\\) is missing,\n\\(r_{ij} = 0\\) when \\(y_{ij}\\) is observed.\n\nHere, \\(r_{ij}\\) is known as the missingness indicator of variable \\(j\\) for person \\(i\\).\nAlso, let\n\n\\(\\boldsymbol{R}_i = (r_{i1},\\ldots,r_{ip})^T\\) be the vector of missing indicators for person \\(i\\).\n\\(\\boldsymbol{R} = (\\boldsymbol{R}_1,\\ldots,\\boldsymbol{R}_n)\\) be the matrix of missing indicators for everyone.\n\\(\\boldsymbol{\\psi}\\) be the set of parameters associated with \\(\\boldsymbol{R}\\).\n\nAssume \\(\\boldsymbol{\\psi}\\) and \\((\\boldsymbol{\\theta}, \\Sigma)\\) are distinct."
  },
  {
    "objectID": "resources/slides/10-missing-data.html#mathematical-formulation-1",
    "href": "resources/slides/10-missing-data.html#mathematical-formulation-1",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Mathematical Formulation",
    "text": "Mathematical Formulation\n\nMCAR: \\[p(\\boldsymbol{R} | \\boldsymbol{Y},\\boldsymbol{\\theta}, \\Sigma, \\boldsymbol{\\psi}) = p(\\boldsymbol{R} | \\boldsymbol{\\psi})\\]\nMAR: \\[p(\\boldsymbol{R} | \\boldsymbol{Y},\\boldsymbol{\\theta}, \\Sigma, \\boldsymbol{\\psi}) = p(\\boldsymbol{R} | \\boldsymbol{Y}_{obs},\\boldsymbol{\\psi})\\]\nMNAR: \\[p(\\boldsymbol{R} | \\boldsymbol{Y},\\boldsymbol{\\theta}, \\Sigma, \\boldsymbol{\\psi}) = p(\\boldsymbol{R} | \\boldsymbol{Y}_{obs},\\boldsymbol{Y}_{mis},\\boldsymbol{\\psi})\\]"
  },
  {
    "objectID": "resources/slides/10-missing-data.html#implications-for-likelihood-function",
    "href": "resources/slides/10-missing-data.html#implications-for-likelihood-function",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Implications for Likelihood Function",
    "text": "Implications for Likelihood Function\n\nEach type of mechanism has a different implication on the likelihood of the observed data \\(\\boldsymbol{Y}_{obs}\\), and the missing data indicator \\(\\boldsymbol{R}\\).\nWithout missingness in \\(\\boldsymbol{Y}\\), the likelihood of the observed data is \\[p(\\boldsymbol{Y}_{obs} | \\boldsymbol{\\theta}, \\Sigma)\\]\nWith missingness in \\(\\boldsymbol{Y}\\), the likelihood of the observed data is instead \\[\n\\begin{split}\np(\\boldsymbol{Y}_{obs}, \\boldsymbol{R} |\\boldsymbol{\\theta}, \\Sigma, \\boldsymbol{\\psi}) & = \\int p(\\boldsymbol{R} | \\boldsymbol{Y}_{obs},\\boldsymbol{Y}_{mis},\\boldsymbol{\\psi}) \\cdot p(\\boldsymbol{Y}_{obs},\\boldsymbol{Y}_{mis} | \\boldsymbol{\\theta}, \\Sigma) \\textrm{d}\\boldsymbol{Y}_{mis}\n\\end{split}\n\\]\nSince we do not actually observe \\(\\boldsymbol{Y}_{mis}\\), we would like to be able to integrate it out so we don’t have to deal with it and infer \\((\\boldsymbol{\\theta}, \\Sigma)\\) using only the observed data."
  },
  {
    "objectID": "resources/slides/10-missing-data.html#likelihood-function-mar",
    "href": "resources/slides/10-missing-data.html#likelihood-function-mar",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Likelihood function: MAR",
    "text": "Likelihood function: MAR\n\nFocus on MAR \\[\n\\begin{split}\np(\\boldsymbol{Y}_{obs}, \\boldsymbol{R} |\\boldsymbol{\\theta}, \\Sigma, \\boldsymbol{\\psi}) & = \\int p(\\boldsymbol{R} | \\boldsymbol{Y}_{obs},\\boldsymbol{Y}_{mis},\\boldsymbol{\\psi}) \\cdot p(\\boldsymbol{Y}_{obs},\\boldsymbol{Y}_{mis} | \\boldsymbol{\\theta}, \\Sigma) \\textrm{d}\\boldsymbol{Y}_{mis} \\\\\n& = \\int p(\\boldsymbol{R} | \\boldsymbol{Y}_{obs}, \\boldsymbol{\\psi}) \\cdot p(\\boldsymbol{Y}_{obs},\\boldsymbol{Y}_{mis} | \\boldsymbol{\\theta}, \\Sigma) \\textrm{d}\\boldsymbol{Y}_{mis} \\\\\n& = p(\\boldsymbol{R} | \\boldsymbol{Y}_{obs},\\boldsymbol{\\psi}) \\cdot \\int p(\\boldsymbol{Y}_{obs},\\boldsymbol{Y}_{mis} | \\boldsymbol{\\theta}, \\Sigma) \\textrm{d}\\boldsymbol{Y}_{mis} \\\\\n& = p(\\boldsymbol{R} | \\boldsymbol{Y}_{obs},\\boldsymbol{\\psi}) \\cdot p(\\boldsymbol{Y}_{obs} | \\boldsymbol{\\theta}, \\Sigma). \\\\\n\\end{split}\n\\]\nFor inference on \\((\\boldsymbol{\\theta}, \\Sigma)\\), we only need \\(p(\\boldsymbol{Y}_{obs} | \\boldsymbol{\\theta}, \\Sigma)\\) in the likelihood function for inference \\((\\boldsymbol{\\theta}, \\Sigma)\\).\nStill is hard, as we need marginal model!"
  },
  {
    "objectID": "resources/slides/10-missing-data.html#bayesian-inference-with-missing-data",
    "href": "resources/slides/10-missing-data.html#bayesian-inference-with-missing-data",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Bayesian Inference with Missing Data",
    "text": "Bayesian Inference with Missing Data\n\nFor posterior sampling for most models (especially multivariate models), sampling is easier with complete data \\(\\boldsymbol{Y}\\)’s to update the parameters.\nThink of the missing data as latent variables and sample from the posterior predictive distribution of the missing data conditional on the observed data and parameters: \\[\n\\begin{split}\np(\\boldsymbol{Y}_{mis} | \\boldsymbol{Y}_{obs},\\boldsymbol{\\theta}, \\Sigma) \\propto \\prod^n_{i=1} p(\\boldsymbol{Y}_{i,mis} | \\boldsymbol{Y}_{i,obs},\\boldsymbol{\\theta}, \\Sigma).\n\\end{split}\n\\]\nIn the case of the multivariate normal model, each \\(p(\\boldsymbol{Y}_{i,mis} | \\boldsymbol{Y}_{i,obs},\\boldsymbol{\\theta}, \\Sigma)\\) is just a normal distribution, and we can leverage results on conditional distributions for normal models."
  },
  {
    "objectID": "resources/slides/10-missing-data.html#model-for-missing-data",
    "href": "resources/slides/10-missing-data.html#model-for-missing-data",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Model for Missing Data",
    "text": "Model for Missing Data\n\nRewrite as \\(\\boldsymbol{Y}_i\\) in block form \\[\\begin{eqnarray*}\n\\boldsymbol{Y}_i =\n\\begin{pmatrix}\\boldsymbol{Y}_{i,mis}\\\\\n\\boldsymbol{Y}_{i,obs}\n\\end{pmatrix} & \\sim & \\mathcal{N}_p\\left[\\left(\\begin{array}{c}\n\\boldsymbol{\\theta}_1\\\\\n\\boldsymbol{\\theta}_2\n\\end{array}\\right),\\left(\\begin{array}{cc}\n\\Sigma_{11} & \\Sigma_{12} \\\\\n\\Sigma_{21} & \\Sigma_{22}\n\\end{array}\\right)\\right],\\\\\n\\end{eqnarray*}\\]\nMissing data has a conditional \\[\\boldsymbol{Y}_{i,mis} | \\boldsymbol{Y}_{i,obs} = \\boldsymbol{y}_{i,obs} \\sim \\mathcal{N}\\left(\\boldsymbol{\\theta}_1 + \\Sigma_{12}\\Sigma_{22}^{-1}  (\\boldsymbol{y}_{i,obs}-\\boldsymbol{\\theta}_2), \\Sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}\\right).\\]\nmultivariate normal distribution (or univariate normal distribution if \\(\\boldsymbol{Y}_i\\) only has one missing entry)\nThis sampling technique actually encodes MAR since the imputations for \\(\\boldsymbol{Y}_{mis}\\) depend on the \\(\\boldsymbol{Y}_{obs}\\)."
  },
  {
    "objectID": "resources/slides/10-missing-data.html#semi-conjugate-prior",
    "href": "resources/slides/10-missing-data.html#semi-conjugate-prior",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Semi-Conjugate Prior",
    "text": "Semi-Conjugate Prior\n\nWe need prior distributions for \\(\\boldsymbol{\\theta}\\) and \\(\\Sigma\\)\nMultivariate Normal Prior for \\(\\boldsymbol{\\theta} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}_0, \\Lambda_0^{-1})\\)\nAnalogous to the univariate case, the inverse-Wishart distribution is the corresponding conditionally conjugate prior for \\(\\Sigma\\) (multivariate generalization of the inverse-gamma).\nA random variable \\(\\Sigma \\sim \\textrm{IW}_p(\\eta_0, \\boldsymbol{S}_0^{-1})\\), where \\(\\Sigma\\) is positive definite and \\(p \\times p\\), has pdf \\[p(\\Sigma) \\propto  \\left|\\Sigma\\right|^{\\frac{-(\\eta_0 + p + 1)}{2}} \\textrm{exp} \\left\\{-\\frac{1}{2} \\textsf{tr}(\\boldsymbol{S}_0\\Sigma^{-1}) \\right\\}\\]\n\n\\(\\eta_0 &gt; p - 1\\) is the “degrees of freedom”, and\n\\(\\boldsymbol{S}_0\\) is a \\(p \\times p\\) positive definite matrix."
  },
  {
    "objectID": "resources/slides/10-missing-data.html#mean",
    "href": "resources/slides/10-missing-data.html#mean",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Mean",
    "text": "Mean\n\nFor this distribution, \\(E[\\Sigma] = \\frac{1}{\\eta_0 - p - 1} \\boldsymbol{S}_0\\), for \\(\\eta_0 &gt; p + 1\\).\nIf we are very confident in a prior guess \\(\\Sigma_0\\), for \\(\\Sigma\\), then we might set\n\n\\(\\eta_0\\), the degrees of freedom to be very large, and\n\\(\\boldsymbol{S}_0 = (\\eta_0 - p - 1)\\Sigma_0\\).\n\\(E[\\Sigma] = \\frac{1}{\\eta_0 - p - 1} \\boldsymbol{S}_0 = \\frac{1}{\\eta_0 - p - 1}(\\eta_0 - p - 1)\\Sigma_0 = \\Sigma_0\\), and \\(\\Sigma\\) is tightly (depending on the value of \\(\\eta_0\\)) centered around \\(\\Sigma_0\\).\n\nIf we are not at all confident but we still have a prior guess \\(\\Sigma_0\\), we might set\n\n\\(\\eta_0 = p + 2\\), so that the \\(E[\\Sigma] = \\frac{1}{\\eta_0 - p - 1} \\boldsymbol{S}_0\\) is finite.\n\\(\\boldsymbol{S}_0 = \\Sigma_0\\)"
  },
  {
    "objectID": "resources/slides/10-missing-data.html#alternatives",
    "href": "resources/slides/10-missing-data.html#alternatives",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Alternatives",
    "text": "Alternatives\n\nJeffreys prior (improper limiting case)\nunit-information (data dependent)\nSun, D. and Berger, J.O (2006) Objective Bayesian Analysis for the Multivariate Normal Model\nMulder, J. Pericchi, L.R. (2018) The Matrix-F Prior for Estimating and Testing Covariance Matrices."
  },
  {
    "objectID": "resources/slides/10-missing-data.html#wishart-distribution",
    "href": "resources/slides/10-missing-data.html#wishart-distribution",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Wishart distribution",
    "text": "Wishart distribution\n\nJust as we had with the gamma and inverse-gamma relationship in the univariate case, we can also work in terms of the Wishart distribution (multivariate generalization of the gamma) instead.\nThe Wishart distribution provides a conditionally-conjugate prior for the precision matrix \\(\\Sigma^{-1}\\) in a multivariate normal model.\nif \\(\\Sigma \\sim \\textrm{IW}_p(\\eta_0, \\boldsymbol{S}_0)\\), then \\(\\Phi = \\Sigma^{-1} \\sim \\textrm{W}_p(\\eta_0, \\boldsymbol{S}_0^{-1})\\).\nA random variable \\(\\Phi \\sim \\textrm{W}_p(\\eta_0, \\boldsymbol{S}_0^{-1})\\), where \\(\\Phi\\) has dimension \\((p \\times p)\\), has pdf \\[\\begin{align*}\nf(\\Phi) \\ \\propto \\ \\left|\\Phi\\right|^{\\frac{\\eta_0 - p - 1}{2}} \\textrm{exp} \\left\\{-\\frac{1}{2} \\text{tr}(\\boldsymbol{S}_0\\Phi) \\right\\}.\n\\end{align*}\\]\nHere, \\(E[\\Phi] = \\eta_0 \\boldsymbol{S}_0\\)."
  },
  {
    "objectID": "resources/slides/10-missing-data.html#conditional-posterior-for-sigma",
    "href": "resources/slides/10-missing-data.html#conditional-posterior-for-sigma",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Conditional posterior for \\(\\Sigma\\)",
    "text": "Conditional posterior for \\(\\Sigma\\)\n\\[\\begin{align}Y_i  \\mid  \\boldsymbol{\\theta}, \\Sigma & \\overset{ind}{\\sim} N(\\boldsymbol{\\theta}, \\Sigma)\\\\\n\\Sigma  & \\sim  \\textrm{IW}_p(\\eta_0, \\boldsymbol{S}_0^{-1}) \\\\\n\\boldsymbol{\\theta} & \\sim N(\\mu_0, \\Psi_0^{-1})\n\\end{align}\\]\n\nThe conditional posterior (full conditional) \\(\\Sigma \\mid \\boldsymbol{\\theta}, \\boldsymbol{Y}\\), is then \\[\\Sigma \\mid \\boldsymbol{\\theta}, \\boldsymbol{Y} \\sim \\textrm{IW}_p\\left(\\eta_0 + n, \\left(\\boldsymbol{S}_0+ \\sum_{i=1}^n (\\boldsymbol{Y}_i - \\boldsymbol{\\theta})(\\boldsymbol{Y}_i - \\boldsymbol{\\theta})^T\\right)^{-1} \\right)\\]\nposterior sample size \\(\\eta_0 + n\\)\nposterior sum of squares \\(\\boldsymbol{S}_0+ \\sum_{i=1}^n (\\boldsymbol{Y}_i - \\boldsymbol{\\theta})(\\boldsymbol{Y}_i - \\boldsymbol{\\theta})^T\\)"
  },
  {
    "objectID": "resources/slides/10-missing-data.html#posterior-derivation",
    "href": "resources/slides/10-missing-data.html#posterior-derivation",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Posterior Derivation",
    "text": "Posterior Derivation\n\nThe conditional posterior (full conditional) \\(\\Sigma \\mid \\boldsymbol{\\theta}, \\boldsymbol{Y}\\), is \\[\\begin{align*}\n\\pi(\\Sigma & \\mid \\boldsymbol{\\theta}, \\boldsymbol{Y})\\propto p(\\Sigma) \\cdot p( \\boldsymbol{Y}  \\mid \\boldsymbol{\\theta}, \\Sigma)\\\\\n& \\propto \\left|\\Sigma\\right|^{\\frac{-(\\eta_0 + p + 1)}{2}} \\textrm{exp} \\left\\{-\\frac{1}{2} \\text{tr}(\\boldsymbol{S}_0\\Sigma^{-1}) \\right\\} \\cdot \\prod_{i = 1}^{n}\\left|\\Sigma\\right|^{-\\frac{1}{2}} \\ \\textrm{exp} \\left\\{-\\frac{1}{2}\\left[(\\boldsymbol{Y}_i - \\boldsymbol{\\theta})^T \\Sigma^{-1} (\\boldsymbol{Y}_i - \\boldsymbol{\\theta})\\right] \\right\\} \\\\\n& \\\\\n& \\\\\n& \\\\\n&\n\\end{align*}\n\\]\n\n\n\\[\\Sigma \\mid \\boldsymbol{\\theta}, \\boldsymbol{Y} \\sim \\textrm{IW}_p\\left(\\eta_0 + n, \\left(\\boldsymbol{S}_0+ \\sum_{i=1}^n (\\boldsymbol{Y}_i - \\boldsymbol{\\theta})(\\boldsymbol{Y}_i - \\boldsymbol{\\theta})^T\\right)^{-1} \\right)\\]"
  },
  {
    "objectID": "resources/slides/10-missing-data.html#gibbs-sampler-with-missing-data",
    "href": "resources/slides/10-missing-data.html#gibbs-sampler-with-missing-data",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Gibbs sampler with missing data",
    "text": "Gibbs sampler with missing data\nAt iteration \\(s+1\\), do the following\n\nSample \\(\\boldsymbol{\\theta}^{(s+1)}\\) from its multivariate normal full conditional \\(p(\\boldsymbol{\\theta}^{(s+1)} | \\boldsymbol{Y}_{obs}, \\boldsymbol{Y}_{mis}^{(s)}, \\Sigma^{(s)})\\)\nSample \\(\\Sigma^{(s+1)}\\) from its inverse-Wishart full conditional \\(p(\\Sigma^{(s+1)} | \\boldsymbol{Y}_{obs}, \\boldsymbol{Y}_{mis}^{(s)}, \\boldsymbol{\\theta}^{(s+1)})\\)\nFor each \\(i = 1, \\ldots, n\\), with at least one “1” value in the missingness indicator vector \\(\\boldsymbol{R}_i\\), sample \\(\\boldsymbol{Y}_{i,mis}^{(s+1)}\\) from the full conditional \\[\\begin{align}\n\\boldsymbol{Y}_{i,mis}^{(s+1)}| \\boldsymbol{Y}_{i,obs},  \\boldsymbol{\\theta}^{(s+1)},  \\Sigma^{(s+1)}  \\sim \\mathcal{N}(& \\boldsymbol{\\theta}_1^{(s+1)} + \\Sigma_{12}^{(s+1)}{\\Sigma_{22}^{(s+1)}}^{-1}  (\\boldsymbol{Y}_{i,obs}-\\boldsymbol{\\theta}_2^{(s+1)}),  \\\\\n&  \\Sigma_{11}^{(s+1)} - \\Sigma_{12}^{(s+1)}{\\Sigma_{22}^{(s+1)}}^{-1}\\Sigma_{21}^{(s+1)})\n\\end{align}\\]\n\n\n\nderived from the original sampling model but with the updated parameters, \\(\\boldsymbol{Y}_i^{(s+1)} = (\\boldsymbol{Y}_{i,obs},\\boldsymbol{Y}_{i,mis}^{(s+1)})^T \\sim \\mathcal{N}_p(\\boldsymbol{\\theta}^{(s+1)}, \\Sigma^{(s+1)})\\)."
  },
  {
    "objectID": "resources/slides/10-missing-data.html#reading-example-from-hoff-with-missing-data",
    "href": "resources/slides/10-missing-data.html#reading-example-from-hoff-with-missing-data",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Reading example from Hoff with missing data",
    "text": "Reading example from Hoff with missing data\n\n\n      pretest posttest\n [1,]      59       77\n [2,]      43       39\n [3,]      34       46\n [4,]      32       NA\n [5,]      NA       38\n [6,]      38       NA\n [7,]      55       NA\n [8,]      67       86\n [9,]      64       77\n[10,]      45       60\n[11,]      49       50\n[12,]      72       59\n\n\n  pretest  posttest \n0.1363636 0.2272727"
  },
  {
    "objectID": "resources/slides/10-missing-data.html#mcmc-summary-for-sigma",
    "href": "resources/slides/10-missing-data.html#mcmc-summary-for-sigma",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "MCMC Summary for \\(\\Sigma\\)",
    "text": "MCMC Summary for \\(\\Sigma\\)\n\n\n\nIterations = 1:20000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 20000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean    SD Naive SE Time-series SE\nsigma_11 194.0 63.08   0.4460         0.4947\nsigma_12 152.1 60.75   0.4295         0.4665\nsigma_21 152.1 60.75   0.4295         0.4665\nsigma_22 248.7 83.70   0.5918         0.6884\n\n2. Quantiles for each variable:\n\n           2.5%   25%   50%   75% 97.5%\nsigma_11 106.45 149.8 182.4 224.1 349.8\nsigma_12  64.04 109.8 142.3 182.8 299.2\nsigma_21  64.04 109.8 142.3 182.8 299.2\nsigma_22 132.50 190.3 233.4 289.5 456.1"
  },
  {
    "objectID": "resources/slides/10-missing-data.html#compare-to-inference-from-full-data",
    "href": "resources/slides/10-missing-data.html#compare-to-inference-from-full-data",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Compare to inference from full data",
    "text": "Compare to inference from full data\n\nWith missing data:\n\n\n\n\n         theta_1  theta_2\nMin.    30.45459 38.29322\n1st Qu. 43.65988 51.96991\nMedian  45.60829 54.19592\nMean    45.63192 54.20408\n3rd Qu. 47.61896 56.48918\nMax.    58.81206 70.49105\n\n\n\nBased on true data:\n\n\n\n\n\n         theta_1  theta_2\nMin.    34.88365 37.80999\n1st Qu. 45.29473 51.47834\nMedian  47.28229 53.65172\nMean    47.26301 53.64100\n3rd Qu. 49.21423 55.81819\nMax.    60.94924 69.92354\n\n\n\nVery similar for the most part."
  },
  {
    "objectID": "resources/slides/10-missing-data.html#compare-to-inference-from-full-data-1",
    "href": "resources/slides/10-missing-data.html#compare-to-inference-from-full-data-1",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Compare to inference from full data",
    "text": "Compare to inference from full data\n\nWith missing data:\n\n\n\n\n        sigma_11  sigma_12  sigma_21  sigma_22\nMin.     64.0883 -20.39204 -20.39204  82.55346\n1st Qu. 149.8338 109.84218 109.84218 190.25962\nMedian  182.4496 142.34686 142.34686 233.43312\nMean    193.9803 152.12898 152.12898 248.67527\n3rd Qu. 224.0994 182.75082 182.75082 289.47663\nMax.    734.8704 668.77332 668.77332 981.99916\n\n\n\nBased on true data:\n\n\n\n\n\n        sigma_11  sigma_12  sigma_21  sigma_22\nMin.     76.4661 -38.75561 -38.75561  93.65776\n1st Qu. 157.5870 113.32529 113.32529 203.69192\nMedian  190.6578 145.08962 145.08962 246.08696\nMean    201.9547 155.20374 155.20374 260.11361\n3rd Qu. 233.5809 186.36991 186.36991 300.70840\nMax.    664.8241 577.99100 577.99100 947.39333\n\n\n\nAlso very similar. A bit more uncertainty in dimension of \\(Y_{i2}\\) because we have more missing data there."
  },
  {
    "objectID": "resources/slides/10-missing-data.html#posterior-distribution-of-the-mean",
    "href": "resources/slides/10-missing-data.html#posterior-distribution-of-the-mean",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Posterior distribution of the mean",
    "text": "Posterior distribution of the mean"
  },
  {
    "objectID": "resources/slides/10-missing-data.html#missing-data-vs-predictions-for-new-observations",
    "href": "resources/slides/10-missing-data.html#missing-data-vs-predictions-for-new-observations",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Missing data vs predictions for new observations",
    "text": "Missing data vs predictions for new observations\n\nHow about predictions for completely new observations?\nThat is, suppose your original dataset plus sampling model is \\(\\boldsymbol{y_i} = (y_{i,1},y_{i,2})^T \\sim \\mathcal{N}_2(\\boldsymbol{\\theta}, \\Sigma)\\), \\(i = 1, \\ldots, n\\).\nSuppose now you have \\(n^\\star\\) new observations with \\(y_{2}^\\star\\) values but no \\(y_{1}^\\star\\).\nHow can we predict \\(y_{i,1}^\\star\\) given \\(y_{i,2}^\\star\\), for \\(i = 1, \\ldots, n^\\star\\)?\nWell, we can view this as a “train \\(\\rightarrow\\) test” prediction problem rather than a missing data problem on an original data."
  },
  {
    "objectID": "resources/slides/10-missing-data.html#missing-data-vs-predictions-for-new-observations-1",
    "href": "resources/slides/10-missing-data.html#missing-data-vs-predictions-for-new-observations-1",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "Missing data vs predictions for new observations",
    "text": "Missing data vs predictions for new observations\n\nThat is, given the posterior samples of the parameters, and the test values for \\(y_{i2}^\\star\\), draw from the posterior predictive distribution of \\((y_{i,1}^\\star | y_{i,2}^\\star, \\{(y_{1,1},y_{1,2}), \\ldots, (y_{n,1},y_{n,2})\\})\\).\nTo sample from this predictive distribution, think of compositional sampling.\nfor each posterior sample of \\((\\boldsymbol{\\theta}, \\Sigma)\\), sample from \\((y_{i,1} | y_{i,2}, \\boldsymbol{\\theta}, \\Sigma)\\), which is just from the form of the sampling distribution.\nIn this case, \\((y_{i,1} | y_{i,2}, \\boldsymbol{\\theta}, \\Sigma)\\) is just a normal distribution derived from \\((y_{i,1}, y_{i,2} | \\boldsymbol{\\theta}, \\Sigma)\\), based on the conditional normal formula.\nNo need to incorporate the prediction problem into your original Gibbs sampler!"
  },
  {
    "objectID": "resources/slides/10-missing-data.html#mnar-likelihood-function",
    "href": "resources/slides/10-missing-data.html#mnar-likelihood-function",
    "title": "Multivariate Normal Models, Missing Data and Imputation",
    "section": "MNAR Likelihood function:",
    "text": "MNAR Likelihood function:\n\nFor MNAR, we have: \\[\n\\begin{split}\np(\\boldsymbol{Y}_{obs}, \\boldsymbol{R} |\\boldsymbol{\\theta}, \\Sigma, \\boldsymbol{\\psi}) & = \\int p(\\boldsymbol{R} | \\boldsymbol{Y}_{obs},\\boldsymbol{Y}_{mis},\\boldsymbol{\\psi}) \\cdot p(\\boldsymbol{Y}_{obs},\\boldsymbol{Y}_{mis} | \\boldsymbol{\\theta}, \\Sigma) \\textrm{d}\\boldsymbol{Y}_{mis} \\\\\n\\end{split}\n\\]\nThe likelihood under MNAR cannot simplify any further.\nIn this case, we cannot ignore the missing data when making inferences about \\((\\boldsymbol{\\theta}, \\Sigma)\\).\nWe must include the model for \\(\\boldsymbol{R}\\) and also infer the missing data \\(\\boldsymbol{Y}_{mis}\\).\nSo how can we tell the type of mechanism we are dealing with?\nIn general, we don’t know!!!\nRare that data are MCAR (unless planned beforehand); more likely that data are MNAR or MNAR.\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/18-outliers.html#body-fat-data",
    "href": "resources/slides/18-outliers.html#body-fat-data",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Body Fat Data",
    "text": "Body Fat Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhich analysis do we use? with Case 39 or not – or something different?"
  },
  {
    "objectID": "resources/slides/18-outliers.html#cooks-distance",
    "href": "resources/slides/18-outliers.html#cooks-distance",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Cook’s Distance",
    "text": "Cook’s Distance\n\nplot(bodyfat.lm, which=5)"
  },
  {
    "objectID": "resources/slides/18-outliers.html#options-for-handling-outliers",
    "href": "resources/slides/18-outliers.html#options-for-handling-outliers",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Options for Handling Outliers",
    "text": "Options for Handling Outliers\nWhat are outliers?\n\nAre there scientific grounds for eliminating the case?\nTest if the case has a different mean than population\nReport results with and without the case\nModel Averaging to Account for Model Uncertainty?\nFull model \\(\\mathbf{Y}= \\mathbf{X}\\boldsymbol{\\beta}+ \\mathbf{I}_n\\delta+ \\epsilon\\)\n\\(\\delta\\) is a \\(n \\times 1\\) vector; \\(\\boldsymbol{\\beta}\\) is \\(p \\times 1\\)\nAll observations have a potentially different mean!"
  },
  {
    "objectID": "resources/slides/18-outliers.html#outliers-in-bayesian-regression",
    "href": "resources/slides/18-outliers.html#outliers-in-bayesian-regression",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Outliers in Bayesian Regression",
    "text": "Outliers in Bayesian Regression\n\nHoeting, Madigan and Raftery (in various permutations) consider the problem of simultaneous variable selection and outlier identification\nThis is implemented in the package BMA in the function MC3.REG\nThis has the advantage that more than 2 points may be considered as outliers at the same time\nThe function uses a Markov chain to identify both important variables and potential outliers, but is coded in Fortran so should run reasonably quickly.\nCan also use BAS or other variable selection programs"
  },
  {
    "objectID": "resources/slides/18-outliers.html#model-averaging-and-outliers",
    "href": "resources/slides/18-outliers.html#model-averaging-and-outliers",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Model Averaging and Outliers",
    "text": "Model Averaging and Outliers\n\nFull model \\(\\mathbf{Y}= \\mathbf{X}\\boldsymbol{\\beta}+ \\mathbf{I}_n\\delta+ \\epsilon\\)\n\\(\\delta\\) is a \\(n \\times 1\\) vector; \\(\\boldsymbol{\\beta}\\) is \\(p \\times 1\\)\n\\(2^n\\) submodels \\(\\gamma_i = 0 \\Leftrightarrow \\delta_i = 0\\)\nIf \\(\\gamma_i = 1\\) then case \\(i\\) has a different mean ``mean shift’’ outliers"
  },
  {
    "objectID": "resources/slides/18-outliers.html#mean-shift-variance-inflation",
    "href": "resources/slides/18-outliers.html#mean-shift-variance-inflation",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Mean Shift \\(=\\) Variance Inflation",
    "text": "Mean Shift \\(=\\) Variance Inflation\n\nModel \\(\\mathbf{Y}= \\mathbf{X}\\boldsymbol{\\beta}+ \\mathbf{I}_n\\delta+ \\epsilon\\)\nPrior \\[\\begin{align}\n\\qquad \\delta_i \\mid \\gamma_i & \\sim N(0, V \\sigma^2 \\gamma_i) \\\\\n\\qquad \\gamma_i & \\sim  \\textsf{Ber}(\\pi)\n\\end{align}\n\\]\nThen \\(\\epsilon_i\\) given \\(\\sigma^2\\) is independent of \\(\\delta_i\\) and \\[\\epsilon^*_i \\equiv \\epsilon_i + \\delta_i \\mid \\sigma^2 \\left\\{\n\\begin{array}{llc}\nN(0, \\sigma^2) & wp &(1 - \\pi) \\\\\nN(0, \\sigma^2(1 + V)) & wp & \\pi\n\\end{array}\n\\right.\n\\]\nModel \\(\\mathbf{Y}= \\mathbf{X}\\boldsymbol{\\beta}+ \\epsilon^*\\) variance inflation\n\\(V+1 = K = 7\\) in the paper by Hoeting et al. package BMA"
  },
  {
    "objectID": "resources/slides/18-outliers.html#simultaneous-outlier-and-variable-selection",
    "href": "resources/slides/18-outliers.html#simultaneous-outlier-and-variable-selection",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Simultaneous Outlier and Variable Selection",
    "text": "Simultaneous Outlier and Variable Selection\n\nlibrary(BMA)\nbodyfat.bma = MC3.REG(all.y = bodyfat$Bodyfat, all.x = as.matrix(bodyfat$Abdomen),\n                      num.its = 10000, outliers = TRUE)\nsummary(bodyfat.bma)\n\n\nCall:\nMC3.REG(all.y = bodyfat$Bodyfat, all.x = as.matrix(bodyfat$Abdomen),     num.its = 10000, outliers = TRUE)\n\nModel parameters: PI = 0.02 K = 7 nu = 2.58 lambda = 0.28 phi = 2.85\n\n  15  models were selected\n Best  5  models (cumulative posterior probability =  0.9939 ): \n\n           prob     model 1   model 2   model 3   model 4   model 5 \nvariables                                                           \n  all.x    1         x         x         x         x         x      \noutliers                                                            \n  39       0.94932   x         x         .         x         .      \n  204      0.04117   .         .         .         x         .      \n  207      0.10427   .         x         .         .         x      \n                                                                    \npost prob           0.814572  0.095383  0.044490  0.035024  0.004385"
  },
  {
    "objectID": "resources/slides/18-outliers.html#bas-with-truncated-prior",
    "href": "resources/slides/18-outliers.html#bas-with-truncated-prior",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "BAS with Truncated Prior",
    "text": "BAS with Truncated Prior\n\nbodyfat.w.out = cbind(bodyfat[, c(\"Bodyfat\", \"Abdomen\")],\n                      diag(nrow(bodyfat)))\n\nbodyfat.bas = bas.lm(Bodyfat ~ ., data=bodyfat.w.out, \n                     prior=\"hyper-g-n\", a=3, method=\"MCMC\",\n                     MCMC.it=2^18, \n                     modelprior=tr.beta.binomial(1,254, 50))"
  },
  {
    "objectID": "resources/slides/18-outliers.html#change-error-assumptions",
    "href": "resources/slides/18-outliers.html#change-error-assumptions",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Change Error Assumptions",
    "text": "Change Error Assumptions\nUse a Student-t error model \\[\\begin{eqnarray*}\nY_i & \\mathrel{\\mathop{\\sim}\\limits^{\\rm ind}}& t(\\nu, \\alpha + \\beta x_i, 1/\\phi) \\\\\nL(\\alpha, \\beta,\\phi) & \\propto & \\prod_{i = 1}^n \\phi^{1/2} \\left(1 +\n\\frac{\\phi (y_i - \\alpha - \\beta x_i)^2}{\\nu}\\right)^{-\\frac{(\\nu +\n  1)}{2}}\n\\end{eqnarray*}\\]\n\nUse Prior \\(p(\\alpha, \\beta, \\phi) \\propto 1/\\phi\\) \nPosterior distribution \\[ p(\\alpha, \\beta, \\phi \\mid Y) \\propto \\phi^{n/2 - 1} \\prod_{i = 1}^n  \\left(1 +\n\\frac{\\phi (y_i - \\alpha - \\beta x_i)^2}{\\nu}\\right)^{-\\frac{(\\nu +\n1)}{2}}\\]"
  },
  {
    "objectID": "resources/slides/18-outliers.html#bounded-influence",
    "href": "resources/slides/18-outliers.html#bounded-influence",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Bounded Influence",
    "text": "Bounded Influence\n\nTreat \\(\\sigma^2\\) as given, then influence of individual observations on the posterior distribution of \\(\\boldsymbol{\\beta}\\) in the model where \\(\\textsf{E}[\\mathbf{Y}_i] = \\mathbf{x}_i^T\\boldsymbol{\\beta}\\) is investigated through the score function: \\[\n\\frac{d} {d \\boldsymbol{\\beta}} \\log p (\\boldsymbol{\\beta}\\mid \\mathbf{Y}) = \\frac{d} {d \\boldsymbol{\\beta}} \\log p(\\boldsymbol{\\beta}) +  \\sum_{i = 1}^n \\mathbf{x}_i g(y_i - \\mathbf{x}^T_i \\boldsymbol{\\beta})\n\\]\ninfluence function of the error distribution (unimodal, continuous, differentiable, symmetric) \\[ g(\\boldsymbol{\\epsilon}) = - \\frac{d} {d \\boldsymbol{\\epsilon}} \\log p(\\boldsymbol{\\epsilon})\n\\]\nAn outlying observation \\(y_j\\) is accommodated if the posterior distribution for \\(p(\\boldsymbol{\\beta}\\mid \\mathbf{Y}\\) converges to \\(p(\\boldsymbol{\\beta}\\mid \\mathbf{Y}_{(i)})\\) for all \\(\\boldsymbol{\\beta}\\) as \\(|\\mathbf{Y}_i| \\to \\infty\\).\nRequires error models with influence functions that go to zero such as the Student \\(t\\) (O’Hagan, 1979, West 1984, Hamura 2023)"
  },
  {
    "objectID": "resources/slides/18-outliers.html#choice-of-df-for-student-t",
    "href": "resources/slides/18-outliers.html#choice-of-df-for-student-t",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Choice of df for Student-\\(t\\)",
    "text": "Choice of df for Student-\\(t\\)\nInvestigate the Score function \\[\n\\frac{d} {d \\boldsymbol{\\beta}} \\log p (\\boldsymbol{\\beta}\\mid \\mathbf{Y}) = \\frac{d} {d \\boldsymbol{\\beta}} \\log p(\\boldsymbol{\\beta}) +  \\sum_{i = 1}^n \\mathbf{x}_i g(y_i - \\mathbf{x}^T_i \\boldsymbol{\\beta})\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScore function for \\(t\\) with \\(\\alpha\\) degrees of freedom has turning points at \\(\\pm \\sqrt{\\alpha}\\)\n\\(g'(\\boldsymbol{\\epsilon})\\) is negative when \\(\\boldsymbol{\\epsilon}^2 &gt; \\alpha\\) (standardized errors)\nContribution of observation to information matrix is negative and the observation is doubtful\nSuggest taking \\(\\alpha = 8\\) or \\(\\alpha = 9\\) to reject errors larger than \\(\\sqrt{8}\\) or \\(3\\) sd."
  },
  {
    "objectID": "resources/slides/18-outliers.html#scale-mixtures-of-normal-representation",
    "href": "resources/slides/18-outliers.html#scale-mixtures-of-normal-representation",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Scale-Mixtures of Normal Representation",
    "text": "Scale-Mixtures of Normal Representation\n\nLatent Variable Model \\[\\begin{eqnarray*}\nY_i \\mid \\alpha, \\beta, \\phi, \\lambda & \\mathrel{\\mathop{\\sim}\\limits^{\\rm ind}}& N(\\alpha + \\beta x_i,\n\\frac{1}{\\phi \\lambda_i}) \\\\\n\\lambda_i & \\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}& G(\\nu/2, \\nu/2) \\\\\np(\\alpha, \\beta, \\phi) & \\propto & 1/\\phi  \n\\end{eqnarray*}\\]\nJoint Posterior Distribution: \\[\\begin{eqnarray*}\np((\\alpha, \\beta, \\phi, \\lambda_1, \\ldots, \\lambda_n \\mid Y)\n\\propto \\,  & &\n\\phi^{n/2} \\exp\\left\\{ - \\frac{\\phi}{2} \\sum \\lambda_i(y_i - \\alpha  - \\beta x_i)^2 \\right\\} \\times \\\\\n&  & \\phi^{-1} \\\\\n&  &\\prod_{i=1}^n \\lambda_i^{\\nu/2 - 1} \\exp(- \\lambda_i \\nu/2)\n\\end{eqnarray*}\\]\nIntegrate out ``latent’’ \\(\\lambda\\)’s to obtain marginal \\(t\\) distribution"
  },
  {
    "objectID": "resources/slides/18-outliers.html#jags---just-another-gibbs-sampler",
    "href": "resources/slides/18-outliers.html#jags---just-another-gibbs-sampler",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "JAGS - Just Another Gibbs Sampler",
    "text": "JAGS - Just Another Gibbs Sampler\n\nrr.model = function() {\n  df &lt;- 9\n  for (i in 1:n) {\n    mu[i] &lt;- alpha0 + alpha1*(X[i] - Xbar)\n    lambda[i] ~ dgamma(df/2, df/2)\n    prec[i] &lt;- phi*lambda[i]\n    Y[i] ~ dnorm(mu[i], prec[i])\n  }\n  phi ~ dgamma(1.0E-6, 1.0E-6)\n  alpha0 ~ dnorm(0, 1.0E-6)\n  alpha1 ~ dnorm(0,1.0E-6)\n  beta0 &lt;- alpha0 - alpha1*Xbar  # transform back\n  beta1 &lt;- alpha1\n  sigma &lt;- pow(phi, -.5)\n  mu34 &lt;- beta0 + beta1*2.54*34  #mean for a man w/ a 34 in waist\n  y34 ~ dt(mu34,phi, df)   # integrate out lambda_34 \n}\n\n\n\n\n\n\n\nWarning! Normals and Student-t are parameterized in terms of precisions!"
  },
  {
    "objectID": "resources/slides/18-outliers.html#what-output-to-save",
    "href": "resources/slides/18-outliers.html#what-output-to-save",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "What output to Save?",
    "text": "What output to Save?\nThe parameters to be monitored and returned to R are specified with the variable parameters\n\nparameters = c(\"beta0\", \"beta1\", \"sigma\", \"mu34\", \"y34\", \"lambda[39]\")\n\n\nUse of &lt;- for assignment for parameters that calculated from the other parameters. (See R-code for definitions of these parameters.)\nmu34 and y34 are the mean functions and predictions for a man with a 34in waist.\nlambda[39] saves only the 39th case of \\(\\lambda\\)\nTo save a whole vector (for example all lambdas, just give the vector name)"
  },
  {
    "objectID": "resources/slides/18-outliers.html#running-jags-from-r",
    "href": "resources/slides/18-outliers.html#running-jags-from-r",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Running JAGS from R",
    "text": "Running JAGS from R\nInstall jags from sourceforge\n\n\nlibrary(R2jags)\n\n# Create a data list with inputs for Winpost/Jags\n\nbf.data = list(Y = bodyfat$Bodyfat, X=bodyfat$Abdomen)\nbf.data$n = length(bf.data$Y)\nbf.data$Xbar = mean(bf.data$X)\n\n# run jags\nbf.sim = jags(bf.data, inits=NULL, par=parameters,\n              model=rr.model, n.chains=2, n.iter=20000)\n\n\n\n\n# create an MCMC object \nlibrary(coda)\nbf.post = as.mcmc(bf.sim$BUGSoutput$sims.matrix)"
  },
  {
    "objectID": "resources/slides/18-outliers.html#posterior-distributions",
    "href": "resources/slides/18-outliers.html#posterior-distributions",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Posterior Distributions",
    "text": "Posterior Distributions"
  },
  {
    "objectID": "resources/slides/18-outliers.html#posterior-of-lambda_39",
    "href": "resources/slides/18-outliers.html#posterior-of-lambda_39",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Posterior of \\(\\lambda_{39}\\)",
    "text": "Posterior of \\(\\lambda_{39}\\)"
  },
  {
    "objectID": "resources/slides/18-outliers.html#comparison",
    "href": "resources/slides/18-outliers.html#comparison",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Comparison",
    "text": "Comparison\n95% Confidence/Credible Intervals for \\(\\beta\\)\n\n\n\n\n\n\n2.5 %\n97.5 %\n\n\n\n\nlm all\n0.5750739\n0.6875349\n\n\nrobust bayes\n0.6016984\n0.7184886\n\n\nlm w/out 39\n0.6144288\n0.7294781\n\n\n\n\n\n\nResults intermediate without having to remove any observations!\nCase 39 down weighted by \\(\\lambda_{39}\\) in posterior for \\(\\beta\\)\nUnder prior \\(E[\\lambda_{i}] = 1\\)\nlarge residuals lead to smaller \\(\\lambda\\) \\[\\lambda_j \\mid \\text{rest}, Y \\sim G \\left(\\frac{\\nu + 1}{2}, \\frac{\\phi(y_j - \\alpha -\n\\beta x_j)^2 + \\nu}{2} \\right)\\]"
  },
  {
    "objectID": "resources/slides/18-outliers.html#prior-distributions-on-parameters",
    "href": "resources/slides/18-outliers.html#prior-distributions-on-parameters",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Prior Distributions on Parameters",
    "text": "Prior Distributions on Parameters\n\nAs a general recommendation, the prior distribution should have ``heavier’’ tails than the likelihood\nwith \\(t_9\\) errors use a \\(t_\\alpha\\) with \\(\\alpha &lt; 9\\)\nalso represent via scale mixture of normals\nHorseshoe, Double Pareto, Cauchy all have heavier tails"
  },
  {
    "objectID": "resources/slides/18-outliers.html#summary",
    "href": "resources/slides/18-outliers.html#summary",
    "title": "Lecture 18: Outliers and Robust Regression",
    "section": "Summary",
    "text": "Summary\n\nClassical diagnostics useful for EDA (checking data, potential outliers/influential points) or posterior predictive checks\nBMA/BVS and Bayesian robust regression avoid interactive decision making about outliers\nRobust Regression (Bayes) can still identify outliers through distribution on weights\ncontinuous versus mixture distribution on scale parameters\nOther mixtures (sub populations?) on scales and \\(\\boldsymbol{\\beta}\\)?\nBe careful about what predictors or transformations are used in the model as some outliers may be a result of model misspecification!\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/13-ridge-mixtures.html#ridge-regression",
    "href": "resources/slides/13-ridge-mixtures.html#ridge-regression",
    "title": "Lecture 13: Ridge Regression, Lasso and Mixture Priors",
    "section": "Ridge Regression",
    "text": "Ridge Regression\nModel: \\(\\mathbf{Y}= \\mathbf{1}_n \\alpha + \\mathbf{X}\\boldsymbol{\\beta}+ \\boldsymbol{\\epsilon}\\)\n\ntypically expect the intercept \\(\\alpha\\) to be a different order of magnitude from the other predictors. Adopt a two block prior with \\(p(\\alpha) \\propto 1\\)\nPrior \\(\\boldsymbol{\\beta}\\mid \\phi \\sim \\textsf{N}(\\mathbf{0}_b, \\frac{1} {\\phi \\kappa} \\mathbf{I}_p\\)) implies the \\(\\boldsymbol{\\beta}\\) are exchangable a priori (i.e. distribution is invariant under permuting the labels and with a common scale and mean)\nPosterior for \\(\\boldsymbol{\\beta}\\) \\[\\boldsymbol{\\beta}\\mid \\phi, \\kappa, \\mathbf{Y}\\sim\n\\textsf{N}\\left((\\kappa I_p + X^TX)^{-1} X^T Y,  \\frac{1}{\\phi}(\\kappa I_p + X^TX)^{-1}\n\\right)\\]\nassume that \\(\\mathbf{X}\\) has been centered and scaled so that \\(\\mathbf{X}^T\\mathbf{X}= \\textsf{corr}(\\mathbf{X})\\) and \\(\\mathbf{1}_n^T \\mathbf{X}= \\mathbf{0}_p\\)\n\n\n\nX = scale(X)/sqrt{nrow(X) - 1}"
  },
  {
    "objectID": "resources/slides/13-ridge-mixtures.html#bayes-ridge-regression",
    "href": "resources/slides/13-ridge-mixtures.html#bayes-ridge-regression",
    "title": "Lecture 13: Ridge Regression, Lasso and Mixture Priors",
    "section": "Bayes Ridge Regression",
    "text": "Bayes Ridge Regression\n\nrelated to penalized maximum likelihood estimation \\[-\\frac{\\phi}{2}\\left(\\|\\mathbf{Y}- \\mathbf{X}\\boldsymbol{\\beta}\\|^2 + \\kappa \\| \\boldsymbol{\\beta}\\|^2 \\right)\n\\]\nfrequentist’s expected mean squared error loss for using \\(\\mathbf{b}_n\\) \\[\\textsf{E}_{\\mathbf{Y}\\mid \\boldsymbol{\\beta}_*}[\\| \\mathbf{b}_n - \\boldsymbol{\\beta}_* \\|^2] = \\sigma^2 \\sum_{j = 1}^2 \\frac{\\lambda_j}{(\\lambda_j + \\kappa)^2} +\n\\kappa^2 \\boldsymbol{\\beta}_*^T(\\mathbf{X}^T\\mathbf{X}+ \\kappa \\mathbf{I}_p)^{-2} \\boldsymbol{\\beta}_*\\]\neigenvalues of \\(\\mathbf{X}^T\\mathbf{X}= \\mathbf{V}\\boldsymbol{\\Lambda}\\mathbf{V}^T\\) with \\([\\boldsymbol{\\Lambda}]_{jj} = \\lambda_j\\)\ncan show that there always is a value of \\(\\kappa\\) where is smaller for the (Bayes) Ridge estimator than MLE\nUnfortunately the optimal choice depends on “true” \\(\\boldsymbol{\\beta}_*\\)!\northogonal \\(\\mathbf{X}\\) leads to James-Stein solution related to Empirical Bayes"
  },
  {
    "objectID": "resources/slides/13-ridge-mixtures.html#choice-of-kappa",
    "href": "resources/slides/13-ridge-mixtures.html#choice-of-kappa",
    "title": "Lecture 13: Ridge Regression, Lasso and Mixture Priors",
    "section": "Choice of \\(\\kappa\\)?",
    "text": "Choice of \\(\\kappa\\)?\n\nfixed a priori Bayes (and how to choose?)\n\nCross-validation (frequentist)\nEmpirical Bayes? (frequentist/Bayes)\nShould there be a common \\(\\kappa\\)? (same shrinkage across all variables?)\nOr a \\(\\kappa_j\\) per variable? (or shared among a group of variables (eg. factors) ?)\nTreat as unknown!"
  },
  {
    "objectID": "resources/slides/13-ridge-mixtures.html#mixture-of-conjugate-priors",
    "href": "resources/slides/13-ridge-mixtures.html#mixture-of-conjugate-priors",
    "title": "Lecture 13: Ridge Regression, Lasso and Mixture Priors",
    "section": "Mixture of Conjugate Priors",
    "text": "Mixture of Conjugate Priors\n\ncan place a prior on \\(\\kappa\\) or \\(\\kappa_j\\) for fully Bayes\nsimilar option for \\(g\\) in the \\(g\\) priors\noften improved robustness over fixed choices of hyperparameter\nmay not have cloosed form posterior but sampling is still often easy!\nExamples:\n\nBayesian Lasso (Park & Casella, Hans)\nGeneralized Double Pareto (Armagan, Dunson & Lee)\nHorseshoe (Carvalho, Polson & Scott)\nNormal-Exponential-Gamma (Griffen & Brown)\nmixtures of \\(g\\)-priors (Liang et al)"
  },
  {
    "objectID": "resources/slides/13-ridge-mixtures.html#lasso",
    "href": "resources/slides/13-ridge-mixtures.html#lasso",
    "title": "Lecture 13: Ridge Regression, Lasso and Mixture Priors",
    "section": "Lasso",
    "text": "Lasso\nTibshirani (JRSS B 1996) proposed estimating coefficients through \\(L_1\\) constrained least squares ``Least Absolute Shrinkage and Selection Operator’’\n\nControl how large coefficients may grow \\[\\begin{align}  \\min_{\\boldsymbol{\\beta}} & \\| \\mathbf{Y}- \\mathbf{1}_n \\alpha - \\mathbf{X}\\boldsymbol{\\beta}\\|^2 \\\\\n  & \\textsf{  subject to }    \\sum |\\beta_j| \\le t\n\\end{align}\\]\nEquivalent Quadratic Programming Problem for ``penalized’’ Likelihood \\[\\min_{\\boldsymbol{\\beta}} \\| \\mathbf{Y}- \\mathbf{1}_n \\alpha - \\mathbf{X}\\boldsymbol{\\beta}\\|^2 + \\lambda \\|\\boldsymbol{\\beta}\\|_1\\]\nEquivalent to finding posterior mode \\[\n\\max_{\\boldsymbol{\\beta}} -\\frac{\\phi}{2} \\{ \\| \\mathbf{Y}- \\mathbf{1}_n \\alpha - \\mathbf{X}\\boldsymbol{\\beta}\\|^2 + \\lambda \\|\\boldsymbol{\\beta}\\|_1 \\}\n\\]"
  },
  {
    "objectID": "resources/slides/13-ridge-mixtures.html#bayesian-lasso",
    "href": "resources/slides/13-ridge-mixtures.html#bayesian-lasso",
    "title": "Lecture 13: Ridge Regression, Lasso and Mixture Priors",
    "section": "Bayesian Lasso",
    "text": "Bayesian Lasso\nPark & Casella (JASA 2008) and Hans (Biometrika 2010) propose Bayesian versions of the Lasso\n\\[\\begin{eqnarray*}\n    \\mathbf{Y}\\mid \\alpha, \\boldsymbol{\\beta}, \\phi & \\sim & \\textsf{N}(\\mathbf{1}_n \\alpha + \\mathbf{X}\\boldsymbol{\\beta}, \\mathbf{I}_n/\\phi)  \\\\\n    \\boldsymbol{\\beta}\\mid \\alpha, \\phi, \\boldsymbol{\\tau}& \\sim & \\textsf{N}(\\mathbf{0}, \\textsf{diag}(\\boldsymbol{\\tau}^2)/\\phi)  \\\\\n    \\tau_1^2 \\ldots, \\tau_p^2 \\mid \\alpha, \\phi & \\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}& \\textsf{Exp}(\\lambda^2/2)  \\\\\n    p(\\alpha, \\phi) & \\propto& 1/\\phi  \\\\\n  \\end{eqnarray*}\\]\n\nCan show that \\(\\beta_j \\mid \\phi, \\lambda \\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}DE(\\lambda \\sqrt{\\phi})\\) \\[\\int_0^\\infty \\frac{1}{\\sqrt{2 \\pi s}}\ne^{-\\frac{1}{2} \\phi \\frac{\\beta^2}{s }}\n\\, \\frac{\\lambda^2}{2} e^{- \\frac{\\lambda^2 s}{2}}\\, ds =\n\\frac{\\lambda \\phi^{1/2}}{2} e^{-\\lambda \\phi^{1/2} |\\beta|}\n\\]\nequivalent to penalized regression with \\(\\lambda^* = \\lambda/\\phi^{1/2}\\)\nScale Mixture of Normals (Andrews and Mallows 1974)"
  },
  {
    "objectID": "resources/slides/13-ridge-mixtures.html#gibbs-sampling",
    "href": "resources/slides/13-ridge-mixtures.html#gibbs-sampling",
    "title": "Lecture 13: Ridge Regression, Lasso and Mixture Priors",
    "section": "Gibbs Sampling",
    "text": "Gibbs Sampling\n\nIntegrate out \\(\\alpha\\): \\(\\alpha \\mid \\mathbf{Y}, \\phi \\sim \\textsf{N}(\\bar{y}, 1/(n \\phi)\\)\n\n\\(\\boldsymbol{\\beta}\\mid \\boldsymbol{\\tau}, \\phi, \\lambda, \\mathbf{Y}\\sim \\textsf{N}(, )\\)\n\n\\(\\phi \\mid \\boldsymbol{\\tau}, \\boldsymbol{\\beta}, \\lambda, \\mathbf{Y}\\sim \\mathbf{G}( , )\\)\n\n\\(1/\\tau_j^2 \\mid \\boldsymbol{\\beta}, \\phi, \\lambda, \\mathbf{Y}\\sim \\textsf{InvGaussian}( , )\\)\nFor \\(X \\sim \\textsf{InvGaussian}(\\mu, \\lambda)\\), the density is \\[\nf(x) =  \\sqrt{\\frac{\\lambda^2}{2 \\pi}}  x^{-3/2} e^{- \\frac{1}{2} \\frac{\n  \\lambda^2( x - \\mu)^2} {\\mu^2 x}} \\qquad x &gt; 0\n\\]\n\n\n\n\n\n\n\n\nHomework\n\n\nDerive the full conditionals for \\(\\boldsymbol{\\beta}\\), \\(\\phi\\), \\(1/\\tau^2\\) for the model in Park & Casella"
  },
  {
    "objectID": "resources/slides/13-ridge-mixtures.html#choice-of-estimator",
    "href": "resources/slides/13-ridge-mixtures.html#choice-of-estimator",
    "title": "Lecture 13: Ridge Regression, Lasso and Mixture Priors",
    "section": "Choice of Estimator",
    "text": "Choice of Estimator\n\nPosterior mode (like in the LASSO) may set some coefficients exactly to zero leading to variable selection - optimization problem (quadratic programming)\nPosterior distribution for \\(\\beta_j\\) does not assign any probability to \\(\\beta_j = 0\\) so posterior mean results in no selection, but shrinkage of coeffiecients to prior mean of zero\nIn both cases, large coefficients may be over-shrunk (true for LASSO too)!\nIssue is that the tails of the prior under the double exponential are not heavier than the normal likelihood\nOnly one parameter \\(\\lambda\\) that controls shrinkage and selection (with the mode)\nNeed priors with heavier tails than the normal!!!"
  },
  {
    "objectID": "resources/slides/13-ridge-mixtures.html#shrinkage-comparison-with-posterior-mean",
    "href": "resources/slides/13-ridge-mixtures.html#shrinkage-comparison-with-posterior-mean",
    "title": "Lecture 13: Ridge Regression, Lasso and Mixture Priors",
    "section": "Shrinkage Comparison with Posterior Mean",
    "text": "Shrinkage Comparison with Posterior Mean\n\n\n\n\nHS - Horseshoe of Carvalho, Polson & Scott (slight difference in CPS notation)\n\\[\\begin{align}\n\\boldsymbol{\\beta}\\mid \\phi, \\boldsymbol{\\tau}& \\sim \\textsf{N}(\\mathbf{0}_p, \\frac{\\textsf{diag}(\\boldsymbol{\\tau}^2)}{ \\phi    }) \\\\\n\\tau_j \\mid \\lambda & \\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}\\textsf{C}^+(0, \\lambda^2) \\\\\n\\lambda & \\sim \\textsf{C}^+(0, 1) \\\\\np(\\alpha, \\phi) & \\propto 1/\\phi)\n\\end{align}\\]\n\nresulting prior on \\(\\boldsymbol{\\beta}\\) has heavy tails like a Cauchy!"
  },
  {
    "objectID": "resources/slides/13-ridge-mixtures.html#bounded-influence-for-mean",
    "href": "resources/slides/13-ridge-mixtures.html#bounded-influence-for-mean",
    "title": "Lecture 13: Ridge Regression, Lasso and Mixture Priors",
    "section": "Bounded Influence for Mean",
    "text": "Bounded Influence for Mean\n\ncanonical representation (normal means problem) \\(\\mathbf{Y}= \\mathbf{I}_p \\boldsymbol{\\beta}+ \\boldsymbol{\\epsilon}\\) so \\(\\hat{\\beta}_i = y_i\\) \\[\nE[\\beta_i \\mid \\mathbf{Y}] = \\int_0^1 (1 - \\psi_i) y^*_i p(\\psi_i \\mid \\mathbf{Y})\\ d\\psi_i = (1 - \\textsf{E}[\\psi_i \\mid y^*_i]) y^*_i\\]\n\\(\\psi_i = 1/(1 + \\tau_i^2)\\) shrinkage factor\nPosterior mean \\(E[\\beta \\mid y] = y + \\frac{d} {d y} \\log m(y)\\) where \\(m(y)\\) is the predictive density under the prior (known \\(\\lambda\\))\nBounded Influence: if \\(\\lim_{|y| \\to \\infty} \\frac{d}{dy} \\log m(y) = c\\) (for some constant \\(c\\))\nHS has bounded influence where \\(c = 0\\) so \\[\\lim_{|y| \\to \\infty} E[\\beta \\mid y) \\to y \\]\nDE has bounded influence but \\((c \\ne 0\\)); bound does not decay to zero and bias for large \\(|y_i|\\)"
  },
  {
    "objectID": "resources/slides/13-ridge-mixtures.html#properties-for-shrinkage-and-selection",
    "href": "resources/slides/13-ridge-mixtures.html#properties-for-shrinkage-and-selection",
    "title": "Lecture 13: Ridge Regression, Lasso and Mixture Priors",
    "section": "Properties for Shrinkage and Selection",
    "text": "Properties for Shrinkage and Selection\nFan & Li (JASA 2001) discuss Variable Selection via Nonconcave Penalties and Oracle Properties\n\nModel \\(Y = \\mathbf{1}_n \\alpha + \\mathbf{X}\\boldsymbol{\\beta}+ \\boldsymbol{\\epsilon}\\) with \\(\\mathbf{X}^T\\mathbf{X}= \\mathbf{I}_p\\) (orthonormal) and \\(\\boldsymbol{\\epsilon}\\sim N(0, \\mathbf{I}_n)\\)\nPenalized Log Likelihood \\[\\frac 1 2 \\|\\mathbf{Y}- \\hat{\\mathbf{Y}}\\|^2 +\\frac 1 2 \\sum_j(\\beta_j - \\hat{\\beta}_j)^2 +  \\sum_j \\text{ pen}_\\lambda(|\\beta_j|)\\]\nduality \\(\\text{pen}_\\lambda(|\\beta|) \\equiv - \\log(p(|\\beta_j|))\\) (negative log prior)\nObjectives:\n\nUnbiasedness: for large \\(|\\beta_j|\\)\nSparsity: thresholding rule sets small coefficients to 0\nContinuity: continuous in \\(\\hat{\\beta}_j\\)"
  },
  {
    "objectID": "resources/slides/13-ridge-mixtures.html#conditions-on-priorpenalty",
    "href": "resources/slides/13-ridge-mixtures.html#conditions-on-priorpenalty",
    "title": "Lecture 13: Ridge Regression, Lasso and Mixture Priors",
    "section": "Conditions on Prior/Penalty",
    "text": "Conditions on Prior/Penalty\nDerivative of \\(\\frac 1 2 \\sum_j(\\beta_j - \\hat{\\beta}_j)^2 + \\sum_j \\text{pen}_\\lambda(|\\beta_j|)\\) is \\(\\mathop{\\mathrm{sgn}}(\\beta_j)\\left\\{|\\beta_j| + \\text{pen}^\\prime_\\lambda(|\\beta_j|) \\right\\} - \\hat{\\beta}_j\\)\n\n\nConditions:\n\nunbiased: if \\(\\text{pen}^\\prime_\\lambda(|\\beta|) = 0\\) for large \\(|\\beta|\\); estimator is \\(\\hat{\\beta}_j\\)\nthresholding: \\(\\min \\left\\{ |\\beta_j| + \\text{pen}^\\prime_\\lambda(|\\beta_j|)\\right\\} &gt; 0\\) then estimator is 0 if \\(|\\hat{\\beta}_j| &lt; \\min \\left\\{ |\\beta_j| + \\text{pen}^\\prime_\\lambda(|\\beta_j|) \\right\\}\\)\ncontinuity: minimum of \\(|\\beta_j| + \\text{pen}^\\prime_\\lambda(|\\beta_j|)\\) is at zero\n\nCan show that LASSO/ Bayesian Lasso fails conditions for unbiasedness\nWhat about other Bayes methods?\n\n\n\n\n\n\n\n\n\nHomework\n\n\nCheck the conditions for the DE, Generalized Double Pareto and Cauchy priors"
  },
  {
    "objectID": "resources/slides/13-ridge-mixtures.html#selection",
    "href": "resources/slides/13-ridge-mixtures.html#selection",
    "title": "Lecture 13: Ridge Regression, Lasso and Mixture Priors",
    "section": "Selection",
    "text": "Selection\n\nOnly get variable selection if we use the posterior mode\nIf selection is a goal of analysis build it into the model/analysis/post-analysis\n\nprior belief that coefficient is zero\nselection solved as a post-analysis decision problem\n\nEven if selection is not an objective, account for the uncertainty that some predictors may be unrelated\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#feature-selection-via-shrinkage",
    "href": "resources/slides/14-hypothesis-testing.html#feature-selection-via-shrinkage",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Feature Selection via Shrinkage",
    "text": "Feature Selection via Shrinkage\n\nmodal estimates in regression models under certain shrinkage priors will set a subset of coefficients to zero\nnot true with posterior mean\nmulti-modal posterior\nno prior probability that coefficient is zero\nhow should we approach selection/hypothesis testing?\nBayesian Hypothesis Testing"
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#basics-of-bayesian-hypothesis-testing",
    "href": "resources/slides/14-hypothesis-testing.html#basics-of-bayesian-hypothesis-testing",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Basics of Bayesian Hypothesis Testing",
    "text": "Basics of Bayesian Hypothesis Testing\nSuppose we have univariate data \\(Y_i \\overset{iid}{\\sim} \\mathcal{N}(\\theta, 1)\\), \\(\\mathbf{Y}= (y_i, \\ldots, y_n)^T\\)\n\ngoal is to test \\(\\mathcal{H}_0: \\theta = 0; \\ \\ \\text{vs } \\mathcal{H}_1: \\theta \\neq 0\\)\nAdditional unknowns are \\(\\mathcal{H}_0\\) and \\(\\mathcal{H}_1\\)\nPut a prior on the actual hypotheses/models, that is, on \\(\\pi(\\mathcal{H}_0) = \\Pr(\\mathcal{H}_0 = \\text{True})\\) and \\(\\pi(\\mathcal{H}_1) = \\Pr(\\mathcal{H}_1 = \\text{True})\\).\n(Marginal) Likelihood of the hypotheses: \\(\\cal{L}(\\mathcal{H}_i) \\propto p( \\mathbf{y}\\mid \\mathcal{H}_i)\\)\n\n\n\\[p( \\mathbf{y}\\mid \\mathcal{H}_0) = \\prod_{i = 1}^n (2 \\pi)^{-1/2} \\exp{- \\frac{1}{2} (y_i - 0)^2}\\]\n\n\n\\[p( \\mathbf{y}\\mid \\mathcal{H}_1)  = \\int_\\Theta p( \\mathbf{y}\\mid \\mathcal{H}_1, \\theta) p(\\theta \\mid \\mathcal{H}_1) \\, d\\theta\\]"
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#bayesian-approach",
    "href": "resources/slides/14-hypothesis-testing.html#bayesian-approach",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Bayesian Approach",
    "text": "Bayesian Approach\n\nNeed priors distributions on parameters under each hypothesis\n\nin our simple normal model, the only additional unknown parameter is \\(\\theta\\)\nunder \\(\\mathcal{H}_0\\), \\(\\theta = 0\\) with probability 1\nunder \\(\\mathcal{H}_0\\), \\(\\theta \\in \\mathbb{R}\\) we could take \\(\\pi(\\theta) = \\mathcal{N}(\\theta_0, 1/\\tau_0^2)\\).\n\nCompute marginal likelihoods for each hypothesis, that is, \\(\\cal{L}(\\mathcal{H}_0)\\) and \\(\\cal{L}(\\mathcal{H}_1)\\).\nObtain posterior probabilities of \\(\\cal{H}_0\\) and \\(\\cal{H}_1\\) via Bayes Theorem. \\[\n\\begin{split}\n\\pi(\\mathcal{H}_1 \\mid \\mathbf{y}) = \\frac{ p( \\mathbf{y}\\mid \\mathcal{H}_1) \\pi(\\mathcal{H}_1) }{ p( \\mathbf{y}\\mid \\mathcal{H}_0) \\pi(\\mathcal{H}_0) + p( \\mathbf{y}\\mid \\mathcal{H}_1) \\pi(\\mathcal{H}_1)}\n\\end{split}\n\\]\nProvides a joint posterior distribution for \\(\\theta\\) and \\(\\mathcal{H}_i\\): \\(p(\\theta \\mid \\mathcal{H}_i, \\mathbf{y})\\) and \\(\\pi(\\mathcal{H}_i \\mid \\mathbf{y})\\)"
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#hypothesis-tests-via-decision-theory",
    "href": "resources/slides/14-hypothesis-testing.html#hypothesis-tests-via-decision-theory",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Hypothesis Tests via Decision Theory",
    "text": "Hypothesis Tests via Decision Theory\n\nLoss function for hypothesis testing\n\n\\(\\hat{\\cal{H}}\\) is the chosen hypothesis\n\\(\\cal{H}_{\\text{true}}\\) is the true hypothesis, \\(\\cal{H}\\) for short\n\nTwo types of errors:\n\nType I error: \\(\\hat{\\cal{H}} = 1\\) and \\(\\cal{H} = 0\\)\nType II error: \\(\\hat{\\cal{H}} = 0\\) and \\(\\cal{H} = 1\\)\n\nLoss function: \\[L(\\hat{\\cal{H}}, \\cal{H}) =  w_1  \\, 1(\\hat{\\cal{H}} = 1, \\cal{H} = 0) + w_2 \\, 1(\\hat{\\cal{H}} = 0, \\cal{H} = 1)\\]\n\n\\(w_1\\) weights how bad it is to make a Type I error\n\\(w_2\\) weights how bad it is to make a Type II error"
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#loss-function-functions-and-decisions",
    "href": "resources/slides/14-hypothesis-testing.html#loss-function-functions-and-decisions",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Loss Function Functions and Decisions",
    "text": "Loss Function Functions and Decisions\n\nRelative weights \\(w = w_2/w_1\\) \\[L(\\hat{\\cal{H}}, \\cal{H}) =   \\, 1(\\hat{\\cal{H}} = 1, \\cal{H} = 0) + w \\, 1(\\hat{\\cal{H}} = 0, \\cal{H} = 1)\\]\nSpecial case \\(w=1\\) \\[L(\\hat{\\cal{H}}, \\cal{H}) =    1(\\hat{\\cal{H}} \\neq \\cal{H})\\]\nknown as 0-1 loss (most common)\nBayes Risk (Posterior Expected Loss) \\[\\textsf{E}_{\\cal{H} \\mid  \\mathbf{y}}[L(\\hat{\\cal{H}}, \\cal{H}) ] =\n1(\\hat{\\cal{H}} = 1)\\pi(\\cal{H}_0 \\mid  \\mathbf{y}) +  1(\\hat{\\cal{H}} = 0) \\pi(\\cal{H}_1 \\mid  \\mathbf{y})\\]\nMinimize loss by picking hypothesis with the highest posterior probability"
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#bayesian-hypothesis-testing",
    "href": "resources/slides/14-hypothesis-testing.html#bayesian-hypothesis-testing",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Bayesian hypothesis testing",
    "text": "Bayesian hypothesis testing\n\nUsing Bayes theorem, \\[\n\\begin{split}\n\\pi(\\mathcal{H}_1 \\mid \\mathbf{y}) = \\frac{ p( \\mathbf{y}\\mid \\mathcal{H}_1) \\pi(\\mathcal{H}_1) }{ p( \\mathbf{y}\\mid \\mathcal{H}_0) \\pi(\\mathcal{H}_0) + p( \\mathbf{y}\\mid \\mathcal{H}_1) \\pi(\\mathcal{H}_1)},\n\\end{split}\n\\]\nIf \\(\\pi(\\mathcal{H}_0) = 0.5\\) and \\(\\pi(\\mathcal{H}_1) = 0.5\\) a priori, then \\[\n\\begin{split}\n\\pi(\\mathcal{H}_1 \\mid \\mathbf{y}) & = \\frac{ 0.5 p( \\mathbf{y}\\mid \\mathcal{H}_1) }{ 0.5 p( \\mathbf{y}\\mid \\mathcal{H}_0) + 0.5 p( \\mathbf{y}\\mid \\mathcal{H}_1) } \\\\\n\\\\\n& = \\frac{ p( \\mathbf{y}\\mid \\mathcal{H}_1) }{ p( \\mathbf{y}\\mid \\mathcal{H}_0) + p( \\mathbf{y}\\mid \\mathcal{H}_1) }= \\frac{ 1 }{ \\frac{p( \\mathbf{y}\\mid \\mathcal{H}_0)}{p( \\mathbf{y}\\mid \\mathcal{H}_1)} + 1 }\\\\\n\\end{split}\n\\]"
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#bayes-factors",
    "href": "resources/slides/14-hypothesis-testing.html#bayes-factors",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Bayes factors",
    "text": "Bayes factors\n\nThe ratio \\(\\frac{p( \\mathbf{y}\\mid \\mathcal{H}_0)}{p( \\mathbf{y}\\mid \\mathcal{H}_1)}\\) is a ratio of marginal likelihoods and is known as the Bayes factor in favor of \\(\\mathcal{H}_0\\), written as \\(\\mathcal{BF}_{01}\\). Similarly, we can compute \\(\\mathcal{BF}_{10}\\) via the inverse ratio.\nBayes factors provide a weight of evidence in the data in favor of one model over another. and are used as an alternative to the frequentist p-value.\nRule of Thumb: \\(\\mathcal{BF}_{01} &gt; 10\\) is strong evidence for \\(\\mathcal{H}_0\\); \\(\\mathcal{BF}_{01} &gt; 100\\) is decisive evidence for \\(\\mathcal{H}_0\\).\nIn the example (with equal prior probabilities), \\[\n\\begin{split}\n\\pi(\\mathcal{H}_1 \\mid \\mathbf{y}) = \\frac{ 1 }{ \\frac{p( \\mathbf{y}\\mid \\mathcal{H}_0)}{p( \\mathbf{y}\\mid \\mathcal{H}_1)} + 1 } = \\frac{ 1 }{ \\mathcal{BF}_{01} + 1 } \\\\\n\\end{split}\n\\]\nthe higher the value of \\(\\mathcal{BF}_{01}\\), that is, the weight of evidence in the data in favor of \\(\\mathcal{H}_0\\), the lower the marginal posterior probability that \\(\\mathcal{H}_1\\) is true.\n\\(\\mathcal{BF}_{01} \\uparrow\\), \\(\\pi(\\mathcal{H}_1 \\mid \\mathbf{y}) \\downarrow\\)."
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#posterior-odds-and-bayes-factors",
    "href": "resources/slides/14-hypothesis-testing.html#posterior-odds-and-bayes-factors",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Posterior Odds and Bayes Factors",
    "text": "Posterior Odds and Bayes Factors\n\nPosterior odds \\(\\frac{\\pi(\\mathcal{H}_0 \\mid \\mathbf{y})}{\\pi(\\mathcal{H}_1 \\mid \\mathbf{y})}\\) \\[\n\\begin{split}\n\\frac{\\pi(\\mathcal{H}_0 | \\mathbf{y})}{\\pi(\\mathcal{H}_1 | \\mathbf{y})} & = \\frac{ p( \\mathbf{y}|\\mathcal{H}_0) \\pi(\\mathcal{H}_0) }{ p( \\mathbf{y}| \\mathcal{H}_0) \\pi(\\mathcal{H}_0) + p( \\mathbf{y}| \\mathcal{H}_1) \\pi(\\mathcal{H}_1)} \\div \\frac{ p( \\mathbf{y}| \\mathcal{H}_1) \\pi(\\mathcal{H}_1) }{ p( \\mathbf{y}\\mathcal{H}_0) \\pi(\\mathcal{H}_0) + p( \\mathbf{y}| \\mathcal{H}_1) \\pi(\\mathcal{H}_1)}\\\\\n\\\\\n& = \\frac{ p( \\mathbf{y}| \\mathcal{H}_0) \\pi(\\mathcal{H}_0) }{ p( \\mathbf{y}| \\mathcal{H}_0) \\pi(\\mathcal{H}_0) + p( \\mathbf{y}| \\mathcal{H}_1) \\pi(\\mathcal{H}_1)} \\times \\frac{ p( \\mathbf{y}| \\mathcal{H}_0) \\pi(\\mathcal{H}_0) + p( \\mathbf{y}| \\mathcal{H}_1) \\pi(\\mathcal{H}_1)}{ p( \\mathbf{y}| \\mathcal{H}_1) \\pi(\\mathcal{H}_1) }\\\\\n\\\\\n\\therefore \\underbrace{\\frac{\\pi(\\mathcal{H}_0 \\mid \\mathbf{y})}{\\pi(\\mathcal{H}_1 \\mid \\mathbf{y})}}_{\\text{posterior odds}} & = \\underbrace{\\frac{ \\pi(\\mathcal{H}_0) }{ \\pi(\\mathcal{H}_1) }}_{\\text{prior odds}} \\times \\underbrace{\\frac{ p( \\mathbf{y}\\mid \\mathcal{H}_0) }{ p( \\mathbf{y}\\mid \\mathcal{H}_1) }}_{\\text{Bayes factor } \\mathcal{BF}_{01}} \\\\\n\\end{split}\n\\]\nThe Bayes factor can be thought of as the factor by which our prior odds change (towards the posterior odds) in the light of the data."
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#likelihoods-evidence",
    "href": "resources/slides/14-hypothesis-testing.html#likelihoods-evidence",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Likelihoods & Evidence",
    "text": "Likelihoods & Evidence\nMaximized Likelihood. \\(n = 10\\)\n\np-value = 0.05"
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#marginal-likelihoods-evidence",
    "href": "resources/slides/14-hypothesis-testing.html#marginal-likelihoods-evidence",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Marginal Likelihoods & Evidence",
    "text": "Marginal Likelihoods & Evidence\nMaximized & Marginal Likelihoods\n\n\\(\\cal{BF}_{10}\\) = 1.73 or \\(\\cal{BF}_{01}\\) = 0.58\nPosterior Probability of \\(\\cal{H}_0\\) = 0.3665"
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#candidates-formula-besag-1989",
    "href": "resources/slides/14-hypothesis-testing.html#candidates-formula-besag-1989",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Candidate’s Formula (Besag 1989)",
    "text": "Candidate’s Formula (Besag 1989)\nAlternative expression for BF based on Candidate’s Formula or Savage-Dickey ratio \\[\\cal{BF}_{01} = \\frac{p( \\mathbf{y}\\mid \\cal{H}_0)}\n       {p( \\mathbf{y}\\mid \\cal{H}_1)} =\n  \\frac{\\pi_\\theta(0 \\mid \\cal{H}_1, \\mathbf{y})}\n       {\\pi_\\theta(0 \\mid \\cal{H}_1)}\\]\n\n\\[\\pi_\\theta(\\theta \\mid \\cal{H}_i, \\mathbf{y})  =  \\frac{p(\\mathbf{y}\\mid \\theta, \\cal{H}_i) \\pi(\\theta \\mid \\cal{H}_i)} {p(\\mathbf{y}\\mid \\cal{H}_i)}  \\Rightarrow  \np(\\mathbf{y}\\mid \\cal{H}_i)   = \\frac{p(\\mathbf{y}\\mid \\theta, \\cal{H}_i) \\pi(\\theta \\mid \\cal{H}_i)} {\\pi_\\theta(\\theta \\mid \\cal{H}_i, \\mathbf{y})}\\]\n\n\n\\[\\cal{BF}_{01}  = \\frac{\\frac{p(\\mathbf{y}\\mid \\theta, \\cal{H}_0) \\pi(\\theta \\mid \\cal{H}_0)} {\\pi_\\theta(\\theta \\mid \\cal{H}_0, \\mathbf{y})} } { \\frac{p(\\mathbf{y}\\mid \\theta, \\cal{H}_1) \\pi(\\theta \\mid \\cal{H}_1)} {\\pi_\\theta(\\theta \\mid \\cal{H}_1, \\mathbf{y})}}  =   \\frac{\\frac{p(\\mathbf{y}\\mid \\theta = 0) \\delta_0(\\theta)} {\\delta_0(\\theta)} } { \\frac{p(\\mathbf{y}\\mid \\theta, \\cal{H}_1) \\pi(\\theta \\mid \\cal{H}_1)} {\\pi_\\theta(\\theta \\mid \\cal{H}_1, \\mathbf{y})}}\n=   \\frac{p(\\mathbf{y}\\mid \\theta = 0)}{p(\\mathbf{y}\\mid \\theta, \\cal{H}_1)}\n   \\frac{\\delta_0(\\theta)} {\\delta_0(\\theta)}  \\frac{\\pi_\\theta(\\theta \\mid \\cal{H}_1, \\mathbf{y})}{\\pi(\\theta \\mid \\cal{H}_1)} \\]\n\nSimplifies to the ratio of the posterior to prior densities when evaluated \\(\\theta\\) at zero"
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#prior",
    "href": "resources/slides/14-hypothesis-testing.html#prior",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Prior",
    "text": "Prior\nPlots were based on a \\(\\theta \\mid \\cal{H}_1 \\sim \\textsf{N}(0, 1)\\)\n\ncentered at value for \\(\\theta\\) under \\(\\cal{H}_0\\) (goes back to Jeffreys)\n“unit information prior” equivalent to a prior sample size is 1\nis this a “reasonable prior”?\n\nWhat happens if \\(n \\to \\infty\\)?\nWhat happens of \\(\\tau_0 \\to 0\\) ? (less informative)"
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#choice-of-precision",
    "href": "resources/slides/14-hypothesis-testing.html#choice-of-precision",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Choice of Precision",
    "text": "Choice of Precision\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\tau_0 = 1/10\\)\nBayes Factor for \\(\\cal{H}_0\\) to \\(\\cal{H}_1\\) is \\(1.5\\)\nPosterior Probability of \\(\\cal{H}_0\\) = 0.6001\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\tau_0 = 1/1000\\)\nBayes Factor for \\(\\cal{H}_0\\) to \\(\\cal{H}_1\\) is \\(14.65\\)\nPosterior Probability of \\(\\cal{H}_0\\) = 0.9361"
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#vague-priors-hypothesis-testing",
    "href": "resources/slides/14-hypothesis-testing.html#vague-priors-hypothesis-testing",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Vague Priors & Hypothesis Testing",
    "text": "Vague Priors & Hypothesis Testing\n\nAs \\(\\tau_0 \\to 0\\) the \\(\\cal{BF}_{01} \\to \\infty\\) and \\(\\Pr(\\cal{H}_0 \\mid \\mathbf{y}\\to 1\\)!\nAs we use a less & less informative prior for \\(\\theta\\) under \\(\\cal{H}_1\\) we obtain more & more evidence for \\(\\cal{H}_0\\) over \\(\\cal{H}_1\\)!\nKnown as Bartlett’s Paradox - the paradox is that a seemingly non-informative prior for \\(\\theta\\) is very informative about \\(\\cal{H}\\)!\nGeneral problem with nested sequence of models. If we choose vague priors on the additional parameter in the larger model we will be favoring the smaller models under consideration!\nSimilar phenomenon with increasing sample size (Lindley’s Paradox)\n\n\n\n\n\n\n\n\nBottom Line Don’t use vague priors!\n\n\n\n\n\nWhat should we use then?"
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#other-options",
    "href": "resources/slides/14-hypothesis-testing.html#other-options",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Other Options",
    "text": "Other Options\n\nPlace a prior on \\(\\tau_0\\) \\[\\tau_0 \\sim \\textsf{Gamma}(1/2, 1/2)\\]\nIf \\(\\theta \\mid \\tau_0, \\cal{H}_1 \\sim \\textsf{N}(0, 1/\\tau_0)\\), then \\(\\theta_0 \\mid \\cal{H}_1\\) has a \\(\\textsf{Cauchy}(0,1)\\) distribution! Recommended by Jeffreys (1961)\nno closed form expressions for marginal likelihood!"
  },
  {
    "objectID": "resources/slides/14-hypothesis-testing.html#intrinsic-bayes-factors-priors-berger-pericchi",
    "href": "resources/slides/14-hypothesis-testing.html#intrinsic-bayes-factors-priors-berger-pericchi",
    "title": "Lecture 14: Basics of Bayesian Hypothesis Testing",
    "section": "Intrinsic Bayes Factors & Priors (Berger & Pericchi)",
    "text": "Intrinsic Bayes Factors & Priors (Berger & Pericchi)\n\nCan’t use improper priors under \\(\\cal{H}_1\\)\nuse part of the data \\(y(l)\\) to update an improper prior on \\(\\theta\\) to get a proper posterior \\(\\pi(\\theta \\mid \\cal{H}_i, y(l))\\)\nuse \\(\\pi(\\theta \\mid y(l), \\cal{H}_i)\\) to obtain the posterior for \\(\\theta\\) based on the rest of the training data\nCalculate a Bayes Factor (avoids arbitrary normalizing constants!)\nChoice of training sample \\(y(l)\\)?\nBerger & Pericchi (1996) propose “averaging” over training samples intrinsic Bayes Factors\nintrinsic prior on \\(\\theta\\) that leads to the Intrisic Bayes Factor\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/15-Bayes-multiple-testing.html#normal-means-model",
    "href": "resources/slides/15-Bayes-multiple-testing.html#normal-means-model",
    "title": "Lecture 15: Bayesian Multiple Testing",
    "section": "Normal Means Model",
    "text": "Normal Means Model\nSuppose we have normal data with \\(Y_i \\mid \\mu_i, \\sigma^2 \\overset{iid}{\\sim} \\textsf{N}(\\mu_i, \\sigma^2)\\)\n\nMultiple Testing \\(H_{0i}: \\mu_i = 0\\) versus \\(H_{1i}: \\mu_i \\neq 0\\)\n\\(n\\) hypotheses that may potentially be closely related, e.g. \\(H_{01}\\) no difference in expression of gene \\(i\\) between cases and controls, for \\(n\\) genes\nMeans Model based on a “Spike & Slab” Prior: \\[\\mu_i  \\mid  \\tau \\overset{iid}{\\sim} \\pi_0 \\delta_0 + (1 - \\pi_0)g(\\mu_i \\mid 0,  \\tau)\\]\nneed to specify\n\\(\\pi_0\\) Probability of \\(H_{0i}\\) or that \\(\\mu_{i} = 0\\) (spike)\n\\(g\\) “slab distribution”\nconcern: is that # errors blows up with \\(n\\) (\\(n\\) = # tests = dimension of \\(\\{\\mu_i\\}\\) )"
  },
  {
    "objectID": "resources/slides/15-Bayes-multiple-testing.html#approach-1-prespecify-pi_0",
    "href": "resources/slides/15-Bayes-multiple-testing.html#approach-1-prespecify-pi_0",
    "title": "Lecture 15: Bayesian Multiple Testing",
    "section": "Approach 1: Prespecify \\(\\pi_0\\)",
    "text": "Approach 1: Prespecify \\(\\pi_0\\)\n\nseemingly non-informative choice?\n\\(\\pi_0 = 0.5\\)\nLet \\[\\gamma_i = \\left\\{ \\begin{array}{c} 1 \\text{ if }  H_{1i} \\text{ is true } \\\\\n0 \\text{ if }  H_{0i} \\text{ is true } \\end{array} \\right.\\]\n\n\n\\[\\gamma^{(n)} = (\\gamma_1, \\gamma_2, \\ldots, \\gamma_n)^2  \\qquad \\text{ e.g.   } \\gamma^{(n)} = (0,1,0,0, \\ldots, 1)^T\\]\n\nmodel size \\(p_\\gamma = \\sum_{i = 1}^n \\gamma_i\\) is the number of non-zero values. What does \\(\\pi_0 = 0.5\\) imply about the number of times \\(H_{1i}\\) is true a priori?"
  },
  {
    "objectID": "resources/slides/15-Bayes-multiple-testing.html#induced-distribution",
    "href": "resources/slides/15-Bayes-multiple-testing.html#induced-distribution",
    "title": "Lecture 15: Bayesian Multiple Testing",
    "section": "Induced Distribution",
    "text": "Induced Distribution\nif \\(p_\\gamma = \\sum_{i = 1}^n \\gamma_i\\) with \\(p(\\gamma_i = 1) = 0.5\\) then \\(p_\\gamma \\sim \\textsf{Binomial(n, 1/2)}\\)\n\nExpect 1/2 of the hypotheses to be true a priori"
  },
  {
    "objectID": "resources/slides/15-Bayes-multiple-testing.html#probabilities-of-no-features-or-at-least-1-feature",
    "href": "resources/slides/15-Bayes-multiple-testing.html#probabilities-of-no-features-or-at-least-1-feature",
    "title": "Lecture 15: Bayesian Multiple Testing",
    "section": "Probabilities of no features or at least 1 feature?",
    "text": "Probabilities of no features or at least 1 feature?\n\\[p_\\gamma \\sim \\textsf{Binomial(n, 1/2)}\\]\n\nprobability of no features \\(\\gamma^{(n)} = (0,0,0,\\ldots, 0)^T\\) or \\(p_\\gamma = 0\\) \\[\\Pr(p_\\gamma = 0) = \\pi_0^n = 0.5^n\\]\napproximately \\(0\\) for large \\(n\\)\nSimilarily, the probability of at least one feature is \\(1 - 0.5^n \\approx 1\\)"
  },
  {
    "objectID": "resources/slides/15-Bayes-multiple-testing.html#control-type-i-errors",
    "href": "resources/slides/15-Bayes-multiple-testing.html#control-type-i-errors",
    "title": "Lecture 15: Bayesian Multiple Testing",
    "section": "Control Type I Errors",
    "text": "Control Type I Errors\n\nSuppose we want to fix \\(\\pi_0\\) to protect against Type I errors blowing up as \\(n\\) increases \\[\\Pr( p_\\gamma = \\mathbf{0}_n) =  \\frac{1}{2} = \\pi_0^n\\]\n“Bayesian Bonferroni Prior”\nleads to \\(\\pi_0 = 0.5^{1/n}\\) very close to 1 for large \\(n\\)! We would need overwhelming evidence in the data for \\(\\Pr(H_{1i} \\mid y^{(n)})\\) to not be \\(\\approx 0\\)!\nnot a great idea to prespecify \\(\\pi_0\\)!"
  },
  {
    "objectID": "resources/slides/15-Bayes-multiple-testing.html#approach-2-empirical-bayes",
    "href": "resources/slides/15-Bayes-multiple-testing.html#approach-2-empirical-bayes",
    "title": "Lecture 15: Bayesian Multiple Testing",
    "section": "Approach 2: Empirical Bayes",
    "text": "Approach 2: Empirical Bayes\n\nEstimate \\(\\pi_0\\) from the data by maximizing the marginal likelihood\n\\[\\begin{align}\nY_i \\mid \\mu_i, \\sigma^2 \\mid \\overset{ind}{\\sim} \\textsf{N}(\\mu_i, \\sigma^2) \\\\\n\\mu_i \\mid \\tau, \\pi_0 & \\overset{iid}{\\sim} \\pi_0 \\delta_0 + (1 - \\pi_0)\\textsf{N}(\\mu_i; 0,  \\tau)\n\\end{align}\\]\nmarginal likelihood \\[\\begin{align*} \\cal{L}(\\pi_0, \\tau) & =  \\int_{\\mathbb{R}^n} \\prod_{i = 1}^n  \\textsf{N}(y_i ; \\mu_i, \\sigma^2) \\left\\{\\pi_0 \\delta_0(\\mu_i) + (1 - \\pi_0)\\textsf{N}(\\mu_i; 0,  \\tau) \\right\\} d\\mu_1 \\ldots d\\mu_n\n\\\\\n& =  \\prod_{i = 1}^n  \\int_\\mathbb{R}  \\textsf{N}(y_i ; \\mu_i, \\sigma^2) \\left\\{\\pi_0 \\delta_0(\\mu_i) + (1 - \\pi_0)\\textsf{N}(\\mu_i; 0,  \\tau) \\right\\} d\\mu_i\n\\end{align*}\\]\nConjugate or nice setups we can integrate out \\(\\mu_i\\) and then maximize marginal likelihood for \\(\\pi_0\\) and \\(\\tau\\)\nNumerical integration (lab) or EM algorithms to get \\(\\hat{\\pi}_0^{\\textsf{EB}}\\) and \\(\\hat{\\tau}^{\\textsf{EB}}\\)"
  },
  {
    "objectID": "resources/slides/15-Bayes-multiple-testing.html#expectation-maximization-sigma-1",
    "href": "resources/slides/15-Bayes-multiple-testing.html#expectation-maximization-sigma-1",
    "title": "Lecture 15: Bayesian Multiple Testing",
    "section": "Expectation-Maximization (\\(\\sigma = 1\\))",
    "text": "Expectation-Maximization (\\(\\sigma = 1\\))\nIntroduce latent variables so that “complete” data likelihood is nice! (no integrals!) \\[\\begin{align} y_i \\mid \\gamma_i, \\tau & \\overset{iid}{\\sim} \\textsf{N}(0, 1)^{1 - \\gamma_i} \\textsf{N}(0, 1 + \\tau)^{\\gamma_i} \\\\\n\\gamma_i \\mid \\pi_0 & \\overset{iid}{\\sim} \\textsf{Ber}(1 - \\pi_0)\n\\end{align}\\]\n\nIterate: For \\(t = 1, \\ldots\\)\nM-step: Solve for \\((\\hat{\\pi}_0^{(t)}, \\hat{\\tau}^{(t)}) = \\arg \\max\\cal{L}(\\pi_0, \\tau \\mid \\hat{\\gamma}^{(t-1)})\\)\nE-step: find the expected values of the latent sufficient statistics given the data, \\(\\hat{\\pi}_0^{(t)}\\) , \\(\\hat{\\tau}^{(t)}\\) (i.e. posterior expectation) \\[\\hat{\\gamma}^{(t)} = \\textsf{E}[\\gamma_i \\mid y, \\hat{\\pi}^{(t)}_0, \\hat{\\tau}^{(t)}]\\]\nClyde & George (2000) Silverman & Johnstone (2004) for orthogonal regression"
  },
  {
    "objectID": "resources/slides/15-Bayes-multiple-testing.html#m-step",
    "href": "resources/slides/15-Bayes-multiple-testing.html#m-step",
    "title": "Lecture 15: Bayesian Multiple Testing",
    "section": "M-Step",
    "text": "M-Step\n\nlog-likelihood \\[\\begin{align} \\cal{L}(\\pi_0, \\tau) = &  \\sum_i (1 -\\gamma_i) \\log(\\pi_0) + \\gamma_i \\log(1 - \\pi_0) + \\\\\n& \\sum_i(1 - \\gamma_i) N(y_i; 0, 1) + \\gamma_i N(y_i; 0, 1 + \\tau)\n\\end{align}\\]\nplug in \\(\\hat{\\gamma}_i^{(t)}\\) above and maximize wrt \\(\\pi_0\\) and \\(\\tau\\)\n\\(\\hat{\\pi}_0^{(t)} = 1 - \\frac{\\sum_i\\hat{\\gamma}_i^{(t)}}{n}\\)\n\\(\\hat{\\tau}^{(t)} = \\max\\{0, \\frac{\\sum_i \\hat{\\gamma}_i^{(t)} y_i^2}{\\sum_i \\hat{\\gamma}_i^{(t)}} - 1\\}\\)"
  },
  {
    "objectID": "resources/slides/15-Bayes-multiple-testing.html#e-step",
    "href": "resources/slides/15-Bayes-multiple-testing.html#e-step",
    "title": "Lecture 15: Bayesian Multiple Testing",
    "section": "E-Step",
    "text": "E-Step\nPosterior distribution for \\(\\gamma_i \\mid y_i, \\hat{\\tau}, \\hat{\\pi}\\) \\[\\gamma_i \\mid y_i, \\hat{\\tau}, \\hat{\\pi}_0 \\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}\\textsf{Ber}(\\omega_{i})\\]\n\n\\(\\omega_i = \\frac{\\cal{O}_i}{1 + \\cal{O}_i}\\) with posterior odds \\(\\cal{O}_i\\) \\[\\begin{align}\n\\cal{O}_i & = \\frac{1 - \\hat{\\pi}^{(t)}_0}{\\hat{\\pi}^{(t)}_0} \\times \\textsf{BF}_{10} \\\\\n\\textsf{BF}_{10} & = \\frac{p(y \\mid \\gamma_i = 1, \\hat{\\tau}^{(t)})}{p(y \\mid \\gamma_i = 0)} =\n\\frac{1}{(1 + \\hat{\\tau}^{(t)})^{1/2}} e^{ \\frac{1}{2} y_i^2 \\frac{\\hat{\\tau}^{(t)}} {1 + \\hat{\\tau}^{(t)}}}\n\\end{align}\\]"
  },
  {
    "objectID": "resources/slides/15-Bayes-multiple-testing.html#adding-noise",
    "href": "resources/slides/15-Bayes-multiple-testing.html#adding-noise",
    "title": "Lecture 15: Bayesian Multiple Testing",
    "section": "Adding Noise",
    "text": "Adding Noise\nWhat happens to \\(\\hat{\\pi}_0^{\\textsf{EB}}\\) if have all noise?\n\n\\(\\hat{\\tau} \\to 0\\) as \\(n \\to \\infty\\) (here \\(n = 10000\\)) (\\(\\hat{\\tau}^{(t)} = \\max\\{0, \\frac{\\sum_i \\hat{\\gamma}_i^{(t)} y_i^2}{\\sum_i \\hat{\\gamma}_i^{(t)}} - 1\\}\\) ) so distribution collapses to the same as the noise model\n\\(\\textsf{BF}_{10} \\to 1\\) so \\(\\hat{\\pi}_0^{(t)} = \\hat{\\pi}_0^{(0)}\\)\n\\(\\hat{\\pi}_0^{\\textsf{EB}}\\) gets stuck at initial value of \\(\\pi_0\\)!\nposterior probability of \\(H_{1i}\\) not consistent as well as \\(\\pi_0\\)\nsimilar problems with convergence to a local mode with even with more features"
  },
  {
    "objectID": "resources/slides/15-Bayes-multiple-testing.html#approach-3-fully-bayes",
    "href": "resources/slides/15-Bayes-multiple-testing.html#approach-3-fully-bayes",
    "title": "Lecture 15: Bayesian Multiple Testing",
    "section": "Approach 3: Fully Bayes",
    "text": "Approach 3: Fully Bayes\nChoose a prior for \\(\\pi_0\\) (and \\(\\tau\\)), simplest case \\(\\pi_0 \\sim \\textsf{Beta}(a,b)\\)\n\nConsider the thought experiment where we don’t know the first hypothesis but we know that the others are all null \\(\\gamma_j = 0\\) for \\(j = 2, \\ldots, n\\) \\[\\gamma^{(n)} = (?, 0,,\\ldots, 0)^T\\]\n\\(\\gamma_i \\sim \\textsf{Bernoulli}(1 - \\pi_0)\\)\nUpdate the prior for \\(\\pi_0\\) to include the info \\(\\gamma_j = 0\\) for \\(j = 2, \\ldots, n\\) \\[\\begin{align}\n\\pi(\\pi_0 \\mid \\gamma_2, \\ldots, \\gamma_n) & \\propto \\pi_0^{a - 1} (1 - \\pi_0)^{b -1} \\prod_{j = 2}^n \\pi_0^{1 - \\gamma_j} (1 - \\pi_0)^{\\gamma_j}\\\\\n\\pi(\\pi_0  \\mid \\gamma_2, \\ldots, \\gamma_n) & \\propto \\pi_0^{a + n -1  -1} (1 - \\pi_0)^{b - 1}\n\\end{align}\\]"
  },
  {
    "objectID": "resources/slides/15-Bayes-multiple-testing.html#beta-posterior",
    "href": "resources/slides/15-Bayes-multiple-testing.html#beta-posterior",
    "title": "Lecture 15: Bayesian Multiple Testing",
    "section": "Beta Posterior",
    "text": "Beta Posterior\nPosterior \\(\\pi_0 \\mid \\gamma_2, \\ldots, \\gamma_n \\sim \\textsf{Beta(a + n - 1, b)}\\) with mean \\[\\textsf{E}[\\pi_0 \\mid \\gamma_2, \\ldots, \\gamma_n] = \\frac{a + n - 1}{a + n - 1 + b}\\]\n\nsuppose \\(a = b = 1\\) (Uniform prior) \\[\\textsf{E}[\\pi_0 \\mid \\gamma_2, \\ldots, \\gamma_n] = \\frac{n}{n + 1}\\]\nimplies probability of \\(H_{01} \\to 1\\) and \\(H_{11} \\to 0\\) as \\(n \\to \\infty\\) borrowing strength from other nulls\nMultiplicity adjustment as in the EB case\nScott & Berger (2006 JSPI, 2010 AoS) show that above framework protects against increasing Type I errors with \\(n\\); We also get FDR control automatically"
  },
  {
    "objectID": "resources/slides/15-Bayes-multiple-testing.html#induced-prior-on-p_gamma",
    "href": "resources/slides/15-Bayes-multiple-testing.html#induced-prior-on-p_gamma",
    "title": "Lecture 15: Bayesian Multiple Testing",
    "section": "Induced Prior on \\(p_{\\gamma}\\)",
    "text": "Induced Prior on \\(p_{\\gamma}\\)\n\n\n\n\n\n\nExercise for the Energetic Student:\n\n\nIf \\(p_{\\gamma} \\mid \\pi_0 \\sim \\textsf{Binomial}(n, 1 - \\pi_0)\\) and \\(\\pi_0 \\sim \\textsf{Beta}(1,1)\\)\n\nWhat is the probability that \\(p_\\gamma = 0\\)\nWhat is the probability that \\(p_\\gamma = n\\)\nWhat is the distribution of \\(p_\\gamma\\) ?\n\n\n\n\n\n\nThis is a Beta-Binomial distribution!\nspecial case \\(a = b = 1\\) this is a discrete uniform on model size!\n\n\nBottomline: We need to “learn” key parameters in our hierarchical prior or the magic doesn’t work! Borrowing comes through using all the data to inform about “global” parameters in the prior, in this case \\(\\pi_0\\) (and \\(\\tau\\))!"
  },
  {
    "objectID": "resources/slides/15-Bayes-multiple-testing.html#posteriors-inference-and-decisions",
    "href": "resources/slides/15-Bayes-multiple-testing.html#posteriors-inference-and-decisions",
    "title": "Lecture 15: Bayesian Multiple Testing",
    "section": "Posteriors, Inference and Decisions",
    "text": "Posteriors, Inference and Decisions\n\nPosterior distribution of \\(\\mu_i\\) is a spike at 0 and continous distribution\nJoint posterior distribution of \\(\\mu_1, \\ldots, \\mu_n\\) averaged over hypotheses “Model averaging”\nselect a hypothesis\nReport posterior (summaries) conditional on a hypothesis\nIssue is the winner’s curse !\nNeed to have coherent conditional inference given that you selected a hypothesis.\nDon’t report selected hypotheses but report results under model averaging!"
  },
  {
    "objectID": "resources/slides/15-Bayes-multiple-testing.html#choice-of-slab",
    "href": "resources/slides/15-Bayes-multiple-testing.html#choice-of-slab",
    "title": "Lecture 15: Bayesian Multiple Testing",
    "section": "Choice of Slab",
    "text": "Choice of Slab\n\\[\\mu_i \\overset{iid}{\\sim} \\pi_0 \\delta_0 + (1 - \\pi_0)g(\\mu_i \\mid 0,  \\tau, H_{i1})\\]\n\ngrowing literature on posterior contraction in high dimensional settings as \\(n \\to \\infty\\) with “sparse signals”\nposterior \\(\\pi(\\mu^{(n)}) \\mid y^{(n)})\\)\nWant \\[\\Pr(\\mu^{(n)} \\in \\cal{N}_{\\epsilon_n}(\\mu_0^{(n)}) \\mid y^{(n)})\\to 1\\]\nassume that there are \\(s\\) features (fixed or growing slowly)\nfeature values are bounded away from zero\nWant the posterior under the Spike and Slab prior to concentrate on this neighborhood (ie. probability 1 )\nactive area of research!\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#normal-linear-regression-example",
    "href": "resources/slides/09-data-augmentation.html#normal-linear-regression-example",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Normal Linear Regression Example",
    "text": "Normal Linear Regression Example\n\nModel \\[\\begin{align*}\nY_i \\mid \\beta, \\phi & \\overset{  ind}{\\sim} \\textsf{N}(x_i^T\\beta, 1/\\phi) \\\\\nY \\mid \\beta, \\phi & \\sim \\textsf{N}(X \\beta, \\phi^{-1} I_n) \\\\\n\\beta & \\sim \\textsf{N}(b_0, \\Phi_0^{-1}) \\\\\n\\phi & \\sim \\textsf{Gamma}(v_0/2, s_0/2)\n\\end{align*}\\]\n\\(x_i\\) is a \\(p \\times 1\\) vector of predictors and \\(X\\) is \\(n \\times p\\) matrix\n\\(\\beta\\) is a \\(p \\times 1\\) vector of coefficients\n\\(\\Phi_0\\) is a \\(p \\times p\\) prior precision matrix\nMultivariate Normal density for \\(\\beta\\) \\[\\pi(\\beta \\mid b_0, \\Phi_0) = \\frac{|\\Phi_0|^{1/2}}{(2 \\pi)^{p/2}}\\exp\\left\\{- \\frac{1}{2}(\\beta - b_0)^T \\Phi_0 (\\beta - b_0)  \\right\\}\\]"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#full-conditional-for-beta",
    "href": "resources/slides/09-data-augmentation.html#full-conditional-for-beta",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Full Conditional for \\(\\beta\\)",
    "text": "Full Conditional for \\(\\beta\\)\n\\[\\begin{align*}\n\\beta & \\mid \\phi, y_1, \\ldots, y_n \\sim \\textsf{N}(b_n, \\Phi_n^{-1}) \\\\\nb_n & =  (\\Phi_0 + \\phi X^TX)^{-1}(\\Phi_0 b_0  +  \\phi X^TX \\hat{\\beta})\\\\\n\\Phi_n & = \\Phi_0 + \\phi X^TX\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#derivation-continued",
    "href": "resources/slides/09-data-augmentation.html#derivation-continued",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Derivation continued",
    "text": "Derivation continued"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#full-conditional-for-phi",
    "href": "resources/slides/09-data-augmentation.html#full-conditional-for-phi",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Full Conditional for \\(\\phi\\)",
    "text": "Full Conditional for \\(\\phi\\)\n\\[\\phi \\mid \\beta, y_1, \\ldots, y_n \\sim \\textsf{Gamma}\\left(\\frac{v_0 + n}{2}, \\frac{s_0 + \\sum_i(y_i - x^T_i \\beta)^2}{2}\\right)\\]"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#choice-of-prior-precision",
    "href": "resources/slides/09-data-augmentation.html#choice-of-prior-precision",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Choice of Prior Precision",
    "text": "Choice of Prior Precision\n\nNon-Informative \\(\\Phi_0 \\to 0\\)\nFormal Posterior given \\(\\phi\\) \\[\\beta \\mid \\phi, y_1, \\ldots, y_n \\sim \\textsf{N}(\\hat{\\beta}, \\phi^{-1} (X^TX)^{-1})\\]\nneeds \\(X^TX\\) to be full rank for distribution to be unique!"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#binary-regression",
    "href": "resources/slides/09-data-augmentation.html#binary-regression",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Binary Regression",
    "text": "Binary Regression\n\\[Y_i \\mid \\beta \\sim \\textsf{Ber}(p(x_i^T \\beta))\\] where \\(\\Pr(Y_i = 1 \\mid \\beta) = p(x_i^T \\beta))\\) and linear predictor \\(x_i^T\\beta = \\lambda_i\\)\n\nlink function for binary regression is any 1-1 function \\(g\\) that will map \\((0,1) \\to \\mathbb{R}\\), i.e. \\(g(p(\\lambda)) = \\lambda\\)\nlogistic regression uses the logit link\n\\[\\log\\left(\\frac{p(\\lambda_i)}{1 - p(\\lambda_i) }\\right) = x_i^T \\beta = \\lambda_i\\]\nprobit link \\[p(x_i^T \\beta) = \\Phi(x_i^T \\beta)\\]\n\\(\\Phi()\\) is the Normal cdf"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#likelihood-and-posterior",
    "href": "resources/slides/09-data-augmentation.html#likelihood-and-posterior",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Likelihood and Posterior",
    "text": "Likelihood and Posterior\nLikelihood: \\[\\cal{L}(\\beta) \\propto \\prod_{i = 1}^n \\Phi(x_i^T \\beta)^{y_i} (1 - \\Phi(x^T_i \\beta))^{1 - y_i}\\]\n\nprior \\(\\beta \\sim \\textsf{N}_p(b_0, \\Phi_0)\\)\nposterior \\(\\pi(\\beta) \\propto \\pi(\\beta) \\cal{L}(\\beta)\\)\nHow to approximate the posterior?\n\nasymptotic Normal approximation\nMH with Independence chain or adaptive Metropolis\nstan (Hamiltonian Monte Carlo)\nGibbs ?\n\nseemingly no, but there is a trick!"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#data-augmentation",
    "href": "resources/slides/09-data-augmentation.html#data-augmentation",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Data Augmentation",
    "text": "Data Augmentation\n\nConsider an augmented posterior \\[\\pi(\\beta, Z \\mid y) \\propto \\pi(\\beta) \\pi(Z \\mid \\beta) \\pi(y \\mid Z, \\beta)\\]\nIF we choose \\(\\pi(Z \\mid \\beta)\\) and \\(\\pi(y \\mid Z, \\beta)\\) carefully, we can carry out Gibbs and get samples of \\(\\pi(\\beta \\mid y)\\) !\ndesired marginal of joint augmented posterior \\[\\pi(\\beta \\mid y) = \\int_{\\cal{Z}} \\pi(\\beta, z \\mid y) \\, dz\\]\nWe have to choose latent prior and sampling model such that \\[p(y \\mid \\beta) = \\int_{\\cal{Z}}  \\pi(z \\mid \\beta) \\pi(y \\mid \\beta, z) \\, dz\\]\ncomplete data likelihood \\(\\pi(z \\mid \\beta) \\pi(y \\mid \\beta, z)\\)"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#augmentation-strategy",
    "href": "resources/slides/09-data-augmentation.html#augmentation-strategy",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Augmentation Strategy",
    "text": "Augmentation Strategy\nSet\n\n\\(y_i = 1_{(Z_i &gt; 0)}\\) i.e. ( \\(y_i = 1\\) if \\(Z_i &gt; 0\\) )\n\\(y_i = 1_{(Z_i &lt; 0)}\\) i.e. ( \\(y_i = 0\\) if \\(Z_i &lt; 0\\) )\n\\(Z_i = x_i^T \\beta + \\epsilon_i \\qquad \\epsilon_i \\overset{iid}{\\sim} \\textsf{N(0,1)}\\)\nRelationship to probit model: \\[\\begin{align*}\\Pr(y = 1 \\mid \\beta) & = P(Z_i &gt; 0 \\mid \\beta) \\\\\n& = P(Z_i - x_i^T \\beta &gt; -x^T\\beta) \\\\\n& = P(\\epsilon_i &gt; -x^T\\beta) \\\\\n& =  1 - \\Phi(-x^T_i \\beta) \\\\\n& =  \\Phi(x^T_i \\beta)\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#augmented-posterior-gibbs",
    "href": "resources/slides/09-data-augmentation.html#augmented-posterior-gibbs",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Augmented Posterior & Gibbs",
    "text": "Augmented Posterior & Gibbs\n\ntwo block Gibbs sampler \\(\\theta_{[1]} = \\beta\\) and \\(\\theta_{[2]} = (Z_1, \\ldots, Z_n)^T\\) \\[\\begin{align*}\\pi(& Z_1,  \\ldots, Z_n,  \\, \\beta \\mid y) \\propto \\\\\n& \\textsf{N}(\\beta; b_0, \\phi_0)  \\left\\{\\prod_{i=1}^n \\textsf{N}(Z_i; x_i^T\\beta, 1)\\right\\} \\left\\{  \\prod_{i=1}^n y_i 1_{(Z_i &gt; 0)} + (1 - y_i)1_{(Z_i &lt; 0)}\\right\\}\n\\end{align*}\\]\nfull conditional for \\(\\beta\\) given \\(Z_i\\)’s based on Normal-Normal regression \\[\\beta \\mid Z_1, \\ldots, Z_n, y_1, \\ldots, y_n \\sim \\textsf{N}(b_n, \\Phi_n)\\]\nFull conditional for latent \\(Z_i\\) (product of independent dist’s) \\[\\begin{align*}\n\\pi(Z_i \\mid \\beta, Z_{[-i]}, y_1, \\ldots, y_n)  & \\propto\n\\textsf{N}(Z_i; x_i^T \\beta, 1)1_{(Z_i &gt; 0)} \\text{   if  } y_1 = 1 \\\\\n\\pi(Z_i \\mid \\beta, Z_{[-i]}, y_1, \\ldots, y_n)  & \\propto\n\\textsf{N}(Z_i; x_i^T \\beta, 1)1_{(Z_i &lt; 0) }\\text{   if  } y_1 = 0 \\\\\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#truncated-sampling",
    "href": "resources/slides/09-data-augmentation.html#truncated-sampling",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Truncated Sampling",
    "text": "Truncated Sampling\n\n\n\nUse inverse cdf method for cdf \\(F\\)\nIf \\(U\\sim U(0,1)\\) set \\(X = F^{-1}(U)\\)\nif \\(X \\in (a, b)\\), Draw \\(X \\sim U(F(a),F(b))\\) and set \\(X = F^{-1}(u)\\)"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#truncated-normal-sampling",
    "href": "resources/slides/09-data-augmentation.html#truncated-normal-sampling",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Truncated Normal Sampling",
    "text": "Truncated Normal Sampling\n\n\n\nsample from independent truncated normal distributions for full conditional for \\(Z_i\\)\nif \\(Y_i = 1\\) then \\(Z_i \\sim \\textsf{Normal}(x_i^T\\beta, 1) I(0, \\infty)\\)\nstandard truncated normal \\(\\tilde{Z} = Z_i - x_i^T \\beta \\in (-x_i^T \\beta, \\infty)\\)\n\n\nGenerate \\(U \\sim \\textsf{Uniform}(\\Phi(-x_i^T\\beta), \\Phi(\\infty))\\)\nSet \\(\\tilde{z} = \\Phi^{-1}(U)\\) (Standard truncated normal)\nShift \\(Z_i = x_i^T \\beta + \\tilde{z}\\)\n\n\n\n\n\n\n\n\n\n\n\n\nU = 0.69, \\(Z_i = x_i^T \\beta + \\Phi^{-1}(U)\\) = 0.99"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#comments-on-gibbs",
    "href": "resources/slides/09-data-augmentation.html#comments-on-gibbs",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Comments on Gibbs",
    "text": "Comments on Gibbs\n\nWhy don’t we treat each individual \\(\\theta_j\\) as a separate block?\nGibbs always accepts, but can mix slowly if parameters in different blocks are highly correlated!\nUse block sizes in Gibbs that are as big as possible to improve mixing (proven faster convergence)\nCollapse the sampler by integrating out as many parameters as possible (as long as resulting sampler has good mixing)\ncan use Gibbs steps and (adaptive) Metropolis Hastings steps together\nlatent variables may allow Gibbs steps, but not always better compared to MH!"
  },
  {
    "objectID": "resources/slides/09-data-augmentation.html#data-augmentation-in-general",
    "href": "resources/slides/09-data-augmentation.html#data-augmentation-in-general",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "Data Augmentation in General",
    "text": "Data Augmentation in General\nDA is a broader than a computational trick allowing Gibbs sampling\n\nrandom effects or latent variable modeling i.e we introduce latent variables to simplify dependence structure modelling\nModeling heavy tailed distributions for priors or errors in robust regression as mixtures of normals\noutliers\nvariable selection\nmissing data\nNext class:\n\nMultivariate Normal data\n\nWishart and inverse-Wishart distributions\nmissing data\n\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#metropolis-hastings-mh",
    "href": "resources/slides/08-gibbs.html#metropolis-hastings-mh",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Metropolis-Hastings (MH)",
    "text": "Metropolis-Hastings (MH)\n\nMetropolis requires that the proposal distribution be symmetric\nHastings (1970) generalizes Metropolis algorithms to allow asymmetric proposals - aka Metropolis-Hastings or MH \\(q(\\theta^* \\mid \\theta^{(s)})\\) does not need to be the same as \\(q(\\theta^{(s)} \\mid \\theta^*)\\)\npropose \\(\\theta^* \\mid \\theta^{(s)} \\sim q(\\theta^* \\mid \\theta^{(s)})\\)\nAcceptance probability \\[\\min \\left\\{ 1, \\frac{\\pi(\\theta^*) \\cal{L}(\\theta^*)/q(\\theta^* \\mid \\theta^{(s)})}\n{\\pi(\\theta^{(s)}) \\cal{L}(\\theta^{(s)})/q( \\theta^{(s)} \\mid \\theta^*)} \\right\\}\\]\nadjustment for asymmetry in acceptance ratio is key to ensuring convergence to stationary distribution!"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#special-cases",
    "href": "resources/slides/08-gibbs.html#special-cases",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Special cases",
    "text": "Special cases\n\nMetropolis\nIndependence chain\nGibbs samplers\nMetropolis-within-Gibbs\ncombinations of the above!"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#independence-chain",
    "href": "resources/slides/08-gibbs.html#independence-chain",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Independence Chain",
    "text": "Independence Chain\n\nsuppose we have a good approximation \\(\\tilde{\\pi}(\\theta \\mid y)\\) to \\(\\pi(\\theta \\mid y)\\)\nDraw \\(\\theta^* \\sim \\tilde{\\pi}(\\theta \\mid y)\\) without conditioning on \\(\\theta^{(s)}\\)\nacceptance probability \\[\\min \\left\\{ 1, \\frac{\\pi(\\theta^*) \\cal{L}(\\theta^*)/\\tilde{\\pi}(\\theta^* \\mid \\theta^{(s)})}\n{\\pi(\\theta^{(s)}) \\cal{L}(\\theta^{(s)})/\\tilde{\\pi}( \\theta^{(s)} \\mid \\theta^*)} \\right\\}\\]\nwhat happens if the approximation is really accurate?\nprobability of acceptance is \\(\\approx 1\\)\nImportant caveat for convergence: tails of the proposalr should be at least as heavy as the tails of the posterior (Tweedie 1994)\nReplace Gaussian by a Student-t with low degrees of freedom\ntransformations of \\(\\theta\\) to imporove approximation"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#blocked-metropolis-hastings",
    "href": "resources/slides/08-gibbs.html#blocked-metropolis-hastings",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Blocked Metropolis-Hastings",
    "text": "Blocked Metropolis-Hastings\nSo far all algorithms update all of the parameters simultaneously\n\nconvenient to break problems in to \\(K\\) blocks and update them separately\n\\(\\theta = (\\theta_{[1]}, \\ldots, \\theta_{[K]}) = (\\theta_1, \\ldots, \\theta_p)\\)\nAt iteration \\(s\\), for \\(k = 1, \\ldots, K\\) Cycle thru blocks: (fixed order or random order)\n\npropose \\(\\theta^*_{[k]} \\sim q_k(\\theta_{[k]} \\mid \\theta_{[&lt;k]}^{(s)}, \\theta_{[&gt;k]}^{(s-1)})\\)\nset \\(\\theta_{[k]}^{(s)} = \\theta^*_{[k]}\\) with probability \\[\\min \\left\\{ 1, \\frac{\n\\pi(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^*,\n  \\theta_{[&gt;k]}^{(s-1)})\n\\cal{L}(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^*,\n     \\theta_{[&gt;k]}^{(s-1)})/\nq_k(\\theta_{[k]}^* \\mid \\theta_{[&lt;k]}^{(s)},    \n\\theta_{[&gt;k]}^{(s-1)})}\n{\\pi(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^{(s-1)},\n  \\theta_{[&gt;k]}^{(s-1)})\n\\cal{L}(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^{(s-1)},\n     \\theta_{[&gt;k]}^{(s-1)})/\nq_k(\\theta_{[k]}^{(s-1)} \\mid \\theta_{[&lt;k]}^{(s)},    \n\\theta_{[&gt;k]}^{(s-1)})} \\right\\}\\]"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#gibbs-sampler",
    "href": "resources/slides/08-gibbs.html#gibbs-sampler",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Gibbs Sampler",
    "text": "Gibbs Sampler\n\nThe Gibbs Sampler is special case of Blocked MH\nproposal distribution \\(q_k\\) for the \\(k\\)th block is the full conditional distribution for \\(\\theta_{[k]}\\) \\[\\begin{split}\n\\pi(\\theta_{[k]} \\mid \\theta_{[-k]}, y) & = \\frac{\\pi(\\theta_{[k]} , \\theta_{[-k]} \\mid y)}{ \\pi(\\theta_{[-k]} \\mid y))} \\propto \\pi(\\theta_{[k]} , \\theta_{[-k]} \\mid y)\\\\\n\\   & \\propto \\cal{L}(\\theta_{[k]} , \\theta_{[-k]})\\pi(\\theta_{[k]} , \\theta_{[-k]})\n\\end{split}\\]\nAcceptance probability \\[\\min \\left\\{ 1, \\frac{\n\\pi(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^*,\n      \\theta_{[&gt;k]}^{(s-1)})\n\\cal{L}(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^*,\n         \\theta_{[&gt;k]}^{(s-1)})/\nq_k(\\theta_{[k]}^* \\mid \\theta_{[&lt;k]}^{(s)},    \n     \\theta_{[&gt;k]}^{(s-1)})}\n{\\pi(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^{(s-1)},\n      \\theta_{[&gt;k]}^{(s-1)})\n\\cal{L}(\\theta_{[&lt;k]}^{(s)},\\theta_{[k]}^{(s-1)},\n         \\theta_{[&gt;k]}^{(s-1)})/\nq_k(\\theta_{[k]}^{(s-1)} \\mid \\theta_{[&lt;k]}^{(s)},    \n     \\theta_{[&gt;k]}^{(s-1)})} \\right\\}\\]\nNote normalizing constant in the proposal ratio cancels out and terms simplify so that acceptance probability is always 1!\neven though joint distribution is messy, full conditionals may be (conditionally) conjugate and easy to sample from!"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#univariate-normal-example",
    "href": "resources/slides/08-gibbs.html#univariate-normal-example",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Univariate Normal Example",
    "text": "Univariate Normal Example\nModel \\[\\begin{align*}\nY_i \\mid \\mu, \\sigma^2 & \\overset{iid}{\\sim} \\textsf{N}(\\mu, 1/\\phi) \\\\\n\\mu & \\sim \\textsf{N}(\\mu_0, 1/\\tau_0) \\\\\n\\phi & \\sim  \\textsf{Gamma}(a/2, b/2)\n\\end{align*}\\]\n\nJoint prior is a product of independent Normal-Gamma\nIs \\(\\pi(\\mu, \\phi \\mid y_1, \\ldots, y_n)\\) also a Normal-Gamma family?"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#full-conditional-for-the-mean",
    "href": "resources/slides/08-gibbs.html#full-conditional-for-the-mean",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Full Conditional for the Mean",
    "text": "Full Conditional for the Mean\nThe full conditional distributions \\(\\mu \\mid \\phi, y_1, \\ldots, y_n\\) \\[\\begin{align*}\n\\mu & \\mid \\phi, y_1, \\ldots, y_n \\sim \\textsf{N}(\\hat{\\mu}, 1/\\tau_n) \\\\\n\\hat{\\mu} & = \\frac{\\tau_0 \\mu_0  + n \\phi \\bar{y}}{\\tau_0 + n \\phi} \\\\\n\\tau_n & = \\tau_0 + n \\phi\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#full-conditional-for-the-precision",
    "href": "resources/slides/08-gibbs.html#full-conditional-for-the-precision",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Full Conditional for the Precision",
    "text": "Full Conditional for the Precision\n\nFull conditional for \\(\\phi\\) \\[\\begin{align*}\n\\phi  \\mid \\mu, y_1, \\ldots, y_n & \\sim \\textsf{Gamma}( a_n/2, b_n/2) \\\\\na_n & = a + n \\\\\nb_n & = b + \\sum_i (y_i - \\mu)^2\n\\end{align*}\\]\n\n\n\\[\\textsf{E}[\\phi \\mid \\mu, y_1, \\ldots, y_n] = \\frac{(a + n)/2}{(b + \\sum_i (y_i - \\mu)^2 )/2}\\]\n\nWhat happens with a non-informative prior i.e \\(a = b = \\epsilon\\) as \\(\\epsilon \\to 0\\)?\n\n\n\n\n\n\n\n\n\nProper full conditionals with improper priors do not ensure proper joint posterior!"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#normal-linear-regression-example",
    "href": "resources/slides/08-gibbs.html#normal-linear-regression-example",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Normal Linear Regression Example",
    "text": "Normal Linear Regression Example\n\nModel \\[\\begin{align*}\nY_i \\mid \\beta, \\phi & \\overset{iid}{\\sim} \\textsf{N}(x_i^T\\beta, 1/\\phi) \\\\\nY \\mid \\beta, \\phi & \\sim \\textsf{N}(X \\beta, \\phi^{-1} I_n) \\\\\n\\beta & \\sim \\textsf{N}(b_0, \\Phi_0^{-1}) \\\\\n\\phi & \\sim \\textsf{Gamma}(v_0/2, s_0/2)\n\\end{align*}\\]\n\\(x_i\\) is a \\(p \\times 1\\) vector of predictors and \\(X\\) is \\(n \\times p\\) matrix\n\\(\\beta\\) is a \\(p \\times 1\\) vector of coefficients\n\\(\\Phi_0\\) is a \\(p \\times p\\) prior precision matrix\nMultivariate Normal density for \\(\\beta\\) \\[\\pi(\\beta \\mid b_0, \\Phi_0) = \\frac{|\\Phi_0|^{1/2}}{(2 \\pi)^{p/2}}\\exp\\left\\{- \\frac{1}{2}(\\beta - b_0)^T \\Phi_0 (\\beta - b_0)  \\right\\}\\] Note: stopped here 9/26/23 ## Full Conditional for \\(\\beta\\) {.smaller}\n\n\\[\\begin{align*}\n\\beta & \\mid \\phi, y_1, \\ldots, y_n \\sim \\textsf{N}(b_n, \\Phi_n^{-1}) \\\\\nb_n & =  (\\Phi_0 + \\phi X^TX)^{-1}(\\Phi_0 b_0  +  \\phi X^TX \\hat{\\beta})\\\\\n\\Phi_n & = \\Phi_0 + \\phi X^TX\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#derivation-continued",
    "href": "resources/slides/08-gibbs.html#derivation-continued",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Derivation continued",
    "text": "Derivation continued"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#full-conditional-for-phi",
    "href": "resources/slides/08-gibbs.html#full-conditional-for-phi",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Full Conditional for \\(\\phi\\)",
    "text": "Full Conditional for \\(\\phi\\)\n\\[\\phi \\mid \\beta, y_1, \\ldots, y_n \\sim \\textsf{Gamma}\\left(\\frac{v_0 + n}{2}, \\frac{s_0 + \\sum_i(y_i - x^T_i \\beta)^2}{2}\\right)\\]"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#choice-of-prior-precision",
    "href": "resources/slides/08-gibbs.html#choice-of-prior-precision",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Choice of Prior Precision",
    "text": "Choice of Prior Precision\n\nNon-Informative \\(\\Phi_0 \\to 0\\)\nFormal Posterior given \\(\\phi\\) \\[\\beta \\mid \\phi, y_1, \\ldots, y_n \\sim \\textsf{N}(\\hat{\\beta}, \\phi^{-1} (X^TX)^{-1})\\]\nneeds \\(X^TX\\) to be full rank for distribution to be unique"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#invariance-and-choice-of-meanprecision",
    "href": "resources/slides/08-gibbs.html#invariance-and-choice-of-meanprecision",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Invariance and Choice of Mean/Precision",
    "text": "Invariance and Choice of Mean/Precision\n\nthe model in vector form \\(Y \\mid \\beta, \\phi \\sim \\textsf{N}_n (X\\beta, \\phi^{-1} I_n)\\)\nWhat if we transform the mean \\(X\\beta = X H H^{-1} \\beta\\) with new \\(X\\) matrix \\(\\tilde{X} = X H\\) where \\(H\\) is \\(p \\times p\\) and invertible and coefficients \\(\\tilde{\\beta} = H^{-1} \\beta\\).\nobtain the posterior for \\(\\tilde{\\beta}\\) using \\(Y\\) and \\(\\tilde{X}\\)\n\\[ Y \\mid  \\tilde{\\beta}, \\phi \\sim \\textsf{N}_n (\\tilde{X}\\tilde{\\beta}, \\phi^{-1} I_n)\\]\nsince \\(\\tilde{X} \\tilde{\\beta} = X H \\tilde{\\beta} = X \\beta\\) invariance suggests that the posterior for \\(\\beta\\) and \\(H \\tilde{\\beta}\\) should be the same\nplus the posterior of \\(H^{-1} \\beta\\) and \\(\\tilde{\\beta}\\) should be the same\n\n\n\n\n\n\n\n\nExercise for the Energetic Student\n\n\nWith some linear algebra, show that this is true for a normal prior if \\(b_0 = 0\\) and \\(\\Phi_0\\) is \\(k X^TX\\) for some \\(k\\)"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#zellners-g-prior",
    "href": "resources/slides/08-gibbs.html#zellners-g-prior",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Zellner’s g-prior",
    "text": "Zellner’s g-prior\n\nPopular choice is to take \\(k = \\phi/g\\) which is a special case of Zellner’s g-prior \\[\\beta \\mid \\phi, g \\sim \\textsf{N}\\left(0, \\frac{g}{\\phi} (X^TX)^{-1}\\right)\\]\nFull conditional \\[\\beta \\mid \\phi, g \\sim \\textsf{N}\\left(\\frac{g}{1 + g} \\hat{\\beta}, \\frac{1}{\\phi} \\frac{g}{1 + g} (X^TX)^{-1}\\right)\\]\none parameter \\(g\\) controls shrinkage\nif \\(\\phi \\sim \\textsf{Gamma}(v_0/2, s_0/2)\\) then posterior is \\[\\phi \\mid y_1, \\ldots, y_n \\sim \\textsf{Gamma}(v_n/2, s_n/2)\\]\nConjugate so we could skip Gibbs sampling and sample directly from gamma and then conditional normal!"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#ridge-regression",
    "href": "resources/slides/08-gibbs.html#ridge-regression",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Ridge Regression",
    "text": "Ridge Regression\n\nIf \\(X^TX\\) is nearly singular, certain elements of \\(\\beta\\) or (linear combinations of \\(\\beta\\)) may have huge variances under the \\(g\\)-prior (or flat prior) as the MLEs are highly unstable!\nRidge regression protects against the explosion of variances and ill-conditioning with the conjugate priors: \\[\\beta \\mid \\phi \\sim \\textsf{N}(0, \\frac{1}{\\phi \\lambda} I_p)\\]\nPosterior for \\(\\beta\\) (conjugate case) \\[\\beta \\mid \\phi, \\lambda, y_1, \\ldots, y_n \\sim\n\\textsf{N}\\left((\\lambda I_p + X^TX)^{-1} X^T Y,  \\frac{1}{\\phi}(\\lambda I_p + X^TX)^{-1}\n\\right)\\]"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#bayes-regression",
    "href": "resources/slides/08-gibbs.html#bayes-regression",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Bayes Regression",
    "text": "Bayes Regression\n\nPosterior mean (or mode) given \\(\\lambda\\) is biased, but can show that there always is a value of \\(\\lambda\\) where the frequentist’s expected squared error loss is smaller for the Ridge estimator than MLE!\nrelated to penalized maximum likelihood estimation\nChoice of \\(\\lambda\\)\nBayes Regression and choice of \\(\\Phi_0\\) in general is a very important problem and provides the foundation for many variations on shrinkage estimators, variable selection, hierarchical models, nonparameteric regression and more!\nBe sure that you can derive the full conditional posteriors for \\(\\beta\\) and \\(\\phi\\) as well as the joint posterior in the conjugate case!"
  },
  {
    "objectID": "resources/slides/08-gibbs.html#comments",
    "href": "resources/slides/08-gibbs.html#comments",
    "title": "Lecture 8: Metropolis-Hastings, Gibbs and Blocking",
    "section": "Comments",
    "text": "Comments\n\nWhy don’t we treat each individual \\(\\beta_j\\) as a separate block?\nGibbs always accepts, but can mix slowly if parameters in different blocks are highly correlated!\nUse block sizes in Gibbs that are as big as possible to improve mixing (proven faster convergence)\nCollapse the sampler by integrating out as many parameters as possible (as long as resulting sampler has good mixing)\ncan use Gibbs steps and (adaptive) Metropolis Hastings steps together\nIntroduce latent variables (data augmentation) to allow Gibbs steps (Next class)\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/16-bma.html#normal-regression-model",
    "href": "resources/slides/16-bma.html#normal-regression-model",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Normal Regression Model",
    "text": "Normal Regression Model\nCentered regression model where \\(\\mathbf{X}^c\\) is the \\(n \\times p\\) centered design matrix where all variables have had their means subtracted (may or may not need to be standardized)\n\\[\\mathbf{Y}= \\mathbf{1}_n \\alpha + \\mathbf{X}^c \\boldsymbol{\\beta}+ \\boldsymbol{\\epsilon}\\]\n\n“Redundant” variables lead to unstable estimates\n\nSome variables may not be relevant at all (\\(\\beta_j = 0\\))\nWe want to reduce the dimension of the predictor space\nHow can we infer a “good” model that uses a subset of predictors from the data?\nExpand model hierarchically to introduce another latent variable \\(\\boldsymbol{\\gamma}\\) that encodes models \\({\\cal M}_\\gamma\\) \\(\\boldsymbol{\\gamma}= (\\gamma_1, \\gamma_2, \\ldots \\gamma_p)^T\\) where \\[\\begin{align*}\n  \\gamma_j = 0 & \\Leftrightarrow \\beta_j = 0 \\\\\n  \\gamma_j = 1 &  \\Leftrightarrow \\beta_j \\neq 0\n  \\end{align*}\\]\nFind Bayes factors and posterior probabilities of models \\({\\cal M}_\\gamma\\)"
  },
  {
    "objectID": "resources/slides/16-bma.html#priors",
    "href": "resources/slides/16-bma.html#priors",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Priors",
    "text": "Priors\nWith \\(2^p\\) models, subjective priors for \\(\\boldsymbol{\\beta}\\) are out of the question for moderate \\(p\\) and improper priors lead to arbitrary Bayes factors leading to conventional priors on model specific parameters\n\nZellner’s g-prior and related have attractive properties as a starting point \\[\\boldsymbol{\\beta}_\\gamma \\mid \\alpha, \\phi, \\boldsymbol{\\gamma}\\sim \\textsf{N}(0, g \\phi^{-1}\n({\\mathbf{X}_{\\boldsymbol{\\gamma}}^c}^\\prime \\mathbf{X}_{\\boldsymbol{\\gamma}}^c)^{-1})\\]\nIndependent Jeffrey’s prior on common parameters \\((\\alpha, \\phi)\\)\n\\(p(\\alpha, \\phi) \\propto 1/\\phi\\)\nmarginal likelihood of \\(\\boldsymbol{\\gamma}\\) that is proportional to \\[ p(\\mathbf{Y}\\mid \\boldsymbol{\\gamma}) = C (1 + g)^{\\frac{n-p_{\\boldsymbol{\\gamma}}-1}{2}} ( 1 + g (1 -\nR^2_\\gamma))^{- \\frac{(n-1)}{2}}\\]\n\\(R^2_\\gamma\\) is the usual coefficient of determination for model \\({\\cal M}_\\gamma\\).\n\\(C\\) is a constant common to all models (proportional to the marginal likelihood of the null model where \\(\\boldsymbol{\\beta_\\gamma}= \\mathbf{0}_p\\)"
  },
  {
    "objectID": "resources/slides/16-bma.html#sketch-for-marginal",
    "href": "resources/slides/16-bma.html#sketch-for-marginal",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Sketch for Marginal",
    "text": "Sketch for Marginal\n\nIntegrate out \\(\\boldsymbol{\\beta_\\gamma}\\) using sums of normals\n\nFind inverse of \\(\\mathbf{I}_n + g \\mathbf{P}_{\\mathbf{X}_{\\boldsymbol{\\gamma}}}\\) (properties of projections or Sherman-Woodbury-Morrison Theorem)\n\nFind determinant of \\(\\phi (\\mathbf{I}_n + g \\mathbf{P}_{\\mathbf{X}_{\\boldsymbol{\\gamma}}})\\)\n\nIntegrate out intercept (normal)\n\nIntegrate out \\(\\phi\\) (gamma)\n\nalgebra to simplify quadratic forms to \\(R^2_{\\boldsymbol{\\gamma}}\\)\n\n\nOr integrate \\(\\alpha\\), \\(\\boldsymbol{\\beta_\\gamma}\\) and \\(\\phi\\) (complete the square!)"
  },
  {
    "objectID": "resources/slides/16-bma.html#posterior-distributions-on-parameters",
    "href": "resources/slides/16-bma.html#posterior-distributions-on-parameters",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Posterior Distributions on Parameters",
    "text": "Posterior Distributions on Parameters\n\\[\\begin{align*}\\alpha \\mid \\boldsymbol{\\gamma}, \\phi, y & \\sim \\textsf{N}\\left(\\bar{y}, \\frac{1}{n \\phi}\\right)\\\\\n\\boldsymbol{\\beta}_{\\boldsymbol{\\gamma}} \\mid \\boldsymbol{\\gamma}, \\phi, g, y &\\sim \\textsf{N}\\left( \\frac{g}{1 + g} \\hat{\\boldsymbol{\\beta}}_{\\gamma}, \\frac{g}{1 + g} \\frac{1}{\\phi} \\left[{\\boldsymbol{X}_{\\gamma}}^T \\boldsymbol{X}_{\\gamma} \\right]^{-1}  \\right) \\\\\n\\phi \\mid \\gamma, y & \\sim \\textsf{Gamma}\\left(\\frac{n-1}{2}, \\frac{\\textsf{TotalSS} - \\frac{g}{1+g} \\textsf{RegSS}}{2}\\right) \\\\\n\\textsf{TotalSS} & \\equiv \\sum_i (y_i - \\bar{y})^2 \\\\\n\\textsf{RegSS} & \\equiv \\hat{\\boldsymbol{\\beta}}_\\gamma^T \\boldsymbol{X}_\\gamma^T \\boldsymbol{X}_\\gamma \\hat{\\beta}\\gamma \\\\\nR^2_\\gamma & = \\frac{\\textsf{RegSS}}{\\textsf{TotalSS}}  = 1 - \\frac{\\textsf{ErrorSS}}{\\textsf{TotalSS}}\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/16-bma.html#priors-on-model-space",
    "href": "resources/slides/16-bma.html#priors-on-model-space",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Priors on Model Space",
    "text": "Priors on Model Space\n\\(p({\\cal M}_\\gamma) \\Leftrightarrow p(\\boldsymbol{\\gamma})\\)\n\nFixed prior probability \\(\\gamma_j\\) \\(p(\\gamma_j = 1) = .5 \\Rightarrow P({\\cal M}_\\gamma) = .5^p\\)\nUniform on space of models \\(p_{\\boldsymbol{\\gamma}}\\sim \\textsf{Bin}(p, .5)\\)\nHierarchical prior \\[\\begin{align}\n\\gamma_j \\mid \\pi & \\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}\\textsf{Ber}(\\pi) \\\\\n\\pi & \\sim \\textsf{Beta}(a,b) \\\\\n\\text{then  }  p_{\\boldsymbol{\\gamma}}& \\sim \\textsf{BB}_p(a, b)\n\\end{align}\\]\n\n\n\\[\np(p_{\\boldsymbol{\\gamma}}\\mid p, a, b) = \\frac{ \\Gamma(p + 1) \\Gamma(p_{\\boldsymbol{\\gamma}}+ a) \\Gamma(p - p_{\\boldsymbol{\\gamma}}+ b) \\Gamma (a + b) }{\\Gamma(p_{\\boldsymbol{\\gamma}}+1) \\Gamma(p - p_{\\boldsymbol{\\gamma}}+ 1) \\Gamma(p + a + b) \\Gamma(a) \\Gamma(b)}\n\\] - Uniform on Model Size \\(\\Rightarrow p_{\\boldsymbol{\\gamma}}\\sim \\textsf{BB}_p(1, 1) \\sim \\textsf{Unif}(0, p)\\)"
  },
  {
    "objectID": "resources/slides/16-bma.html#posterior-probabilities-of-models",
    "href": "resources/slides/16-bma.html#posterior-probabilities-of-models",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Posterior Probabilities of Models",
    "text": "Posterior Probabilities of Models\n\nCalculate posterior distribution analytically under enumeration. \\[p({\\cal M}_\\gamma\\mid \\mathbf{Y})= \\frac{p(\\mathbf{Y}\\mid \\boldsymbol{\\gamma}) p(\\boldsymbol{\\gamma})} {\\sum_{\\boldsymbol{\\gamma}^\\prime \\in \\Gamma} p(\\mathbf{Y}\\mid \\boldsymbol{\\gamma}^\\prime) p(\\boldsymbol{\\gamma}^\\prime)}\\]\nExpress as a function of Bayes factors and prior odds!\nUse MCMC over \\(\\Gamma\\) - Gibbs, Metropolis Hastings if \\(p\\) is large (depends on Bayes factors and prior odds)\nslow convergence/poor mixing with high correlations\n\nMetropolis Hastings algorithms more flexibility\n(swap pairs of variables)\n\n\n\n\n\n\n\n\nNo need to run MCMC over \\(\\boldsymbol{\\gamma}\\), \\(\\boldsymbol{\\beta_\\gamma}\\), \\(\\alpha\\), and \\(\\phi\\)!"
  },
  {
    "objectID": "resources/slides/16-bma.html#choice-of-g-bartletts-paradox",
    "href": "resources/slides/16-bma.html#choice-of-g-bartletts-paradox",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Choice of \\(g\\): Bartlett’s Paradox",
    "text": "Choice of \\(g\\): Bartlett’s Paradox\nThe Bayes factor for comparing \\(\\boldsymbol{\\gamma}\\) to the null model: \\[\nBF(\\boldsymbol{\\gamma}: \\boldsymbol{\\gamma}_0) =    (1 + g)^{(n - 1 - p_{\\boldsymbol{\\gamma}})/2} (1 + g(1 - R_{\\boldsymbol{\\gamma}}^2))^{-(n-1)/2}\n\\]\n\nFor fixed sample size \\(n\\) and \\(R_{\\boldsymbol{\\gamma}}^2\\), consider taking values of \\(g\\) that go to infinity\n\nIncreasing vagueness in prior\nWhat happens to BF as \\(g \\to \\infty\\)?\n\n\n\n\n\n\n\n\nBartlett Paradox\n\n\nWhy is this a paradox?"
  },
  {
    "objectID": "resources/slides/16-bma.html#information-paradox",
    "href": "resources/slides/16-bma.html#information-paradox",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Information Paradox",
    "text": "Information Paradox\nThe Bayes factor for comparing \\(\\boldsymbol{\\gamma}\\) to the null model: \\[\nBF(\\boldsymbol{\\gamma}: \\boldsymbol{\\gamma}_0) =    (1 + g)^{(n - 1 - p_{\\boldsymbol{\\gamma}})/2} (1 + g(1 - R_{\\boldsymbol{\\gamma}}^2))^{-(n-1)/2}\n\\]\n\nLet \\(g\\) be a fixed constant and take \\(n\\) fixed.\n\nUsual F statistic for testing \\(\\boldsymbol{\\gamma}\\) versus \\(\\boldsymbol{\\gamma}_0\\) is \\(F = \\frac{R_{\\boldsymbol{\\gamma}}^2/p_{\\boldsymbol{\\gamma}}}{(1 - R_{\\boldsymbol{\\gamma}}^2)/(n - 1 - p_{\\boldsymbol{\\gamma}})}\\)\n\nAs \\(R^2_{\\boldsymbol{\\gamma}} \\to 1\\), \\(F \\to \\infty\\) Likelihood Rqtio test (F-test) would reject \\(\\boldsymbol{\\gamma}_0\\) where \\(F\\) is the usual \\(F\\) statistic for comparing model \\(\\boldsymbol{\\gamma}\\) to \\(\\boldsymbol{\\gamma}_0\\)\n\nBF converges to a fixed constant \\((1+g)^{n - 1 -p_{\\boldsymbol{\\gamma}}/2}\\) (does not go to infinity !\n\n\nInformation Inconsistency of Liang et al JASA 2008"
  },
  {
    "objectID": "resources/slides/16-bma.html#mixtures-of-g-priors-information-consistency",
    "href": "resources/slides/16-bma.html#mixtures-of-g-priors-information-consistency",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Mixtures of \\(g\\)-priors & Information consistency",
    "text": "Mixtures of \\(g\\)-priors & Information consistency\n\nWant \\(\\textsf{BF}\\to \\infty\\) if \\(\\textsf{R}_{\\boldsymbol{\\gamma}}^2 \\to 1\\) if model is full rank\nPut a prior on \\(g\\) \\[BF(\\boldsymbol{\\gamma}: \\boldsymbol{\\gamma}_0) =  \\frac{ C \\int (1 + g)^{(n - 1 - p_{\\boldsymbol{\\gamma}})/2} (1 + g(1 - R_{\\boldsymbol{\\gamma}}^2))^{-(n-1)/2} \\pi(g) dg}{C}\\]\ninterchange limit and integration as \\(R^2 \\to 1\\) want \\[ \\textsf{E}_g[(1 +\ng)^{(n-1-p_{\\boldsymbol{\\gamma}})/2}]\\] to diverge under the prior"
  },
  {
    "objectID": "resources/slides/16-bma.html#one-solution",
    "href": "resources/slides/16-bma.html#one-solution",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "One Solution",
    "text": "One Solution\n\nhyper-g prior (Liang et al JASA 2008) \\[p(g) = \\frac{a-2}{2}(1 + g)^{-a/2}\\] or \\(g/(1+g) \\sim Beta(1, (a-2)/2)\\) for \\(a &gt; 2\\)\nprior expectation converges if \\(a &gt; n + 1 - p_{\\boldsymbol{\\gamma}}\\) (properties of \\(_2F_1\\) function)\nConsider minimal model \\(p_{\\boldsymbol{\\gamma}}= 1\\) and \\(n = 3\\) (can estimate intercept, one coefficient, and \\(\\sigma^2\\), then for \\(a &gt; 3\\) integral exists\nFor \\(2 &lt; a \\le 3\\) integral diverges and resolves the information paradox! (see proof in Liang et al JASA 2008 )"
  },
  {
    "objectID": "resources/slides/16-bma.html#examples-of-priors-on-g",
    "href": "resources/slides/16-bma.html#examples-of-priors-on-g",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Examples of Priors on \\(g\\)",
    "text": "Examples of Priors on \\(g\\)\n\nhyper-g prior (Liang et al JASA 2008)\n\nSpecial case is Jeffreys prior for \\(g\\) which corresponds to \\(a = 2\\) (improper)\n\n\nZellner-Siow Cauchy prior \\(1/g \\sim \\textsf{Gamma}(1/2, n/2)\\)\n\nHyper-g/n \\((g/n)(1 + g/n) \\sim \\textsf{Beta}(1, (a-2)/2)\\) (generalized Beta distribution)\nrobust prior (Bayarri et al Annals of Statistics 2012 )\nIntrinsic prior (Womack et al JASA 2015)\n\n\nAll have prior tails for \\(\\boldsymbol{\\beta}\\) that behave like a Cauchy distribution and all except the Gamma prior have marginal likelihoods that can be computed using special hypergeometric functions (\\(_2F_1\\), Appell \\(F_1\\))\n\n\nNo fixed value of \\(g\\) (i.e a point mass prior) will resolve!"
  },
  {
    "objectID": "resources/slides/16-bma.html#us-air-example",
    "href": "resources/slides/16-bma.html#us-air-example",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "US Air Example",
    "text": "US Air Example\n\nlibrary(BAS)\ndata(usair, package=\"HH\")\npoll.bma = bas.lm(log(SO2) ~ temp + log(mfgfirms) +\n                             log(popn) + wind +\n                             precip + raindays,\n                  data=usair,\n                  prior=\"JZS\",  #Jeffrey-Zellner-Siow\n                  alpha=nrow(usair), # n\n                  n.models=2^6,\n                  modelprior = uniform(),\n                  method=\"deterministic\")"
  },
  {
    "objectID": "resources/slides/16-bma.html#summary",
    "href": "resources/slides/16-bma.html#summary",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Summary",
    "text": "Summary\n\nsummary(poll.bma, n.models=4)\n\n              P(B != 0 | Y) model 1   model 2   model 3   model 4\nIntercept        1.00000000 1.00000 1.0000000 1.0000000 1.0000000\ntemp             0.91158530 1.00000 1.0000000 1.0000000 1.0000000\nlog(mfgfirms)    0.31718916 0.00000 0.0000000 0.0000000 1.0000000\nlog(popn)        0.09223957 0.00000 0.0000000 0.0000000 0.0000000\nwind             0.29394451 0.00000 0.0000000 0.0000000 1.0000000\nprecip           0.28384942 0.00000 1.0000000 0.0000000 1.0000000\nraindays         0.22903262 0.00000 0.0000000 1.0000000 0.0000000\nBF                       NA 1.00000 0.3286643 0.2697945 0.2655873\nPostProbs                NA 0.29410 0.0967000 0.0794000 0.0781000\nR2                       NA 0.29860 0.3775000 0.3714000 0.5427000\ndim                      NA 2.00000 3.0000000 3.0000000 5.0000000\nlogmarg                  NA 3.14406 2.0313422 1.8339656 1.8182487"
  },
  {
    "objectID": "resources/slides/16-bma.html#plots-of-coefficients",
    "href": "resources/slides/16-bma.html#plots-of-coefficients",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Plots of Coefficients",
    "text": "Plots of Coefficients\n\n beta = coef(poll.bma)\n par(mfrow=c(2,3));  plot(beta, subset=2:7,ask=F)"
  },
  {
    "objectID": "resources/slides/16-bma.html#posterior-distribution-with-uniform-prior-on-model-space",
    "href": "resources/slides/16-bma.html#posterior-distribution-with-uniform-prior-on-model-space",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Posterior Distribution with Uniform Prior on Model Space",
    "text": "Posterior Distribution with Uniform Prior on Model Space\n\nimage(poll.bma, rotate=FALSE)"
  },
  {
    "objectID": "resources/slides/16-bma.html#posterior-distribution-with-bb11-prior-on-model-space",
    "href": "resources/slides/16-bma.html#posterior-distribution-with-bb11-prior-on-model-space",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Posterior Distribution with BB(1,1) Prior on Model Space",
    "text": "Posterior Distribution with BB(1,1) Prior on Model Space\n\npoll.bb.bma = bas.lm(log(SO2) ~ temp + log(mfgfirms) +\n                                log(popn) + wind +\n                                precip + raindays,\n                     data=usair,\n                     prior=\"JZS\",\n                     alpha=nrow(usair),\n                     n.models=2^6,  #enumerate\n                     modelprior=beta.binomial(1,1))"
  },
  {
    "objectID": "resources/slides/16-bma.html#posterior-distribution-with-bb11-prior-on-model-space-1",
    "href": "resources/slides/16-bma.html#posterior-distribution-with-bb11-prior-on-model-space-1",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Posterior Distribution with BB(1,1) Prior on Model Space",
    "text": "Posterior Distribution with BB(1,1) Prior on Model Space\n\nimage(poll.bb.bma, rotate=FALSE)"
  },
  {
    "objectID": "resources/slides/16-bma.html#summary-1",
    "href": "resources/slides/16-bma.html#summary-1",
    "title": "Lecture 16: Bayesian Variable Selection and Model Averaging",
    "section": "Summary",
    "text": "Summary\n\nChoice of prior on \\(\\boldsymbol{\\beta_\\gamma}\\)\ng-priors or mixtures of \\(g\\) (sensitivity)\npriors on the models (sensitivity)\nposterior summaries - select a model or “average” over all models\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/20-mixed-effects.html#random-effects-regression",
    "href": "resources/slides/20-mixed-effects.html#random-effects-regression",
    "title": "Linear Mixed Effects Models",
    "section": "Random Effects Regression",
    "text": "Random Effects Regression\n\nEasy to extend from random means by groups to random group level coefficients: \\[\\begin{align*}Y_{ij} & = \\boldsymbol{\\theta}^T_j \\mathbf{x}_{ij}+ \\epsilon_{ij} \\\\\n\\epsilon_{ij}   & \\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}\\textsf{N}(0, \\sigma^2)\n\\end{align*}\n\\]\n\\(\\boldsymbol{\\theta}_j\\) is a \\(d \\times 1\\) vector regression coefficients for group \\(j\\)\n\\(\\mathbf{x}_{ij}\\) is a \\(d \\times 1\\) vector of predictors for group \\(j\\)\nIf we view the groups as exchangeable, describe across group heterogeneity by \\[\\boldsymbol{\\theta}_j \\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}\\textsf{N}(\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma})\\]\n\\(\\boldsymbol{\\beta}\\), \\(\\boldsymbol{\\Sigma}\\) and \\(\\sigma^2\\) are population parameters to be estimated.\nDesigned to accommodate correlated data due to nested/hierarchical structure/repeated measurements: students w/in schools; patients w/in hospitals; additional covariates"
  },
  {
    "objectID": "resources/slides/20-mixed-effects.html#linear-mixed-effects-models",
    "href": "resources/slides/20-mixed-effects.html#linear-mixed-effects-models",
    "title": "Linear Mixed Effects Models",
    "section": "Linear Mixed Effects Models",
    "text": "Linear Mixed Effects Models\n\nWe can write \\(\\boldsymbol{\\theta}= \\boldsymbol{\\beta}+ \\boldsymbol{\\gamma}_j\\) with \\(\\boldsymbol{\\gamma}_j \\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}\\textsf{N}(\\mathbf{0}, \\boldsymbol{\\Sigma})\\)\nSubstituting, we can rewrite model \\[\\begin{align*}Y_{ij} & = \\boldsymbol{\\beta}^T \\mathbf{x}_{ij}+ \\boldsymbol{\\gamma}_j^T \\mathbf{x}_{ij} + \\epsilon_{ij}, \\qquad\n\\epsilon_{ij}  \\overset{iid}{\\sim}  \\textsf{N}(0, \\sigma^2) \\\\\n\\boldsymbol{\\gamma}_j & \\overset{iid}{\\sim} \\textsf{N}_d(\\mathbf{0}_d, \\boldsymbol{\\Sigma})\n\\end{align*}\\]\nFixed effects contribution \\(\\boldsymbol{\\beta}\\) is constant across groups\nRandom effects are \\(\\boldsymbol{\\gamma}_j\\) as they vary across groups\ncalled mixed effects as we have both fixed and random effects in the regression model"
  },
  {
    "objectID": "resources/slides/20-mixed-effects.html#more-general-model",
    "href": "resources/slides/20-mixed-effects.html#more-general-model",
    "title": "Linear Mixed Effects Models",
    "section": "More General Model",
    "text": "More General Model\n\nNo reason for the fixed effects and random effect covariates to be the same \\[\\begin{align*}Y_{ij} & = \\boldsymbol{\\beta}^T \\mathbf{x}_{ij}+ \\boldsymbol{\\gamma}_j^T \\mathbf{z}_{ij} + \\epsilon_{ij}, \\qquad\n\\epsilon_{ij}  \\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}\\textsf{N}(0, \\sigma^2) \\\\\n\\boldsymbol{\\gamma}_j & {\\sim} \\textsf{N}_p(\\mathbf{0}_p, \\boldsymbol{\\Sigma})\n\\end{align*}\\]\ndimension of \\(\\mathbf{x}_{ij}\\) \\(d \\times 1\\)\ndimension of \\(\\mathbf{z}_{ij}\\) \\(p \\times 1\\)\nmay or may not be overlapping\n\\(\\mathbf{x}_{ij}\\) could include predictors that are constant across all \\(i\\) in group \\(j\\). (can’t estimate if they are in \\(\\mathbf{z}_{ij}\\))\nfeatures of school \\(j\\) that"
  },
  {
    "objectID": "resources/slides/20-mixed-effects.html#likelihoods",
    "href": "resources/slides/20-mixed-effects.html#likelihoods",
    "title": "Linear Mixed Effects Models",
    "section": "Likelihoods",
    "text": "Likelihoods\n\nComplete Data Likelihood \\((\\boldsymbol{\\beta}, \\{\\boldsymbol{\\gamma}_j\\}, \\sigma^2, \\boldsymbol{\\Sigma})\\) \\[{\\cal{L}}(\\boldsymbol{\\beta}, \\{\\boldsymbol{\\gamma}_j\\}, \\sigma^2, \\boldsymbol{\\Sigma}) \\propto \\prod_j \\textsf{N}(\\boldsymbol{\\gamma}_j; \\mathbf{0}_p, \\boldsymbol{\\Sigma}) \\prod_i \\textsf{N}(y_{ij}; \\boldsymbol{\\beta}^T \\mathbf{x}_{ij} + \\boldsymbol{\\gamma}_j^T\\mathbf{z}_{ij}, \\sigma^2 )\\]\nMarginal likelihood \\((\\boldsymbol{\\beta}, \\{\\boldsymbol{\\gamma}_j\\}, \\sigma^2, \\boldsymbol{\\Sigma})\\) \\[{\\cal{L}}(\\boldsymbol{\\beta}, \\sigma^2, \\boldsymbol{\\Sigma})\\propto \\prod_j \\int_{\\mathbb{R}^p} \\textsf{N}(\\boldsymbol{\\gamma}_j; \\mathbf{0}_p, \\boldsymbol{\\Sigma}) \\prod_i \\textsf{N}(y_{ij}; \\boldsymbol{\\beta}^T \\mathbf{x}_{ij} + \\boldsymbol{\\gamma}_j^T \\mathbf{z}_{ij}, \\sigma^2 ) \\, d \\boldsymbol{\\gamma}_j\\]\nOption A: we can calculate this integral by brute force algebraically\nOption B: (lazy option) We can calculate marginal exploiting properties of Gaussians as sums will be normal - just read off the first two moments!"
  },
  {
    "objectID": "resources/slides/20-mixed-effects.html#marginal-distribution",
    "href": "resources/slides/20-mixed-effects.html#marginal-distribution",
    "title": "Linear Mixed Effects Models",
    "section": "Marginal Distribution",
    "text": "Marginal Distribution\n\nExpress observed data as vectors for each group \\(j\\): \\((\\mathbf{Y}_j, \\mathbf{X}_j, \\mathbf{Z}_j)\\) where \\(\\mathbf{Y}_j\\) is \\(n_j \\times 1\\), \\(\\mathbf{X}_j\\) is \\(n_j \\times d\\) and \\(\\mathbf{Z}_j\\) is \\(n_j \\times p\\);\nGroup Specific Model (1): \\[\\begin{align}\\mathbf{Y}_j  & = \\mathbf{X}_j \\boldsymbol{\\beta}+ \\mathbf{Z}_j \\boldsymbol{\\gamma}_j + \\boldsymbol{\\epsilon}_j, \\qquad\n\\boldsymbol{\\epsilon}_j  \\sim \\textsf{N}(\\mathbf{0}_{n_j}, \\sigma^2 \\mathbf{I}_{n_j})\\\\\n\\boldsymbol{\\gamma}_j & \\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}\\textsf{N}(\\mathbf{0}_p, \\boldsymbol{\\Sigma})\n\\end{align}\\]\nPopulation Mean \\(\\textsf{E}[\\mathbf{Y}_j] = \\textsf{E}[\\mathbf{X}_j \\boldsymbol{\\beta}+ \\mathbf{Z}_j \\boldsymbol{\\gamma}_j + \\boldsymbol{\\epsilon}_j] = \\mathbf{X}_j \\boldsymbol{\\beta}\\)\nCovariance \\(\\textsf{Var}[\\mathbf{Y}_j] = \\textsf{Var}[\\mathbf{X}_j \\boldsymbol{\\beta}+ \\mathbf{Z}_j \\boldsymbol{\\gamma}_j + \\boldsymbol{\\epsilon}_j] = \\mathbf{Z}_j \\boldsymbol{\\Sigma}\\mathbf{Z}_j^T + \\sigma^2 \\mathbf{I}_{n_j}\\)\nGroup Specific Model (2) \\[\\mathbf{Y}_j \\mid  \\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\sigma^2 \\mathrel{\\mathop{\\sim}\\limits^{\\rm ind}}\\textsf{N}(\\mathbf{X}_j \\boldsymbol{\\beta}, \\mathbf{Z}_j \\boldsymbol{\\Sigma}\\mathbf{Z}_j^T + \\sigma^2 \\mathbf{I}_{n_j})\\]"
  },
  {
    "objectID": "resources/slides/20-mixed-effects.html#priors",
    "href": "resources/slides/20-mixed-effects.html#priors",
    "title": "Linear Mixed Effects Models",
    "section": "Priors",
    "text": "Priors\n\nModel (1) leads to a simple Gibbs sampler if we use conditional (semi-) conjugate priors on \\((\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\phi = 1/\\sigma^2)\\) \\[\\begin{align*}\n\\boldsymbol{\\beta}& \\sim \\textsf{N}(\\mu_0, \\Psi_0^{-1}) \\\\\n\\phi & \\sim \\textsf{Gamma}(v_0/2, v_o \\sigma^2_0/2) \\\\\n\\boldsymbol{\\Sigma}&\\sim \\textrm{IW}_p(\\eta_0, \\boldsymbol{S}_0^{-1})\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/20-mixed-effects.html#mcmc-sampling",
    "href": "resources/slides/20-mixed-effects.html#mcmc-sampling",
    "title": "Linear Mixed Effects Models",
    "section": "MCMC Sampling",
    "text": "MCMC Sampling\n\nModel (1) leads to a simple Gibbs sampler if we use conditional (semi-) conjugate priors on \\((\\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\phi = 1/\\sigma^2)\\) \\[\\begin{align*}\n\\boldsymbol{\\beta}& \\sim \\textsf{N}(\\mu_0, \\Psi_0^{-1}) \\\\\n\\phi & \\sim \\textsf{Gamma}(v_0/2, v_o \\sigma^2_0/2) \\\\\n\\boldsymbol{\\Sigma}&\\sim \\textrm{IW}_p(\\eta_0, \\boldsymbol{S}_0^{-1})\n\\end{align*}\\]\nModel (2) can be challenging to update the variance components! no conjugacy and need to ensure that MH updates maintain the positive-definiteness of \\(\\boldsymbol{\\Sigma}\\) (can reparameterize)\nIs Gibbs always more efficient?\nNo - because the Gibbs sampler can have high autocorrelation in updating the \\(\\{\\boldsymbol{\\gamma}_j \\}\\) from their full conditional and then updating \\(\\boldsymbol{\\beta}\\), \\(\\sigma^2\\) and \\(\\boldsymbol{\\Sigma}\\) from their full full conditionals given the \\(\\{ \\boldsymbol{\\gamma}_j\\}\\)\nslow mixing"
  },
  {
    "objectID": "resources/slides/20-mixed-effects.html#blocked-gibbs-sampler",
    "href": "resources/slides/20-mixed-effects.html#blocked-gibbs-sampler",
    "title": "Linear Mixed Effects Models",
    "section": "Blocked Gibbs Sampler",
    "text": "Blocked Gibbs Sampler\n\nsample \\(\\boldsymbol{\\beta}\\) and \\(\\boldsymbol{\\gamma}\\)’s as a block! (marginal and conditionals) given the others\nupdate \\(\\boldsymbol{\\beta}\\) using (2) instead of (1) (marginalization so is independent of \\(\\boldsymbol{\\gamma}_j\\)’s\n\n\n\n\n\n\n\n3 Block Sampler at each iteration\n\n\n\nDraw \\(\\boldsymbol{\\beta}, \\boldsymbol{\\gamma}_1, \\ldots \\boldsymbol{\\gamma}_J\\) as a block given \\(\\phi\\), \\(\\boldsymbol{\\Sigma}\\) by\n\nDraw \\(\\boldsymbol{\\beta}\\mid \\phi, \\boldsymbol{\\Sigma}, \\mathbf{Y}_1, \\ldots \\mathbf{Y}_j\\) then\nDraw \\(\\boldsymbol{\\gamma}_j \\mid \\boldsymbol{\\beta}, \\phi, \\boldsymbol{\\Sigma}, \\mathbf{Y}_j\\) for \\(j = 1, \\ldots J\\)\n\nDraw \\(\\boldsymbol{\\Sigma}\\mid \\boldsymbol{\\gamma}_1, \\ldots \\boldsymbol{\\gamma}_J, \\boldsymbol{\\beta}, \\phi, \\mathbf{Y}_1, \\ldots \\mathbf{Y}_j\\)\nDraw \\(\\phi \\mid \\boldsymbol{\\beta}, \\boldsymbol{\\gamma}_1, \\ldots \\boldsymbol{\\gamma}_J, \\boldsymbol{\\Sigma}, \\mathbf{Y}_1, \\ldots \\mathbf{Y}_j\\)\n\n\n\n\n\nReduces correlation and improves mixing!"
  },
  {
    "objectID": "resources/slides/20-mixed-effects.html#marginal-update-for-boldsymbolbeta",
    "href": "resources/slides/20-mixed-effects.html#marginal-update-for-boldsymbolbeta",
    "title": "Linear Mixed Effects Models",
    "section": "Marginal update for \\(\\boldsymbol{\\beta}\\)",
    "text": "Marginal update for \\(\\boldsymbol{\\beta}\\)\n\\[\\begin{align*}\\mathbf{Y}_j \\mid  \\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}, \\sigma^2 & \\overset{ind}{\\sim}\\textsf{N}(\\mathbf{X}_j \\boldsymbol{\\beta}, \\mathbf{Z}_j \\boldsymbol{\\Sigma}\\mathbf{Z}_j^T + \\sigma^2 \\mathbf{I}_{n_j}) \\\\\n\\boldsymbol{\\beta}& \\sim \\textsf{N}(\\mu_0, \\Psi_0^{-1})\n\\end{align*}\\]\n\nLet \\(\\Phi_j = (\\mathbf{Z}_j \\boldsymbol{\\Sigma}\\mathbf{Z}_j^T + \\sigma^2 \\mathbf{I}_{n_j})^{-1}\\) (precision in model 2) \\[\\begin{align*}\n\\pi(\\boldsymbol{\\beta}& \\mid \\boldsymbol{\\Sigma}, \\sigma^2, \\boldsymbol{Y})  \\propto |\\Psi_0|^{1/2}\n\\exp\\left\\{- \\frac{1}{2} (\\boldsymbol{\\beta}- \\mu_0)^T \\Psi_0 (\\boldsymbol{\\beta}- \\mu_0)\\right\\} \\cdot \\\\\n& \\qquad \\qquad \\qquad\\prod_{j=1}^{J} |\\Phi_j|^{1/2} \\exp \\left\\{ - \\frac{1}{2} (\\mathbf{Y}_j - \\mathbf{X}_j \\boldsymbol{\\beta})^T \\Phi_j (\\mathbf{Y}_j - \\mathbf{X}_j \\boldsymbol{\\beta}) \\right\\} \\\\\n\\\\\n& \\propto \\exp\\left\\{- \\frac{1}{2} \\left( (\\boldsymbol{\\beta}- \\mu_0)^T \\Psi_0 (\\boldsymbol{\\beta}- \\mu_0) +\n\\sum_j (\\mathbf{Y}_j - \\mathbf{X}_j \\boldsymbol{\\beta})^T \\Phi_j (\\mathbf{Y}_j - \\mathbf{X}_j \\boldsymbol{\\beta}) \\right) \\right\\}\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/20-mixed-effects.html#marginal-posterior-for-boldsymbolbeta",
    "href": "resources/slides/20-mixed-effects.html#marginal-posterior-for-boldsymbolbeta",
    "title": "Linear Mixed Effects Models",
    "section": "Marginal Posterior for \\(\\boldsymbol{\\beta}\\)",
    "text": "Marginal Posterior for \\(\\boldsymbol{\\beta}\\)\n\\[\\begin{align*}\n\\pi(\\boldsymbol{\\beta}& \\mid \\boldsymbol{\\Sigma}, \\sigma^2, \\boldsymbol{Y})  \\\\\n& \\propto \\exp\\left\\{- \\frac{1}{2} \\left( (\\boldsymbol{\\beta}- \\mu_0)^T \\Psi_0 (\\boldsymbol{\\beta}- \\mu_0) +\n\\sum_j (\\mathbf{Y}_j - \\mathbf{X}_j \\boldsymbol{\\beta})^T \\Phi_j (\\mathbf{Y}_j - \\mathbf{X}_j \\boldsymbol{\\beta}) \\right) \\right\\}\n\\end{align*}\\]\n\nprecision \\(\\Psi_n = \\Psi_0 + \\sum_{j=1}^J \\mathbf{X}_j^T \\Phi_j \\mathbf{X}_j\\)\nmean \\[\\mu_n = \\left(\\Psi_0 + \\sum_{j=1}^J \\mathbf{X}_j^T \\Phi_j \\mathbf{X}_j\\right)^{-1} \\left(\\Psi_0 \\mu_0 +\n\\sum_{j=1}^J \\mathbf{X}_j^T \\Phi_j \\mathbf{X}_j \\hat{\\boldsymbol{\\beta}}_j\\right)\\]\nwhere \\(\\hat{\\boldsymbol{\\beta}}_j = (\\mathbf{X}_j^T \\Phi \\mathbf{X}_j)^{-1} \\mathbf{X}_j^T \\Phi_j \\mathbf{Y}_j\\) is the generalized least squares estimate of \\(\\boldsymbol{\\beta}\\) for group \\(j\\)"
  },
  {
    "objectID": "resources/slides/20-mixed-effects.html#full-conditional-for-sigma2-or-phi",
    "href": "resources/slides/20-mixed-effects.html#full-conditional-for-sigma2-or-phi",
    "title": "Linear Mixed Effects Models",
    "section": "Full conditional for \\(\\sigma^2\\) or \\(\\phi\\)",
    "text": "Full conditional for \\(\\sigma^2\\) or \\(\\phi\\)\n\\[\\begin{align}\\mathbf{Y}_j  \\mid \\boldsymbol{\\beta}, \\boldsymbol{\\gamma}_j, \\sigma^2 & \\mathrel{\\mathop{\\sim}\\limits^{\\rm ind}}\\textsf{N}(\\mathbf{X}_j \\boldsymbol{\\beta}+ \\mathbf{Z}_j \\boldsymbol{\\gamma}_j , \\sigma^2 \\mathbf{I}_{n_j})\\\\\n\\boldsymbol{\\gamma}_j  \\mid \\boldsymbol{\\Sigma}& \\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}\\textsf{N}(\\mathbf{0}_d, \\boldsymbol{\\Sigma}) \\\\\n\\boldsymbol{\\Sigma}& \\sim  \\textrm{IW}_p(\\eta_0, \\boldsymbol{S}_0^{-1}) \\\\\n\\boldsymbol{\\beta}& \\sim \\textsf{N}(\\mu_0, \\Psi_0^{-1}) \\\\\n\\phi & \\sim \\textsf{Gamma}(v_0/2, v_o \\sigma^2_0/2)\n\\end{align}\\]\n\n\\[\\pi(\\phi \\mid \\boldsymbol{\\beta}, \\{\\boldsymbol{\\gamma}_j\\} \\{Y_j\\}) \\propto \\textsf{Gamma}(\\phi; v_0/2, v_o \\sigma^2_0/2) \\prod_j \\textsf{N}(\\mathbf{Y}_j; \\mathbf{X}_j \\boldsymbol{\\beta}+ \\mathbf{Z}_j \\boldsymbol{\\gamma}_j , \\phi^{-1} \\mathbf{I}_{n_j}))\\]\n\n\n\\[\\phi \\mid \\{Y_j \\}, \\boldsymbol{\\beta}, \\{\\boldsymbol{\\gamma}_j\\} \\sim \\textsf{Gamma}\\left(\\frac{v_0 + \\sum_j n_j}{2}, \\frac{v_o \\sigma^2_0  + \\sum_j \\|\\mathbf{Y}_j - \\mathbf{X}_j\\boldsymbol{\\beta}- \\mathbf{Z}_j\\boldsymbol{\\gamma}_j \\|^2}{2}\\right)\\]"
  },
  {
    "objectID": "resources/slides/20-mixed-effects.html#conditional-posterior-for-boldsymbolsigma",
    "href": "resources/slides/20-mixed-effects.html#conditional-posterior-for-boldsymbolsigma",
    "title": "Linear Mixed Effects Models",
    "section": "Conditional posterior for \\(\\boldsymbol{\\Sigma}\\)",
    "text": "Conditional posterior for \\(\\boldsymbol{\\Sigma}\\)\n\\[\\begin{align}\\mathbf{Y}_j  \\mid \\boldsymbol{\\beta}, \\boldsymbol{\\gamma}_j, \\sigma^2 & \\mathrel{\\mathop{\\sim}\\limits^{\\rm ind}}\\textsf{N}(\\mathbf{X}_j \\boldsymbol{\\beta}+ \\mathbf{Z}_j \\boldsymbol{\\gamma}_j , \\sigma^2 \\mathbf{I}_{n_j})\\\\\n\\boldsymbol{\\gamma}_j  \\mid \\boldsymbol{\\Sigma}& \\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}\\textsf{N}(\\mathbf{0}_d, \\boldsymbol{\\Sigma}) \\\\\n\\boldsymbol{\\Sigma}& \\sim  \\textrm{IW}_p(\\eta_0, \\boldsymbol{S}_0^{-1}) \\\\\n\\boldsymbol{\\beta}& \\sim \\textsf{N}(\\mu_0, \\Psi_0^{-1}) \\\\\n\\phi & \\sim \\textsf{Gamma}(v_0/2, v_o \\sigma^2_0/2)\n\\end{align}\\]\n\nThe conditional posterior (full conditional) \\(\\boldsymbol{\\Sigma}\\mid \\boldsymbol{\\boldsymbol{\\gamma}}, \\mathbf{Y}\\), is then \\[\\begin{align*}\n\\pi(\\boldsymbol{\\Sigma}& \\mid \\boldsymbol{\\gamma}, \\boldsymbol{Y})\\propto \\pi(\\boldsymbol{\\Sigma}) \\cdot \\pi( \\boldsymbol{\\gamma} \\mid \\boldsymbol{\\Sigma})\\\\\n& \\propto \\underbrace{\\left|\\boldsymbol{\\Sigma}\\right|^{\\frac{-(\\eta_0 + p + 1)}{2}} \\textrm{exp} \\left\\{-\\frac{1}{2} \\text{tr}(\\boldsymbol{S}_0\\boldsymbol{\\Sigma}^{-1}) \\right\\}}_{\\pi(\\boldsymbol{\\Sigma})} \\cdot \\underbrace{\\prod_{j = 1}^{J}\\left|\\boldsymbol{\\Sigma}\\right|^{-\\frac{1}{2}} \\ \\textrm{exp} \\left\\{-\\frac{1}{2}\\left[\\boldsymbol{\\gamma}_j^T \\boldsymbol{\\Sigma}^{-1} \\gamma_j\\right] \\right\\}}_{\\pi(\\boldsymbol{\\gamma} \\mid \\boldsymbol{\\Sigma})}  \n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/20-mixed-effects.html#posterior-continued",
    "href": "resources/slides/20-mixed-effects.html#posterior-continued",
    "title": "Linear Mixed Effects Models",
    "section": "Posterior Continued",
    "text": "Posterior Continued\n\nFull conditional \\(\\boldsymbol{\\Sigma}\\mid \\{\\gamma_j\\}, \\boldsymbol{Y} \\sim \\textrm{IW}_p\\left(\\eta_0 + J, (\\boldsymbol{S}_0+ \\sum_{j=1}^J \\gamma_j \\gamma_j^T)^{-1} \\right)\\)\nWork \\[\\begin{align*}\n\\pi(\\boldsymbol{\\Sigma}& \\mid \\boldsymbol{\\gamma}, \\boldsymbol{Y})\\propto \\pi(\\boldsymbol{\\Sigma}) \\cdot \\pi( \\boldsymbol{\\gamma} \\mid \\boldsymbol{\\Sigma})\\\\\n& \\propto \\left|\\boldsymbol{\\Sigma}\\right|^{\\frac{-(\\eta_0 + p + 1)}{2}} \\textrm{exp} \\left\\{-\\frac{1}{2} \\text{tr}(\\boldsymbol{S}_0\\boldsymbol{\\Sigma}^{-1}) \\right\\} \\cdot \\prod_{j = 1}^{J}\\left|\\boldsymbol{\\Sigma}\\right|^{-\\frac{1}{2}} \\ \\textrm{exp} \\left\\{-\\frac{1}{2}\\left[\\boldsymbol{\\gamma}_j^T \\boldsymbol{\\Sigma}^{-1} \\gamma_j\\right] \\right\\}  \n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/20-mixed-effects.html#full-conditional-for-gamma_j",
    "href": "resources/slides/20-mixed-effects.html#full-conditional-for-gamma_j",
    "title": "Linear Mixed Effects Models",
    "section": "Full conditional for \\(\\{ \\gamma_j \\}\\)",
    "text": "Full conditional for \\(\\{ \\gamma_j \\}\\)\n\\[\\begin{align}\\mathbf{Y}_j  \\mid \\boldsymbol{\\beta}, \\boldsymbol{\\gamma}_j, \\sigma^2 & \\mathrel{\\mathop{\\sim}\\limits^{\\rm ind}}\\textsf{N}(\\mathbf{X}_j \\boldsymbol{\\beta}+ \\mathbf{Z}_j \\boldsymbol{\\gamma}_j , \\sigma^2 \\mathbf{I}_{n_j})\\\\\n\\boldsymbol{\\gamma}_j  \\mid \\boldsymbol{\\Sigma}& \\overset{iid}{\\sim} \\textsf{N}(\\mathbf{0}_d, \\boldsymbol{\\Sigma}) \\\\\n\\boldsymbol{\\Sigma}& \\sim  \\textrm{IW}_p(\\eta_0, \\boldsymbol{S}_0^{-1}) \\\\\n\\boldsymbol{\\beta}& \\sim \\textsf{N}(\\mu_0, \\Psi_0^{-1}) \\\\\n\\phi & \\sim \\textsf{Gamma}(v_0/2, v_o \\sigma^2_0/2)\n\\end{align}\\]\n\\[\\pi(\\boldsymbol{\\gamma}_j \\mid \\boldsymbol{\\beta}, \\phi, \\boldsymbol{\\Sigma}) \\propto \\textsf{N}(\\boldsymbol{\\gamma}_j; 0, \\boldsymbol{\\Sigma}) \\prod_j \\textsf{N}(\\mathbf{Y}_j; \\mathbf{X}_j \\boldsymbol{\\beta}+ \\mathbf{Z}_j \\boldsymbol{\\gamma}_j , \\phi^{-1} \\mathbf{I}_{n_j}))\\]\n\nwork out as HW"
  },
  {
    "objectID": "resources/slides/20-mixed-effects.html#other-questions",
    "href": "resources/slides/20-mixed-effects.html#other-questions",
    "title": "Linear Mixed Effects Models",
    "section": "Other Questions",
    "text": "Other Questions\n\nHow do you decide what is a random effect or fixed effect?\nDesign structure is often important\nOther priors ?\nHow would you implement MH in Model 2? (other sampling methods?)\nWhat if the means are not normal? Extensions to Generalized linear models\nmore examples in\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#ingredients",
    "href": "resources/slides/01-basics-of-bayes.html#ingredients",
    "title": "Basics of Bayesian Statistics",
    "section": "Ingredients",
    "text": "Ingredients\n\nPrior Distribution \\(\\pi(\\theta)\\) for unknown \\(\\theta\\)\nLikelihood Function \\({\\cal{L}}(\\theta \\mid y ) \\propto p(y \\mid \\theta)\\) (sampling model)\nPosterior Distribution \\[\\pi(\\theta | y) = \\frac{\\pi(\\theta)p(y \\mid \\theta)}{\\int_{\\Theta}\\pi({\\theta})p(y\\mid {\\theta}) \\textrm{d}{\\theta}} = \\frac{\\pi(\\theta)p(y\\mid\\theta)}{p(y)}\\]\nLoss Function Depends on what you want to report; estimate of \\(\\theta\\), predict future \\(Y_{n+1}\\), etc"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#posterior-depends-on-likelihoods",
    "href": "resources/slides/01-basics-of-bayes.html#posterior-depends-on-likelihoods",
    "title": "Basics of Bayesian Statistics",
    "section": "Posterior Depends on Likelihoods",
    "text": "Posterior Depends on Likelihoods\n\nLikelihood function is defined up to a consant \\[c \\, {\\cal{L}}(\\theta \\mid Y) =  p(y \\mid \\theta) \\]\nBayes’ Rule \\[\\pi(\\theta | y) = \\frac{\\pi(\\theta)p(y \\mid \\theta)}{\\int_{\\Theta}\\pi({\\theta})p(y\\mid {\\theta}) \\textrm{d}{\\theta}} =\n\\frac{\\pi(\\theta)c {\\cal{L}}(\\theta \\mid y)}{\\int_{\\Theta}\\pi({\\theta})c{\\cal{L}}(\\theta \\mid y) \\textrm{d}{\\theta}}  =\n\\frac{\\pi(\\theta){\\cal{L}}(\\theta \\mid y)}{m(y)}\\]\n\\(m(y)\\) is proportional to the marginal distribution of data\n\\[m(y) = \\int_{\\Theta}\\pi({\\theta}){\\cal{L}}(\\theta \\mid y) \\textrm{d}{\\theta}\\]\nmarginal likelihood of this model or “evidence”\n\n\nNote: the marginal likelihood and maximized likelihood are very different!"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#binomial-example",
    "href": "resources/slides/01-basics-of-bayes.html#binomial-example",
    "title": "Basics of Bayesian Statistics",
    "section": "Binomial Example",
    "text": "Binomial Example\n\nBinomial sampling \\(Y \\mid n, \\theta \\sim \\textsf{Binomial}(n, \\theta)\\)\nProbability Mass Function \\[p(y \\mid \\theta) = {n \\choose y} \\theta^y(1-\\theta)^{n-y}\\]\nLikelihood \\(\\cal{L}(\\theta ) = \\theta^y(1-\\theta)^{n-y}\\)\nMLE \\(\\hat{\\theta}\\) of Binomial is \\(\\bar{y} = y/n\\) proportion of successes\nRecall Derivation!"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#marginal-likelihood",
    "href": "resources/slides/01-basics-of-bayes.html#marginal-likelihood",
    "title": "Basics of Bayesian Statistics",
    "section": "Marginal Likelihood",
    "text": "Marginal Likelihood\n\\[m(y) = \\int_\\Theta \\cal{L}(\\theta)  \\pi(\\theta) \\textrm{d}\\theta=  \\int_\\Theta \\theta^y(1-\\theta)^{n-y} \\pi(\\theta) \\textrm{d}\\theta\\]\n“Averaging” of likelihood over prior \\(\\pi(\\theta) = 1\\)"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#binomial-example-1",
    "href": "resources/slides/01-basics-of-bayes.html#binomial-example-1",
    "title": "Basics of Bayesian Statistics",
    "section": "Binomial Example",
    "text": "Binomial Example\n\nPrior \\(\\theta \\sim \\textsf{U}(0,1)\\) or \\(\\pi(\\theta) = 1, \\quad \\textrm{for } \\theta \\in (0,1)\\)\nMarginal \\(m(y) = \\int_0^1 \\theta^y(1-\\theta)^{n-y}\\, 1 \\,\\textrm{d}\\theta\\)\nSpecial function known as the beta function - see Rudin \\[{B}(a, b) =  \\int_0^1 \\theta^{a - 1}(1-\\theta)^{b - 1} \\,\\textrm{d}\\theta \\]\nPosterior Distribution \\[\\pi(\\theta \\mid y ) = \\frac{ \\theta^{(y+1)-1} (1-\\theta)^{(n - y +1) -1}}{B(y + 1,n - y + 1)}\\]\n\n\n\\[\\theta \\mid y \\sim \\textsf{Beta}(y + 1, n - y + 1) \\]"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#beta-prior-distributions",
    "href": "resources/slides/01-basics-of-bayes.html#beta-prior-distributions",
    "title": "Basics of Bayesian Statistics",
    "section": "Beta Prior Distributions",
    "text": "Beta Prior Distributions\n\\(\\textsf{Beta}(a, b)\\) is a probability density function (pdf) on (0,1),\n\n\\[\\pi(\\theta) = \\frac{1}{B(a,b)} \\theta^{a-1} (1-\\theta)^{b -1}\\]\n\nUse the kernel trick to find the posterior \\[\\pi(\\theta \\mid y) \\propto \\cal{L}(\\theta \\mid y) \\pi(\\theta)\\]\nWrite down likelihood and prior (ignore constants wrt \\(\\theta\\))\nRecognize kernel of density\nFigure out normalizing constant/distribution"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#try-it",
    "href": "resources/slides/01-basics-of-bayes.html#try-it",
    "title": "Basics of Bayesian Statistics",
    "section": "Try it!",
    "text": "Try it!"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#prior-to-posterior-updating-binomial-data",
    "href": "resources/slides/01-basics-of-bayes.html#prior-to-posterior-updating-binomial-data",
    "title": "Basics of Bayesian Statistics",
    "section": "Prior to Posterior Updating Binomial Data",
    "text": "Prior to Posterior Updating Binomial Data\n\nPrior \\(\\textsf{Beta}(a, b)\\)\nPosterior \\(\\textsf{Beta}(a + y, b + n - y)\\)\nConjugate prior & posterior distribution are in the same family of distributions, (Beta)\nSimple updating of information from the prior to posterior\n\n\\(a + b\\) “prior sample size” (number of trials in a hypothetical experiment)\n\\(a\\) “number of successes”\n\\(b\\) “number of failures”\n\nprior elicitation (process of choosing the prior hyperparamters) based on historic or imaginary data"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#summaries-properties",
    "href": "resources/slides/01-basics-of-bayes.html#summaries-properties",
    "title": "Basics of Bayesian Statistics",
    "section": "Summaries & Properties",
    "text": "Summaries & Properties\n\nFor \\(\\theta \\sim \\textsf{Beta}(a,b)\\) let \\(a + b = n_0\\) “prior sample size”\nPrior mean \\[\\textsf{E}[\\theta] = \\frac{a}{a+b}  \\equiv \\theta_0 \\]\nPosterior mean \\[\\textsf{E}[\\theta \\mid y ] = \\frac{a + y }{a+b +n}  \\equiv \\tilde{\\theta} \\]\nRewrite with MLE \\(\\hat{\\theta} = \\bar{y} = \\frac{y}{n}\\) and prior mean \\[\\textsf{E}[\\theta \\mid y ] = \\frac{a + y }{a+b +n}  \n= \\frac{n_0}{n_0 + n} \\theta_0  + \\frac{n}{n_0 + n} \\hat{\\theta}\\]\nWeighted average of prior mean and MLE where weight for \\(\\theta_0 \\propto n_0\\) and weight for \\(\\hat{\\theta} \\propto n\\)"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#properties",
    "href": "resources/slides/01-basics-of-bayes.html#properties",
    "title": "Basics of Bayesian Statistics",
    "section": "Properties",
    "text": "Properties\n\nPosterior mean \\[\\tilde{\\theta} = \\frac{n_0}{n_0 + n} \\theta_0  + \\frac{n}{n_0 + n} \\hat{\\theta}\\]\nin finite samples we get shrinkage: posterior mean pulls the MLE toward the prior mean; amount depends on prior sample size \\(n_0\\) and data sample size \\(n\\)\nregularization effect to reduce Mean Squared Error for estimation with small sample sizes and noisy data\n\nintroduces some bias (in the frequentist sense) due to prior mean \\(\\theta_0\\)\nreduces variance (bias-variance trade-off)\n\nhelpful in the Binomial case, when sample size is small or \\(\\theta_{\\text{true}} \\approx 0\\) (rare events) and \\(\\hat{\\theta} = 0\\) (inbalanced categorical data)\nas we get more information from the data \\(n \\to \\infty\\) we have \\(\\tilde{\\theta} \\to \\hat{\\theta}\\) and consistency ! As \\(n \\to \\infty, \\textsf{E}[\\tilde{\\theta}] \\to \\theta_{\\text{true}}\\)"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#some-possible-prior-densities",
    "href": "resources/slides/01-basics-of-bayes.html#some-possible-prior-densities",
    "title": "Basics of Bayesian Statistics",
    "section": "Some possible prior densities",
    "text": "Some possible prior densities"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#prior-choice",
    "href": "resources/slides/01-basics-of-bayes.html#prior-choice",
    "title": "Basics of Bayesian Statistics",
    "section": "Prior Choice",
    "text": "Prior Choice\n\nIs the uniform prior \\(\\textsf{Beta}(1,1)\\) non-informative?\n\nNo- if \\(y = 0\\) (or \\(n\\)) sparse/rare events saying that we have a prior “historical” sample with 1 success and 1 failure ( \\(a = 1\\) and \\(b = 1\\) ) can be very informative\n\nWhat about a uniform prior on the log odds? \\(\\eta \\equiv \\log\\left( \\frac{\\theta} {1 - \\theta} \\right)\\)? \\[\\pi(\\eta) \\propto 1, \\qquad \\eta \\in \\mathbb{R}\\]\n\nIs this a proper prior distribution?\nwhat would be induced measure for \\(\\theta\\)?\nFind Jacobian (exercise!) \\[\\pi(\\theta) \\propto \\theta^{-1} (1 - \\theta)^{-1}, \\qquad \\theta \\in (0,1)\\]\nlimiting case of a Beta \\(a \\to 0\\) and \\(b \\to 0\\) (Haldane’s prior)"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#formal-bayes",
    "href": "resources/slides/01-basics-of-bayes.html#formal-bayes",
    "title": "Basics of Bayesian Statistics",
    "section": "Formal Bayes",
    "text": "Formal Bayes\n\nuse of improper prior and turn the Bayesian crank\ncalculate \\(m(y)\\) and renormalize likelihood times “improper prior” if \\(m(y)\\) is finite\nformal posterior is \\(\\textsf{Beta}(y, n-y)\\) and reasonable only if \\(y \\neq 0\\) or \\(y \\neq n\\) as \\(B(0, -)\\) and \\(B(-, 0)\\) (normalizing constant) are undefined!\nno shrinkage \\(\\textsf{E}[\\theta \\mid y] = \\frac{y}{n} = \\tilde{\\theta} = \\hat{\\theta}\\)"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#invariance",
    "href": "resources/slides/01-basics-of-bayes.html#invariance",
    "title": "Basics of Bayesian Statistics",
    "section": "Invariance",
    "text": "Invariance\n\nJeffreys argues that priors should be invariant to transformations to be non-informative. . . . i.e. if we reparameterize with \\(\\theta = h(\\rho)\\) then the rule should be that \\[\\pi_\\theta(\\theta) = \\left|\\frac{ d \\rho} {d \\theta}\\right| \\pi_\\rho(h^{-1}(\\theta))\\]\nJefferys’ rule is to pick \\(\\pi(\\rho) \\propto (I(\\rho))^{1/2}\\)\nExpected Fisher Information for \\(\\rho\\) \\[ I(\\rho) = - \\textsf{E} \\left[ \\frac {d^2 \\log ({\\cal{L}}(\\rho))} {d^2 \\rho} \\right]\\]\nFor the Binomial example \\(\\pi(\\theta) \\propto \\theta^{-1/2} (1 - \\theta)^{-1/2}\\)\nThus Jefferys’ prior is a \\(\\textsf{Beta}(1/2, 1/2)\\)"
  },
  {
    "objectID": "resources/slides/01-basics-of-bayes.html#why",
    "href": "resources/slides/01-basics-of-bayes.html#why",
    "title": "Basics of Bayesian Statistics",
    "section": "Why ?",
    "text": "Why ?\nChain Rule!\n\nFind Jefferys’ prior for \\(\\theta\\) where \\(Y \\sim \\textsf{Ber}(\\theta)\\)\nFind information matrix \\(I(\\rho)\\) for \\(\\rho = \\rho(\\theta)\\) from \\(I(\\theta)\\)\nShow that the prior satisfies the invariance property!\nFind Jeffreys’ prior for \\(\\rho = \\log(\\frac{\\theta}{1 - \\theta})\\)\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/17-bvs.html#diabetes-example",
    "href": "resources/slides/17-bvs.html#diabetes-example",
    "title": "Lecture 17: Bayesian Variable Selection and Model Averaging",
    "section": "Diabetes Example",
    "text": "Diabetes Example\n\nset.seed(8675309)\nsource(\"yX.diabetes.train.txt\")\ndiabetes.train = as.data.frame(diabetes.train)\nsource(\"yX.diabetes.test.txt\")\ndiabetes.test = as.data.frame(diabetes.test)\ncolnames(diabetes.test)[1] = \"y\"\n\nstr(diabetes.train)\n\n'data.frame':   342 obs. of  65 variables:\n $ y      : num  -0.0147 -1.0005 -0.1444 0.6987 -0.2222 ...\n $ age    : num  0.7996 -0.0395 1.7913 -1.8703 0.113 ...\n $ sex    : num  1.064 -0.937 1.064 -0.937 -0.937 ...\n $ bmi    : num  1.296 -1.081 0.933 -0.243 -0.764 ...\n $ map    : num  0.459 -0.553 -0.119 -0.77 0.459 ...\n $ tc     : num  -0.9287 -0.1774 -0.9576 0.256 0.0826 ...\n $ ldl    : num  -0.731 -0.402 -0.718 0.525 0.328 ...\n $ hdl    : num  -0.911 1.563 -0.679 -0.757 0.171 ...\n $ tch    : num  -0.0544 -0.8294 -0.0544 0.7205 -0.0544 ...\n $ ltg    : num  0.4181 -1.4349 0.0601 0.4765 -0.6718 ...\n $ glu    : num  -0.371 -1.936 -0.545 -0.197 -0.979 ...\n $ age^2  : num  -0.312 -0.867 1.925 2.176 -0.857 ...\n $ bmi^2  : num  0.4726 0.1185 -0.0877 -0.6514 -0.2873 ...\n $ map^2  : num  -0.652 -0.573 -0.815 -0.336 -0.652 ...\n $ tc^2   : num  -0.091 -0.6497 -0.0543 -0.6268 -0.6663 ...\n $ ldl^2  : num  -0.289 -0.521 -0.3 -0.45 -0.555 ...\n $ hdl^2  : num  -0.0973 0.8408 -0.3121 -0.2474 -0.5639 ...\n $ tch^2  : num  -0.639 -0.199 -0.639 -0.308 -0.639 ...\n $ ltg^2  : num  -0.605 0.78 -0.731 -0.567 -0.402 ...\n $ glu^2  : num  -0.578 1.8485 -0.4711 -0.6443 -0.0258 ...\n $ age:sex: num  0.69 -0.139 1.765 1.609 -0.284 ...\n $ age:bmi: num  0.852 -0.142 1.489 0.271 -0.271 ...\n $ age:map: num  0.0349 -0.3346 -0.5862 1.1821 -0.3025 ...\n $ age:tc : num  -0.978 -0.246 -1.927 -0.72 -0.244 ...\n $ age:ldl: num  -0.803 -0.203 -1.504 -1.2 -0.182 ...\n $ age:hdl: num  -0.7247 0.0147 -1.2661 1.6523 0.1046 ...\n $ age:tch: num  -0.254 -0.176 -0.31 -1.598 -0.216 ...\n $ age:ltg: num  0.0644 -0.2142 -0.163 -1.1657 -0.3474 ...\n $ age:glu: num  -0.636 -0.239 -1.359 0.071 -0.438 ...\n $ sex:bmi: num  1.304 0.935 0.915 0.142 0.635 ...\n $ sex:map: num  0.258 0.289 -0.381 0.5 -0.697 ...\n $ sex:tc : num  -1.02 0.131 -1.051 -0.274 -0.112 ...\n $ sex:ldl: num  -0.927 0.236 -0.913 -0.638 -0.452 ...\n $ sex:hdl: num  -0.647 -1.188 -0.377 1.189 0.238 ...\n $ sex:tch: num  -0.411 0.47 -0.411 -1.062 -0.296 ...\n $ sex:ltg: num  0.2988 1.2093 -0.0866 -0.6032 0.4857 ...\n $ sex:glu: num  -0.6171 1.6477 -0.8069 -0.0239 0.7283 ...\n $ bmi:map: num  0.189 0.191 -0.477 -0.195 -0.702 ...\n $ bmi:tc : num  -1.5061 -0.0595 -1.1853 -0.3231 -0.3239 ...\n $ bmi:ldl: num  -1.267 0.183 -0.976 -0.407 -0.536 ...\n $ bmi:hdl: num  -0.869 -1.41 -0.286 0.586 0.251 ...\n $ bmi:tch: num  -0.505 0.505 -0.484 -0.614 -0.388 ...\n $ bmi:ltg: num  0.1014 1.1613 -0.4085 -0.5893 0.0716 ...\n $ bmi:glu: num  -0.862 1.693 -0.89 -0.337 0.358 ...\n $ map:tc : num  -0.687 -0.148 -0.131 -0.451 -0.21 ...\n $ map:ldl: num  -0.5407 0.0388 -0.1034 -0.6114 -0.036 ...\n $ map:hdl: num  -0.235 -0.672 0.254 0.745 0.252 ...\n $ map:tch: num  -0.29 0.207 -0.258 -0.835 -0.29 ...\n $ map:ltg: num  -0.214 0.428 -0.427 -0.811 -0.748 ...\n $ map:glu: num  -0.541 0.659 -0.314 -0.23 -0.812 ...\n $ tc:ldl : num  -0.144 -0.551 -0.139 -0.509 -0.581 ...\n $ tc:hdl : num  0.8363 -0.3457 0.6304 -0.2579 -0.0392 ...\n $ tc:tch : num  -0.405 -0.326 -0.404 -0.295 -0.451 ...\n $ tc:ltg : num  -0.901 -0.259 -0.571 -0.392 -0.569 ...\n $ tc:glu : num  0.0202 0.0196 0.2073 -0.396 -0.4283 ...\n $ ldl:hdl: num  0.889 -0.446 0.705 -0.207 0.26 ...\n $ ldl:tch: num  -0.463 -0.243 -0.463 -0.21 -0.506 ...\n $ ldl:ltg: num  -0.6536 0.2724 -0.3783 -0.0708 -0.5638 ...\n $ ldl:glu: num  -0.0194 0.4995 0.1032 -0.4013 -0.6234 ...\n $ hdl:tch: num  0.703 -0.5 0.692 0.171 0.651 ...\n $ hdl:ltg: num  0.0179 -1.9846 0.3839 0.0399 0.3043 ...\n $ hdl:glu: num  0.654 -2.948 0.689 0.452 0.113 ...\n $ tch:ltg: num  -0.592 0.531 -0.574 -0.253 -0.537 ...\n $ tch:glu: num  -0.371 1.114 -0.362 -0.522 -0.34 ...\n $ ltg:glu: num  -0.584 2.184 -0.468 -0.526 0.183 ..."
  },
  {
    "objectID": "resources/slides/17-bvs.html#mcmc-with-bas",
    "href": "resources/slides/17-bvs.html#mcmc-with-bas",
    "title": "Lecture 17: Bayesian Variable Selection and Model Averaging",
    "section": "MCMC with BAS",
    "text": "MCMC with BAS\n\nlibrary(BAS)\ndiabetes.bas = bas.lm(y ~ ., data=diabetes.train,\n                      prior = \"JZS\",\n                      method=\"MCMC\",\n                      n.models = 10000,\n                      MCMC.iterations=500000,\n                      thin = 10,\n                      initprobs=\"eplogp\",\n                      force.heredity=FALSE)\n\n\n\n   user  system elapsed \n 19.523   0.951  20.530 \n\n\n[1] \"number of unique models 5008\"\n\n\n\nincrease MCMC.iterations?\ncheck diagnostics"
  },
  {
    "objectID": "resources/slides/17-bvs.html#estimates-of-posterior-probabilities",
    "href": "resources/slides/17-bvs.html#estimates-of-posterior-probabilities",
    "title": "Lecture 17: Bayesian Variable Selection and Model Averaging",
    "section": "Estimates of Posterior Probabilities",
    "text": "Estimates of Posterior Probabilities\n\nrelative frequencies \\(\\hat{P}_{RF}(\\boldsymbol{\\gamma}\\mid \\mathbf{Y}) = \\frac{\\text{# times } \\boldsymbol{\\gamma}\\in S }{S}\\)\n\nergodic average converges to \\(p(\\boldsymbol{\\gamma}\\mid \\mathbf{Y})\\) as \\(S \\to \\infty\\)\nasymptoptically unbaised\n\nrenormalized posterior probabilities \\(\\hat{P}_{RN}(\\boldsymbol{\\gamma}\\mid \\mathbf{Y}) = \\frac{p(\\mathbf{Y}\\mid \\boldsymbol{\\gamma}) p(\\boldsymbol{\\gamma})} {\\sum_{\\boldsymbol{\\gamma}\\in S} p(\\mathbf{Y}\\mid \\boldsymbol{\\gamma}) p(\\boldsymbol{\\gamma})}\\)\n\nalso asymptoptically unbaised\nFisher consistent (e.g if we happen to enumerate all models in \\(S\\) iterations we recover the truth)\n\nif we run long enough the two should agree\nalso look at other summaries i.e posterior inclusion probabilities \\[\\hat{p}(\\gamma_j = 1 \\mid \\mathbf{Y}) = \\sum_S \\gamma_j \\hat{P}(\\boldsymbol{\\gamma}\\mid \\mathbf{Y})\\]"
  },
  {
    "objectID": "resources/slides/17-bvs.html#diagnostic-plot",
    "href": "resources/slides/17-bvs.html#diagnostic-plot",
    "title": "Lecture 17: Bayesian Variable Selection and Model Averaging",
    "section": "Diagnostic Plot",
    "text": "Diagnostic Plot\n\ndiagnostics(diabetes.bas, type=\"pip\")\n\n\n\nmodel probabilities converge much slower!"
  },
  {
    "objectID": "resources/slides/17-bvs.html#out-of-sample-prediction",
    "href": "resources/slides/17-bvs.html#out-of-sample-prediction",
    "title": "Lecture 17: Bayesian Variable Selection and Model Averaging",
    "section": "Out of Sample Prediction",
    "text": "Out of Sample Prediction\n\nWhat is the optimal value to predict \\(\\mathbf{Y}^{\\text{test}}\\) given \\(\\mathbf{Y}\\) under squared error?\nIterated expectations leads to BMA for \\(\\textsf{E}[\\mathbf{Y}^{\\text{test}} \\mid \\mathbf{Y}]\\)\nPrediction under model averaging \\[\\hat{Y} = \\sum_S (\\hat{\\alpha}_\\boldsymbol{\\gamma}+ \\mathbf{X}_{\\boldsymbol{\\gamma}}^{\\text{test}} \\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{\\gamma}}) \\hat{p}(\\boldsymbol{\\gamma}\\mid \\mathbf{Y})\\]\n\n\n\npred.bas = predict(diabetes.bas,\n                   newdata=diabetes.test,\n                   estimator=\"BMA\",\n                   se=TRUE)\nmean((pred.bas$fit- diabetes.test$y)^2)\n\n[1] 0.4558026"
  },
  {
    "objectID": "resources/slides/17-bvs.html#credible-intervals-coverage",
    "href": "resources/slides/17-bvs.html#credible-intervals-coverage",
    "title": "Lecture 17: Bayesian Variable Selection and Model Averaging",
    "section": "Credible Intervals & Coverage",
    "text": "Credible Intervals & Coverage\n\nposterior predictive distribution \\[\np(\\mathbf{y}^{\\text{test}} \\mid \\mathbf{y}) = \\sum_\\boldsymbol{\\gamma}p(\\mathbf{y}^{\\text{test}} \\mid \\mathbf{y}, \\boldsymbol{\\gamma})p(\\boldsymbol{\\gamma}\\mid \\mathbf{y})\n\\]\nintegrate out \\(\\alpha\\) and \\(\\boldsymbol{\\beta_\\gamma}\\) to get a normal predictive given \\(\\phi\\) and \\(\\boldsymbol{\\gamma}\\) (and \\(\\mathbf{y}\\))\nintegrate out \\(\\phi\\) to get a t distribution given \\(\\boldsymbol{\\gamma}\\) and \\(\\mathbf{y}\\)\ncredible intervals via sampling\n\nsample a model from \\(p(\\boldsymbol{\\gamma}\\mid \\mathbf{y})\\)\nconditional on a model sample \\(y \\sim p(\\mathbf{y}^{\\text{test}} \\mid \\mathbf{y}, \\boldsymbol{\\gamma})\\)\ncompute quantiles from sammple \\(y\\)\n\n\n\n\nci.bas = confint(pred.bas);\ncoverage = mean(diabetes.test$y &gt; ci.bas[,1] & diabetes.test$y &lt; ci.bas[,2])\ncoverage\n\n[1] 0.99"
  },
  {
    "objectID": "resources/slides/17-bvs.html#prediction-intervals",
    "href": "resources/slides/17-bvs.html#prediction-intervals",
    "title": "Lecture 17: Bayesian Variable Selection and Model Averaging",
    "section": "95% Prediction intervals",
    "text": "95% Prediction intervals\n\nplot(ci.bas)\n\nNULL\n\npoints(diabetes.test$y, col=2, pch=15)"
  },
  {
    "objectID": "resources/slides/17-bvs.html#selection-and-prediction",
    "href": "resources/slides/17-bvs.html#selection-and-prediction",
    "title": "Lecture 17: Bayesian Variable Selection and Model Averaging",
    "section": "Selection and Prediction",
    "text": "Selection and Prediction\n\nBMA - optimal for squared error loss Bayes \\[\\textsf{E}[\\| \\mathbf{Y}^{\\text{test}} - a\\|^2 \\mid \\mathbf{y}] = \\textsf{E}[\\| \\mathbf{Y}^{\\text{test}} - \\textsf{E}[\\mathbf{Y}^{\\text{test}}\\mid \\mathbf{y}] \\|^2 \\mid \\mathbf{y}]  + \\| \\textsf{E}[\\mathbf{Y}^{\\text{test}}\\mid \\mathbf{y}] - a\\|^2  \\]\nWhat if we want to use only a single model for prediction under squared error loss?\nHPM: Highest Posterior Probability model is optimal for selection, but not prediction\nMPM: Median Probabilty model (select model where PIP &gt; 0.5) (optimal under certain conditions; nested models)\nBPM: Best Probability Model - Model closest to BMA under loss (usually includes more predictors than HPM or MPM)"
  },
  {
    "objectID": "resources/slides/17-bvs.html#example",
    "href": "resources/slides/17-bvs.html#example",
    "title": "Lecture 17: Bayesian Variable Selection and Model Averaging",
    "section": "Example",
    "text": "Example\n\npred.bas = predict(diabetes.bas,\n                   newdata=diabetes.test,\n                   estimator=\"BPM\",\n                   se=TRUE)\n#MSE\nmean((pred.bas$fit- diabetes.test$y)^2)\n\n[1] 0.4740667\n\n#Coverage\nci.bas = confint(pred.bas)\nmean(diabetes.test$y &gt; ci.bas[,1] &\n     diabetes.test$y &lt; ci.bas[,2])\n\n[1] 0.98"
  },
  {
    "objectID": "resources/slides/17-bvs.html#theory---consistency-of-g-priors",
    "href": "resources/slides/17-bvs.html#theory---consistency-of-g-priors",
    "title": "Lecture 17: Bayesian Variable Selection and Model Averaging",
    "section": "Theory - Consistency of g-priors",
    "text": "Theory - Consistency of g-priors\n\ndesire that posterior probability of model goes to 1 as \\(n \\to \\infty\\)\n\ndoes not alwyas hold if the null model is true (may be highest posterior probability model)\nneed prior on \\(g\\) to depend on \\(n\\) (rules out EB and fixed g-priors with \\(g \\ne n\\))\nasymptotically BMA collapses to the true model\n\nother quantities may converge i.e. posterior mean\nwhat if the true model \\(\\boldsymbol{\\gamma}_T\\) is not in \\(\\Gamma\\)? What can we say?\n\n\\(\\boldsymbol{{\\cal M}}\\)-complete; BMA converges to the model that is “closest” to the truth in Kullback-Leibler divergence\n\\(\\boldsymbol{{\\cal M}}\\)-closed; realize that \\((p\\boldsymbol{\\gamma}) = 0 \\forall \\boldsymbol{\\gamma}\\in \\mathbf{G}\\) and is nonsense but know \\(\\boldsymbol{\\gamma}_T\\), however want to use models in \\(\\mathbf{G}\\) only\n\\(\\boldsymbol{{\\cal M}}\\)-open; realize that \\((p\\boldsymbol{\\gamma}) = 0 \\forall \\boldsymbol{\\gamma}\\in \\mathbf{G}\\) and is nonsense but know \\(\\boldsymbol{\\gamma}_T\\)\nlatter is related to “stacking” which is a frequentist method of ensemble learning using cross-validation; see Clyde & Iversen (2013) for the curious"
  },
  {
    "objectID": "resources/slides/17-bvs.html#summary",
    "href": "resources/slides/17-bvs.html#summary",
    "title": "Lecture 17: Bayesian Variable Selection and Model Averaging",
    "section": "Summary",
    "text": "Summary\n\nChoice of prior on \\(\\boldsymbol{\\beta_\\gamma}\\)\n\northogonally invariant priors - multivariate Spike & Slab\nproducts of independent Spike & Slab priors\nnon-semi-conjugate\n\npriors on the models (sensitivity)\ncomputation (MCMC, “stochastic search”, variational, orthogonal data augmentation, reversible jump-MCMC)\nposterior summaries - select a model or “average” over all models\n\n\nOther aspects of model selection?\n\ntransformations of \\(Y\\)\nfunctions of \\(X\\): interactions or nonlinear functions such as splines kernels\nchoice of error distribution\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "hw/hw-04.html",
    "href": "hw/hw-04.html",
    "title": "Homework 4",
    "section": "",
    "text": "Please see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-04.html#due-1159am-oct-4",
    "href": "hw/hw-04.html#due-1159am-oct-4",
    "title": "Homework 4",
    "section": "",
    "text": "Please see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-04.html#rstudio",
    "href": "hw/hw-04.html#rstudio",
    "title": "Homework 4",
    "section": "RStudio",
    "text": "RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not, first install the latest version of R here: https://cran.rstudio.com (remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "hw/hw-04.html#r-knitr",
    "href": "hw/hw-04.html#r-knitr",
    "title": "Homework 4",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the .Rnw format to type up this lab report. To get started see basics about knitr."
  },
  {
    "objectID": "hw/hw-04.html#getting-started-with-github-classroom",
    "href": "hw/hw-04.html#getting-started-with-github-classroom",
    "title": "Homework 4",
    "section": "Getting started with Github Classroom",
    "text": "Getting started with Github Classroom\nGo to Github classroom to accept the invitation to create a repository for this assignment at HW4 this will create a private repo in the STA702-F23 organization on Github with your github user name. Note: You may receive an email invitation to join STA702-F23 on your behalf.\nHit refresh, to see the link for the repo, and then click on it to go to the STA702-F23 organization in Github.\nFollow the instructions in the README in your repo and in the hw*.Rnw file to complete the assignment and push to GitHub. If you encounter issues with Gradescope submission, it is critical that you have pushed your final assignment to GitHub by the due date to validate timestamps."
  },
  {
    "objectID": "hw/hw-04.html#gradescope-submission",
    "href": "hw/hw-04.html#gradescope-submission",
    "title": "Homework 4",
    "section": "Gradescope Submission",
    "text": "Gradescope Submission\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github and upload the pdf to Gradescope here: https://www.gradescope.com/courses/585736/assignments\nMake sure to knit to pdf; ask the TA about knitting to pdf if you cannot figure it out. Be sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "hw/hw-04.html#grading",
    "href": "hw/hw-04.html#grading",
    "title": "Homework 4",
    "section": "Grading",
    "text": "Grading\nTotal: 20 points."
  },
  {
    "objectID": "hw/hw-01.html",
    "href": "hw/hw-01.html",
    "title": "Homework 1",
    "section": "",
    "text": "(see Gradescope for any updates on due dates)"
  },
  {
    "objectID": "hw/hw-01.html#due-1159pm-tues-sept-12",
    "href": "hw/hw-01.html#due-1159pm-tues-sept-12",
    "title": "Homework 1",
    "section": "",
    "text": "(see Gradescope for any updates on due dates)"
  },
  {
    "objectID": "hw/hw-01.html#rstudio",
    "href": "hw/hw-01.html#rstudio",
    "title": "Homework 1",
    "section": "RStudio",
    "text": "RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not, first install the latest version of R here: https://cran.rstudio.com (remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "hw/hw-01.html#r-knitr",
    "href": "hw/hw-01.html#r-knitr",
    "title": "Homework 1",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the .Rnw format to type up this lab report. To get started see basics about knitr."
  },
  {
    "objectID": "hw/hw-01.html#getting-started-with-github-classroom",
    "href": "hw/hw-01.html#getting-started-with-github-classroom",
    "title": "Homework 1",
    "section": "Getting started with Github Classroom",
    "text": "Getting started with Github Classroom\nGo to Github classroom to accept the invitation to create a repository for this assignment at HW1\nThis will create a private repo in the STA702-F23 organization on Github with your github user name. Note: You may receive an email invitation to join STA702-F23 on your behalf.\nHit refresh, to see the link for the repo, and then click on it to go to the STA702-F23 organization in Github.\nFollow the instructions in the README in your repo and in the hw1.Rnw file to complete the assignment and push to GitHub. If you encounter issues with Gradescope submission, it is critical that you have pushed your final assignment to GitHub by the due date to validate timestamps."
  },
  {
    "objectID": "hw/hw-01.html#gradescope-submission",
    "href": "hw/hw-01.html#gradescope-submission",
    "title": "Homework 1",
    "section": "Gradescope Submission",
    "text": "Gradescope Submission\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github and upload the pdf to Gradescope here: https://www.gradescope.com/courses/585736/assignments\nMake sure to knit to pdf; ask the TA about knitting to pdf if you cannot figure it out. Be sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "hw/hw-01.html#grading",
    "href": "hw/hw-01.html#grading",
    "title": "Homework 1",
    "section": "Grading",
    "text": "Grading\nTotal: 20 points."
  },
  {
    "objectID": "hw/hw-10.html#getting-started-with-github-classroom",
    "href": "hw/hw-10.html#getting-started-with-github-classroom",
    "title": "Homework 10",
    "section": "Getting started with Github Classroom",
    "text": "Getting started with Github Classroom\nGo to Github classroom to accept the invitation to create a repository for this assignment at HW10 this will create a private repo in the STA702-F23 organization on Github with your github user name. Note: You may receive an email invitation to join STA702-F23 on your behalf.\nHit refresh, to see the link for the repo, and then click on it to go to the STA702-F23 organization in Github.\nFollow the instructions in the README in your repo and in the hw*.Rnw file to complete the assignment and push to GitHub. If you encounter issues with Gradescope submission, it is critical that you have pushed your final assignment to GitHub by the due date to validate timestamps."
  },
  {
    "objectID": "hw/hw-10.html#gradescope-submission",
    "href": "hw/hw-10.html#gradescope-submission",
    "title": "Homework 10",
    "section": "Gradescope Submission",
    "text": "Gradescope Submission\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github and upload the pdf to Gradescope here: https://www.gradescope.com/courses/585736/assignments\nMake sure to knit to pdf; ask the TA about knitting to pdf if you cannot figure it out. Be sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "hw/hw-10.html#grading",
    "href": "hw/hw-10.html#grading",
    "title": "Homework 10",
    "section": "Grading",
    "text": "Grading\nTotal: 20 points."
  },
  {
    "objectID": "hw/hw-03.html",
    "href": "hw/hw-03.html",
    "title": "Homework 3",
    "section": "",
    "text": "Please see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-03.html#due-1159pm-tues-sept-26",
    "href": "hw/hw-03.html#due-1159pm-tues-sept-26",
    "title": "Homework 3",
    "section": "",
    "text": "Please see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-03.html#rstudio",
    "href": "hw/hw-03.html#rstudio",
    "title": "Homework 3",
    "section": "RStudio",
    "text": "RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not, first install the latest version of R here: https://cran.rstudio.com (remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "hw/hw-03.html#r-knitr",
    "href": "hw/hw-03.html#r-knitr",
    "title": "Homework 3",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the .Rnw format to type up this lab report. To get started see basics about knitr."
  },
  {
    "objectID": "hw/hw-03.html#getting-started-with-github-classroom",
    "href": "hw/hw-03.html#getting-started-with-github-classroom",
    "title": "Homework 3",
    "section": "Getting started with Github Classroom",
    "text": "Getting started with Github Classroom\nGo to Github classroom to accept the invitation to create a repository for this assignment at HW3 - this will create a private repo in the STA702-F23 organization on Github with your github user name. Note: You may receive an email invitation to join STA702-F23 on your behalf.\nHit refresh, to see the link for the repo, and then click on it to go to the STA702-F23 organization in Github.\nFollow the instructions in the README in your repo and in the hw*.Rnw file to complete the assignment and push to GitHub. If you encounter issues with Gradescope submission, it is critical that you have pushed your final assignment to GitHub by the due date to validate timestamps."
  },
  {
    "objectID": "hw/hw-03.html#gradescope-submission",
    "href": "hw/hw-03.html#gradescope-submission",
    "title": "Homework 3",
    "section": "Gradescope Submission",
    "text": "Gradescope Submission\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github and upload the pdf to Gradescope here: https://www.gradescope.com/courses/585736/assignments\nMake sure to knit to pdf; ask the TA about knitting to pdf if you cannot figure it out. Be sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "hw/hw-03.html#grading",
    "href": "hw/hw-03.html#grading",
    "title": "Homework 3",
    "section": "Grading",
    "text": "Grading\nTotal: 20 points."
  },
  {
    "objectID": "hw/hw-05.html",
    "href": "hw/hw-05.html",
    "title": "Homework 5",
    "section": "",
    "text": "Please see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-05.html#due-1159am-oct-11",
    "href": "hw/hw-05.html#due-1159am-oct-11",
    "title": "Homework 5",
    "section": "",
    "text": "Please see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-05.html#getting-started-with-github-classroom",
    "href": "hw/hw-05.html#getting-started-with-github-classroom",
    "title": "Homework 5",
    "section": "Getting started with Github Classroom",
    "text": "Getting started with Github Classroom\nGo to Github classroom to accept the invitation to create a repository for this assignment at HW5 this will create a private repo in the STA702-F23 organization on Github with your github user name. Note: You may receive an email invitation to join STA702-F23 on your behalf.\nHit refresh, to see the link for the repo, and then click on it to go to the STA702-F23 organization in Github.\nFollow the instructions in the README in your repo and in the hw*.Rnw file to complete the assignment and push to GitHub. If you encounter issues with Gradescope submission, it is critical that you have pushed your final assignment to GitHub by the due date to validate timestamps."
  },
  {
    "objectID": "hw/hw-05.html#gradescope-submission",
    "href": "hw/hw-05.html#gradescope-submission",
    "title": "Homework 5",
    "section": "Gradescope Submission",
    "text": "Gradescope Submission\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github and upload the pdf to Gradescope here: https://www.gradescope.com/courses/585736/assignments\nMake sure to knit to pdf; ask the TA about knitting to pdf if you cannot figure it out. Be sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "hw/hw-05.html#grading",
    "href": "hw/hw-05.html#grading",
    "title": "Homework 5",
    "section": "Grading",
    "text": "Grading\nTotal: 20 points."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": " Schedule",
    "section": "",
    "text": "Please refresh often in case links/content has been updated\n\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    \n    \n      Week\n      Date\n      Lesson\n      Reading\n      Slides\n      Labs\n      HW\n    \n  \n  \n    WEEK 1\n\nTues, Aug 29\n\nLecture 0: Course Overview and Introduction\n\n\n\n \n\n\n\n\n    \nThur, Aug 31\n\nLecture 1: Basics of Bayesian Inference\n\n\n\n \n\n\n\n    \nFri, Sept 1\n\nLab 1: R and Monte Carlo Review\n\n\n\n\n\n\n    WEEK 2\n\nTues, Sept 5\n\nLecture 2: Loss Functions & Summaries\n\n\n\n \n\n\n hw-01\n\n    \nThur, Sept 7\n\nLecture 3: Normal Model & Predictive Distributions\n\n\n\n \n\n\n\n    \nFri, Sept 8\n\nLab 2: Beta-Binomial Model and Introduction to stan\n\n\n\n\n\n\n    WEEK 3\n\nTues, Sept 12\n\nLecture 4: Predictive Checks\n\n\n\n \n\n\n hw-02\n\n    \nThur, Sept 14\n\nLecture 5: Introduction to Hierarchical Models, EB & Metropolis\n\n\n\n \n\n\n\n    \nFri, Sept 15\n\nLab 3: Posterior Predictive Checks\n\n\n\n\n\n\n    WEEK 4\n\nTues, Sept 19\n\nLecture 6: Metropolis Algorithm & Stochastic Sampling\n\n\n\n \n\n\n hw-03\n\n    \nThur, Sept 21\n\nLecture 7: Diagnostics and Adaptive Metropolis\n\n\n\n \n\n\n\n    \nFri, Sept 22\n\nLab 4: Metropolis Hastings\n\n\n\n\n\n\n    WEEK 5\n\nTues, Sept 26\n\nLecture 8: Metropolis-Hastings and Gibbs\n\n\n\n \n\n\n hw-04\n\n    \nThur, Sept 28\n\nLecture 9: Data Augmentation\n\n\n\n \n\n\n\n    \nFri, Sept 29\n\nLab 5:  Gibbs, DA and Adaptive Metropolis\n\n\n\n\n\n\n    WEEK 6\n\nTues, Oct 3\n\nLecture 10: Missing Data\n\n\n\n \n\n\n hw-05\n\n    \nThu, Oct 5\n\nLecture 11: Bayes Linear Regression\n\n\n\n \n\n\n\n    \nFri, Oct 6\n\nLab 6:  Q & A on HW 5 & Missing Data\n\n\n\n\n\n    WEEK 7\n\nTue, Oct 10\n\nLec 12: Choice of Priors in  Regression\n\n\n\n \n\n\n\n    \nThu, Oct 12\n\nLec 13:  Mixtures of Conjugate Priors\n\n\n\n \n\n\n hw-06\n\n    \nFri, Oct 13\n\nLab : Review for Midterm I\n\n\n\n\n\n\n    WEEK 8\n\nTue, Oct 17\n\nNO CLASS FALL BREAK\n\n\n\n\n\n    \nThur, Oct 19\n\nMidterm 1\n\n\n\n\n\n    \nFri, Oct 20\n\nLab 6: Shrinkage Priors in Regression Comparison\n\n\n\n\n\n\n    WEEK 9\n\nTue, Oct 24\n\nLec 14:  Basics of Bayesian Hypothesis Tests\n\n\n\n \n\n\n hw-07\n\n    \nThur, Oct 26\n\nLec 15:  Bayesian Multiple Testing and Hierachical Models\n\n\n\n \n\n\n\n    \nFri, Oct 27\n\nLab 7:  Multiple Hypothesis Testing\n\n\n\n\n\n\n    WEEK 10\n\nTues, Oct 31\n\nLec 16: Bayesian Variable Selection and Model Averaging\n\n\n\n \n\n\n\n    \nThur, Nov 2\n\nLec 17: Bayesian Variable Selection and Model Averaging\n\n\n\n \n\n\n hw-08\n\n    \nFri, Nov 3\n\nLab 8: Variable Selection\n\n\n\n\n\n\n    Week 11\n\nTues, Nov 7\n\nLec 18: Outliers\n\n\n\n \n\n\n\n    \nThurs, Nov 9\n\nLec 19:  Random Effects\n\n\n\n \n\n\n hw-09\n\n    \nFri, Nov 10\n\nLab 9: Review\n\n\n\n\n\n\n    Week 12\n\nTues, Nov 14\n\nMidterm II\n\n\n\n\n\n    \nThurs, Nov 16\n\nLec 20: Mixed Effects Models\n\n\n\n \n\n\n hw-10\n\n    \nFri, Nov 17\n\nLab 10:  Random Effect Models in stan\n\n\n\n\n\n\n    Week 12\n\nTues, Nov 21\n\nLec 21: Hamiltonian Monte Carlo\n\n\n\n\n\n    \nThurs, Nov 23\n\nThanksgiving Break - No Class \n\n\n\n\n hw-11\n\n    Week 13\n\nTues, Nov 28\n\nHMC\n\n\n\n\n\n    \nThur, Nov 30\n\nBARK: NonParametric Regression\n\n\n\n\n\n    \nFri, Dec 1\n\nLab 11\n\n\n\n\n\n    Week 14\n\n\nReading Period\n\n\n\n\n\n    Finals Period\n\nSat, Dec 16 2pm-5pm (in classroom)"
  },
  {
    "objectID": "labs/lab-midterm-II-review.html",
    "href": "labs/lab-midterm-II-review.html",
    "title": "Lab: Midterm II Review",
    "section": "",
    "text": "Go to Github classroom to create a repository for this assignment at Midterm II Review with the old exams"
  },
  {
    "objectID": "labs/lab-midterm-II-review.html#nothing-to-submit",
    "href": "labs/lab-midterm-II-review.html#nothing-to-submit",
    "title": "Lab: Midterm II Review",
    "section": "",
    "text": "Go to Github classroom to create a repository for this assignment at Midterm II Review with the old exams"
  },
  {
    "objectID": "labs/lab-07.html#github-classroom",
    "href": "labs/lab-07.html#github-classroom",
    "title": "Lab 6: Shrinkage Priors in Regression Comparison",
    "section": "Github Classroom",
    "text": "Github Classroom\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github by the due date."
  },
  {
    "objectID": "labs/lab-07.html#gradescope",
    "href": "labs/lab-07.html#gradescope",
    "title": "Lab 6: Shrinkage Priors in Regression Comparison",
    "section": "Gradescope",
    "text": "Gradescope\nYou must upload the final pdf from your Github repo to Gradescope.\nBe sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "labs/lab-05.html#rrstudio",
    "href": "labs/lab-05.html#rrstudio",
    "title": "Lab 5: Gibbs Sampling",
    "section": "R/RStudio",
    "text": "R/RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not and want to use your own computer, first install the latest version of R here: https://cran.rstudio.com remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "labs/lab-05.html#r-knitr",
    "href": "labs/lab-05.html#r-knitr",
    "title": "Lab 5: Gibbs Sampling",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the Rnw format to type up this lab report. To get started see basics about knitr. Make sure to knit to pdf ; ask the TA about knitting to pdf if you cannot figure it out."
  },
  {
    "objectID": "labs/lab-05.html#github-classroom",
    "href": "labs/lab-05.html#github-classroom",
    "title": "Lab 5: Gibbs Sampling",
    "section": "Github Classroom",
    "text": "Github Classroom\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github by the due date."
  },
  {
    "objectID": "labs/lab-05.html#gradescope",
    "href": "labs/lab-05.html#gradescope",
    "title": "Lab 5: Gibbs Sampling",
    "section": "Gradescope",
    "text": "Gradescope\nYou must upload the final pdf from your Github repo to Gradescope.\nBe sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "labs/lab-midterm-I-review.html",
    "href": "labs/lab-midterm-I-review.html",
    "title": "Lab: Midterm I Review",
    "section": "",
    "text": "Go to Github classroom to create a repository for this assignment at Midterm I Review with the old exams"
  },
  {
    "objectID": "labs/lab-midterm-I-review.html#nothing-to-submit",
    "href": "labs/lab-midterm-I-review.html#nothing-to-submit",
    "title": "Lab: Midterm I Review",
    "section": "",
    "text": "Go to Github classroom to create a repository for this assignment at Midterm I Review with the old exams"
  },
  {
    "objectID": "labs/lab-00-getting-started.html#rrstudio",
    "href": "labs/lab-00-getting-started.html#rrstudio",
    "title": "Lab 0: Getting Started with R and Sweave/Knitr",
    "section": "R/RStudio",
    "text": "R/RStudio\nYou all should have R and RStudio installed on your computers or feel free to use the Department servers. If you want a local version of RStudion, first install the latest version of R here: https://cran.rstudio.com (remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system. You may also need to install git as well."
  },
  {
    "objectID": "labs/lab-00-getting-started.html#github",
    "href": "labs/lab-00-getting-started.html#github",
    "title": "Lab 0: Getting Started with R and Sweave/Knitr",
    "section": "Github",
    "text": "Github\nCreate a github account if you do not have one here https://github.com"
  },
  {
    "objectID": "labs/lab-00-getting-started.html#r-sweave",
    "href": "labs/lab-00-getting-started.html#r-sweave",
    "title": "Lab 0: Getting Started with R and Sweave/Knitr",
    "section": "R Sweave",
    "text": "R Sweave\nYou are required to use R Sweave/knitr to type up HW and lab reports. Don’t worry we will guide you along the way!"
  },
  {
    "objectID": "labs/lab-00-getting-started.html#gradescope",
    "href": "labs/lab-00-getting-started.html#gradescope",
    "title": "Lab 0: Getting Started with R and Sweave/Knitr",
    "section": "Gradescope",
    "text": "Gradescope\nYou MUST submit the final pdf file to the course site on Gradescope. Make sure to knit to pdf and to submit under the right assignment entry."
  },
  {
    "objectID": "reading/12-reading.html",
    "href": "reading/12-reading.html",
    "title": "Lecture 12: Prior Choice in Conjugate Regression",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSectoin 14.1: Conditional Modeling\nSection 14.2: Bayesian analysis of the classical regression model\nSection 14.3: Regression for Causal Inference\nSection 14.4: Goals of Regression Analysis\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/12-reading.html#readings",
    "href": "reading/12-reading.html#readings",
    "title": "Lecture 12: Prior Choice in Conjugate Regression",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSectoin 14.1: Conditional Modeling\nSection 14.2: Bayesian analysis of the classical regression model\nSection 14.3: Regression for Causal Inference\nSection 14.4: Goals of Regression Analysis\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/13-reading.html",
    "href": "reading/13-reading.html",
    "title": "Lecture 13: Ridge, Lasso and Mixtures in Bayesian Regression",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 14.5: Ssembling the Matrix of Explanatory Variables\nSection 14.6: Regularization and Dimension Reduction\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\nPapers:\n\nPark, T. & Casella, G. (2008) The Bayesian Lasso, Journal of the American Statistical Association, 103:681-686\nHans, C. (2009) Model uncertainty and variable selection in Bayesian lasso regression, Statistics and Computing 20:221–229\nHans, C. (2010) Bayesian Lasso Regression, Biometrika, 96: 835-845\nCarvalho, C. Polson, N. and Scott, J (2010) The Horseshoe Estimator for Sparse Signals, Biometrika, 97:465-480\nArmagan, A. Dunson, D, and Lee, J. (2013) Generalized double Pareto shrinkage, Statistica Sinica 23:119-143 arXiv: 1104.0861v4\nFan, J. and Li (2001) Variable Selection via Nonconcave Penalized Likelihood and Its Oracle Properties,[Journal of the American Statistical Association, 96:1348-1360] (https://www.jstor.org/stable/3085904)\nGeorge, E.I. Liang, F., Xu, X., (2012) From Minimax Shrinkage Estimation to Minimax Shrinkage Prediction, Statistical Science, 27:82-94"
  },
  {
    "objectID": "reading/13-reading.html#readings",
    "href": "reading/13-reading.html#readings",
    "title": "Lecture 13: Ridge, Lasso and Mixtures in Bayesian Regression",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 14.5: Ssembling the Matrix of Explanatory Variables\nSection 14.6: Regularization and Dimension Reduction\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\nPapers:\n\nPark, T. & Casella, G. (2008) The Bayesian Lasso, Journal of the American Statistical Association, 103:681-686\nHans, C. (2009) Model uncertainty and variable selection in Bayesian lasso regression, Statistics and Computing 20:221–229\nHans, C. (2010) Bayesian Lasso Regression, Biometrika, 96: 835-845\nCarvalho, C. Polson, N. and Scott, J (2010) The Horseshoe Estimator for Sparse Signals, Biometrika, 97:465-480\nArmagan, A. Dunson, D, and Lee, J. (2013) Generalized double Pareto shrinkage, Statistica Sinica 23:119-143 arXiv: 1104.0861v4\nFan, J. and Li (2001) Variable Selection via Nonconcave Penalized Likelihood and Its Oracle Properties,[Journal of the American Statistical Association, 96:1348-1360] (https://www.jstor.org/stable/3085904)\nGeorge, E.I. Liang, F., Xu, X., (2012) From Minimax Shrinkage Estimation to Minimax Shrinkage Prediction, Statistical Science, 27:82-94"
  },
  {
    "objectID": "reading/15-reading.html",
    "href": "reading/15-reading.html",
    "title": "Lecture 15: Bayes Multiple Testing & Empirical Bayes",
    "section": "",
    "text": "[Bayes and Empirical Bayes Multiplicity Adjustment in Variable Selection](https://projecteuclid.org/journals/annals-of-statistics/volume-38/issue-5/Bayes-and-empirical-Bayes-multiplicity-adjustment-in-the-variable-selection/10.1214/10-AOS792.full\nEmpirical Bayes Correction for the Winner’s Curse in Genetic Association Studies\nMixture of g-priors\n\nA First Course in Bayesian Statistical Methods by Peter D. Hoff\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 11.1: Gibbs sampler\nSection 11.2: Metropolis and Metropolis-Hastings algorithms\nSection 11.3: Using Gibbs and Metropolis as building blocks\nSection 11.7: Bibliographic note\nSection 14.1: Conditional modeling\nSection 14.2: Bayesian analysis of the classical regression model\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/15-reading.html#readings",
    "href": "reading/15-reading.html#readings",
    "title": "Lecture 15: Bayes Multiple Testing & Empirical Bayes",
    "section": "",
    "text": "[Bayes and Empirical Bayes Multiplicity Adjustment in Variable Selection](https://projecteuclid.org/journals/annals-of-statistics/volume-38/issue-5/Bayes-and-empirical-Bayes-multiplicity-adjustment-in-the-variable-selection/10.1214/10-AOS792.full\nEmpirical Bayes Correction for the Winner’s Curse in Genetic Association Studies\nMixture of g-priors\n\nA First Course in Bayesian Statistical Methods by Peter D. Hoff\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 11.1: Gibbs sampler\nSection 11.2: Metropolis and Metropolis-Hastings algorithms\nSection 11.3: Using Gibbs and Metropolis as building blocks\nSection 11.7: Bibliographic note\nSection 14.1: Conditional modeling\nSection 14.2: Bayesian analysis of the classical regression model\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/19-reading.html",
    "href": "reading/19-reading.html",
    "title": "Lecture 19: Random Effects",
    "section": "",
    "text": "Hill, B. (1965) Inference about Variance Components in the One-Way Model. JASA 60: 806-825\nHobart, J. and Casella, G. (1996) The Effect of Improper Priors on Gibbs Sampling in Hierarchical Linear Mixed Models. JASA 91:1461-1473\nBrowne, W. J. and Draper, D. (2006). A comparison of Bayesian and likelihood-based methods for fitting multilevel models. Bayesian Analysis, 1: 473-514\nGelman, A.J. (2006) Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper). Bayesian Analysis, 1: 515-534\nA First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nChapter 8\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nChapter 5\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/19-reading.html#readings",
    "href": "reading/19-reading.html#readings",
    "title": "Lecture 19: Random Effects",
    "section": "",
    "text": "Hill, B. (1965) Inference about Variance Components in the One-Way Model. JASA 60: 806-825\nHobart, J. and Casella, G. (1996) The Effect of Improper Priors on Gibbs Sampling in Hierarchical Linear Mixed Models. JASA 91:1461-1473\nBrowne, W. J. and Draper, D. (2006). A comparison of Bayesian and likelihood-based methods for fitting multilevel models. Bayesian Analysis, 1: 473-514\nGelman, A.J. (2006) Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper). Bayesian Analysis, 1: 515-534\nA First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nChapter 8\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nChapter 5\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/05-reading.html",
    "href": "reading/05-reading.html",
    "title": "Lecture 5: Introduction to Hierarchical Models",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 8.2: Comparing multiple groups\nSection 8.3: The hierarchical normal model\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 5.2: Exchangeability and setting up hierarchical models\nSection 5.3: Fully Bayesian analysis of conjugate hierarchical models\nSection 5.4: Estimating exchangeable parameters for a normal model\nSection 5.7: Weakly informative priors for hierarchical variance parameters\nSection 11.2 Metropolis and Metropolis-Hastings algorithms\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/05-reading.html#readings",
    "href": "reading/05-reading.html#readings",
    "title": "Lecture 5: Introduction to Hierarchical Models",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 8.2: Comparing multiple groups\nSection 8.3: The hierarchical normal model\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 5.2: Exchangeability and setting up hierarchical models\nSection 5.3: Fully Bayesian analysis of conjugate hierarchical models\nSection 5.4: Estimating exchangeable parameters for a normal model\nSection 5.7: Weakly informative priors for hierarchical variance parameters\nSection 11.2 Metropolis and Metropolis-Hastings algorithms\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/16-reading.html",
    "href": "reading/16-reading.html",
    "title": "Lecture 16: Bayesian Model Averaging",
    "section": "",
    "text": "Mixture of g-priors Liang et al (2008)\nA First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\nSection 9.3: Model Selection (linear regression)\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 14.2: Bayesian analysis of the classical regression model\n\nThe Bayesian Choice (Second Edition) by Christian Robert\nLiang, F., Paulo, R, Molina, G. Clyde, M, Berger, J (2008) Mixtures of g-priors for Bayesian Variable Selection. Journal of the American Statistical Association, 103: 410-423\nHoeting, J.A, Madigan, D. Raftery,A. Volinsky, C.T. (1999) Bayesian Model Averaging: A Tutorial Statistical Science, 14: 382-401"
  },
  {
    "objectID": "reading/16-reading.html#readings",
    "href": "reading/16-reading.html#readings",
    "title": "Lecture 16: Bayesian Model Averaging",
    "section": "",
    "text": "Mixture of g-priors Liang et al (2008)\nA First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\nSection 9.3: Model Selection (linear regression)\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 14.2: Bayesian analysis of the classical regression model\n\nThe Bayesian Choice (Second Edition) by Christian Robert\nLiang, F., Paulo, R, Molina, G. Clyde, M, Berger, J (2008) Mixtures of g-priors for Bayesian Variable Selection. Journal of the American Statistical Association, 103: 410-423\nHoeting, J.A, Madigan, D. Raftery,A. Volinsky, C.T. (1999) Bayesian Model Averaging: A Tutorial Statistical Science, 14: 382-401"
  },
  {
    "objectID": "reading/08-reading.html",
    "href": "reading/08-reading.html",
    "title": "Lecture 8: Gibbs Sampling, Blocked Samplers and Metropolis Hastings",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nChapter 6: Posterior approximation with the Gibbs sampler\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\nSection 10.4: Metropolis, Metropolis-Hastings and Gibbs\nSection 10.5: Combining the Metropolis and Gibbs algorithm\nSection 10.6: Discussion and further references\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 11.1: Gibbs sampler\nSection 11.2: Metropolis and Metropolis-Hastings algorithms\nSection 11.3: Using Gibbs and Metropolis as building blocks\nSection 11.7: Bibliographic note\nSection 14.1: Conditional modeling\nSection 14.2: Bayesian analysis of the classical regression model\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/08-reading.html#readings",
    "href": "reading/08-reading.html#readings",
    "title": "Lecture 8: Gibbs Sampling, Blocked Samplers and Metropolis Hastings",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nChapter 6: Posterior approximation with the Gibbs sampler\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\nSection 10.4: Metropolis, Metropolis-Hastings and Gibbs\nSection 10.5: Combining the Metropolis and Gibbs algorithm\nSection 10.6: Discussion and further references\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 11.1: Gibbs sampler\nSection 11.2: Metropolis and Metropolis-Hastings algorithms\nSection 11.3: Using Gibbs and Metropolis as building blocks\nSection 11.7: Bibliographic note\nSection 14.1: Conditional modeling\nSection 14.2: Bayesian analysis of the classical regression model\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/01-reading.html",
    "href": "reading/01-reading.html",
    "title": "Lecture 1: Basics of Bayesian inference",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 1: Introduction and examples\nSection 3.1: The binomial model\nSection 3.4: Discussion and further references\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin:\n\nSection 1.1: The three steps of Bayesian data analysis\nSection 1.2: General notation for statistical inference\nSection 1.3: Bayesian inference\nSection 1.9: Computation and software\nSection 1.10: Bayesian inference in applied statistics\nSection 2.1: Estimating a probability from binomial data\nSection 2.2: Posterior as compromise between data and prior information\nSection 2.4: Informative prior distributions"
  },
  {
    "objectID": "reading/01-reading.html#readings",
    "href": "reading/01-reading.html#readings",
    "title": "Lecture 1: Basics of Bayesian inference",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 1: Introduction and examples\nSection 3.1: The binomial model\nSection 3.4: Discussion and further references\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin:\n\nSection 1.1: The three steps of Bayesian data analysis\nSection 1.2: General notation for statistical inference\nSection 1.3: Bayesian inference\nSection 1.9: Computation and software\nSection 1.10: Bayesian inference in applied statistics\nSection 2.1: Estimating a probability from binomial data\nSection 2.2: Posterior as compromise between data and prior information\nSection 2.4: Informative prior distributions"
  },
  {
    "objectID": "reading/01-reading.html#optional",
    "href": "reading/01-reading.html#optional",
    "title": "Lecture 1: Basics of Bayesian inference",
    "section": "Optional",
    "text": "Optional\n\nBayesian Computation with R (Second Edition) by Jim Albert:\n\nSection 2: Introduction to Bayesian thinking"
  },
  {
    "objectID": "reading/07-reading.html",
    "href": "reading/07-reading.html",
    "title": "Lecture 7: Adaptive Metropolis & Metropolis-Hastings",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 10.4: Metropolis, Metropolis-Hastings and Gibbs\nSection 10.5: Combining the Metropolis and Gibbs algorithm\nSection 10.6: Discussion and further references\nChapter 6: Posterior approximation with the Gibbs sampler\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 11.2: Metropolis and Metropolis-Hastings algorithms\nSection 11.4: Inference and assessing convergence\nSection 11.6: Example\nSection 11.7: Bibliographic note\n\nAn Adaptive Metropolis Algoritm by Heikki Haario, Eero Saksman, Johanna Tamminen (2001)\nExamples of Adaptive Metropolis by Gareth O. Roberts & Jeffrey S. Rosenthal (2009) Journal of Computational and Graphical Statistics, 18:2, 349-367, DOI: 10.1198/ jcgs.2009.06134\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/07-reading.html#readings",
    "href": "reading/07-reading.html#readings",
    "title": "Lecture 7: Adaptive Metropolis & Metropolis-Hastings",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 10.4: Metropolis, Metropolis-Hastings and Gibbs\nSection 10.5: Combining the Metropolis and Gibbs algorithm\nSection 10.6: Discussion and further references\nChapter 6: Posterior approximation with the Gibbs sampler\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 11.2: Metropolis and Metropolis-Hastings algorithms\nSection 11.4: Inference and assessing convergence\nSection 11.6: Example\nSection 11.7: Bibliographic note\n\nAn Adaptive Metropolis Algoritm by Heikki Haario, Eero Saksman, Johanna Tamminen (2001)\nExamples of Adaptive Metropolis by Gareth O. Roberts & Jeffrey S. Rosenthal (2009) Journal of Computational and Graphical Statistics, 18:2, 349-367, DOI: 10.1198/ jcgs.2009.06134\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/06-reading.html",
    "href": "reading/06-reading.html",
    "title": "Lecture 6: Introduction to Metropolis Algorithms and Diagnostics",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 10.1: Generalized linear models\n\nSection 10.2: The Metropolis algorithm\nSection 10.3: The Metropolis algorithm for Poisson regression\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 11.2 Metropolis and Metropolis-Hastings algorithms\nSection 11.4 Inference and Assessing Convergence\nSection 11.5 Effective number of simulations\nSection 11.6 Example\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\nSee also Dunson, D. & Johndrow, J. (2020) The Hastings algorithm at fifty. Biometrika,107: pp. 1–23"
  },
  {
    "objectID": "reading/06-reading.html#readings",
    "href": "reading/06-reading.html#readings",
    "title": "Lecture 6: Introduction to Metropolis Algorithms and Diagnostics",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 10.1: Generalized linear models\n\nSection 10.2: The Metropolis algorithm\nSection 10.3: The Metropolis algorithm for Poisson regression\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 11.2 Metropolis and Metropolis-Hastings algorithms\nSection 11.4 Inference and Assessing Convergence\nSection 11.5 Effective number of simulations\nSection 11.6 Example\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\nSee also Dunson, D. & Johndrow, J. (2020) The Hastings algorithm at fifty. Biometrika,107: pp. 1–23"
  },
  {
    "objectID": "reading/09-reading.html",
    "href": "reading/09-reading.html",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nChapter 6: Posterior approximation with the Gibbs sampler\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\nSection 10.4: Metropolis, Metropolis-Hastings and Gibbs\nSection 10.5: Combining the Metropolis and Gibbs algorithm\nSection 10.6: Discussion and further references\nSection 12.1 Latent Variables for Ordinal Data\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 11.1: Gibbs sampler\nSection 11.2: Metropolis and Metropolis-Hastings algorithms\nSection 11.3: Using Gibbs and Metropolis as building blocks\nSection 11.7: Bibliographic note\nSection 14.1: Conditional modeling\nSection 14.2: Bayesian analysis of the classical regression model\n\nAlbert & Chib Bayesian Analysis of Binary and Polychotomous Response Data, Journal of the American Statistical Association, Vol. 88, No. 422 pp. 669- 679 )\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/09-reading.html#readings",
    "href": "reading/09-reading.html#readings",
    "title": "Lecture 9: Gibbs Sampling and Data Augmentation",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nChapter 6: Posterior approximation with the Gibbs sampler\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\nSection 10.4: Metropolis, Metropolis-Hastings and Gibbs\nSection 10.5: Combining the Metropolis and Gibbs algorithm\nSection 10.6: Discussion and further references\nSection 12.1 Latent Variables for Ordinal Data\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 11.1: Gibbs sampler\nSection 11.2: Metropolis and Metropolis-Hastings algorithms\nSection 11.3: Using Gibbs and Metropolis as building blocks\nSection 11.7: Bibliographic note\nSection 14.1: Conditional modeling\nSection 14.2: Bayesian analysis of the classical regression model\n\nAlbert & Chib Bayesian Analysis of Binary and Polychotomous Response Data, Journal of the American Statistical Association, Vol. 88, No. 422 pp. 669- 679 )\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": " Resources",
    "section": "",
    "text": "Supplementary Textbooks\nThese textbooks are great resources for some of the topics we will cover. You do not need to buy them, but you may be able to borrow them from Duke library should you need extra reading materials, besides the class slides and main textbooks.\n\nDoing Bayesian Data Analysis in brms and the tidyverse\nStatistical rethinking with brms, ggplot2, and the tidyverse: Second edition\nAlbert, J. (2009), “Bayesian Computation with R (Second Edition).”\nBolstad, W. M. and Curran, J. M. (2016), “Introduction to Bayesian Statistics (Third Edition).”\n\n\n\nR and R Markdown Resources\nR Markdown can be used to create high quality reports and presentations with embedded chunks of R code. You are required to use R Markdown to type up your lab reports. R Markdown would also be my personal favorite for typing up your homework assignments for this course, but you are welcome to use any word processor of your choice for those. To learn more about R Markdown and for other resources for programming in R, see the links below.\n\nR for Data Science (by Hadley Wickham & Garrett Grolemund)\nIntroduction to R Markdown (Article by Garrett Grolemund)\nIntroduction to R Markdown (Slides by Andrew Cho)\nR Markdown Cheat Sheet\nData Visualization with ggplot2 Cheat Sheet\nOther Useful Cheat Sheets\nA very (very!) basic R Markdown template\n\n\n\nLaTeX\nYou may also use LaTeX to type up your assignments. You may find it easier to create your TeX and LaTeX documents using online editors such as Overleaf (simply create a free account and you are good to go!). However, that need not be the case. If you prefer to create them locally/offline on your personal computers, you will need to download a TeX distribution (the most popular choices are MiKTeX for Windows and MacTeX for macOS) plus an editor (I personally prefer TeXstudio but feel free to download any editor of your choice). Follow the links below for some options, and to also learn how to use LaTeX.\n\nLearn LaTeX in 30 minutes\nChoosing a LaTeX Compiler.\n\n\n\nInteresting Articles\nI will add articles I find interesting below. These are articles I find useful as supplementary readings for topics covered in class, or as good sources that cover concepts I think you should know, but which we may not have time to cover. I strongly suggest you find time to (at the very least) take a “quick peek” at each article.\n\nEfron, B., 1986. Why isn’t everyone a Bayesian?. The American Statistician, 40(1), pp. 1-5.\nGelman, A., 2008. Objections to Bayesian statistics. Bayesian Analysis, 3(3), pp. 445-449.\nDiaconis, P., 1977. Finite forms of de Finetti’s theorem on exchangeability. Synthese, 36(2), pp. 271-281.\nGelman, A., Meng, X. L. and Stern, H., 1996. Posterior predictive assessment of model fitness via realized discrepancies. Statistica sinica, pp. 733-760.\nDunson, D. B., 2018. Statistics in the big data era: Failures of the machine. Statistics & Probability Letters, 136, pp. 4-9."
  },
  {
    "objectID": "reading/03-reading.html",
    "href": "reading/03-reading.html",
    "title": "Lecture 3: Normal Models and Predictive Distributions",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 5.1: The normal model\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 2.5: Normal Distribution with Known Variance (page 39)"
  },
  {
    "objectID": "reading/03-reading.html#readings",
    "href": "reading/03-reading.html#readings",
    "title": "Lecture 3: Normal Models and Predictive Distributions",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 5.1: The normal model\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 2.5: Normal Distribution with Known Variance (page 39)"
  },
  {
    "objectID": "reading/14-reading.html",
    "href": "reading/14-reading.html",
    "title": "Lecture 14: Basics of Hypothesis Testing",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\npage 16\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 7.4: Model comparison using Bayes factors\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\n5: Tests and Confidence Regions\n5.1: Introduction\n5.2: A first approach to testing theory\n5.3: Comparison with the classical approach\n5.4: A second decision-theoretic approach"
  },
  {
    "objectID": "reading/14-reading.html#readings",
    "href": "reading/14-reading.html#readings",
    "title": "Lecture 14: Basics of Hypothesis Testing",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\npage 16\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 7.4: Model comparison using Bayes factors\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\n5: Tests and Confidence Regions\n5.1: Introduction\n5.2: A first approach to testing theory\n5.3: Comparison with the classical approach\n5.4: A second decision-theoretic approach"
  },
  {
    "objectID": "reading/00-reading.html",
    "href": "reading/00-reading.html",
    "title": "Lecture 0: Readings to Pique Your Interest",
    "section": "",
    "text": "These are articles I find useful as supplementary readings for topics covered in class, or as good sources that cover concepts I think you should know, but which we may not have time to cover. I strongly suggest you find time to (at the very least) take a “quick peek” at each article.\n\nEfron, B., 1986. Why isn’t everyone a Bayesian?. The American Statistician, 40(1), pp. 1-5.\nGelman, A., 2008. Objections to Bayesian statistics. Bayesian Analysis, 3(3), pp. 445-449.\nDiaconis, P., 1977. Finite forms of de Finetti’s theorem on exchangeability. Synthese, 36(2), pp. 271-281.\nGelman, A., Meng, X. L. and Stern, H., 1996. Posterior predictive assessment of model fitness via realized discrepancies. Statistica sinica, pp. 733-760.\nDunson, D. B., 2018. Statistics in the big data era: Failures of the machine. Statistics & Probability Letters, 136, pp. 4-9."
  },
  {
    "objectID": "reading/00-reading.html#readings",
    "href": "reading/00-reading.html#readings",
    "title": "Lecture 0: Readings to Pique Your Interest",
    "section": "",
    "text": "These are articles I find useful as supplementary readings for topics covered in class, or as good sources that cover concepts I think you should know, but which we may not have time to cover. I strongly suggest you find time to (at the very least) take a “quick peek” at each article.\n\nEfron, B., 1986. Why isn’t everyone a Bayesian?. The American Statistician, 40(1), pp. 1-5.\nGelman, A., 2008. Objections to Bayesian statistics. Bayesian Analysis, 3(3), pp. 445-449.\nDiaconis, P., 1977. Finite forms of de Finetti’s theorem on exchangeability. Synthese, 36(2), pp. 271-281.\nGelman, A., Meng, X. L. and Stern, H., 1996. Posterior predictive assessment of model fitness via realized discrepancies. Statistica sinica, pp. 733-760.\nDunson, D. B., 2018. Statistics in the big data era: Failures of the machine. Statistics & Probability Letters, 136, pp. 4-9."
  },
  {
    "objectID": "reading/17-reading.html",
    "href": "reading/17-reading.html",
    "title": "Lecture 17: Bayesian Model Averaging",
    "section": "",
    "text": "Liang, F., Paulo, R, Molina, G. Clyde, M, Berger, J (2008) Mixtures of g-priors for Bayesian Variable Selection. Journal of the American Statistical Association, 103: 410-423\nHoeting, J.A, Madigan, D. Raftery,A. Volinsky, C.T. (1999) Bayesian Model Averaging: A Tutorial Statistical Science, 14: 382-401\nA First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\nSection 9.3: Model Selection (linear regression)\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 14.2: Bayesian analysis of the classical regression model\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/17-reading.html#readings",
    "href": "reading/17-reading.html#readings",
    "title": "Lecture 17: Bayesian Model Averaging",
    "section": "",
    "text": "Liang, F., Paulo, R, Molina, G. Clyde, M, Berger, J (2008) Mixtures of g-priors for Bayesian Variable Selection. Journal of the American Statistical Association, 103: 410-423\nHoeting, J.A, Madigan, D. Raftery,A. Volinsky, C.T. (1999) Bayesian Model Averaging: A Tutorial Statistical Science, 14: 382-401\nA First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\nSection 9.3: Model Selection (linear regression)\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 14.2: Bayesian analysis of the classical regression model\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/10-reading.html",
    "href": "reading/10-reading.html",
    "title": "Lecture 10: Missing Data",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 7.1 Multivariate normal\nSection 7.2 Semi-conjugate prior for the mean\nSection 7.3 Inverse-Wishart\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 3.6 Multivariate Normal\nChapter 21: Missing Data\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\nSun, D. and Berger, J.O (2006) Objective Bayesian Analysis for the Multivariate Normal Model with Discussion. Proc. Valencia / ISBA 8th World Meeting on Bayesian Statistics Benidorm (Alicante, Spain)\nMulder, J. Pericchi, L.R. (2018) The Matrix-F Prior for Estimating and Testing Covariance Matrices. _Bayesian Analysis, 13: 1193-1214"
  },
  {
    "objectID": "reading/10-reading.html#readings",
    "href": "reading/10-reading.html#readings",
    "title": "Lecture 10: Missing Data",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 7.1 Multivariate normal\nSection 7.2 Semi-conjugate prior for the mean\nSection 7.3 Inverse-Wishart\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 3.6 Multivariate Normal\nChapter 21: Missing Data\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\nSun, D. and Berger, J.O (2006) Objective Bayesian Analysis for the Multivariate Normal Model with Discussion. Proc. Valencia / ISBA 8th World Meeting on Bayesian Statistics Benidorm (Alicante, Spain)\nMulder, J. Pericchi, L.R. (2018) The Matrix-F Prior for Estimating and Testing Covariance Matrices. _Bayesian Analysis, 13: 1193-1214"
  },
  {
    "objectID": "reading/04-reading.html",
    "href": "reading/04-reading.html",
    "title": "Lecture 4: Predictive Checks",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nChapter 4: Monte Carlo Approximations\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nChapter 6: Model Checking"
  },
  {
    "objectID": "reading/04-reading.html#readings",
    "href": "reading/04-reading.html#readings",
    "title": "Lecture 4: Predictive Checks",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nChapter 4: Monte Carlo Approximations\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nChapter 6: Model Checking"
  },
  {
    "objectID": "reading/04-reading.html#optional",
    "href": "reading/04-reading.html#optional",
    "title": "Lecture 4: Predictive Checks",
    "section": "Optional",
    "text": "Optional\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\n2.6 Criticisms and alternatives\n6.2.2 Monte Carlo methods"
  },
  {
    "objectID": "reading/04-reading.html#recommended",
    "href": "reading/04-reading.html#recommended",
    "title": "Lecture 4: Predictive Checks",
    "section": "Recommended",
    "text": "Recommended\nBayarri, M. and Berger, J. (2000). P-values for composite null models. Journal of the American Statistical Association, 95(452):1127–1142\nBerger, J (2003) Could Fisher, Jeffreys and Neyman Have Agreed on Testing? Statistical Science, 18:1-12."
  },
  {
    "objectID": "reading/11-reading.html",
    "href": "reading/11-reading.html",
    "title": "Lecture 11: Bayesian Conjugate Regression",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSectoin 14.1: Conditional Modeling\nSection 14.2: Bayesian analysis of the classical regression model\nSection 14.3: Regression for Causal Inference\nSection 14.4: Goals of Regression Analysis\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/11-reading.html#readings",
    "href": "reading/11-reading.html#readings",
    "title": "Lecture 11: Bayesian Conjugate Regression",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSectoin 14.1: Conditional Modeling\nSection 14.2: Bayesian analysis of the classical regression model\nSection 14.3: Regression for Causal Inference\nSection 14.4: Goals of Regression Analysis\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/02-reading.html",
    "href": "reading/02-reading.html",
    "title": "Lecture 2: Optimal Bayesian Point and Interval Estimation",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 3.1.2: Confidence regions\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 2.3: Summarizing posterior inference\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\nChapter 2 (skip Section 2.4 for now) Decision-Theoretic Foundations\nSection 4.1: Bayesian inference\nSection 4.2: Bayesian Decision Theory\nSection 5.5: Confidence regions"
  },
  {
    "objectID": "reading/02-reading.html#readings",
    "href": "reading/02-reading.html#readings",
    "title": "Lecture 2: Optimal Bayesian Point and Interval Estimation",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff.:\n\nSection 3.1.2: Confidence regions\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.:\n\nSection 2.3: Summarizing posterior inference\n\nThe Bayesian Choice (Second Edition) by Christian Robert\n\nChapter 2 (skip Section 2.4 for now) Decision-Theoretic Foundations\nSection 4.1: Bayesian inference\nSection 4.2: Bayesian Decision Theory\nSection 5.5: Confidence regions"
  },
  {
    "objectID": "reading/18-reading.html",
    "href": "reading/18-reading.html",
    "title": "Lecture 18: Outliers and Robust Bayesian Regression",
    "section": "",
    "text": "Hamura, Y.. (2023) A Simple Proof of Posterior Robustness\nDesgagné, A. and Gagnon P (2018) Bayesian Robustness to Outliers in Linear Regression and Ratio Estimation\nWest, M. (1984). Outlier Models and Prior Distributions in Bayesian Linear Regression. JRSS B 46, 431-439\nHoeting, J., Raftery, A., Madigan, D. (1996) A method for simultaneous variable selection and outlier identification in linear regression Computational Statistics & Data Analysis, 22, 251-270\n\n-O’hagan, T. (1979) On Outlier Rejection Phenomena in Bayes Inference. JRSSB, 41:358-367\n\nA First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\nSection 9.3: Model Selection (linear regression)\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 14.2: Bayesian analysis of the classical regression model\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/18-reading.html#readings",
    "href": "reading/18-reading.html#readings",
    "title": "Lecture 18: Outliers and Robust Bayesian Regression",
    "section": "",
    "text": "Hamura, Y.. (2023) A Simple Proof of Posterior Robustness\nDesgagné, A. and Gagnon P (2018) Bayesian Robustness to Outliers in Linear Regression and Ratio Estimation\nWest, M. (1984). Outlier Models and Prior Distributions in Bayesian Linear Regression. JRSS B 46, 431-439\nHoeting, J., Raftery, A., Madigan, D. (1996) A method for simultaneous variable selection and outlier identification in linear regression Computational Statistics & Data Analysis, 22, 251-270\n\n-O’hagan, T. (1979) On Outlier Rejection Phenomena in Bayes Inference. JRSSB, 41:358-367\n\nA First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nSection 9.1: The linear regression model (review)\nSection 9.2: Bayesian estimation for a regression model\nSection 9.3: Model Selection (linear regression)\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nSection 14.2: Bayesian analysis of the classical regression model\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/20-reading.html",
    "href": "reading/20-reading.html",
    "title": "Lecture 20: Mixed Effects",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nChapter 8\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nChapter 15\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "reading/20-reading.html#readings",
    "href": "reading/20-reading.html#readings",
    "title": "Lecture 20: Mixed Effects",
    "section": "",
    "text": "A First Course in Bayesian Statistical Methods by Peter D. Hoff\n\nChapter 8\n\nBayesian Data Analysis (Third Edition) by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\n\nChapter 15\n\nThe Bayesian Choice (Second Edition) by Christian Robert"
  },
  {
    "objectID": "labs/lab-01-r-review.html#rrstudio",
    "href": "labs/lab-01-r-review.html#rrstudio",
    "title": "Lab 1: R Review and Monte Carlo",
    "section": "R/RStudio",
    "text": "R/RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not and want to use your own computer, first install the latest version of R here: https://cran.rstudio.com remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "labs/lab-01-r-review.html#r-knitr",
    "href": "labs/lab-01-r-review.html#r-knitr",
    "title": "Lab 1: R Review and Monte Carlo",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the Rnw format to type up this lab report. To get started see basics about knitr. Make sure to knit to pdf ; ask the TA about knitting to pdf if you cannot figure it out."
  },
  {
    "objectID": "labs/lab-01-r-review.html#github-classroom",
    "href": "labs/lab-01-r-review.html#github-classroom",
    "title": "Lab 1: R Review and Monte Carlo",
    "section": "Github Classroom",
    "text": "Github Classroom\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github by the due date."
  },
  {
    "objectID": "labs/lab-01-r-review.html#gradescope",
    "href": "labs/lab-01-r-review.html#gradescope",
    "title": "Lab 1: R Review and Monte Carlo",
    "section": "Gradescope",
    "text": "Gradescope\nYou must upload the final pdf from your Github repo to Gradescope.\nBe sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "labs/lab-03.html#rrstudio",
    "href": "labs/lab-03.html#rrstudio",
    "title": "Lab 3: Posterior Predictive Checks",
    "section": "R/RStudio",
    "text": "R/RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not and want to use your own computer, first install the latest version of R here: https://cran.rstudio.com remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "labs/lab-03.html#r-knitr",
    "href": "labs/lab-03.html#r-knitr",
    "title": "Lab 3: Posterior Predictive Checks",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the Rnw format to type up this lab report. To get started see basics about knitr. Make sure to knit to pdf ; ask the TA about knitting to pdf if you cannot figure it out."
  },
  {
    "objectID": "labs/lab-03.html#github-classroom",
    "href": "labs/lab-03.html#github-classroom",
    "title": "Lab 3: Posterior Predictive Checks",
    "section": "Github Classroom",
    "text": "Github Classroom\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github by the due date."
  },
  {
    "objectID": "labs/lab-03.html#gradescope",
    "href": "labs/lab-03.html#gradescope",
    "title": "Lab 3: Posterior Predictive Checks",
    "section": "Gradescope",
    "text": "Gradescope\nYou must upload the final pdf from your Github repo to Gradescope.\nBe sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "labs/lab-02-beta-binomial.html#rrstudio",
    "href": "labs/lab-02-beta-binomial.html#rrstudio",
    "title": "Lab 2: Beta-Binomial Model and Introduction to stan",
    "section": "R/RStudio",
    "text": "R/RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not and want to use your own computer, first install the latest version of R here: https://cran.rstudio.com remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "labs/lab-02-beta-binomial.html#r-knitr",
    "href": "labs/lab-02-beta-binomial.html#r-knitr",
    "title": "Lab 2: Beta-Binomial Model and Introduction to stan",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the Rnw format to type up this lab report. To get started see basics about knitr. Make sure to knit to pdf ; ask the TA about knitting to pdf if you cannot figure it out."
  },
  {
    "objectID": "labs/lab-02-beta-binomial.html#github-classroom",
    "href": "labs/lab-02-beta-binomial.html#github-classroom",
    "title": "Lab 2: Beta-Binomial Model and Introduction to stan",
    "section": "Github Classroom",
    "text": "Github Classroom\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github by the due date."
  },
  {
    "objectID": "labs/lab-02-beta-binomial.html#gradescope",
    "href": "labs/lab-02-beta-binomial.html#gradescope",
    "title": "Lab 2: Beta-Binomial Model and Introduction to stan",
    "section": "Gradescope",
    "text": "Gradescope\nYou must upload the final pdf from your Github repo to Gradescope.\nBe sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "labs/lab-06.html#github-classroom",
    "href": "labs/lab-06.html#github-classroom",
    "title": "Lab 6: Shrinkage Priors in Regression Comparison",
    "section": "Github Classroom",
    "text": "Github Classroom\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github by the due date."
  },
  {
    "objectID": "labs/lab-06.html#gradescope",
    "href": "labs/lab-06.html#gradescope",
    "title": "Lab 6: Shrinkage Priors in Regression Comparison",
    "section": "Gradescope",
    "text": "Gradescope\nYou must upload the final pdf from your Github repo to Gradescope.\nBe sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "labs/lab-04.html#rrstudio",
    "href": "labs/lab-04.html#rrstudio",
    "title": "Lab 4: Metropolis Random Walk Algorithms",
    "section": "R/RStudio",
    "text": "R/RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not and want to use your own computer, first install the latest version of R here: https://cran.rstudio.com remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "labs/lab-04.html#r-knitr",
    "href": "labs/lab-04.html#r-knitr",
    "title": "Lab 4: Metropolis Random Walk Algorithms",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the Rnw format to type up this lab report. To get started see basics about knitr. Make sure to knit to pdf ; ask the TA about knitting to pdf if you cannot figure it out."
  },
  {
    "objectID": "labs/lab-04.html#github-classroom",
    "href": "labs/lab-04.html#github-classroom",
    "title": "Lab 4: Metropolis Random Walk Algorithms",
    "section": "Github Classroom",
    "text": "Github Classroom\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github by the due date."
  },
  {
    "objectID": "labs/lab-04.html#gradescope",
    "href": "labs/lab-04.html#gradescope",
    "title": "Lab 4: Metropolis Random Walk Algorithms",
    "section": "Gradescope",
    "text": "Gradescope\nYou must upload the final pdf from your Github repo to Gradescope.\nBe sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "labs/lab-08.html#github-classroom",
    "href": "labs/lab-08.html#github-classroom",
    "title": "Lab 6: Shrinkage Priors in Regression Comparison",
    "section": "Github Classroom",
    "text": "Github Classroom\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github by the due date."
  },
  {
    "objectID": "labs/lab-08.html#gradescope",
    "href": "labs/lab-08.html#gradescope",
    "title": "Lab 6: Shrinkage Priors in Regression Comparison",
    "section": "Gradescope",
    "text": "Gradescope\nYou must upload the final pdf from your Github repo to Gradescope.\nBe sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "index.html#bayesian-statistical-modeling-and-data-analysis",
    "href": "index.html#bayesian-statistical-modeling-and-data-analysis",
    "title": "STA 702 Fall 2023",
    "section": "Bayesian Statistical Modeling and Data Analysis",
    "text": "Bayesian Statistical Modeling and Data Analysis\n\nCourse Overview\nThis course provides an introduction to Bayesian statistics targeted towards building a foundation for later research in developing models appropriate to complex data applications and to methodology research developing new modeling/inferential frameworks and algorithms. Topics include the basic foundations of Bayesian inferences – prior distributions, likelihood functions, posterior distributions, loss functions, and Bayes estimators/decisions with illustration in simple cases. Posterior computation in non-conjugate models with Markov chain Monte Carlo (MCMC) algorithms in addition to approximations to posteriors based on Laplace and variational approaches will be covered. We will build (and critique) models for a variety of data types and structures including regression, classification, and dependent data, hierarchical models for the borrowing of information, and methods for dealing with model uncertainty. Throughout we will discuss the difference between classical and Bayesian paradigms as well as advantages/disadvantages of Bayes. Time permitting we will discuss generalized Bayes.\n\n\nLearning Objectives\nBy the end of this course, students should be able to\n\nUnderstand the basics of Bayesian inference, that is, be able to define likelihood functions, prior distributions, posterior distributions, prior predictive distributions and posterior predictive distributions.\nDerive posterior distributions, prior predictive distributions and posterior predictive distributions, for common likelihood-prior combinations of distributions.\nInterpret the results of fitted models and conduct checks to ascertain that the models have converged.\nUse the Bayesian methods and models covered in class to analyze real data sets.\nAssess the adequacy of Bayesian models to any given data and make a decision on what to do in cases when certain models are not appropriate for a given data set."
  },
  {
    "objectID": "index.html#course-info",
    "href": "index.html#course-info",
    "title": "STA 702 Fall 2023",
    "section": "Course Info",
    "text": "Course Info\n\nInstructional Team and Office Hours\n\n\n\nRole\nName\nEmail\nOffice Hours\nLocation\n\n\n\n\nInstructor\nDr Merlise Clyde\n\nMon 9:00- 10:00, Thur 130-2:30  or by appointment (I have lots of 30 minute gaps!) \n223E Old Chem\n\n\nTA\nRick Presman\n\nMon 3:00 - 4:00, Fri 9:00-10:00\n203B Old Chem\n\n\n\n\n\nMeeting Times\n\nLecture\n   Tuesdays and Thursdays (10:05am - 11:20am)\n   Perkins LINK 060 (Classroom 1)\n\n\nLabs\n   Fridays (11:45pm - 1:00pm)\n   Perkins LINK 060 (Classroom 1)\n\n\nZoom meetings\nOccasionally we may need to meet over Zoom for class/lab or Office hours. The easiest way for you to join the different Zoom meetings is to log in to Sakai, go to the “Zoom meetings” tab, and click “Upcoming Meetings”. For the recordings (for lecture/lab and discussion sessions were recorded), also log in to Sakai, go to the “Zoom meetings” tab, and click “Cloud Recordings”. Those will be available few minutes after the sessions.\n\n\n\nTexts\n\n\n\n \nTitle\nAuthor(s)\nPublisher\n\n\n\n\n\nA First Course in Bayesian Statistical Methods\nPeter D. Hoff, 2009\nSpringer\n\n\n\nBayesian Data Analysis (Third Edition)\nAndrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\nChapman and Hall/CRC\n\n\n\nAll books are available available online from Duke library. See the Resources tab for additional links\n\n\nMaterials\nLecture notes and slides, and assigned readings will be posted on the course website. Homework and Lab Assignments will be posted on Github \n\n\nImportant Dates\n\n\n\n \n \n\n\n\n\nTues, Aug 29\nClasses begin\n\n\nFri, Sept 8\nDrop/Add ends\n\n\nFriday, Oct 13\nMidterm I (tentative)\n\n\nSat - Tues, Oct 14 - 17\nFall Break\n\n\nTues, Nov 20\nMidterm II (tentative)\n\n\nFriday, Dec 1\nGraduate Classes End\n\n\nDec 2 - Dec 12\nGraduate Reading Period\n\n\nSat, Dec 16\nFinal Exam (Perkins 060 2:00-5:00pm)\n\n\n\n\n\nGreen Classroom\n This course has achieved Duke’s Green Classroom Certification. The certification indicates that the faculty member teaching this course has taken significant steps to green the delivery of this course. Your faculty member has completed a checklist indicating their common practices in areas of this course that have an environmental impact, such as paper and energy consumption. Some common practices implemented by faculty to reduce the environmental impact of their course include allowing electronic submission of assignments, providing online readings and turning off lights and electronics in the classroom when they are not in use. The eco-friendly aspects of course delivery may vary by faculty, by course and throughout the semester. Learn more at https://sustainability.duke.edu/action/certification.\n\n\nAcknowledgement\nThis web page contains materials developed or adapted by Dr. Alexander Volfovsky, Dr. David B. Dunson, Dr. Rebecca Carter Steorts and Dr Michael Akande."
  },
  {
    "objectID": "hw/hw-08.html",
    "href": "hw/hw-08.html",
    "title": "Homework 8",
    "section": "",
    "text": "This assignment has three main types of problems - exercises that are starred and suggested to work as practice for the midterm, a theory problem you can delay until after the midterm, and a copmutational problem to also work on for lab after the midterm.\nPlease see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-08.html#due-1145am-nov-8",
    "href": "hw/hw-08.html#due-1145am-nov-8",
    "title": "Homework 8",
    "section": "",
    "text": "This assignment has three main types of problems - exercises that are starred and suggested to work as practice for the midterm, a theory problem you can delay until after the midterm, and a copmutational problem to also work on for lab after the midterm.\nPlease see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-08.html#getting-started-with-github-classroom",
    "href": "hw/hw-08.html#getting-started-with-github-classroom",
    "title": "Homework 8",
    "section": "Getting started with Github Classroom",
    "text": "Getting started with Github Classroom\nGo to Github classroom to accept the invitation to create a repository for this assignment at HW8 this will create a private repo in the STA702-F23 organization on Github with your github user name. Note: You may receive an email invitation to join STA702-F23 on your behalf.\nHit refresh, to see the link for the repo, and then click on it to go to the STA702-F23 organization in Github.\nFollow the instructions in the README in your repo and in the hw*.Rnw file to complete the assignment and push to GitHub. If you encounter issues with Gradescope submission, it is critical that you have pushed your final assignment to GitHub by the due date to validate timestamps."
  },
  {
    "objectID": "hw/hw-08.html#gradescope-submission",
    "href": "hw/hw-08.html#gradescope-submission",
    "title": "Homework 8",
    "section": "Gradescope Submission",
    "text": "Gradescope Submission\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github and upload the pdf to Gradescope here: https://www.gradescope.com/courses/585736/assignments\nMake sure to knit to pdf; ask the TA about knitting to pdf if you cannot figure it out. Be sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "hw/hw-08.html#grading",
    "href": "hw/hw-08.html#grading",
    "title": "Homework 8",
    "section": "Grading",
    "text": "Grading\nTotal: 20 points."
  },
  {
    "objectID": "hw/hw-02.html",
    "href": "hw/hw-02.html",
    "title": "Homework 2",
    "section": "",
    "text": "Please see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-02.html#due-1159pm-tues-sept-19",
    "href": "hw/hw-02.html#due-1159pm-tues-sept-19",
    "title": "Homework 2",
    "section": "",
    "text": "Please see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-02.html#rstudio",
    "href": "hw/hw-02.html#rstudio",
    "title": "Homework 2",
    "section": "RStudio",
    "text": "RStudio\nYou all should have R and RStudio installed on your computers by now or access to the Department Server. If you do not, first install the latest version of R here: https://cran.rstudio.com (remember to select the right installer for your operating system). Next, install the latest version of RStudio here: https://www.rstudio.com/products/rstudio/download/. Scroll down to the “Installers for Supported Platforms” section and find the right installer for your operating system."
  },
  {
    "objectID": "hw/hw-02.html#r-knitr",
    "href": "hw/hw-02.html#r-knitr",
    "title": "Homework 2",
    "section": "R Knitr",
    "text": "R Knitr\nYou are required to use R knitr with the .Rnw format to type up this lab report. To get started see basics about knitr."
  },
  {
    "objectID": "hw/hw-02.html#getting-started-with-github-classroom",
    "href": "hw/hw-02.html#getting-started-with-github-classroom",
    "title": "Homework 2",
    "section": "Getting started with Github Classroom",
    "text": "Getting started with Github Classroom\nGo to Github classroom to accept the invitation to create a repository for this assignment at HW2\nThis will create a private repo in the STA702-F23 organization on Github with your github user name. Note: You may receive an email invitation to join STA702-F23 on your behalf.\nHit refresh, to see the link for the repo, and then click on it to go to the STA702-F23 organization in Github.\nFollow the instructions in the README in your repo and in the hw*.Rnw file to complete the assignment and push to GitHub. If you encounter issues with Gradescope submission, it is critical that you have pushed your final assignment to GitHub by the due date to validate timestamps."
  },
  {
    "objectID": "hw/hw-02.html#gradescope-submission",
    "href": "hw/hw-02.html#gradescope-submission",
    "title": "Homework 2",
    "section": "Gradescope Submission",
    "text": "Gradescope Submission\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github and upload the pdf to Gradescope here: https://www.gradescope.com/courses/585736/assignments\nMake sure to knit to pdf; ask the TA about knitting to pdf if you cannot figure it out. Be sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "hw/hw-02.html#grading",
    "href": "hw/hw-02.html#grading",
    "title": "Homework 2",
    "section": "Grading",
    "text": "Grading\nTotal: 20 points."
  },
  {
    "objectID": "hw/hw-06.html",
    "href": "hw/hw-06.html",
    "title": "Homework 6",
    "section": "",
    "text": "This assignment has three main types of problems - exercises that are starred and suggested to work as practice for the midterm, a theory problem you can delay until after the midterm, and a copmutational problem to also work on for lab after the midterm.\nPlease see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-06.html#due-1159pm-oct-24-note-this-is-after-the-midterm",
    "href": "hw/hw-06.html#due-1159pm-oct-24-note-this-is-after-the-midterm",
    "title": "Homework 6",
    "section": "",
    "text": "This assignment has three main types of problems - exercises that are starred and suggested to work as practice for the midterm, a theory problem you can delay until after the midterm, and a copmutational problem to also work on for lab after the midterm.\nPlease see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-06.html#getting-started-with-github-classroom",
    "href": "hw/hw-06.html#getting-started-with-github-classroom",
    "title": "Homework 6",
    "section": "Getting started with Github Classroom",
    "text": "Getting started with Github Classroom\nGo to Github classroom to accept the invitation to create a repository for this assignment at HW6 this will create a private repo in the STA702-F23 organization on Github with your github user name. Note: You may receive an email invitation to join STA702-F23 on your behalf.\nHit refresh, to see the link for the repo, and then click on it to go to the STA702-F23 organization in Github.\nFollow the instructions in the README in your repo and in the hw*.Rnw file to complete the assignment and push to GitHub. If you encounter issues with Gradescope submission, it is critical that you have pushed your final assignment to GitHub by the due date to validate timestamps."
  },
  {
    "objectID": "hw/hw-06.html#gradescope-submission",
    "href": "hw/hw-06.html#gradescope-submission",
    "title": "Homework 6",
    "section": "Gradescope Submission",
    "text": "Gradescope Submission\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github and upload the pdf to Gradescope here: https://www.gradescope.com/courses/585736/assignments\nMake sure to knit to pdf; ask the TA about knitting to pdf if you cannot figure it out. Be sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "hw/hw-06.html#grading",
    "href": "hw/hw-06.html#grading",
    "title": "Homework 6",
    "section": "Grading",
    "text": "Grading\nTotal: 20 points."
  },
  {
    "objectID": "hw/hw-07.html",
    "href": "hw/hw-07.html",
    "title": "Homework 7",
    "section": "",
    "text": "This assignment has three main types of problems - exercises that are starred and suggested to work as practice for the midterm, a theory problem you can delay until after the midterm, and a copmutational problem to also work on for lab after the midterm.\nPlease see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-07.html#due-1145am-nov-1",
    "href": "hw/hw-07.html#due-1145am-nov-1",
    "title": "Homework 7",
    "section": "",
    "text": "This assignment has three main types of problems - exercises that are starred and suggested to work as practice for the midterm, a theory problem you can delay until after the midterm, and a copmutational problem to also work on for lab after the midterm.\nPlease see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-07.html#getting-started-with-github-classroom",
    "href": "hw/hw-07.html#getting-started-with-github-classroom",
    "title": "Homework 7",
    "section": "Getting started with Github Classroom",
    "text": "Getting started with Github Classroom\nGo to Github classroom to accept the invitation to create a repository for this assignment at HW7 this will create a private repo in the STA702-F23 organization on Github with your github user name. Note: You may receive an email invitation to join STA702-F23 on your behalf.\nHit refresh, to see the link for the repo, and then click on it to go to the STA702-F23 organization in Github.\nFollow the instructions in the README in your repo and in the hw*.Rnw file to complete the assignment and push to GitHub. If you encounter issues with Gradescope submission, it is critical that you have pushed your final assignment to GitHub by the due date to validate timestamps."
  },
  {
    "objectID": "hw/hw-07.html#gradescope-submission",
    "href": "hw/hw-07.html#gradescope-submission",
    "title": "Homework 7",
    "section": "Gradescope Submission",
    "text": "Gradescope Submission\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github and upload the pdf to Gradescope here: https://www.gradescope.com/courses/585736/assignments\nMake sure to knit to pdf; ask the TA about knitting to pdf if you cannot figure it out. Be sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "hw/hw-07.html#grading",
    "href": "hw/hw-07.html#grading",
    "title": "Homework 7",
    "section": "Grading",
    "text": "Grading\nTotal: 20 points."
  },
  {
    "objectID": "hw/hw-09.html",
    "href": "hw/hw-09.html",
    "title": "Homework 9",
    "section": "",
    "text": "This assignment has three main types of problems - exercises that are starred and suggested to work as practice for the midterm, a theory problem you can delay until after the midterm, and a copmutational problem to also work on for lab after the midterm.\nPlease see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-09.html#due-130pm-nov-17",
    "href": "hw/hw-09.html#due-130pm-nov-17",
    "title": "Homework 9",
    "section": "",
    "text": "This assignment has three main types of problems - exercises that are starred and suggested to work as practice for the midterm, a theory problem you can delay until after the midterm, and a copmutational problem to also work on for lab after the midterm.\nPlease see Gradescope for any updates on due dates."
  },
  {
    "objectID": "hw/hw-09.html#getting-started-with-github-classroom",
    "href": "hw/hw-09.html#getting-started-with-github-classroom",
    "title": "Homework 9",
    "section": "Getting started with Github Classroom",
    "text": "Getting started with Github Classroom\nGo to Github classroom to accept the invitation to create a repository for this assignment at HW9 this will create a private repo in the STA702-F23 organization on Github with your github user name. Note: You may receive an email invitation to join STA702-F23 on your behalf.\nHit refresh, to see the link for the repo, and then click on it to go to the STA702-F23 organization in Github.\nFollow the instructions in the README in your repo and in the hw*.Rnw file to complete the assignment and push to GitHub. If you encounter issues with Gradescope submission, it is critical that you have pushed your final assignment to GitHub by the due date to validate timestamps."
  },
  {
    "objectID": "hw/hw-09.html#gradescope-submission",
    "href": "hw/hw-09.html#gradescope-submission",
    "title": "Homework 9",
    "section": "Gradescope Submission",
    "text": "Gradescope Submission\nYou MUST submit both your final .Rnw and .pdf files to the repo on Github and upload the pdf to Gradescope here: https://www.gradescope.com/courses/585736/assignments\nMake sure to knit to pdf; ask the TA about knitting to pdf if you cannot figure it out. Be sure to submit under the right assignment entry by the due date!"
  },
  {
    "objectID": "hw/hw-09.html#grading",
    "href": "hw/hw-09.html#grading",
    "title": "Homework 9",
    "section": "Grading",
    "text": "Grading\nTotal: 20 points."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": " Syllabus",
    "section": "",
    "text": "When in doubt about anything at all, ask questions!!!\n\nPrerequisites\nALL students are expected to be familiar with all the topics covered within the required prerequisites to be in this course. That is - mathematical statistics and probability, linear algebra, and multivariate calculus. Students are also expected to be familiar with R and are encouraged to learn LaTeX during the course.\n\n\nWorkload\nWork hours will include time spent going through the preassigned readings, attending lectures and lab sessions, and doing all graded work.\n\n\nGraded Work\nGraded work for the course will consist of homework assignments, lab exercises, two midterms and a final exam. Regrade requests for problem sets and lab exercises must be done via Gradescope AT MOST 24 hours after grades are released! Regrade requests for quizzes, midterm, and final exams must be done via Gradescope AT MOST 12 hours after grades are released! Always write in complete sentences and show your steps.\nStudents’ final grades will be determined as shown below:\n\nComponent Percentage\n\n\nComponent\nPercentage\n\n\n\n\nHomework\n20%\n\n\nMidterm\n20%\n\n\nMidterm II\n20%\n\n\nLab exercises\n10%\n\n\nParticipation\n5%\n\n\nFinal Exam\n25%\n\n\n\nThere are no make-ups for any of the graded work except for medical or familial emergencies or for reasons approved by the instructor BEFORE the due date. See the instructor in advance of relevant due dates to discuss possible alternatives.\nGrades may be curved at the end of the semester. Cumulative averages of 90% – 100% are guaranteed at least an A-, 80% – 89% at least a B-, and 70% – 79% at least a C-, however the exact ranges for letter grades will be determined at the end of the course.\n\n\nDescriptions of graded work\n\nProblem sets\nHomework will be handed out on a weekly basis. They will be based on both the lectures and labs and will be announced every Thursday or Friday – be sure to check the website regularly! Also, please note that any work that is not legible by the instructor or TAs will not be graded (given a score of 0). Every write-up must be clearly written in full sentences and clear English. Any assignment that is completely unclear to the instructors and/or TAs, may result in a grade of a 0. For programming exercises, we will be using R/knitr with \\(\\LaTeX\\) for preparing assignments using github classroom for data analysis.\nEach student MUST write up and turn in her or his own answers. You are encouraged to talk to each other regarding homework problems or to the instructor/TA. However, the write-up, solution, and code must be entirely your own work. No sharing of solutions or code! The assignments must be submitted on Gradescope under Assignments. Note that you will not be able to make online submissions after the due date, so be sure to submit before or by the Gradescope-specified deadline. You may resubmit, so when in doubt submit work early. In certain situations if there are issues with submissions, the TA may review your GitHub repository prior to the due date.\nSolutions will be curated from student solutions with proper attribution. Every week the TAs will select a representative correct solution for the assigned problems and put them together into one solutions set with each answer being attributed to the student who wrote it. If you would like to OPT OUT of having your homework solutions used for the class solutions, please let the Instructor and TAs know in advance.\nFinally, your lowest homework score will be dropped!\n\n\nLab exercises\nThe objective of the lab assignments is to give you more hands-on experience with Bayesian data analysis. Attend the lab session and learn a concept or two and some R from the TA, and then work on the computational part of the problem sets. Each lab assignment should be submitted in timely fashion. You are REQUIRED to use R/knitr (or R/Rmarkdown in some cases).\n\n\nMidterm Exams\nThere will be two inclass midterm exams. Detailed instructions on the midterm will be made available later but please check dates on the calendar well in advance!\n\n\nFinal Exam\nThere will be a final exam after the reading week. If you miss any quiz or the midterm, your grade will depend more on the final exam score since there are no make-up exams. You cannot miss the final exam! Please check the important dates on the homepage for the date and time of the final before making plans to return home at the end of the semester. Detailed instructions on the final will be made available later.\n\n\n\nLate Submission Policy\n\nno late submission of homework or lab assignments, however we will drop the lowest score in each.\n\n\n\nCourse Topics\n\nBasics of Bayesian Models\nLoss Functions, Inference and Decision Making\nPredictive Distributions\nPredictive Distributions and Model Checking\nBayesian Hypothesis Testing\nMultiple Testing\nMCMC (Gibbs & Metropolis Hastings Algorithms)\nBayesian Generalized Linear Models\nHiearchical Modeling and Random Effects\nHamiltonian Monte Carlo\nNonParametric Bayes\n\nFor a detailed day-by-day list of topics, please refer to the Course Schedule\n\n\nAcademic integrity\nDuke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, respect, and accountability. Citizens of this community commit to reflect upon and uphold these principles in all academic and nonacademic endeavors, and to protect and promote a culture of integrity.\nRemember the Duke Community Standard that you have agreed to abide by:\n\nTo uphold the Duke Community Standard:\n\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\nCheating or plagiarism on any graded assessments, lying about an illness or absence and other forms of academic dishonesty are a breach of trust with classmates and faculty, violate the Duke Community Standard, and will not be tolerated. Such incidences will result in a 0 grade for all parties involved. Additionally, there may be penalties to your final class grade along with being reported to the Office of Student Conduct. Review the academic dishonesty policies at https://studentaffairs.duke.edu/conduct/z-policies/academic-dishonesty.\n\n\nDiversity & Inclusiveness\nThis course is designed so that students from all backgrounds and perspectives all feel welcome both in and out of class. Please feel free to talk to me (in person or via email) if you do not feel well-served by any aspect of this class, or if some aspect of class is not welcoming or accessible to you. My goal is for you to succeed in this course, therefore, let me know immediately if you feel you are struggling with any part of the course more than you know how to manage. Doing so will not affect your grades, but it will allow me to provide the resources to help you succeed in the course.\n\n\nDisability Statement\nStudents with disabilities who believe that they may need accommodations in the class are encouraged to contact the Student Disabilities Access Office at 919-668-1267 or disabilities@aas.duke.edu as soon as possible to better ensure that such accommodations are implemented in a timely fashion.\n\n\nOther Information\nIt can be a lot more pleasant oftentimes to get one-on-one answers and help. Make use of the teaching team’s office hours, we’re here to help! Do not hesitate to talk to me during office hours or by appointment to discuss a problem set or any aspect of the course. Questions related to course assignments and honesty policy should be directed to me. When the teaching team has announcements for you we will send an email to your Duke email address. Be sure to check your email daily.\nMost of the course components will be held in person, but occasionally may need to be held online using Zoom meetings. If you have any concerns, issues or challenges, let the instructor know as soon as possible. Also, all students are strongly encouraged to rely on the forums in Sakai, for interacting among yourself and asking other students questions. You can also ask the instructor or the TAs questions on there and we will try to respond as soon as possible. If you experience any technical issues with joining or using the forums, let the instructor know.\n\n\nProfessionalism\nTry as much as possible to refrain from texting or using your computer for anything other than coursework during class and labs. Again, the more engaged you are, the quicker you will be able to get through the materials. You are responsible for everything covered in the lecture videos, lecture notes/slides, and in the assigned readings."
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#last-time",
    "href": "resources/slides/02-loss-functions.html#last-time",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Last Time …",
    "text": "Last Time …\n\nIntroduction to “ingredients” of Bayesian analysis\nIllustrated a simple Beta-Binomial conjugate example\nPosterior \\(\\pi(\\theta \\mid y)\\) is a \\(\\textsf{Beta}(a + y, b + n - y )\\)\n\n\nToday …\n\nan introduction to loss functions\nBayes Risk\noptimal decisions and estimators"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#bayes-estimate",
    "href": "resources/slides/02-loss-functions.html#bayes-estimate",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Bayes estimate",
    "text": "Bayes estimate\n\nAs we’ve seen by now, having posterior distributions instead of one-number summaries is great for capturing uncertainty.\nThat said, it is still very appealing to have simple summaries, especially when dealing with clients or collaborators from other fields, who desire one.\n\nWhat if we want to produce a single “best” estimate of \\(\\theta\\)?\nWhat if we want to produce an interval estimate \\((\\theta_L, \\theta_U )\\)?\n\n\n\nThese would provide alternatives to the frequentist MLEs and confidence intervals"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#heuristically",
    "href": "resources/slides/02-loss-functions.html#heuristically",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Heuristically",
    "text": "Heuristically\n\n\n\n\n\n\n\n\n\n“best” estimate of \\(\\theta\\) is the maximum a posteriori estimate (MAP) or posterior mode\n\nwhat do we really mean by “best”?\n\nfind an interval such that \\(P(\\theta \\in ( \\theta_L, \\theta_U ) \\mid y) = 1- \\alpha\\)\n\nlots of intervals that satisfy this! which one is “best”?"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#loss-functions-for-estimators",
    "href": "resources/slides/02-loss-functions.html#loss-functions-for-estimators",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Loss Functions for Estimators",
    "text": "Loss Functions for Estimators\nIntroduce loss functions for decision making about what to report!\n\na loss function provides a summary for how bad an estimator \\(\\hat{\\theta}\\) is relative to the “true” value of \\(\\theta\\)\nSquared error loss \\((L2)\\)\n\\[l(\\theta, \\hat{\\theta}) = (\\hat{\\theta} - \\theta)^2\\]\nAbsolute error loss \\((L1)\\) \\[l(\\theta, \\hat{\\theta}) = |\\hat{\\theta} - \\theta|\\]\n\n\nBut how do we deal with the fact that we do not know \\(\\theta\\)?"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#bayes-risk",
    "href": "resources/slides/02-loss-functions.html#bayes-risk",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Bayes Risk",
    "text": "Bayes Risk\n\nBayes risk is defined as the expected loss of using \\(\\hat{\\theta}\\) averaging over the posterior distribution. \\[ R(\\hat{\\theta}) = \\textsf{E}_{\\pi(\\theta \\mid y)} [l(\\theta, \\hat{\\theta}) ]\\]\nthe Bayes optimal estimate \\(\\hat{\\theta}\\) is the estimator that has the lowest posterior expected loss or Bayes Risk\nDepends on choice of loss function\nFrequentist risk also exists for evaluating a given estimator under true value of \\(\\theta\\) \\[\\textsf{E}_{p(y \\mid \\theta_{\\textrm{true}})} [l(\\theta_{\\textrm{true}} , \\hat{\\theta}) )]\\]"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#squared-error-loss",
    "href": "resources/slides/02-loss-functions.html#squared-error-loss",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Squared Error Loss",
    "text": "Squared Error Loss\nA common choice for point estimation is squared error loss:\n\\[R(\\hat{\\theta}) = \\textsf{E}_{\\pi(\\theta \\mid y)} [l(\\theta, \\hat{\\theta}) ] = \\int_\\Theta (\\hat{\\theta} - \\theta)^2 \\pi(\\theta \\mid y) \\, d\\theta\\]\n\n\n\n\n\n\n\nLet’s work it out!\n\n\nExpand, take expectations of \\(R(\\hat{\\theta})\\) with respect to \\(\\theta\\) and factor as a quadratic to find the minimizer (or take derivatives)"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#steps",
    "href": "resources/slides/02-loss-functions.html#steps",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Steps",
    "text": "Steps\n\\[R(\\hat{\\theta}) = \\int_\\Theta (\\hat{\\theta}^2 - 2 \\hat{\\theta} \\theta + \\theta^2) \\pi(\\theta \\mid y) \\, d \\theta\\]\n\n\\[R(\\hat{\\theta}) = \\hat{\\theta}^2 - 2 \\hat{\\theta} \\int_\\Theta \\theta \\pi(\\theta \\mid y) \\, d\\theta +  \\int_\\Theta \\theta^2  \\pi(\\theta \\mid y) \\, d\\theta\\]\n\n\n\\[R(\\hat{\\theta}) = \\hat{\\theta}^2 - 2 \\hat{\\theta} \\textsf{E}[\\theta \\mid y] + \\textsf{E}[\\theta^2 \\mid y]\\]\n\n\n\\[R(\\hat{\\theta}) = \\hat{\\theta}^2 - 2 \\hat{\\theta} \\textsf{E}[\\theta \\mid y] +  \\textsf{E}[\\theta \\mid y]^2 - \\textsf{E}[\\theta \\mid y]^2 +  \\textsf{E}[\\theta^2 \\mid y]\\]\n\n\nQuadratic in \\(\\hat{\\theta}\\) minimized when \\(\\hat{\\theta} = \\textsf{E}[\\theta \\mid y]\\)\n\\(\\Rightarrow\\) posterior mean is the Bayes optimal estimator for \\(\\theta\\) under squared error loss\n\nIn the beta-binomial case for example, the optimal Bayes estimate under squared error loss is \\(\\hat{\\theta} = \\frac{a+y}{a+b+n}\\)"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#what-about-other-loss-functions",
    "href": "resources/slides/02-loss-functions.html#what-about-other-loss-functions",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "What about other loss functions?",
    "text": "What about other loss functions?\n\nClearly, squared error is only one possible loss function. An alternative is absolute loss, which has \\[l(\\theta, \\hat{\\theta})  = |\\theta - \\hat{\\theta}|\\]\nAbsolute loss places less of a penalty on large deviations & the resulting Bayes estimate is the posterior median.\nMedian is actually relatively easy to estimate.\nRecall that for a continuous random variable \\(Y\\) with cdf \\(F\\), the median of the distribution is the value \\(z\\), which satisfies \\[F(z) = \\Pr(Y\\leq z) = \\dfrac{1}{2}= \\Pr(Y\\geq z) = 1-F(z)\\]\nAs long as we know how to evaluate the CDF of the distribution we have, we can solve for \\(z\\)."
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#beta-binomial",
    "href": "resources/slides/02-loss-functions.html#beta-binomial",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Beta-Binomial",
    "text": "Beta-Binomial\n\nFor the beta-binomial model, the CDF of the beta posterior can be written as \\[F(z) = \\Pr(\\theta\\leq z | y) = \\int^z_0 \\textrm{Beta}(\\theta| a+y, b+n-y) d\\theta.\\]\nThen, if \\(\\hat{\\theta}\\) is the median, we have that \\(F(\\hat{\\theta}) = 0.5\\)\nTo solve for \\(\\hat{\\theta}\\), apply the inverse CDF \\[\\hat{\\theta} = F^{-1}(0.5)\\]\nIn R, that’s simply\n\n\n\nqbeta(0.5,a+y,b+n-y)\n\n\nFor other distributions, switch out the beta."
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#loss-functions-in-general",
    "href": "resources/slides/02-loss-functions.html#loss-functions-in-general",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Loss Functions in General",
    "text": "Loss Functions in General\n\nA loss function \\(l(\\theta, \\delta(y) )\\) is a function of the parameter \\(\\theta\\) and \\(\\delta(y)\\) based on just the data \\(y\\)\nFor example, \\(\\delta(y) = \\bar{y}\\) can be the decision to use the sample mean to estimate \\(\\theta\\), the true population mean.\n\\(l(\\theta, \\delta(y) )\\) determines the penalty for making the decision \\(\\delta(y)\\), if \\(\\theta\\) is the true parameter or state of nature; the loss function characterizes the price paid for errors.\nBayes optimal estimator or action is the estimator/action that minimizes the expected posterior loss marginalizing out any unknowns over posterior/predictive distribution."
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#map-estimator",
    "href": "resources/slides/02-loss-functions.html#map-estimator",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "MAP Estimator",
    "text": "MAP Estimator\n\nWhat about the MAP estimator? Is it an optimal Bayes estimator & under what choice of loss function?\n\\(L_\\infty\\) loss: \\[R_{\\infty}(\\hat{\\theta}) = \\lim_{p \\to \\infty} \\int_\\Theta (\\theta - \\hat{\\theta})^p \\pi(\\theta \\mid y) \\, d \\theta\\]\nEssentially saying that we need the estimator to be right on the truth or the error blows up!\nIs this a reasonable loss function?"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#interval-estimates",
    "href": "resources/slides/02-loss-functions.html#interval-estimates",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Interval Estimates",
    "text": "Interval Estimates\nRecall that a frequentist confidence interval \\([l(y), \\ u(y)]\\) has 95% frequentist coverage for a population parameter \\(\\theta\\) if, before we collect the data, \\[\\Pr[l(y) &lt; \\theta &lt; u(y) | \\theta] = 0.95.\\]\n\nThis means that 95% of the time, our constructed interval will cover the true parameter, and 5% of the time it won’t.\nThere is NOT a 95% chance your interval covers the true parameter once you have collected the data.\nIn any given sample, you don’t know whether you’re in the lucky 95% or the unlucky 5%. You just know that either the interval covers the parameter, or it doesn’t (useful, but not too helpful clearly).\nOften based on aysmptotics i.e use a Wald or other type of frequentist asymptotic interval \\(\\hat{\\theta} \\pm 1.96 \\,\\text{se}(\\hat{\\theta})\\)"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#bayesian-intervals",
    "href": "resources/slides/02-loss-functions.html#bayesian-intervals",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Bayesian Intervals",
    "text": "Bayesian Intervals\n\nWe want a Bayesian alternative to confidence intervals for some pre-specified value of \\(\\alpha\\)\nAn interval \\([l(y), \\ u(y)]\\) has \\(1 - \\alpha\\) 100% Bayesian coverage for \\(\\theta\\) if \\[\\Pr(\\theta \\in [l(y), \\ u(y)] \\mid y) = 1 - \\alpha\\]\nThis describes our information about where \\(\\theta\\) lies after we observe the data.\nFantastic! This is actually the interpretation people want to give to the frequentist confidence interval.\nBayesian interval estimates are often generally called credible intervals or credible sets.\n\n\nHow to choose \\([l(y), \\ u(y)]\\)?"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#bayesian-equal-tail-interval",
    "href": "resources/slides/02-loss-functions.html#bayesian-equal-tail-interval",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Bayesian Equal Tail Interval",
    "text": "Bayesian Equal Tail Interval\n\nThe easiest way to obtain a Bayesian interval estimate is to use posterior quantiles with equal tail areas. Often when researchers refer to a credible interval, this is what they mean.\nTo make a \\(100 \\times (1-\\alpha)%\\) equi-tail quantile-based credible interval, find numbers (quantiles) \\(\\theta_{\\alpha/2} &lt; \\theta_{1-\\alpha/2}\\) such that\n\n\\(\\Pr(\\theta &lt; \\theta_{\\alpha/2} \\mid y) = \\dfrac{\\alpha}{2}\\); and\n\\(\\Pr(\\theta &gt; \\theta_{1-\\alpha/2} \\mid y) = \\dfrac{\\alpha}{2}\\).\n\n\n\nConvenient conceptually and easy as we just take the \\(\\alpha/2\\) and \\(1 - \\alpha/2\\) quantiles of \\(\\pi(\\theta \\mid y)\\) as \\(l(y)\\) and \\(u(y)\\), respectively."
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#beta-binomial-equal-tailed-interval",
    "href": "resources/slides/02-loss-functions.html#beta-binomial-equal-tailed-interval",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Beta-Binomial Equal-tailed Interval",
    "text": "Beta-Binomial Equal-tailed Interval\n\n95% Equal -Tail Area interval is \\((0.02, 0.41)\\)"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#monte-carlo-version",
    "href": "resources/slides/02-loss-functions.html#monte-carlo-version",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Monte Carlo Version",
    "text": "Monte Carlo Version\n\nSuppose we don’t have \\(\\pi(\\theta \\mid y)\\) is a simple form, but we do have samples \\(\\theta_1, \\ldots, \\theta_T\\) from \\(\\pi(\\theta \\mid y)\\)\nWe can use these samples to obtain Monte Carlo (MC) estimates of posterior summaries \\[\\hat{\\theta} = \\textsf{E}[\\theta \\mid y] \\approx \\frac{1}{T} \\sum_{t= 1}^T \\theta_t\\]\nwhat about MC quantile estimates?\nFind the 2.5th and 97.5th percentile from the empirical distribution\n\n\n\ntheta = rbeta(1000, a + y, b + n - y)\nquantile(theta, c(0.025, 0.975))\n\n      2.5%      97.5% \n0.02141993 0.39572970"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#equal-tail-interval",
    "href": "resources/slides/02-loss-functions.html#equal-tail-interval",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Equal-Tail Interval",
    "text": "Equal-Tail Interval\n\nNote there are values of \\(\\theta\\) outside the quantile-based credible interval, with higher density than some values inside the interval."
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#hpd-region",
    "href": "resources/slides/02-loss-functions.html#hpd-region",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "HPD Region",
    "text": "HPD Region\n\nA \\(100 \\times (1-\\alpha)%\\) highest posterior density (HPD) region is a subset \\(s(y)\\) of the parameter space \\(\\Theta\\) such that\n\n\\(\\Pr(\\theta \\in s(y) \\mid y) = 1-\\alpha\\); and\nIf \\(\\theta_a \\in s(y)\\) and \\(\\theta_b \\notin s(y)\\), then \\(p(\\theta_a \\mid y) &gt; p(\\theta_b \\mid y)\\) (highest density set)\n\n\\(\\Rightarrow\\) All points in a HPD region have higher posterior density than points outside the region.\nThe basic idea is to gradually move a horizontal line down across the density, including in the HPD region all values of \\(\\theta\\) with a density above the horizontal line.\nStop moving the line down when the posterior probability of the values of \\(\\theta\\) in the region reaches \\(1-\\alpha\\)."
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#simulation-based-using-the-coda-package",
    "href": "resources/slides/02-loss-functions.html#simulation-based-using-the-coda-package",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Simulation Based using the coda Package",
    "text": "Simulation Based using the coda Package\n\n\n\n\n\n\n\n\n \n \n\nlibrary(coda)\nHPDinterval(as.mcmc(theta))\n\n           lower     upper\nvar1 0.005930904 0.3669906\nattr(,\"Probability\")\n[1] 0.95"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#properties-of-hpd-sets",
    "href": "resources/slides/02-loss-functions.html#properties-of-hpd-sets",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Properties of HPD Sets",
    "text": "Properties of HPD Sets\n\nShortest length interval (or volume) for the given coverage\nEquivalent to Equal-Tail Intervals if the posterior is unimodal and symmetric\nMay not be an interval if the posterior distribution is multi-modal\nIn general, not invariant under monotonic transformations of \\(\\theta\\). (Why?)\nMore computationally intensive to solve exactly!\n\n\n\n\n\n\n\n\nSee “The Bayesian Choice” by Christian Robert Section 5.5.5 for more info on Loss Functions for Interval Estimation"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#connections-between-bayes-and-mle-based-frequentist-inference",
    "href": "resources/slides/02-loss-functions.html#connections-between-bayes-and-mle-based-frequentist-inference",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Connections between Bayes and MLE Based Frequentist Inference",
    "text": "Connections between Bayes and MLE Based Frequentist Inference\nBerstein von Mises (BvM) Theorems) aka Bayesian Central Limit Theorems\n\nexamine limiting form of the posterior distribution \\(\\pi(\\theta \\mid y)\\) as \\(n \\to \\infty\\)\n\\(\\pi(\\theta \\mid y)\\) goes to a Gaussian under regularity conditions\n\ncentered at the MLE\nvariance given by the inverse of the Expected Fisher Information (var of MLE)\n\nThe most important implication of the BvM is that Bayesian inference is asymptotically correct from a frequentist point of view\nUsed to justify Normal Approximations to the posterior distribution (eg Laplace approximations)"
  },
  {
    "objectID": "resources/slides/02-loss-functions.html#model-misspecification",
    "href": "resources/slides/02-loss-functions.html#model-misspecification",
    "title": "Loss Functions, Bayes Risk and Posterior Summaries",
    "section": "Model Misspecification ?",
    "text": "Model Misspecification ?\n\nWe might have chosen a bad sampling model/likelihood\nposterior still converges to a Gaussian centered at the MLE under the misspecified model, but wrong variance\n95% Bayesian credible sets do not have correct frequentist coverage\nSee Klein & van der Vaart for more rigorous treatment if interested\nparametric model is “close” to the true data-generating process\nmodel diagnostics & changing the model can reduce the gap between model we are using and the true data generating process\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#building-hierarchical-models",
    "href": "resources/slides/19-random-effects.html#building-hierarchical-models",
    "title": "Lecture 19: Random Effects",
    "section": "Building Hierarchical Models",
    "text": "Building Hierarchical Models\n\nModels for Gaussian Data with no Covariates \\[ y_{ij} \\sim \\, ? \\qquad i = 1, \\ldots n_j; j = 1, \\ldots, J\\]\n\\(j\\) blocking variable - schools, counties, etc (categorical)\n\\(i\\) observations within a block - students within schools, households within counties, etc\npotentially there may be within block dependence in the observations due to unmeasured covariates\nstructure?"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#models",
    "href": "resources/slides/19-random-effects.html#models",
    "title": "Lecture 19: Random Effects",
    "section": "Models",
    "text": "Models\n\nNaive model (baseline) \\[ y_{ij} \\overset{iid}{\\sim}  N(\\mu, \\sigma^2) \\]\nissue: no systematic variation across blocks\nFixed Effects model: \\[  y_{ij} \\overset{ind}{\\sim}  N(\\mu_j, \\sigma^2) \\]\nCommon reparameterization \\[  y_{ij} \\overset{ind}{\\sim}  N(\\alpha + \\beta_j, \\sigma^2) \\]\n\\(\\mu\\) intercept\n\\(\\beta_j\\) shift for school\nIdentifiability ?"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#non-identifiability",
    "href": "resources/slides/19-random-effects.html#non-identifiability",
    "title": "Lecture 19: Random Effects",
    "section": "Non-Identifiability",
    "text": "Non-Identifiability\n\nExample: \\(y_{ij} \\sim N(\\alpha + \\beta_j, \\sigma^2)\\) overparameterized\n\\(\\mu_j = \\alpha + \\beta_j\\) and \\(\\sigma^2\\) are uniquely estimated, but not \\(\\alpha\\) or \\(\\beta_j\\)\n\\(x_{ij} \\in \\{1, \\ldots, J \\}\\) factor levels \\[y_{ij} \\sim N(\\alpha+ \\sum_{j^\\prime}\\beta_j 1(x_{ij^{\\prime}} = j), \\sigma^2)\\]\n\\(\\mu_j = \\alpha + \\beta_j\\) identifiable - \\(J\\) equations but \\(J + 1\\) unknowns\nPut constraints on parameters\n\n\\(\\alpha = 0\\)\n\\(\\beta_J = 0\\)\n\\(\\sum \\beta_j = 0\\)"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#bayesian-notion-of-identifiability",
    "href": "resources/slides/19-random-effects.html#bayesian-notion-of-identifiability",
    "title": "Lecture 19: Random Effects",
    "section": "Bayesian Notion of Identifiability",
    "text": "Bayesian Notion of Identifiability\n\nBayesian Learning\nmodel is likelihood and prior\nthe posterior distribution differs from the prior\n\n\n\n\n\n\n\n\nNote:\n\n\n\nPriors may lead to posteriors where parameters are identifiable even if not under likelihood\nForcing identifiability may involve (complex) constraints that bias parameter estimates \\[\n\\begin{align}\n\\alpha  & \\sim \\textsf{N}(0, \\sigma^2_\\alpha) \\\\\n\\beta_j & \\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}\\textsf{N}(0, \\sigma^2_\\beta)  \\text{ for } j = 1, \\ldots, J-1 \\\\\n\\mu_J & \\sim  \\textsf{N}(0, \\sigma^2_\\alpha) \\\\\n\\mu_j &\\ iid \\textsf{N}(0, \\sigma^2_\\alpha + \\sigma^2_\\beta)  \\text{ for } j = 1, \\ldots, J-1\n\\end{align}\n\\]\nsometimes purposely introduce non-identifiability to improve computation (parameter expansion PX)\nrun non-identifiable model and focus on identifiable parameters or functions of them"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#issue-with-fixed-effect-approach",
    "href": "resources/slides/19-random-effects.html#issue-with-fixed-effect-approach",
    "title": "Lecture 19: Random Effects",
    "section": "Issue with Fixed Effect Approach",
    "text": "Issue with Fixed Effect Approach\n\nWhat if \\(n_i\\), number of observations per block, are small?\nEstimated uncertainty/variances are large based on MLE using group specific means\nWhat if blocks might be viewed as a sample from some larger population? Sample of schools?\nMay want inference about the larger population and say things about future blocks (schools) !\nfixed effects do not allow us to say anything about blocks not in our sample!\nhow to address this?"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#random-effects",
    "href": "resources/slides/19-random-effects.html#random-effects",
    "title": "Lecture 19: Random Effects",
    "section": "Random Effects",
    "text": "Random Effects\n\\[\\begin{align*}\ny_{ij} & = \\alpha + \\beta_i + \\epsilon_{ij}, \\qquad \\epsilon_{ij} \\overset{iid}{\\sim} N(0, \\sigma^2) \\\\\n\\beta_i & \\overset{iid}{\\sim} N(0, \\tau^2)\n\\end{align*}\\]\n\nrandom effects \\(\\beta_j\\)\n\n\n\n\n\n\n\n\nNote: Don’t confuse random effect distributions with prior distributions!\n\n\n\n\n\n\n\nRandom effect distributions should be viewed as part of the model specification\nWe’ve specified the likelihood in a hierarchical manner to induce desirable structure\nunknown parameters are population parameters \\(\\alpha\\), \\(\\tau\\) and \\(\\sigma^2\\)\nBayesians put prior distributions on \\(\\alpha\\), \\(\\tau\\) and \\(\\sigma^2\\); frequentists don’t!"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#equivalent-model",
    "href": "resources/slides/19-random-effects.html#equivalent-model",
    "title": "Lecture 19: Random Effects",
    "section": "Equivalent Model",
    "text": "Equivalent Model\n\\[y_{j} = (y_{1j}, y_{2j}, \\ldots, y_{n_j j})\\] \\[y_j  \\mid  \\alpha, \\sigma^2, \\tau^2 \\mathrel{\\mathop{\\sim}\\limits^{\\rm ind}}N_{n_j}\\left( \\mathbf{1}_{n_j} \\alpha, \\left(\n\\begin{array}{cccc}\n\\sigma^2 + \\tau^2 & \\tau^2 & \\ldots & \\tau^2 \\\\\n\\tau^2 & \\ddots &    & \\tau^2  \\\\\n\\vdots & & \\ddots & \\vdots \\\\\n\\tau^2 & \\ldots & \\tau^2 & \\sigma^2 + \\tau^2 \\end{array}\\right) \\right)\\]\n\nwithin-block correlation constant\nalgorithmically we can use either the latent variable model or the collapsed (marginal) model for inferences;\noften latent variable is easier to work with for Bayes!\nMLEs of \\(\\tau\\) on boundary in some cases!"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#simple-gibbs-sampler",
    "href": "resources/slides/19-random-effects.html#simple-gibbs-sampler",
    "title": "Lecture 19: Random Effects",
    "section": "Simple Gibbs Sampler",
    "text": "Simple Gibbs Sampler\n\nReparameterize \\(\\theta = (\\alpha, \\phi_\\tau = 1/\\tau^2, \\phi_\\sigma = 1/\\sigma^2, \\beta_1, \\ldots, \\beta_J)\\)\nPriors (parameters Greek letters, hyperparameters Roman) \\[\\begin{align*}\n\\alpha & \\sim \\textsf{N}(a_0, 1/P_0) \\\\\n\\phi_\\tau & \\sim \\textsf{Gamma}(a_\\tau/2, b_\\tau/2) \\\\\n\\phi_\\sigma  & \\sim  \\textsf{Gamma}(a_\\sigma/2, b_\\sigma/2)\n\\end{align*}\\]\nFull Conditional for \\(\\alpha\\) \\[\\begin{align*}\\alpha \\mid \\tau^2, \\sigma^2, \\beta_1, \\ldots \\beta_n & \\sim \\textsf{N}(a_n, 1/P_n) \\\\\nP_n = \\left(P_0 + \\sum_j n_{j} \\phi_\\sigma  \\right) &  \\quad\na_n  = \\frac{a_0 P_0 +  \\sum_j n_j \\bar{y}^*_j }{P_n} \\\\\n\\bar{y}^*_j  & \\equiv \\frac{\\sum_i (y_{ij} - \\beta_j)}{n_j}\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#full-conditionals-continued",
    "href": "resources/slides/19-random-effects.html#full-conditionals-continued",
    "title": "Lecture 19: Random Effects",
    "section": "Full Conditionals Continued",
    "text": "Full Conditionals Continued\n\\[\\begin{align*}\n\\phi_\\sigma \\mid \\alpha, \\phi_\\tau, \\beta_1, \\ldots, \\beta_J \\sim  \\textsf{Gamma}\\left(\\frac{a_\\sigma + \\sum_j n_j}{2}, \\frac{b_\\sigma + \\sum_{ij} (y_{ij} - \\alpha - \\beta_j)^2}{2} \\right)\n\\end{align*}\\]\n\n\\[\\begin{align*}\\beta_j \\mid \\alpha, \\tau, \\sigma^2  & \\mathrel{\\mathop{\\sim}\\limits^{\\rm ind}}\\textsf{N}( \\hat{b}_j, \\hat{P}_{\\beta_j}^{-1}) \\\\\n\\hat{P}_{\\beta_j} &= \\left(\\phi_\\tau +  n_j \\phi_\\sigma \\right) \\\\\n\\hat{b}_j & = \\frac{\\phi_{\\tau} +  n_j \\phi_\\sigma \\bar{y}^{**}_j }{\\hat{P}_{\\beta_j}} \\\\\n\\bar{y}^{**}_j  & \\equiv \\frac{\\sum_i (y_{ij} - \\alpha)}{n_j}\n\\end{align*}\\]\n\n\n\\[\\begin{align*}\n\\phi_\\tau \\mid \\alpha, \\sigma^2, \\beta_1, \\ldots, \\beta_J \\sim  \\textsf{Gamma}\\left(\\frac{a_\\tau +  J}{2}, \\frac{b_\\tau+ \\sum_j \\beta_j^2}{2} \\right)\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#complications-relative-to-usual-regression",
    "href": "resources/slides/19-random-effects.html#complications-relative-to-usual-regression",
    "title": "Lecture 19: Random Effects",
    "section": "Complications Relative to Usual Regression",
    "text": "Complications Relative to Usual Regression\n\nPrior Choice\nMixing and its dependence on parameterization\n\n\nEarly recommendation after Gibbs Sampler used non-informative priors \\[\\begin{align*}\n\\pi(\\alpha) & \\propto 1 \\\\\n\\pi(\\phi_\\sigma) & \\sim \\textsf{Gamma}(\\epsilon/2, \\epsilon/2) \\qquad \\pi(\\phi_\\sigma ) \\propto 1/\\phi_\\sigma \\text{ as } \\epsilon \\to 0 \\\\\n\\pi(\\phi_\\tau) & \\sim \\textsf{Gamma}(\\epsilon/2, \\epsilon/2)  \\qquad  \\pi(\\phi_\\tau) \\propto 1/\\phi_\\tau  \\text{ as } \\epsilon \\to 0\n\\end{align*}\\]\nAre full conditionals proper ?\nIs joint posterior proper ?"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#mcmc-and-improper-priors",
    "href": "resources/slides/19-random-effects.html#mcmc-and-improper-priors",
    "title": "Lecture 19: Random Effects",
    "section": "MCMC and Improper Priors",
    "text": "MCMC and Improper Priors\n\nproper full conditionals even with improper priors\nbut joint is improper !\nMCMC won’t converge to the stationary distribution (doesn’t exist)\nmay not notice it!\nHill (1965) considered the one-way anova model and showed impropriety for \\(p(\\tau^2) \\propto 1/\\tau^2\\)\nHobart & Casella (1996) provide conditions on improper priors leading to proper posteriors in more general random and mixed effects models"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#diffuse-but-proper",
    "href": "resources/slides/19-random-effects.html#diffuse-but-proper",
    "title": "Lecture 19: Random Effects",
    "section": "Diffuse But Proper",
    "text": "Diffuse But Proper\n\\[\\begin{align*}\n\\alpha & \\sim N(0, 10^{-6})\\\\\n\\pi(\\phi_\\sigma) & \\sim \\textsf{Gamma}(10^{-6}, 10^{-6} )\\\\\n\\pi(\\phi_\\tau) & \\sim \\textsf{Gamma}(10^{-6}, 10^{-6} )\n\\end{align*}\\]\n\nNearly improper priors may lead to terrible performance! highly sensitive to just how vague the prior is! (Domains of attraction)"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#alternative-priors",
    "href": "resources/slides/19-random-effects.html#alternative-priors",
    "title": "Lecture 19: Random Effects",
    "section": "Alternative Priors",
    "text": "Alternative Priors\n\\[\\begin{align*}\ny_{ij} \\mid \\alpha, \\beta_1, \\ldots \\beta_J, \\phi_\\sigma^2 & \\mathrel{\\mathop{\\sim}\\limits^{\\rm ind}}\\textsf{N}(\\alpha + \\beta_j, 1/\\phi_\\sigma^2) \\\\\np(\\alpha, \\phi_\\sigma) & \\propto 1/\\phi_\\sigma \\\\\n\\beta_j  \\mid \\tau & \\overset{iid}{\\sim} \\textsf{N}(0, \\tau^2)\n\\end{align*}\\]\n\nGelman 2006 in a discussion of Browne & Draper paper in Bayesian Analysis recommended priors on random effect standard deviation \\(\\tau\\)\n\\(\\pi(\\tau ) \\propto 1(\\tau &gt; 0)\\) (improper prior on sd)\n\\(\\pi(\\tau ) \\propto 1(\\tau &gt; 0)\\textsf{N}(0,1)\\) folded standard normal (half-normal)\n\\(\\pi(\\tau ) \\propto 1(\\tau &gt; 0)\\textsf{N}(0,1/\\psi) \\qquad \\psi \\sim \\textsf{Gamma}(\\nu/2, \\nu/2)\\) leads to a folded t or half t with \\(\\nu\\) degrees of freedom marginally"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#proper-posterior",
    "href": "resources/slides/19-random-effects.html#proper-posterior",
    "title": "Lecture 19: Random Effects",
    "section": "Proper Posterior ?",
    "text": "Proper Posterior ?\nIntegrate out \\(\\beta_j\\) and work with\n\\[\\pi(\\mu, \\tau, \\sigma^2 \\mid y) \\propto \\pi(\\mu, \\tau, \\sigma^2) \\prod_{j=1}^J \\textsf{N}\\left(y_{j}; \\mathbf{1}_{n_j} \\alpha, \\left(\n\\begin{array}{cccc}\n\\sigma^2 + \\tau^2 & \\tau^2 & \\ldots & \\tau^2 \\\\\n\\tau^2 & \\ddots &    & \\tau^2  \\\\\n\\vdots & & \\ddots & \\vdots \\\\\n\\tau^2 & \\ldots & \\tau^2 & \\sigma^2 + \\tau^2 \\end{array}\\right) \\right)\\]\n\ntake \\(\\pi(\\mu, \\tau, \\sigma^2) \\propto \\sigma^{-2} \\, \\textsf{C}^+(\\tau; 0, 1)\\)\n\n\nOR\n\ntake \\(\\pi(\\mu, \\tau, \\sigma^2) \\propto \\sigma^{-2}\\) (note prior on standard deviation \\(\\tau\\))\nIs joint posterior is proper ? (see Hobart & Casella)"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#propriety",
    "href": "resources/slides/19-random-effects.html#propriety",
    "title": "Lecture 19: Random Effects",
    "section": "Propriety",
    "text": "Propriety\n\nexpression for marginal likelihood requires determinant and inverse of intra-class correlation matrix!\nWrite covariance as \\(\\sigma^2 \\mathbf{I}_{n_j} + \\tau^2 n_j \\mathbf{P}_{\\mathbf{1}_{n_j}}\\) and find spectral decomposition \\[\\begin{align}\n\\sigma^2 \\mathbf{I}_{n_j} + \\tau^2 n_j \\mathbf{P}_{\\mathbf{1}_{n_j}}  & =\n\\mathbf{U}[\\sigma^2 \\mathbf{I}_{n_j} + \\tau^2 n_j \\text{diag}(1, 0 , \\ldots, 0)] \\mathbf{U}^T\\\\\n(\\sigma^2 \\mathbf{I}_{n_j} + \\tau^2 n_j \\mathbf{P}_{\\mathbf{1}_{n_j}} )^{-1}  & = \\frac{1}{\\sigma^2} (\\mathbf{I}_{n_j} + \\frac{\\tau^2 n_j}{\\sigma^2 + \\tau^2 n_j} \\mathbf{P}_{\\mathbf{1}_{n_j}})\n\\end{align}\\]\nintegrate out \\(\\alpha\\) (messy completing the square)! see Hill 1965 Equation 3.\nconsider conditional distributions from \\(1/\\sigma^2\\) and \\(\\tau\\)\ndetermine if integrals are finite (what happens at \\(\\tau\\) near 0 ?)\nlook at special case when \\(n_j\\) are all equal"
  },
  {
    "objectID": "resources/slides/19-random-effects.html#bayes-estimates-of-variances",
    "href": "resources/slides/19-random-effects.html#bayes-estimates-of-variances",
    "title": "Lecture 19: Random Effects",
    "section": "Bayes Estimates of Variances",
    "text": "Bayes Estimates of Variances\n\nAvoids issues when estimate of variance is on the boundary of the parmaeter space\nDo not have to use asymptotics to construct CI!\nfull uncertainty propagation\npredictive distributions for future data\nGelman (2006) recommends half-t if the number of groups is small or uniform but uniform on the standard deviation \\(\\tau\\) does lead to an improper posterior if \\(J \\leq 3\\)\nHobart & Casella (1996) provides more rigorous conditions with improper priors\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#last-class-normal-means-model",
    "href": "resources/slides/06-metropolis.html#last-class-normal-means-model",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Last Class: Normal Means Model",
    "text": "Last Class: Normal Means Model\n\nData Model \\(Y_i \\mid \\mu_i, \\sigma^2 \\overset{ind}{\\sim} \\textsf{N}(\\mu_i, \\sigma^2)\\)\nMeans Model \\(\\mu_i \\mid \\mu, \\sigma^2_\\mu \\overset{iid}{\\sim} \\textsf{N}(\\mu, \\sigma^2_{\\mu})\\)$\nFound marginal likelihood \\(\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu)\\) by integrating out \\(\\mu_i\\) with respect to \\(g\\) \\[\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu) \\propto (\\sigma^2 + \\sigma^2_\\mu)^{-n/2} \\exp \\left\\{ - \\frac{1}{2} \\frac{\\sum_{i=1}^n\\left(y_i - \\mu \\right)^2}{\\sigma^2 + \\sigma^2_\\mu }\\right\\}\\]\nPosterior for \\(\\theta = \\mu, \\sigma^2_\\mu\\) with \\(\\sigma^2 = 1\\) \\[\\pi(\\theta \\mid y) = \\frac{\\pi(\\theta) \\cal{L}(\\theta)}\n{\\int_\\Theta \\pi(\\theta) \\cal{L}(\\theta) \\, d\\theta} =\n\\frac{\\pi(\\theta) \\cal{L}(\\theta)}\n{m(y)}\\]\nwhile we can integrate out \\(\\mu\\), no closed form for posterior of \\(\\sigma^2_\\mu\\) given \\(\\sigma^2\\)"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#important-sampling-estimate",
    "href": "resources/slides/06-metropolis.html#important-sampling-estimate",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Important Sampling Estimate",
    "text": "Important Sampling Estimate\n\nEstimate of \\(m(y)\\) \\[m(y) \\approx \\frac{1}{T} \\sum_{t=1}^{T}  \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})} \\qquad \\theta^{(t)} \\sim q(\\theta)\\]\nRatio estimator of \\(\\textsf{E}[h(\\theta) \\mid y]\\) \\[\\textsf{E}[h(\\theta) \\mid y] \\approx \\frac{\\sum_{t=1}^{T} h(\\theta^{(t)}) \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}}\n{ \\sum_{t=1}^{T}  \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}}\n\\qquad \\theta^{(t)} \\sim q(\\theta)\\]\nWeighted average with importance weights \\(w(\\theta^{(t)}) \\propto \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}\\) \\[\\textsf{E}[h(\\theta) \\mid y] \\approx \\sum_{t=1}^{T} h(\\theta^{(t)}) w(\\theta^{(t)})/\\sum_{t=1}^T w(\\theta^{(t)}) \\qquad \\theta^{(t)} \\sim q(\\theta)\\]"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#issues",
    "href": "resources/slides/06-metropolis.html#issues",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Issues",
    "text": "Issues\n\nif \\(q()\\) puts too little mass in regions with high posterior density, we can have some extreme weights\noptimal case is that \\(q()\\) is as close as possible to the posterior so that all weights are constant\nEstimate may have large variance\nProblems with finding a good \\(q()\\) in high dimensions \\((d &gt; 20)\\) or with skewed distributions"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#markov-chain-monte-carlo-mcmc",
    "href": "resources/slides/06-metropolis.html#markov-chain-monte-carlo-mcmc",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Markov Chain Monte Carlo (MCMC)",
    "text": "Markov Chain Monte Carlo (MCMC)\n\nTypically \\(\\pi(\\theta)\\) and \\(\\cal{L}(\\theta)\\) are easy to evaluate\n\n\n\n\n\n\n\n\nQuestion\n\n\nHow do we draw samples only using evaluations of the prior and likelihood in higher dimensional settings?\n\n\n\n\nconstruct a Markov chain \\(\\theta^{(t)}\\) in such a way the the stationary distribution of the Markov chain is the posterior distribution \\(\\pi(\\theta \\mid y)\\)! \\[\\theta^{(0)} \\overset{k}{\\longrightarrow} \\theta^{(1)} \\overset{k}{\\longrightarrow} \\theta^{(2)} \\cdots\\]\n\\(k_t(\\theta^{(t-1)} ; \\theta^{(t)})\\) transition kernel\ninitial state \\(\\theta^{(0)}\\)\nchoose some nice \\(k_t\\) such that \\(\\theta^{(t)} \\to \\pi(\\theta \\mid y)\\) as \\(t \\to \\infty\\)\nbiased samples initially but get closer to the target\nMetropolis Algorithm (1950’s)"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#stochastic-sampling-intuition",
    "href": "resources/slides/06-metropolis.html#stochastic-sampling-intuition",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Stochastic Sampling Intuition",
    "text": "Stochastic Sampling Intuition\n\nFrom a sampling perspective, we need to have a large sample or group of values, \\(\\theta^{(1)}, \\ldots, \\theta^{(S)}\\) from \\(\\pi(\\theta \\mid y)\\) whose empirical distribution approximates \\(\\pi(\\theta \\mid y)\\).\nfor any two sets \\(A\\) and \\(B\\), we want \\[\\frac{\\dfrac{\\# \\theta^{(s)} \\in A}{S}}{\\dfrac{\\# \\theta^{(s)} \\in B}{S} } = \\dfrac{\\# \\theta^{(s)} \\in A}{\\# \\theta^{(s)} \\in B} \\approx \\dfrac{\\pi(\\theta \\in A \\mid  y)}{\\pi(\\theta \\in B \\mid  y)}\\]\nSuppose we have a working group \\(\\theta^{(1)}, \\ldots, \\theta^{(s)}\\) at iteration \\(s\\), and need to add a new value \\(\\theta^{(s+1)}\\).\nConsider a candidate value \\(\\theta^\\star\\) that is close to \\(\\theta^{(s)}\\)\nShould we set \\(\\theta^{(s+1)} = \\theta^\\star\\) or not?"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#posterior-ratio",
    "href": "resources/slides/06-metropolis.html#posterior-ratio",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Posterior Ratio",
    "text": "Posterior Ratio\nlook at the ratio \\[\n\\begin{split}\nM & = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)} = \\frac{\\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y)} } {\\dfrac{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}{p(y)}}\\\\\n\\\\\n&  = \\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}\n\\end{split}\n\\]\n\ndoes not depend on the marginal likelihood we don’t know!"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#metropolis-algorithm",
    "href": "resources/slides/06-metropolis.html#metropolis-algorithm",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Metropolis Algorithm",
    "text": "Metropolis Algorithm\n\nIf \\(M &gt; 1\\)\n\nIntuition: \\(\\theta^{(s)}\\) is already a part of the density we desire and the density at \\(\\theta^\\star\\) is even higher than the density at \\(\\theta^{(s)}\\).\nAction: set \\(\\theta^{(s+1)} = \\theta^\\star\\)\n\nIf \\(M &lt; 1\\),\n\nIntuition: relative frequency of values in our group \\(\\theta^{(1)}, \\ldots, \\theta^{(s)}\\) “equal” to \\(\\theta^\\star\\) should be \\(\\approx M = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)}\\).\nFor every \\(\\theta^{(s)}\\), include only a fraction of an instance of \\(\\theta^\\star\\).\nAction: set \\(\\theta^{(s+1)} = \\theta^\\star\\) with probability \\(M\\) and \\(\\theta^{(s+1)} = \\theta^{(s)}\\) with probability \\(1-M\\)."
  },
  {
    "objectID": "resources/slides/06-metropolis.html#proposal-distribution",
    "href": "resources/slides/06-metropolis.html#proposal-distribution",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Proposal Distribution",
    "text": "Proposal Distribution\n\nWhere should the proposed value \\(\\theta^\\star\\) come from?\nSample \\(\\theta^\\star\\) close to the current value \\(\\theta^{(s)}\\) using a symmetric proposal distribution \\(\\theta^\\star \\sim q(\\theta^\\star \\mid \\theta^{(s)})\\)\n\\(q()\\) is actually a “family of proposal distributions”, indexed by the specific value of \\(\\theta^{(s)}\\).\nHere, symmetric means that \\(q(\\theta^\\star \\mid \\theta^{(s)}) = q(\\theta^{(s)} \\mid \\theta^\\star)\\).\nCommon choice \\[\\textsf{N}(\\theta^\\star; \\theta^{(s)}, \\delta^2 \\Sigma)\\] with \\(\\Sigma\\) based on the approximate \\(\\textsf{Cov}(\\theta \\mid y)\\) and \\(\\delta^2 = 2.38^2/\\text{dim}(\\theta)\\) or \\[\\text{Unif}(\\theta^\\star; \\theta^{(s)} - \\delta, \\theta^{(s)} + \\delta)\\]"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#metropolis-algorithm-recap",
    "href": "resources/slides/06-metropolis.html#metropolis-algorithm-recap",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Metropolis Algorithm Recap",
    "text": "Metropolis Algorithm Recap\nThe algorithm proceeds as follows:\n\nGiven \\(\\theta^{(1)}, \\ldots, \\theta^{(s)}\\), generate a candidate value \\(\\theta^\\star \\sim q(\\theta^\\star \\mid \\theta^{(s)})\\).\nCompute the acceptance ratio \\[\\begin{split}\nM & = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)} = \\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}.\n\\end{split}\\]\nSet \\[\\begin{eqnarray*}\n\\theta^{(s+1)} = \\left\\{ \\begin{array}{ll}\n\\theta^\\star & \\quad \\text{with probability} \\quad \\text{min}(M,1) \\\\\n\\theta^{(s)} & \\quad \\text{with probability} \\quad 1 - \\text{min}(M,1) \\\\\n\\end{array} \\right.\n\\end{eqnarray*}\\] equivalent to sampling \\(u \\sim U(0,1)\\) independently and setting \\[\\begin{eqnarray*}\n\\theta^{(s+1)} = \\left\\{ \\begin{array}{ll}\n\\theta^\\star & \\quad \\text{if} \\quad u &lt; M \\\\\n\\theta^{(s)} & \\quad \\text{if} \\quad \\text{otherwise} \\\\\n\\end{array} \\right. .\n\\end{eqnarray*}\n\\]"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#notes",
    "href": "resources/slides/06-metropolis.html#notes",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Notes",
    "text": "Notes\n\nAcceptance probability is \\[M = \\min \\left\\{ 1, \\frac{\\pi(\\theta^\\star) \\cal{L}(\\theta^\\star)}\n                         {\\pi(\\theta^{(s)}) \\cal{L}(\\theta^{(s)})}\\right\\}\\]\nratio of posterior densities where normalizing constant cancels!\nThe Metropolis chain ALWAYS moves to the proposed \\(\\theta^\\star\\) at iteration \\(s+1\\) if \\(\\theta^\\star\\) has higher target density than the current \\(\\theta^{(s)}\\).\nSometimes, it also moves to a \\(\\theta^\\star\\) value with lower density in proportion to the density value itself.\nThis leads to a random, Markov process that naturally explores the space according to the probability defined by \\(\\pi(\\theta \\mid y)\\), and hence generates a sequence that, while dependent, eventually represents draws from \\(\\pi(\\theta \\mid y)\\) (stationary distribution of the Markov Chain)."
  },
  {
    "objectID": "resources/slides/06-metropolis.html#summarizing-samples",
    "href": "resources/slides/06-metropolis.html#summarizing-samples",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Summarizing Samples",
    "text": "Summarizing Samples\n\nOnce we obtain the samples, then we are back to using Monte Carlo approximations for quantities of interest!\nwe can approximate posterior means, quantiles, and other quantities of interest using the empirical distribution of our sampled values.\neasy to compute the posterior distribution of nonlinear functions of parameters! \\[\\psi^{(s)} = g(\\theta^{(s)})\\]\nsome posterior summaries are hard to calculate based on samples \\(\\{ \\theta^{(s)}\\}\\)\n\nmode/MAP (at least for continuous)\nmarginal likelihood \\(m(y) = \\int \\pi(\\theta) p(y \\mid \\theta)\\, d\\theta\\)"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#convergence",
    "href": "resources/slides/06-metropolis.html#convergence",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Convergence",
    "text": "Convergence\nWe will not cover the convergence theory behind Metropolis chains in detail, but …\n\nThe Markov process generated under this procedure is ergodic (irreducible and aperiodic) and has a unique limiting distribution (stationary distribution)\n\nergodicity means that the chain can move anywhere at each step, which is ensured, if \\(q(\\theta^\\star \\mid \\theta^{(s)}) &gt; 0\\) everywhere!\n\nBy construction, Metropolis chains are reversible, so that \\(\\pi(\\theta \\mid y)\\) is the stationary distribution\n\nThink of reversibility as being equivalent to symmetry of the joint density of two consecutive \\(\\theta^{(s)}\\) and \\(\\theta^{(s+1)}\\) in the stationary process (which we get by using a symmetric proposal distribution)\ndetailed balance"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#example",
    "href": "resources/slides/06-metropolis.html#example",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Example",
    "text": "Example\nPriors with \\(\\sigma^2 = 1\\): \\[p(\\mu) \\propto 1\\]\n\nUse a \\(\\textsf{Cauchy}(0,1)\\) prior on \\(\\sigma_\\mu\\) independent of \\(\\mu\\) and\nSymmetric proposal for \\(\\mu\\) and \\(\\sigma_\\tau\\)?\nTry independent normals \\(\\frac{2.38^2}{d} \\textsf{Cov}(\\theta)\\) where \\(d\\) is the dimension of \\(\\theta\\) (d = 2)"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#samples",
    "href": "resources/slides/06-metropolis.html#samples",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Samples",
    "text": "Samples\n\n\nOverall Acceptance probability is 0.6 out of 10^{4} samples\nGoal is around 0.44 in 1 dimension to 0.23 in higher dimensions"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#tuning",
    "href": "resources/slides/06-metropolis.html#tuning",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Tuning",
    "text": "Tuning\n\nSampled values are correlated\nCorrelation between samples can be adjusted by selecting an optimal \\(\\delta\\) (i.e., spread of the distribution) in the proposal distribution\n\\(\\delta\\) too small leads to \\(M \\approx 1\\) for most proposed values, a high acceptance rate, but very small moves, leading to highly correlated chain.\n\\(\\delta\\) too large can get “stuck” because \\(\\theta^\\star\\) may be very far away from high density regions, leading to a very low acceptance rate and again high correlation in the Markov chain.\nBurn-in and thinning can help!"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#burn-in",
    "href": "resources/slides/06-metropolis.html#burn-in",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Burn-in",
    "text": "Burn-in\n\nConvergence occurs regardless of our starting point (in theory), so we can usually pick any reasonable values in the parameter space as a starting point.\nMay take a long time to reach high density regions\nOver representation of low density samples given finite iterations\nGenerally, we throw out a certain number of the first draws, known as the burn-in, as an attempt to make our draws closer to the stationary distribution and less dependent on any single set of starting values.\nHowever, we don’t know exactly when convergence occurs, so it is not always clear how much burn-in we would need.\nIf you run long enough you should not need to discard any samples! (ergodicity)"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#example-1",
    "href": "resources/slides/06-metropolis.html#example-1",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#convergence-diagnostics",
    "href": "resources/slides/06-metropolis.html#convergence-diagnostics",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Convergence diagnostics",
    "text": "Convergence diagnostics\n\nDiagnostics available to help decide on number of burn-in & collected samples.\nNote: no definitive tests of convergence but you should do as many diagnostics as you can, on all parameters in your model.\nWith “experience”, visual inspection of trace plots perhaps most useful approach.\nThere are a number of useful automated tests in R.\nCAUTION: diagnostics cannot guarantee that a chain has converged, but they can indicate it has not converged."
  },
  {
    "objectID": "resources/slides/06-metropolis.html#diagnostics-in-r",
    "href": "resources/slides/06-metropolis.html#diagnostics-in-r",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Diagnostics in R",
    "text": "Diagnostics in R\n\nThe most popular package for MCMC diagnostics in R is coda.\ncoda uses a special MCMC format so you must always convert your posterior matrix into an MCMC object.\nFor the example, we have the following in R.\n\n\n\n#library(coda)\ntheta.mcmc &lt;- mcmc(theta,start=1) #no burn-in (simple problem!)"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#diagnostics-in-r-1",
    "href": "resources/slides/06-metropolis.html#diagnostics-in-r-1",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Diagnostics in R",
    "text": "Diagnostics in R\n\nsummary(theta.mcmc)\n\n\nIterations = 1:10000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n             Mean     SD Naive SE Time-series SE\nmu       -0.07977 0.1046 0.001046       0.002839\nsigma_mu  0.17550 0.1273 0.001273       0.004397\n\n2. Quantiles for each variable:\n\n              2.5%     25%      50%      75%  97.5%\nmu       -0.283420 -0.1508 -0.08193 -0.00848 0.1337\nsigma_mu  0.007995  0.0758  0.15024  0.25228 0.4693\n\n\n\nThe naive SE is the standard error of the mean, which captures simulation error of the mean rather than the posterior uncertainty.\nThe time-series SE adjusts the naive SE for autocorrelation."
  },
  {
    "objectID": "resources/slides/06-metropolis.html#effective-sample-size.",
    "href": "resources/slides/06-metropolis.html#effective-sample-size.",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Effective sample size.",
    "text": "Effective sample size.\n\nThe effective sample size translates the number of MCMC samples \\(S\\) into an equivalent number of independent samples.\nIt is defined as \\[\\textrm{ESS} = \\dfrac{S}{1 + 2 \\sum_k \\rho_k},\\]\n\\(S\\) is the sample size and \\(\\rho_k\\) is the lag \\(k\\) autocorrelation.\nFor our data, we have\n\n\n\neffectiveSize(theta.mcmc)\n\n       mu  sigma_mu \n1356.6495  838.2613 \n\n\n\nSo our 10,000 samples are equivalent to 1356.6 independent samples for \\(\\mu\\) and 838.3 independent samples for \\(\\sigma_\\mu\\)."
  },
  {
    "objectID": "resources/slides/06-metropolis.html#trace-plot-for-mean",
    "href": "resources/slides/06-metropolis.html#trace-plot-for-mean",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Trace plot for mean",
    "text": "Trace plot for mean"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#trace-plot-for-sigma_mu",
    "href": "resources/slides/06-metropolis.html#trace-plot-for-sigma_mu",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Trace plot for \\(\\sigma_\\mu\\)",
    "text": "Trace plot for \\(\\sigma_\\mu\\)\n\nOK (be careful of scaling in plots!)"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#autocorrelation",
    "href": "resources/slides/06-metropolis.html#autocorrelation",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Autocorrelation",
    "text": "Autocorrelation\n\nAnother way to evaluate convergence is to look at the autocorrelation between draws of our Markov chain.\nThe lag \\(k\\) autocorrelation, \\(\\rho_k\\), is the correlation between each draw and its \\(k\\)th lag, defined as \\[\\rho_k = \\dfrac{\\sum_{s=1}^{S-k}(\\theta_s - \\bar{\\theta})(\\theta_{s+k} - \\bar{\\theta})}{\\sum_{s=1}^{S-k}(\\theta_s - \\bar{\\theta})^2}\\]\nWe expect the autocorrelation to decrease as \\(k\\) increases.\nIf autocorrelation remains high as \\(k\\) increases, we have slow mixing due to the inability of the sampler to move around the space well."
  },
  {
    "objectID": "resources/slides/06-metropolis.html#autocorrelation-for-mean",
    "href": "resources/slides/06-metropolis.html#autocorrelation-for-mean",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Autocorrelation for mean",
    "text": "Autocorrelation for mean\n\nSo-So"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#autocorrelation-for-variance",
    "href": "resources/slides/06-metropolis.html#autocorrelation-for-variance",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Autocorrelation for variance",
    "text": "Autocorrelation for variance\n\nworse"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#gelman-rubin",
    "href": "resources/slides/06-metropolis.html#gelman-rubin",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Gelman-Rubin",
    "text": "Gelman-Rubin\nGelman & Rubin suggested a diagnostic \\(R\\) based on taking separate chains with dispersed initial values to test convergence"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#gelman-rubin-diagnostic",
    "href": "resources/slides/06-metropolis.html#gelman-rubin-diagnostic",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Gelman-Rubin Diagnostic",
    "text": "Gelman-Rubin Diagnostic\n\nRun m &gt; 2 chains of length 2S from overdispersed starting values.\nDiscard the first S draws in each chain.\nCalculate the pooled within-chain variance \\(W\\) and between-chain variance \\(B\\). \\[R = \\frac{\\frac{S-1}{S} W + \\frac{1}{S} B }{W}\\]\nnumerator and denominator are both unbiased estimates of the variance if the two chains have converged\n\notherwise \\(W\\) is an underestimate (hasn’t explored enough)\nnumerator will overestimate as \\(B\\) is too large (overdispersed starting points)\n\nAs \\(S \\to \\infty\\) and \\(B \\to 0\\), \\(R \\to 1\\)\nversion in R is slightly different"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#gelman-rubin-diagnostic-1",
    "href": "resources/slides/06-metropolis.html#gelman-rubin-diagnostic-1",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Gelman-Rubin Diagnostic",
    "text": "Gelman-Rubin Diagnostic\n\ntheta.mcmc = mcmc.list(mcmc(theta1, start=5000), mcmc(theta2, start=5000))\ngelman.diag(theta.mcmc)\n\nPotential scale reduction factors:\n\n         Point est. Upper C.I.\nmu                1          1\nsigma_mu          1          1\n\nMultivariate psrf\n\n1\n\n\n\nValues of \\(R &gt; 1.1\\) suggest lack of convergence\nLooks OK\nSee also gelman.plot"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#geweke-statistic",
    "href": "resources/slides/06-metropolis.html#geweke-statistic",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Geweke statistic",
    "text": "Geweke statistic\n\nGeweke proposed taking two non-overlapping parts of a single Markov chain (usually the first 10% and the last 50%) and comparing the mean of both parts, using a difference of means test\nThe null hypothesis would be that the two parts of the chain are from the same distribution.\nThe test statistic is a z-score with standard errors adjusted for autocorrelation, and if the p-value is significant for a variable, you need more draws.\nOutput in R is the Z score"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#geweke-diagnostic",
    "href": "resources/slides/06-metropolis.html#geweke-diagnostic",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Geweke Diagnostic",
    "text": "Geweke Diagnostic\n\nThe output is the z-score itself (not the p-value).\n\n\ngeweke.diag(theta.mcmc)\n\n[[1]]\n\nFraction in 1st window = 0.1\nFraction in 2nd window = 0.5 \n\n      mu sigma_mu \n -0.7779   0.7491 \n\n\n[[2]]\n\nFraction in 1st window = 0.1\nFraction in 2nd window = 0.5 \n\n      mu sigma_mu \n  0.4454   0.6377"
  },
  {
    "objectID": "resources/slides/06-metropolis.html#practical-advice-on-diagnostics",
    "href": "resources/slides/06-metropolis.html#practical-advice-on-diagnostics",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Practical advice on diagnostics",
    "text": "Practical advice on diagnostics\n\nThere are more tests we can use: Raftery and Lewis diagnostic, Heidelberger and Welch, etc.\nThe Gelman-Rubin approach is quite appealing in using multiple chains\nGeweke (and Heidelberger and Welch) sometimes reject even when the trace plots look good.\nOverly sensitive to minor departures from stationarity that do not impact inferences.\nMost common method of assessing convergence is visual examination of trace plots."
  },
  {
    "objectID": "resources/slides/06-metropolis.html#improving",
    "href": "resources/slides/06-metropolis.html#improving",
    "title": "Lecture 6: Metropolis Algorithms and Stochastic Sampling",
    "section": "Improving",
    "text": "Improving\n\nmore iterations and multiple chains\nthinning to reduce correlations and increase ESS e.g. if autocorrelation drops to near zero at say lag 5, keep every 5th draw\nchange the proposal distribution \\(q\\)\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#what-is-this-course-about",
    "href": "resources/slides/00-course-overview.html#what-is-this-course-about",
    "title": "Welcome to STA 702",
    "section": "What is this course about?",
    "text": "What is this course about?\n\nLearn the foundations and theory of Bayesian inference in the context of several models.\nUse Bayesian models to answer inferential questions.\nApply the models to several different problems.\nUnderstand the advantages/disadvantages of Bayesian methods vs classical methods\n\n\n\n A Bayesian version will usually make things better…\n– Andrew Gelman."
  },
  {
    "objectID": "resources/slides/00-course-overview.html#instructional-team",
    "href": "resources/slides/00-course-overview.html#instructional-team",
    "title": "Welcome to STA 702",
    "section": "Instructional Team",
    "text": "Instructional Team\nInstructor: Dr Merlise Clyde\n   clyde@duke.edu     223 Old Chemistry     https://www2.stat.duke.edu/~clyde \n\n \nTeaching Assistant: Rick Presman\n   rick.presman@duke.edu\n \n   See course website for Office Hours, Policies and more!"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#prerequisites",
    "href": "resources/slides/00-course-overview.html#prerequisites",
    "title": "Welcome to STA 702",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nrandom variables, common families of probability distribution functions and expectations\nconditional distributions\ntransformations of random variables and change of variables\nprinciples of statistical inference (likelihoods)\nsampling distributions and hypothesis testing\nconcepts of convergence\n\n\nReview Chapters 1 to 5 of the Casella and Berger book"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#computing",
    "href": "resources/slides/00-course-overview.html#computing",
    "title": "Welcome to STA 702",
    "section": "Computing",
    "text": "Computing\n\nLabs/HW will involve computing in R!\nWrite your own MCMC samplers and run code long enough to show convergence\nYou can learn R on the fly\n\nsee Resources Tab on website\nmaterials from 2023 Bootcamp/Orientation"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#grading-policies",
    "href": "resources/slides/00-course-overview.html#grading-policies",
    "title": "Welcome to STA 702",
    "section": "Grading Policies",
    "text": "Grading Policies\n\n5% class\n20% HW\n10% Lab\n20% Midterm I\n20% Midterm II\n25% Final\nNo Late Submissions for HW/Lab; Drop the lowest score\nYou are encouraged to discuss assignments, but copying others work is considered a misconduct violation and will result in a 0 on the assignment\nConfirm that you have access to Sakai, Gradescope, and GitHub"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#course-structure-and-policies",
    "href": "resources/slides/00-course-overview.html#course-structure-and-policies",
    "title": "Welcome to STA 702",
    "section": "Course structure and policies",
    "text": "Course structure and policies\n\nSee the Syllabus\nMake use of the teaching team’s office hours, we’re here to help!\nDo not hesitate to come to my office hours or you can also make an appointment to discuss a homework problem or any aspect of the course.\nPlease make sure to check your email daily for announcements\nUse the  Reporting an issue link to report broken links or missing content"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#important-dates",
    "href": "resources/slides/00-course-overview.html#important-dates",
    "title": "Welcome to STA 702",
    "section": "Important Dates",
    "text": "Important Dates\n\n\n\n \n \n\n\n\n\nTues, Aug 29\nClasses begin\n\n\nFri, Sept 8\nDrop/Add ends\n\n\nFriday, Oct 13\nMidterm I (tentative)\n\n\nSat - Tues, Oct 14 - 17\nFall Break\n\n\nTues, Nov 20\nMidterm II (tentative)\n\n\nFriday, Dec 1\nGraduate Classes End\n\n\nDec 2 - Dec 12\nGraduate Reading Period\n\n\nSat, Dec 16\nFinal Exam (Perkins 060 2:00-5:00pm)\n\n\n\n\nSee Class Schedule for slides, readings, HW, Labs, etc"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#topics",
    "href": "resources/slides/00-course-overview.html#topics",
    "title": "Welcome to STA 702",
    "section": "Topics",
    "text": "Topics\n\nBasics of Bayesian Models\nLoss Functions, Inference and Decision Making\nPredictive Distributions\nPredictive Distributions and Model Checking\nBayesian Hypothesis Testing\nMultiple Testing\nMCMC (Gibbs & Metropolis Hastings Algorithms)\nModel Uncertainty/Model Choice\nBayesian Generalized Linear Models\nHiearchical Modeling and Random Effects\nHamiltonian Monte Carlo\nNonparametric Bayes Regression"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#basics-of-bayesian-inference",
    "href": "resources/slides/00-course-overview.html#basics-of-bayesian-inference",
    "title": "Welcome to STA 702",
    "section": "Basics of Bayesian inference",
    "text": "Basics of Bayesian inference\nGenerally (unless otherwise stated), in this course, we will use the following notation. Let\n\n\\(Y\\) is a random variable from some probability distribution \\(p(y \\mid \\theta)\\)\n\\(\\mathcal{Y}\\) be the sample space (possible outcomes for \\(Y\\))\n\\(y\\) is the observed data\n\\(\\theta\\) is the unknown parameter of interest\n\\(\\Theta\\) be the parameter space\ne.g. \\(Y \\sim \\textsf{Ber}(\\theta)\\) where \\(\\theta = \\Pr(Y = 1)\\)"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#frequentist-inference",
    "href": "resources/slides/00-course-overview.html#frequentist-inference",
    "title": "Welcome to STA 702",
    "section": "Frequentist inference",
    "text": "Frequentist inference\n\nGiven data \\(y\\), how would we estimate the population parameter \\(\\theta\\)?\n\nMaximum likelihood estimate (MLE)\nMethod of moments\nand so on…\n\nFrequentist MLE finds the one value of \\(\\theta\\) that maximizes the likelihood\nTypically uses large sample (asymptotic) theory to obtain confidence intervals and do hypothesis testing."
  },
  {
    "objectID": "resources/slides/00-course-overview.html#what-are-bayesian-methods",
    "href": "resources/slides/00-course-overview.html#what-are-bayesian-methods",
    "title": "Welcome to STA 702",
    "section": "What are Bayesian methods?",
    "text": "What are Bayesian methods?\n\nBayesian methods are data analysis tools derived from the principles of Bayesian inference and provide\n\nparameter estimates with good statistical properties;\nparsimonious descriptions of observed data;\npredictions for missing data and forecasts of future data with full uncertainty quantification; and\na computational framework for model estimation, selection, decision making and validation.\nbuilds on likelihood inference"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#bayes-theorem",
    "href": "resources/slides/00-course-overview.html#bayes-theorem",
    "title": "Welcome to STA 702",
    "section": "Bayes’ theorem",
    "text": "Bayes’ theorem\n\nLet’s take a step back and quickly review the basic form of Bayes’ theorem.\nSuppose there are some events \\(A\\) and B having probabilities \\(\\Pr(A)\\) and \\(\\Pr(B)\\).\nBayes’ rule gives the relationship between the marginal probabilities of A and B and the conditional probabilities.\nIn particular, the basic form of Bayes’ rule or Bayes’ theorem is \\[\\Pr(A | B) = \\frac{\\Pr(A \\ \\textrm{and} \\ B)}{\\Pr(B)} = \\frac{\\Pr(B|A)\\Pr(A)}{\\Pr(B)}\\]\n\\(\\Pr(A)\\) = marginal probability of event \\(A\\), \\(\\Pr(B | A)\\) = conditional probability of event \\(B\\) given event \\(A\\), and so on.\n“reverses the conditioning” e.g. Probability of Covid given a negative test versus probability of a negative test given Covid"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#bayes-rule-more-generally",
    "href": "resources/slides/00-course-overview.html#bayes-rule-more-generally",
    "title": "Welcome to STA 702",
    "section": "Bayes’ Rule more generally",
    "text": "Bayes’ Rule more generally\n\nFor each \\(\\theta \\in \\Theta\\), specify a prior distribution \\(p(\\theta)\\) or \\(\\pi(\\theta)\\), describing our beliefs about \\(\\theta\\) being the true population parameter.\nFor each \\(\\theta \\in \\Theta\\) and \\(y \\in \\mathcal{Y}\\), specify a sampling distribution \\(p(y|\\theta)\\), describing our belief that the data we see \\(y\\) is the outcome of a study with true parameter \\(\\theta\\).  Likelihood \\(L(\\theta|y)\\) proportional to \\(p(y|\\theta)\\)\nAfter observing the data \\(y\\), for each \\(\\theta \\in \\Theta\\), update the prior distribution to a posterior distribution \\(p(\\theta | y)\\) or \\(\\pi(\\theta | y)\\), describing our “updated” belief about \\(\\theta\\) being the true population parameter.\n\n\nGetting from Step 1 to 3? Bayes’ rule!\n\\[p(\\theta | y) = \\frac{p(\\theta)p(y|\\theta)}{\\int_{\\Theta}p(\\tilde{\\theta})p(y| \\tilde{\\theta}) \\textrm{d}\\tilde{\\theta}} = \\frac{p(\\theta)p(y|\\theta)}{p(y)}\\] where \\(p(y)\\) obtained by Law of Total Probability"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#notes-on-prior-distributions",
    "href": "resources/slides/00-course-overview.html#notes-on-prior-distributions",
    "title": "Welcome to STA 702",
    "section": "Notes on prior distributions",
    "text": "Notes on prior distributions\nMany types of priors may be of interest. These may\n\nrepresent our own beliefs;\nrepresent beliefs of a variety of people with differing prior opinions; or\nassign probability more or less evenly over a large region of the parameter space\ndesigned to provide good frequentist behavior when little is known"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#notes-on-prior-distributions-1",
    "href": "resources/slides/00-course-overview.html#notes-on-prior-distributions-1",
    "title": "Welcome to STA 702",
    "section": "Notes on prior distributions",
    "text": "Notes on prior distributions\n\nSubjective Bayes: a prior should accurately quantify some individual’s beliefs about \\(\\theta\\)\nObjective Bayes: the prior should be chosen to produce a procedure with “good” operating characteristics without including subjective prior knowledge\nWeakly informative: prior centered in a plausible region but not overly-informative, as there is a tendency to be over confident about one’s beliefs\nEmpirical Bayes: uses the data to estimate the prior, then pretends it was known\nPractical Bayes: Combination"
  },
  {
    "objectID": "resources/slides/00-course-overview.html#notes-on-prior-distributions-2",
    "href": "resources/slides/00-course-overview.html#notes-on-prior-distributions-2",
    "title": "Welcome to STA 702",
    "section": "Notes on prior distributions",
    "text": "Notes on prior distributions\n\nThe prior quantifies ‘your’ initial uncertainty in \\(\\theta\\) before you observe new data (new information) - this may be necessarily subjective & summarizes experience in a field or prior research.\nEven if the prior is not “perfect”, placing higher probability in a ballpark of the truth leads to better performance.\nHence, it is very seldom the case that a weakly informative prior is not preferred over no prior. (Model selection is one case where one needs to be careful!)\nOne (very important) role of the prior is to stabilize estimates (shrinkage) in the presence of limited data."
  },
  {
    "objectID": "resources/slides/00-course-overview.html#next-steps",
    "href": "resources/slides/00-course-overview.html#next-steps",
    "title": "Welcome to STA 702",
    "section": "Next Steps",
    "text": "Next Steps\nWork on Lab 0\nFinally, here are some readings to entertain you. Make sure to glance through them within the next week. See Course Resources\n\nEfron, B., 1986. Why isn’t everyone a Bayesian?. The American Statistician, 40(1), pp. 1-5.\nGelman, A., 2008. Objections to Bayesian statistics. Bayesian Analysis, 3(3), pp. 445-449.\nDiaconis, P., 1977. Finite forms of de Finetti’s theorem on exchangeability. Synthese, 36(2), pp. 271-281.\nGelman, A., Meng, X. L. and Stern, H., 1996. Posterior predictive assessment of model fitness via realized discrepancies. Statistica sinica, pp. 733-760. 5. Dunson, D. B., 2018. Statistics in the big data era: Failures of the machine. Statistics & Probability Letters, 136, pp. 4-9.\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#outline",
    "href": "resources/slides/03-normal-predictive-distributions.html#outline",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Outline",
    "text": "Outline\n\nNormal Model\nPredictive Distributions\nPrior Predictive; useful for prior elicitation\nPosterior Predictive; predicting/forecasting future events\nComparing Estimators"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#normal-model-setup",
    "href": "resources/slides/03-normal-predictive-distributions.html#normal-model-setup",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Normal Model Setup",
    "text": "Normal Model Setup\n\nSuppose we have independent observations \\[\\mathbf{y} = (y_1,y_2,\\ldots,y_n)^T\\] where each \\(Y_i \\mid \\theta, \\sigma^2 \\stackrel{iid}{\\sim} \\textsf{N}(\\theta, \\sigma^2)\\)\nWe will see that it is more convenient to work with \\(\\tau = 1/\\sigma^2\\) (precision)\nreparameterizing the model for the data we have \\[Y_i \\mid \\theta, \\tau  \\sim \\mathcal{N}(\\theta, \\tau^{-1})\\]\nfor simplicity we will treat \\(\\tau\\) as known initially.\nNeed to specify a prior for \\(\\theta\\) on \\(\\mathbb{R}\\)"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#prior-for-a-normal-mean",
    "href": "resources/slides/03-normal-predictive-distributions.html#prior-for-a-normal-mean",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Prior for a Normal Mean",
    "text": "Prior for a Normal Mean\n\nNatural choice is a Normal/Gaussian distribution (Conjugate prior) \\[\\theta \\sim \\textsf{N}(\\theta_0, 1/\\tau_0)\\]\n\\(\\theta_0\\) is the prior mean - best guess for \\(\\theta\\) using information other than \\(\\mathbf{y}\\)\n\\(\\tau_0\\) is the prior precision and expresses our certainty about this guess\none notion of non-informative is to let \\(\\tau_0 \\to 0\\)\nbetter justification is as Jeffreys’ prior (uniform measure)\n\\(\\pi(\\theta) \\propto 1\\)\nparameterization invariant and invariant to location/scale changes in the data (group invariance)\n\n\n\n\n\n\n\n\nExercise for the Energetic Student\n\n\nYou should be able to derive Jeffreys prior!"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#posterior-distribution-1-observaton",
    "href": "resources/slides/03-normal-predictive-distributions.html#posterior-distribution-1-observaton",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Posterior Distribution (1 observaton)",
    "text": "Posterior Distribution (1 observaton)\n\nPosterior \\[p(\\theta \\mid y) \\propto \\exp\\left\\{- \\frac 1 2 [\\tau (y - \\theta) ^2 + \\tau_0(\\theta - \\theta_0) ^2 \\right\\} \\, d\\theta\\]\nQuadratic in exponential term: \\(\\tau_0(\\theta - \\theta_0)^2 = \\tau_0 \\theta^2 - 2 \\tau_0 \\theta_0 \\theta + \\tau_0 \\theta_0^2\\)\n\nExpand quadratics, regroup and read off precision from quadtric term in \\(\\theta\\) and mean from linear term in \\(\\theta\\)\n\nposterior precision is the sum of prior precision and data precision \\(\\tau_0 + \\tau\\)\nposterior mean \\(\\hat{\\theta} = \\frac{\\tau_0} {\\tau_0 + \\tau} \\theta_0 + \\frac{\\tau}{\\tau_0 + \\tau} y\\); precision weighted average of prior mean and MLE\nconjugate family updating \\(\\theta \\mid y \\sim \\textsf{N} \\left(\\hat{\\theta}, \\frac{1}{\\tau_0 + \\tau} \\right)\\)"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#marginal-distribution",
    "href": "resources/slides/03-normal-predictive-distributions.html#marginal-distribution",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Marginal Distribution",
    "text": "Marginal Distribution\n\nRecall that the marginal distribution is \\[p({y}) = p(y_1,\\ldots,y_n) = \\int_\\Theta p(y_1,\\ldots,y_n \\mid \\theta) \\pi(\\theta)\\, d\\theta\\]\nthis is also called the prior predictive distribution and is independent of any unknown parameters\nWe may care about making predictions before we even see any data.\nThis is often useful as a way to see if the sampling distribution or prior we have chosen is appropriate, after integrating out all unknown parameters."
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#prior-predictive-for-a-single-case",
    "href": "resources/slides/03-normal-predictive-distributions.html#prior-predictive-for-a-single-case",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Prior Predictive for a Single Case",
    "text": "Prior Predictive for a Single Case\n\\[\\begin{split} p(y) & \\propto \\int_\\mathbb{R} p(y \\mid \\theta) \\pi(\\theta) \\, d\\theta \\\\\n& \\propto \\int_\\mathbb{R}\\exp\\left\\{- \\frac 1 2 \\tau (y - \\theta) ^2 \\right\\} \\exp\\left\\{-  \\frac 1 2 \\tau_0(\\theta - \\theta_0) ^2 \\right\\} \\, d\\theta\n\\end{split}\\]\n\n\n\nIntegration\n\nExpand quadratics in exp terms\nGroup terms with \\(\\theta^2\\) and \\(\\theta\\)\nRead off posterior precision and\nposterior mean\nComplete the square\nIntegrate out \\(\\theta\\) to obtain marginal!\n\n\n\nLinear combinations of Normals are Normal! \\[Y \\stackrel{D}{=} \\theta + \\epsilon, \\quad \\epsilon \\sim N(0, 1/\\tau) \\quad \\theta \\sim N(\\theta_0, 1/\\tau_0)\\]\nFind Mean of sum\nFind Variance of sum\nMarginal \\(Y \\sim N(\\theta_0, 1/\\tau_0 + 1/\\tau)\\)"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#prior-predictive",
    "href": "resources/slides/03-normal-predictive-distributions.html#prior-predictive",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Prior Predictive",
    "text": "Prior Predictive\n\nmarginal distribution for \\(Y\\) (prior predictive) \\[Y \\sim \\textsf{N}\\left(\\theta_0, \\frac{1}{\\tau_0} + \\frac{1}{\\tau}\\right) \\text{ or } \\textsf{N}(\\theta_0, \\sigma^2 + \\sigma^2_0)\\]\ntwo sources of variability: data variability and prior variability\nuseful to think about observable quantities when choosing the prior\nsample directly from the prior predictive and assess whether the samples are consistent with our prior knowledge\nif not, go back and modify the prior & repeat\nsequential substitution sampling (repeat \\(T\\) times)\n\ndraw \\(\\theta^{(t)} \\sim \\pi(\\theta)\\)\ndraw \\(y^{(t)} \\mid \\theta^{(t)} \\sim p(y \\mid \\theta^{(t)})\\)\n\ntakes into account uncertain about \\(\\theta\\) and variability in \\(Y\\)!"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#posterior-updating",
    "href": "resources/slides/03-normal-predictive-distributions.html#posterior-updating",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Posterior Updating",
    "text": "Posterior Updating\n\nSequential updating using the previous result as our prior!\nNew prior after seeing 1 observation is \\[\\textsf{N}(\\theta_1, 1/\\tau_1)\\]\nprior mean weighted average \\[\\theta_1 \\equiv \\frac{\\tau_0 \\theta_0 + \\tau y_1}{\\tau_0 + \\tau_1}\\]\nprior precision after 1 observation \\[\\tau_1 \\equiv \\tau_0 + \\tau\\]\nprior variance is now \\(\\sigma^2_1 = 1/\\tau_1\\)"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#posterior-predictive-for-y_2-given-y_1",
    "href": "resources/slides/03-normal-predictive-distributions.html#posterior-predictive-for-y_2-given-y_1",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Posterior Predictive for \\(y_2\\) given \\(y_1\\)",
    "text": "Posterior Predictive for \\(y_2\\) given \\(y_1\\)\n\nConditional \\(p(y_2 \\mid y_1) = p(y_2, y_1)/p(y_1)\\) (Hard way!)\nUse latent variable representation \\[p(y_2 \\mid y_1) = \\int_\\Theta \\frac{p(y_2, \\mid \\theta) p( y_1 \\mid \\theta ) \\pi(\\theta) \\, d\\theta}{p(y_1)}\\]\nsimplify to previous problem and use results \\[p(y_2 \\mid y_1) =  \\int_\\Theta p(y_2 \\mid \\theta) \\pi(\\theta \\mid y_1) \\, d\\theta\\]\n(Posterior) Predictive \\[Y_2 \\mid y_1 \\sim \\textsf{N}(\\theta_1, \\sigma^2 + \\sigma^2_1)\\]"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#iterated-expectations",
    "href": "resources/slides/03-normal-predictive-distributions.html#iterated-expectations",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Iterated Expectations",
    "text": "Iterated Expectations\nBased on expressions we have an exponential of a quadratic in \\(y_2\\) so know that distribution is Gaussian\n\nFind the mean and variance using iterated expectations:\nmean \\[\\textsf{E}[Y_2 \\mid y_1] = \\textsf{E}_{\\theta \\mid y_1}[\\textsf{E}_{Y_2 \\mid y_1, \\theta} [Y_2 \\mid y_1, \\theta] \\mid y_1]\\]\nConditional Variance \\(\\textsf{Var}[Y_2 \\mid y_1]\\)\nIterated expectations (prove!) \\[\\textsf{Var}[Y_2  \\mid y_1] = \\textsf{E}_{\\theta \\mid y_1}[\\textsf{Var}_{Y_2 \\mid y_1, \\theta} [Y_2 \\mid y_1, \\theta] \\mid y_1] + \\textsf{Var}_{\\theta \\mid y_1}[\\textsf{E}_{Y_2 \\mid y_1, \\theta} [Y_2 \\mid y_1, \\theta] \\mid y_1]\\]"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#updated-posterior-for-theta",
    "href": "resources/slides/03-normal-predictive-distributions.html#updated-posterior-for-theta",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Updated Posterior for \\(\\theta\\)",
    "text": "Updated Posterior for \\(\\theta\\)\n\\[p(\\theta \\mid y_1, y_2) \\propto p(y_2 \\mid \\theta) p(y_1 \\mid \\theta) \\pi(\\theta)\\]\n\\[p(\\theta \\mid y_1, y_2) \\propto  p(y_2 \\mid \\theta) p(\\theta \\mid y_1)\\]\n\nApply previous updating rules\n\nnew posterior mean \\[\\theta_2 = \\frac{\\tau_1 \\theta_1  + \\tau y_2}{\\tau_1 + \\tau} = \\frac{\\tau_0 \\theta_0 + 2 \\tau \\bar{y}}\n{\\tau_0 + 2 \\tau}\\]\nnew precision \\[ \\tau_2 = \\tau_1 + \\tau = \\tau_0 + 2 \\tau\\]"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#after-n-observations",
    "href": "resources/slides/03-normal-predictive-distributions.html#after-n-observations",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "After \\(n\\) observations",
    "text": "After \\(n\\) observations\n\nPosterior for \\(\\theta\\) \\[\\theta \\mid y_1, \\ldots, y_n \\sim \\textsf{N}\\left( \\frac{\\tau_0 \\theta_0 + n \\tau \\bar{y}}\n{\\tau_0 + n \\tau}, \\frac{1}{ \\tau_0 + n \\tau} \\right)\\]\nPosterior Predictive Distribution for \\(Y_{n+1}\\) \\[Y_{n+1} \\mid y_1, \\ldots, y_n \\sim \\textsf{N}\\left( \\frac{\\tau_0 \\theta_0 + n \\tau \\bar{y}}\n{\\tau_0 + n \\tau}, \\frac{1}{\\tau} + \\frac{1}{ \\tau_0 + n \\tau} \\right)\\]\nShrinkage of the MLE to the prior mean\nMore accurate estimation of \\(\\theta\\) as \\(n \\to \\infty\\) (reducible error)\nCannot reduce the error for prediction \\(Y_{n+1}\\) due to \\(\\sigma^2\\)\npredictive distribution for a next observation given everything we know - prior and likelihood"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#results-with-jeffreys-prior",
    "href": "resources/slides/03-normal-predictive-distributions.html#results-with-jeffreys-prior",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Results with Jeffreys’ Prior",
    "text": "Results with Jeffreys’ Prior\n\nWhat if \\(\\tau_0 \\to 0\\)? (or \\(\\sigma^2_0 \\to \\infty\\))\nPrior predictive \\(\\textsf{N}(\\theta_0, \\sigma^2_0 + \\sigma^2 )\\) (not proper in the limit)\nPosterior for \\(\\theta\\) (formal posterior) \\[\\theta \\mid y_1, \\ldots, y_n \\sim \\textsf{N}\\left( \\frac{\\tau_0 \\theta_0 + n \\tau \\bar{y}}\n{\\tau_0 + n \\tau}, \\frac{1}{ \\tau_0 + n \\tau} \\right)\\]\n\n\n\\[\\to  \\qquad \\theta \\mid y_1, \\ldots, y_n \\sim \\textsf{N}\\left( \\bar{y},\n\\frac{1}{n \\tau} \\right)\\]\n\nRecovers the MLE as the posterior mode!\nPosterior variance of \\(\\theta = \\sigma^2/n\\) (same as variance of the MLE)"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#posterior-predictive-distribution",
    "href": "resources/slides/03-normal-predictive-distributions.html#posterior-predictive-distribution",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Posterior Predictive Distribution",
    "text": "Posterior Predictive Distribution\n\nPosterior predictive distribution for \\(Y_{n+1}\\) \\[Y_{n+1} \\mid y_1, \\ldots, y_n \\sim \\textsf{N}\\left( \\frac{\\tau_0 \\theta_0 + n \\tau \\bar{y}}\n{\\tau_0 + n \\tau}, \\frac{1}{\\tau} + \\frac{1}{ \\tau_0 + n \\tau} \\right)\\]\nUnder Jeffreys’ prior \\[Y_{n+1} \\mid y_1, \\ldots, y_n \\sim \\textsf{N}\\left( \\bar{y}, \\sigma^2 (1 + \\frac{1}{n} )\\right)\\]\nCaptures extra uncertainty due to not knowing \\(\\theta\\) (compared to plug-in approach where we plug in MLE in sampling model!"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#comparing-estimators",
    "href": "resources/slides/03-normal-predictive-distributions.html#comparing-estimators",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Comparing Estimators",
    "text": "Comparing Estimators\n\nExpected loss (from frequentist perspective) of using Bayes Estimator\nPosterior mean is optimal under squared error loss (min Bayes Risk) [also absolute error loss]\nCompute Mean Square Error (or Expected Average Loss) \\[\\textsf{E}_{\\bar{y} \\mid \\theta}\\left[\\left(\\hat{\\theta} - \\theta \\right)^2 \\mid \\theta \\right]\\]\n\n\n\\[ = \\textsf{Bias}(\\hat{\\theta})^2 + \\textsf{Var}(\\hat{\\theta})\\]\n\nFor the MLE \\(\\bar{Y}\\) this is just the variance of \\(\\bar{Y}\\) or \\(\\sigma^2/n\\)"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#mse-for-bayes",
    "href": "resources/slides/03-normal-predictive-distributions.html#mse-for-bayes",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "MSE for Bayes",
    "text": "MSE for Bayes\n\nFrequentist Risk \\[\\textsf{E}_{\\bar{y} \\mid \\theta}\\left[\\left(\\hat{\\theta} - \\theta \\right)^2 \\mid \\theta \\right] = \\textsf{MSE} =  \\textsf{Bias}(\\hat{\\theta})^2 + \\textsf{Var}(\\hat{\\theta})\\]\nBias of Bayes Estimate \\[\\textsf{E}_{\\bar{Y} \\mid \\theta}\\left[ \\frac{\\tau_0 \\theta_0 + \\tau n \\bar{Y}}\n{\\tau_0  + \\tau n}\\right] =\n\\frac{\\tau_0(\\theta_0 - \\theta)}{\\tau_0 + \\tau n}\\]\nVariance \\[\\textsf{Var}\\left(\\frac{\\tau_0 \\theta_0 + \\tau n \\bar{Y}}{\\tau_0 + \\tau n} - \\theta  \\mid \\theta \\right)  = \\frac{\\tau n}{(\\tau_0 + \\tau n)^2}\\]\n(Frequentist) expected Loss when truth is \\(\\theta\\) \\[\\textsf{MSE} = \\frac{\\tau_0^2(\\theta - \\theta_0)^2 + \\tau n}{(\\tau_0 + \\tau n)^2}\\]"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#plot",
    "href": "resources/slides/03-normal-predictive-distributions.html#plot",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Plot",
    "text": "Plot\nBehavior ?"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#updating-with-n-observations",
    "href": "resources/slides/03-normal-predictive-distributions.html#updating-with-n-observations",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Updating with \\(n\\) Observations",
    "text": "Updating with \\(n\\) Observations\n\nCan update sequentially as before -or-\nWe can use the \\(\\cal{L}(\\theta)\\) based on \\(n\\) observations and repeat completing the square with the original prior \\(\\theta \\sim \\textsf{N}(\\theta_0, 1/\\tau_0)\\)\nsame answer!\nThe likelihood for \\(\\theta\\) is proportional to the sampling model \\[p(y \\mid \\theta,\\tau)  =\n\\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi}} \\tau^{\\frac{1}{2}}  \\exp{\\left\\{-\\frac{1}{2} \\tau (y_i-\\theta)^2\\right\\}}\\]\n\n\n\n\n\n\n\n\nExercise\n\n\nRewrite in terms of sufficient statistics!"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#exercises-for-practice",
    "href": "resources/slides/03-normal-predictive-distributions.html#exercises-for-practice",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Exercises for Practice",
    "text": "Exercises for Practice\n\n\n\n\n\n\nExercise 1\n\n\nUse \\(\\cal{L}(\\theta)\\) based on \\(n\\) observations and \\(\\pi(\\theta)\\) to find \\(\\pi(\\theta \\mid y_1, \\ldots, y_n)\\) based on the sufficient statistics\n\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\nUse \\(\\pi(\\theta \\mid y_1, \\ldots, y_n)\\) to find the posterior predictive distribution for \\(Y_{n+1}\\)"
  },
  {
    "objectID": "resources/slides/03-normal-predictive-distributions.html#simplification",
    "href": "resources/slides/03-normal-predictive-distributions.html#simplification",
    "title": "The Normal Model & Prior/Posterior Predictive Distributions",
    "section": "Simplification",
    "text": "Simplification\n\\[\\begin{split}\n\\cal{L}(\\theta) & \\propto \\tau^{\\frac{n}{2}} \\ \\exp\\left\\{-\\frac{1}{2} \\tau \\sum_{i=1}^n (y_i-\\theta)^2\\right\\}\\\\\n& \\propto \\tau^{\\frac{n}{2}} \\ \\exp\\left\\{-\\frac{1}{2} \\tau \\sum_{i=1}^n \\left[ (y_i-\\bar{y}) - (\\theta - \\bar{y}) \\right]^2 \\right\\}\\\\\n\\\\\n& \\propto \\tau^{\\frac{n}{2}} \\ \\exp\\left\\{-\\frac{1}{2} \\tau \\left[ \\sum_{i=1}^n (y_i-\\bar{y})^2 + \\sum_{i=1}^n(\\theta - \\bar{y})^2 \\right] \\right\\}\\\\\n& \\propto \\tau^{\\frac{n}{2}} \\ \\exp\\left\\{-\\frac{1}{2} \\tau \\left[ \\sum_{i=1}^n (y_i-\\bar{y})^2 + n(\\theta - \\bar{y})^2 \\right] \\right\\}\\\\\n& \\propto \\tau^{\\frac{n}{2}} \\ \\exp\\left\\{-\\frac{1}{2} \\tau s^2(n-1) \\right\\} \\ \\exp\\left\\{-\\frac{1}{2} \\tau n(\\theta - \\bar{y})^2 \\right\\}\n\\end{split}\\]\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#example-from-last-class",
    "href": "resources/slides/07-adaptive-metropolis.html#example-from-last-class",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Example from Last Class",
    "text": "Example from Last Class\n\nMarginal Likelihood \\[\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu) \\propto (\\sigma^2 + \\sigma^2_\\mu)^{-n/2} \\exp \\left\\{ - \\frac{1}{2} \\frac{\\sum_{i=1}^n\\left(y_i - \\mu \\right)^2}{\\sigma^2 + \\sigma^2_\\mu }\\right\\}\\]\nPriors with \\(\\sigma^2 = 1\\): \\(p(\\mu) \\propto 1\\) and \\(\\sigma_\\mu \\sim \\textsf{Cauchy}^+(0,1)\\) independent of \\(\\mu\\)\nSymmetric proposal for \\(\\mu\\) and \\(\\sigma_\\tau\\)\nIndependent normals centered at current values of \\(\\mu\\) and \\(\\sigma_\\mu\\) with covariance \\(\\frac{2.38^2}{d} \\textsf{Cov}(\\theta)\\) where \\(d = 2\\) (the dimension of \\(\\theta\\) )\n\\(\\delta^2 = 2.38^2/d\\) optimal for multivariate normal target Roberts, Gelman, and Gilks (1997) with acceptance rate ranging from 40% to 23.4% (as \\(d \\to \\infty\\))"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#convergence-diagnostics",
    "href": "resources/slides/07-adaptive-metropolis.html#convergence-diagnostics",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Convergence diagnostics",
    "text": "Convergence diagnostics\n\nDiagnostics available to help decide on number of burn-in & collected samples.\nNote: no definitive tests of convergence but you should do as many diagnostics as you can, on all parameters in your model.\nWith “experience”, visual inspection of trace plots perhaps most useful approach.\nThere are a number of useful automated tests in R.\nCAUTION: diagnostics cannot guarantee that a chain has converged, but they can indicate it has not converged."
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#diagnostics-in-r",
    "href": "resources/slides/07-adaptive-metropolis.html#diagnostics-in-r",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Diagnostics in R",
    "text": "Diagnostics in R\n\nThe most popular package for MCMC diagnostics in R is coda.\ncoda uses a special MCMC format so you must always convert your posterior matrix into an MCMC object.\nFor the example, we have the following in R.\n\n\n\n#library(coda)\ntheta.mcmc &lt;- mcmc(theta,start=1) #no burn-in (simple problem!)"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#diagnostics-in-r-1",
    "href": "resources/slides/07-adaptive-metropolis.html#diagnostics-in-r-1",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Diagnostics in R",
    "text": "Diagnostics in R\n\nsummary(theta.mcmc)\n\n\nIterations = 1:10000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n             Mean     SD Naive SE Time-series SE\nmu       -0.07977 0.1046 0.001046       0.002839\nsigma_mu  0.17550 0.1273 0.001273       0.004397\n\n2. Quantiles for each variable:\n\n              2.5%     25%      50%      75%  97.5%\nmu       -0.283420 -0.1508 -0.08193 -0.00848 0.1337\nsigma_mu  0.007995  0.0758  0.15024  0.25228 0.4693\n\n\n\nThe naive SE is the standard error of the mean, which captures simulation error of the mean rather than the posterior uncertainty.\nThe time-series SE adjusts the naive SE for autocorrelation."
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#effective-sample-size",
    "href": "resources/slides/07-adaptive-metropolis.html#effective-sample-size",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Effective Sample Size",
    "text": "Effective Sample Size\n\nThe effective sample size translates the number of MCMC samples \\(S\\) into an equivalent number of independent samples.\nIt is defined as \\[\\textrm{ESS} = \\dfrac{S}{1 + 2 \\sum_k \\rho_k},\\]\n\\(S\\) is the sample size and \\(\\rho_k\\) is the lag \\(k\\) autocorrelation.\nFor our data, we have\n\n\n\neffectiveSize(theta.mcmc)\n\n       mu  sigma_mu \n1356.6495  838.2613 \n\n\n\nSo our 10,000 samples are equivalent to 1356.6 independent samples for \\(\\mu\\) and 838.3 independent samples for \\(\\sigma_\\mu\\)."
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#trace-plot-for-mean",
    "href": "resources/slides/07-adaptive-metropolis.html#trace-plot-for-mean",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Trace plot for mean",
    "text": "Trace plot for mean"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#trace-plot-for-sigma_mu",
    "href": "resources/slides/07-adaptive-metropolis.html#trace-plot-for-sigma_mu",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Trace plot for \\(\\sigma_\\mu\\)",
    "text": "Trace plot for \\(\\sigma_\\mu\\)\n\nOK (be careful of scaling in plots!)"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#autocorrelation",
    "href": "resources/slides/07-adaptive-metropolis.html#autocorrelation",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Autocorrelation",
    "text": "Autocorrelation\n\nAnother way to evaluate convergence is to look at the autocorrelation between draws of our Markov chain.\nThe lag \\(k\\) autocorrelation, \\(\\rho_k\\), is the correlation between each draw and its \\(k\\)th lag, defined as \\[\\rho_k = \\dfrac{\\sum_{s=1}^{S-k}(\\theta_s - \\bar{\\theta})(\\theta_{s+k} - \\bar{\\theta})}{\\sum_{s=1}^{S-k}(\\theta_s - \\bar{\\theta})^2}\\]\nWe expect the autocorrelation to decrease as \\(k\\) increases.\nIf autocorrelation remains high as \\(k\\) increases, we have slow mixing due to the inability of the sampler to move around the space well."
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#autocorrelation-for-mean",
    "href": "resources/slides/07-adaptive-metropolis.html#autocorrelation-for-mean",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Autocorrelation for mean",
    "text": "Autocorrelation for mean\n\nSo-So"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#autocorrelation-for-variance",
    "href": "resources/slides/07-adaptive-metropolis.html#autocorrelation-for-variance",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Autocorrelation for variance",
    "text": "Autocorrelation for variance\n\nworse"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#gelman-rubin",
    "href": "resources/slides/07-adaptive-metropolis.html#gelman-rubin",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Gelman-Rubin",
    "text": "Gelman-Rubin\nGelman & Rubin suggested a diagnostic \\(R\\) based on taking separate chains with dispersed initial values to test convergence"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#gelman-rubin-diagnostic",
    "href": "resources/slides/07-adaptive-metropolis.html#gelman-rubin-diagnostic",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Gelman-Rubin Diagnostic",
    "text": "Gelman-Rubin Diagnostic\n\nRun m &gt; 2 chains of length 2S from overdispersed starting values.\nDiscard the first S draws in each chain.\nCalculate the pooled within-chain variance \\(W\\) and between-chain variance \\(B\\). \\[R = \\frac{\\frac{S-1}{S} W + \\frac{1}{S} B }{W}\\]\nnumerator and denominator are both unbiased estimates of the variance if the two chains have converged\n\notherwise \\(W\\) is an underestimate (hasn’t explored enough)\nnumerator will overestimate as \\(B\\) is too large (overdispersed starting points)\n\nAs \\(S \\to \\infty\\) and \\(B \\to 0\\), \\(R \\to 1\\)\nversion in R is slightly different"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#gelman-rubin-diagnostic-1",
    "href": "resources/slides/07-adaptive-metropolis.html#gelman-rubin-diagnostic-1",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Gelman-Rubin Diagnostic",
    "text": "Gelman-Rubin Diagnostic\n\ntheta.mcmc = mcmc.list(mcmc(theta1, start=5000), mcmc(theta2, start=5000))\ngelman.diag(theta.mcmc)\n\nPotential scale reduction factors:\n\n         Point est. Upper C.I.\nmu                1          1\nsigma_mu          1          1\n\nMultivariate psrf\n\n1\n\n\n\nValues of \\(R &gt; 1.1\\) suggest lack of convergence\nLooks OK\nSee also gelman.plot"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#geweke-statistic",
    "href": "resources/slides/07-adaptive-metropolis.html#geweke-statistic",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Geweke statistic",
    "text": "Geweke statistic\n\nGeweke proposed taking two non-overlapping parts of a single Markov chain (usually the first 10% and the last 50%) and comparing the mean of both parts, using a difference of means test\nThe null hypothesis would be that the two parts of the chain are from the same distribution.\nThe test statistic is a z-score with standard errors adjusted for autocorrelation, and if the p-value is significant for a variable, you need more draws.\nOutput in R is the Z score"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#geweke-diagnostic",
    "href": "resources/slides/07-adaptive-metropolis.html#geweke-diagnostic",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Geweke Diagnostic",
    "text": "Geweke Diagnostic\n\ngeweke.diag(theta.mcmc)\n\n[[1]]\n\nFraction in 1st window = 0.1\nFraction in 2nd window = 0.5 \n\n      mu sigma_mu \n -0.7779   0.7491 \n\n\n[[2]]\n\nFraction in 1st window = 0.1\nFraction in 2nd window = 0.5 \n\n      mu sigma_mu \n  0.4454   0.6377 \n\n\n\nThe output is the z-score itself (not the p-value)."
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#practical-advice-on-diagnostics",
    "href": "resources/slides/07-adaptive-metropolis.html#practical-advice-on-diagnostics",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Practical advice on diagnostics",
    "text": "Practical advice on diagnostics\n\nThere are more tests we can use: Raftery and Lewis diagnostic, Heidelberger and Welch, etc.\nThe Gelman-Rubin approach is quite appealing in using multiple chains\nGeweke (and Heidelberger and Welch) sometimes reject even when the trace plots look good.\nOverly sensitive to minor departures from stationarity that do not impact inferences.\nMost common method of assessing convergence is visual examination of trace plots."
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#improving-results",
    "href": "resources/slides/07-adaptive-metropolis.html#improving-results",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Improving Results",
    "text": "Improving Results\n\nmore iterations and multiple chains\nthinning to reduce correlations and increase ESS\nchange the proposal distribution \\(q\\)\nadaptive Metropolis to tune \\(q\\)"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#proposal-distribution",
    "href": "resources/slides/07-adaptive-metropolis.html#proposal-distribution",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Proposal Distribution",
    "text": "Proposal Distribution\n\nCommon choice \\[\\textsf{N}(\\theta^\\star; \\theta^{(s)}, \\delta^2 \\Sigma)\\]\nrough estimate of \\(\\Sigma\\) based on the asymptotic Gaussian approximation \\(\\textsf{Cov}(\\theta \\mid y)\\) and \\(\\delta = 2.38/\\sqrt{\\text{dim}(\\theta)}\\)\nfind the MAP estimate (posterior mode) \\(\\hat{\\theta}\\)\ntake \\[\\Sigma =  \\left[-\n  \\frac{\\partial^2 \\log(\\cal{L}(\\theta)) + \\log(\\pi(\\theta))}\n   {\\partial \\theta \\partial \\theta^T} \\right]^{-1}_{\\theta = \\hat{\\theta}}\\]\nignore prior and use inverse of Fisher Information (covariance of MLE)"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#learn-covariance-in-proposal",
    "href": "resources/slides/07-adaptive-metropolis.html#learn-covariance-in-proposal",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Learn Covariance in Proposal?",
    "text": "Learn Covariance in Proposal?\n\nCan we learn the proposal distribution?\nad hoc?\n\nrun an initial MCMC for an initial tuning phase (e.g. 1000 samples) with a fixed \\(\\delta\\) and estimate \\(\\Sigma(\\theta)\\) from samples.\n\nrun more to tweak \\(\\delta\\) to get acceptance rate between \\(23\\%-40\\%\\).\nfix the kernel for final run\n\nMCMC doesn’t allow you to use the full history of the chain \\(\\theta^{(1)}, \\ldots, \\theta^{(s)}\\) in constructing the proposal distributions as it violates the Markov assumption\neven with no further “learning”, no guarantee we will converge to posterior!\nmore elegant approach - formal adaptive Metropolis\n\nkeep adapting the entire time!\n\n\n\n\n\n\n\n\n\nad hoc adaptation may mess up convergence !"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#adaptive-mcmc",
    "href": "resources/slides/07-adaptive-metropolis.html#adaptive-mcmc",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Adaptive MCMC",
    "text": "Adaptive MCMC\n\nrun RWM with a Gaussian proposal for a fixed number of iterations for \\(s &lt; s_0\\)\nestimate of covariance at state \\(s\\) \\[\\Sigma^{(s)} = \\frac{1}{s}\\left(\\sum_{i=1}^s \\theta^{(i)} {\\theta^{(i)}}^T -\ns \\bar{\\theta}^{(s)} {\\bar{\\theta}^{(s)}}^T\\right)\\]\nproposal for \\(s &gt; s_0\\) with \\(\\delta = 2.38/\\sqrt{d}\\) \\[\\theta^* \\sim \\textsf{N}(\\theta^{(s)}, \\delta^2 (\\Sigma^{(s)} + \\epsilon I_d))\\]\n\\(\\epsilon &gt; 0\\) insures covariance is positive definite\nif \\(s_0\\) is too large will take longer for adaptation to be seen\nneed conditions for vanishing adaptation e.g. that the proposal depends less and less on recent states in the chain - see Roberts & Rosenthal (2009)for examples and other conditions"
  },
  {
    "objectID": "resources/slides/07-adaptive-metropolis.html#example-again",
    "href": "resources/slides/07-adaptive-metropolis.html#example-again",
    "title": "Lecture 7: MCMC Diagnostics & Adaptive Metropolis",
    "section": "Example again",
    "text": "Example again\n\n\n\n\n\n\n\n\n\nAcceptance rate now around 30-35 % of 10,000 iterations!\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/template.html",
    "href": "resources/slides/template.html",
    "title": "STA 702 Fall 2023",
    "section": "",
    "text": "subtitle: “STA 702: Lecture ?” title: “template” author: “Merlise Clyde” institute: “Duke University” format: revealjs: theme: [simple, custom.scss] slide-number: true incremental: true scrollable: false controls: true fragments: true preview-links: auto logo: ../../img/icon.png footer: https://sta702-F23.github.io/website/ chalkboard: boardmarker-width: 1 chalk-width: 2 chalk-effect: 0 embed-resources: false html-math-method: method: mathjax url: “https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js”\neditor: markdown: wrap: 72 execute: echo: false"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#uses-of-posterior-predictive",
    "href": "resources/slides/04-predictive-checks.html#uses-of-posterior-predictive",
    "title": "Prior/Posterior Checks",
    "section": "Uses of Posterior Predictive",
    "text": "Uses of Posterior Predictive\n\nPlot the entire density or summarize\nAvailable analytically for conjugate families\nMonte Carlo Approximation \\[p(y_{n+1} \\mid y_1, \\ldots y_n) \\approx \\frac 1 T \\sum_{t = 1}^T  p(y_{n+1} \\mid \\theta^{(t)})\\] where \\(\\theta^{(t)} \\sim \\pi(\\theta \\mid y_1, \\ldots y_n)\\) for \\(t = 1, \\ldots, T\\)\nT samples from the posterior distribution\nEmpirical Estimates & Quantiles from Monte Carlo Samples"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#models",
    "href": "resources/slides/04-predictive-checks.html#models",
    "title": "Prior/Posterior Checks",
    "section": "Models",
    "text": "Models\n\nSo far this all assumes we have a correct sampling model and a “reasonable” prior distrbution\nGeorge Box: All models are wrong but some are useful\n“Useful” \\(\\rightarrow\\) model provides a good approximation; there aren’t clear aspects of the data that are ignored or misspecified\nhow can we decide if a model is misspecified and needs to change?"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#example",
    "href": "resources/slides/04-predictive-checks.html#example",
    "title": "Prior/Posterior Checks",
    "section": "Example",
    "text": "Example\n\nPoisson model \\[Y_i  \\mid \\theta \\stackrel{iid}{\\sim }\\textsf{Poisson}(\\theta) \\qquad i = 1, \\ldots, n\\]\nHow might our model be misspecified?\n\nPoisson assumes that \\(\\textsf{E}(Y_i) = \\textsf{Var}(Y_i) = \\theta\\)\nit’s very common for data to be over-dispersed \\(\\textsf{E}(Y_i) &lt; \\textsf{Var}(Y_i)\\)\nignored additional structure in the data, i.e. data are not iid\nzero-inflation many more zero values than consistent with the poisson model"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#posterior-predictive-checks",
    "href": "resources/slides/04-predictive-checks.html#posterior-predictive-checks",
    "title": "Prior/Posterior Checks",
    "section": "Posterior Predictive Checks",
    "text": "Posterior Predictive Checks\n\nGuttman (1967), Rubin (1984) proposed the use of Posterior Predictive Checks (PPC)] for model criticism; further developed by Gelman et al (1996)\nthe spirit of posterior predictive checks is that “If my model is good, then its posterior predictive distribution will generate data that look like my oberved data”\n\\(y^{\\text{obs}}\\) is the observed data\n\\(y^{\\text{rep}}\\) is a new dataset sampled from the posterior predictive \\(p(y^{\\text{rep}} \\mid y^{\\text{obs}})\\) of size \\(n\\) (same size as the observed)\nUse a diagnostic statistic \\(d(y)\\) to capture some feature of the data that the model may fail to capture, say variance\ncompare \\(d(y^{\\text{obs}})\\) to the reference distribution of \\(d(y^{\\text{rep}})\\)\nUse Posterior Predictive P-value as a summary \\[ p_{PPC} = P(d(y^{\\text{obs}}) &gt; d(y^{\\text{rep}}) \\mid y^{\\text{obs}})\n\\]"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#formally",
    "href": "resources/slides/04-predictive-checks.html#formally",
    "title": "Prior/Posterior Checks",
    "section": "Formally",
    "text": "Formally\n\nchoose a “diagnostic statistic” \\(d(\\cdot)\\) that captures some summary of the data, e.g. \\(\\textsf{Var}(y)\\) for over-dispersion, where large values of the statistic would be surprising if the model were correct.\n\\(d(y^{\\text{obs}}) \\equiv d_{\\textrm{obs}}\\) value of statistic in observed data\n\\(d(y^{\\text{rep}}_t) \\equiv d_{\\textrm{pred}}\\) value of statistic for the \\(t\\)th random dataset drawn from the posterior predictive distribution\n\nGenerate \\(\\theta_t \\stackrel{iid}{\\sim}p(\\theta \\mid y^{\\textrm{obs}})\\)\nGenerate \\(y^{\\textrm{rep}_t} \\mid \\theta_t \\stackrel{iid}{\\sim} p(y \\mid \\theta_t)\\)\nCalculate \\(d(y^{\\text{rep}}_t)\\)\n\nplot posterior predictive distribution of \\(d(y^{\\text{rep}}_t)\\) and add \\(d_{\\textrm{obs}}\\)\nHow extreme is \\(t_{\\textrm{obs}}\\) compared to the distribution of \\(d(y^{\\text{rep}})\\)?\ncompute p-value \\(p_{PPC} = \\frac 1 T \\sum_t I(d(y^{\\text{obs}}) &gt; d(y^{\\text{rep}}_t))\\)"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#example-with-over-dispersion",
    "href": "resources/slides/04-predictive-checks.html#example-with-over-dispersion",
    "title": "Prior/Posterior Checks",
    "section": "Example with Over Dispersion",
    "text": "Example with Over Dispersion\n\n\n\nn = 100; phi = 1; mu = 5\ntheta.t = rgamma(n,phi,phi/mu)\ny = rpois(n, theta.t)\na = 1; b = 1;\nt.obs = var(y)\n\nnT = 10000\nt.pred = rep(NA, nT)\nfor (t in 1:nT) {\n  theta.post = rgamma(1, a + sum(y),\n                         b + n)\n  y.pred = rpois(n, theta.post)\n  t.pred[t] = var(y.pred)\n}\n\nhist(t.pred, \n     xlim = range(c(t.pred, t.obs)),\n     xlab=\"var\", \n     main=\"Posterior Predictive Distribution\")\n\nabline(v = t.obs, col=\"red\")"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#zero-inflated-distribution",
    "href": "resources/slides/04-predictive-checks.html#zero-inflated-distribution",
    "title": "Prior/Posterior Checks",
    "section": "Zero Inflated Distribution",
    "text": "Zero Inflated Distribution\n\n\n\n\n\n\n\n\n\n\n\n\nR Code to generate zero inflated\n\nn = 1000\nmu = 5; phi = 1\ntheta.t = rgamma(n,phi,phi/mu)\nz = rbinom(n, 1, .90)\ny = rpois(n, theta.t)*z\n\n\nLet the \\(d()\\) be the proportion of zeros in the sample \\[\\begin{aligned}\nd(y) & = \\frac{\\sum_{i = 1}^{n}1(y_i = 0)}{n} \\\\\n   & = 0.24\n\\end{aligned}\\]"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#posterior-predictive-distribution",
    "href": "resources/slides/04-predictive-checks.html#posterior-predictive-distribution",
    "title": "Prior/Posterior Checks",
    "section": "Posterior Predictive Distribution",
    "text": "Posterior Predictive Distribution"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#posterior-predictive-p-values-ppps",
    "href": "resources/slides/04-predictive-checks.html#posterior-predictive-p-values-ppps",
    "title": "Prior/Posterior Checks",
    "section": "Posterior Predictive p-values (PPPs)",
    "text": "Posterior Predictive p-values (PPPs)\n\np-value is probability of seeing something as extreme or more so under a hypothetical “null” model\nfrom a frequentist perspect, one appealing property of p-values is that they should be uniformally distributed under the “null” model\nPPPs advocated by Gelman & Rubin in papers and BDA are not valid p-values generally. They are do not have a uniform distribution under the hypothesis that the model is correctly specified\nthe PPPs tend to be concentrated around 0.5, tend not to reject (conservative)\ntheoretical reason for the incorrect distribution is due to double use of the data\nDO NOT USE as a formal test! use as a diagnostic plot to see how model might fall flat, but be cautious!"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#example-bivariate-normal",
    "href": "resources/slides/04-predictive-checks.html#example-bivariate-normal",
    "title": "Prior/Posterior Checks",
    "section": "Example: Bivariate Normal",
    "text": "Example: Bivariate Normal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPPP = 0.52\nWhat’s happening?"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#problems-with-ppc",
    "href": "resources/slides/04-predictive-checks.html#problems-with-ppc",
    "title": "Prior/Posterior Checks",
    "section": "Problems with PPC",
    "text": "Problems with PPC\n\nBayarri & Berger (2000) provides more discussion about why PPP are not always calibrated\nDouble use of the data; \\(Y^{\\text{rep}}\\) depends on the observed diagnostic in last case\nBayarri & Berger propose partial predictive p-values and conditional predictive p-values that avoid double use of the data by “removing” the contribution of \\(d_{\\text{obs}}\\) to the posterior for \\(\\theta\\) or conditioning on a statistic, such as the MLE of \\(\\theta\\)\nheuristically, need the diagnostic to be independent of posterior for \\(\\theta\\) (asymptoptically) under the assumed model\nnot always easy to find!\nMoran et al (2022) propose a workaround to avoid double use of the data by spliting the data \\(y_{\\text{obs}}, y_{\\text{new}}\\), use \\(y_{\\text{obs}}\\), to learn \\(\\theta\\) and the other to calculate \\(d_{\\textrm{new}}\\)\ncan be calculated via simulation easily"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#pop-pc-of-moran-et-al",
    "href": "resources/slides/04-predictive-checks.html#pop-pc-of-moran-et-al",
    "title": "Prior/Posterior Checks",
    "section": "POP-PC of Moran et al",
    "text": "POP-PC of Moran et al\n\n\nPOP-PPC = 0.35"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#modeling-over-dispersion",
    "href": "resources/slides/04-predictive-checks.html#modeling-over-dispersion",
    "title": "Prior/Posterior Checks",
    "section": "Modeling Over-Dispersion",
    "text": "Modeling Over-Dispersion\n\nOriginal Model \\(Y_i \\mid \\theta \\sim \\textsf{Poisson}(\\theta)\\)\ncause of overdispersion is variation in the rate \\[ Y_i \\mid \\theta_i \\sim \\textsf{Poisson}(\\theta_i)\\]\nmodel variation via prior \\[\\theta_i \\sim \\pi_\\theta()\\]\n\\(\\pi_\\theta()\\) characterizes variation in the rate parameter across inviduals\nSimple Two Stage Hierarchical Model"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#modeling-perspectives",
    "href": "resources/slides/04-predictive-checks.html#modeling-perspectives",
    "title": "Prior/Posterior Checks",
    "section": "Modeling Perspectives",
    "text": "Modeling Perspectives\n\n\n\nstart with a simple model\n\n\nask if there are surprises through Posterior Checks\nneed calibrated diagnostic(s) with good power\nneed these to work even if starting model is relatively complex\nother informal diagnostics (residuals)\nremodel if needed based on departures\nBayesian meaning?\n\n\n\nstart with a fairly complex model or models\n\n\nshrinkage to prevent overfitting\nformal tests for simplifying models\nmethods to combine multiple models to express uncertaity\nproperties"
  },
  {
    "objectID": "resources/slides/04-predictive-checks.html#example-1",
    "href": "resources/slides/04-predictive-checks.html#example-1",
    "title": "Prior/Posterior Checks",
    "section": "Example",
    "text": "Example\n\\[\\theta_i \\sim \\textsf{Gamma}(\\phi \\mu, \\phi)\\]\n\nFind pmf for \\(Y_i \\mid \\mu, \\phi\\)\nFind \\(\\textsf{E}[Y_i \\mid \\mu, \\phi]\\) and \\(\\textsf{Var}[Y_i \\mid \\mu, \\phi]\\)\nHomework: \\[\\theta_i \\sim \\textsf{Gamma}(\\phi, \\phi/\\mu)\\]\nCan either of these model zero-inflation?\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/12-priors-regression.html#conjugate-priors-in-linear-regression",
    "href": "resources/slides/12-priors-regression.html#conjugate-priors-in-linear-regression",
    "title": "Lecture 12: Choice of Priors in Regression",
    "section": "Conjugate Priors in Linear Regression",
    "text": "Conjugate Priors in Linear Regression\n\nRegression Model (Sampling model) \\[\\mathbf{Y}\\mid \\boldsymbol{\\beta}, \\phi  \\sim \\textsf{N}(\\mathbf{X}\\boldsymbol{\\beta}, \\phi^{-1} \\mathbf{I}_n)\n\\]\nConjugate Normal-Gamma Model: factor joint prior \\(p(\\boldsymbol{\\beta}, \\phi ) = p(\\boldsymbol{\\beta}\\mid \\phi)p(\\phi)\\) \\[\\begin{align*}\n\\boldsymbol{\\beta}\\mid \\phi & \\sim \\textsf{N}(\\mathbf{b}_0, \\phi^{-1}\\boldsymbol{\\Phi}_0^{-1}) & p(\\boldsymbol{\\beta}\\mid \\phi) & = \\frac{|\\phi \\boldsymbol{\\Phi}_0|^{1/2}}{(2 \\pi)^{p/2}}e^{\\left\\{- \\frac{\\phi}{2}(\\boldsymbol{\\beta}- \\mathbf{b}_0)^T \\boldsymbol{\\Phi}_0 (\\boldsymbol{\\beta}- \\mathbf{b}_0)  \\right\\}}\\\\\n\\phi & \\sim \\textsf{Gamma}(v_0/2, \\textsf{SS}_0/2)  & p(\\phi) & = \\frac{1}{\\Gamma{(\\nu_0/2)}}\n\\left(\\frac{\\textsf{SS}_0}{2} \\right)^{\\nu_0/2}\n\\phi^{\\nu_0/2 - 1}\ne^{- \\phi \\frac{\\textsf{SS}_0}{2}}\\\\\n\\Rightarrow (\\boldsymbol{\\beta}, \\phi) & \\sim \\textsf{NG}(\\mathbf{b}_0, \\boldsymbol{\\Phi}_0, \\nu_o, \\textsf{SS}_0)\n\\end{align*}\\]\nNeed to specify the 4 hyperparameters of the Normal-Gamma distribution!\nhard in higher dimensions!"
  },
  {
    "objectID": "resources/slides/12-priors-regression.html#choice-of-conjugate-prior",
    "href": "resources/slides/12-priors-regression.html#choice-of-conjugate-prior",
    "title": "Lecture 12: Choice of Priors in Regression",
    "section": "Choice of Conjugate Prior",
    "text": "Choice of Conjugate Prior\nSeek default choices\n\nJeffreys’ prior\nunit-information prior\nZellner’s g-prior\nridge regression priors\nmixtures of conjugate priors\n\nZellner-Siow Cauchy Prior\n(Bayesian) Lasso\nHorseshoe\n\n\n\nWhich? Why?"
  },
  {
    "objectID": "resources/slides/12-priors-regression.html#jeffreys-prior",
    "href": "resources/slides/12-priors-regression.html#jeffreys-prior",
    "title": "Lecture 12: Choice of Priors in Regression",
    "section": "Jeffreys’ Prior",
    "text": "Jeffreys’ Prior\n\nJeffreys prior is invariant to model parameterization of \\(\\boldsymbol{\\theta}= (\\boldsymbol{\\beta},\\phi)\\) \\[p(\\boldsymbol{\\theta}) \\propto |{\\cal{I}}(\\boldsymbol{\\theta})|^{1/2}\\]\n\\({\\cal{I}}(\\boldsymbol{\\theta})\\) is the Expected Fisher Information matrix \\[{\\cal{I}}(\\theta) = - \\textsf{E}[ \\left[ \\frac{\\partial^2 \\log({\\cal{L}}(\\boldsymbol{\\theta}))}{\\partial\n\\theta_i \\partial \\theta_j} \\right] ]\\]\nlog likelihood expressed as function of sufficient statistics\n\n\n\\[\\log({\\cal{L}}(\\boldsymbol{\\beta}, \\phi))  =  \\frac{n}{2} \\log(\\phi)  - \\frac{\\phi}{2} \\| (\\mathbf{I}_n - \\mathbf{P}_\\mathbf{x}) \\mathbf{Y}\\|^2\n- \\frac{\\phi}{2}(\\boldsymbol{\\beta}- \\hat{\\boldsymbol{\\beta}})^T(\\mathbf{X}^T\\mathbf{X})(\\boldsymbol{\\beta}- \\hat{\\boldsymbol{\\beta}})\\]\n\nprojection \\(\\mathbf{P}_{\\mathbf{X}} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T\\) onto the column space of \\(\\mathbf{X}\\)"
  },
  {
    "objectID": "resources/slides/12-priors-regression.html#information-matrix",
    "href": "resources/slides/12-priors-regression.html#information-matrix",
    "title": "Lecture 12: Choice of Priors in Regression",
    "section": "Information matrix",
    "text": "Information matrix\n\\[\\begin{eqnarray*}\n\\frac{\\partial^2 \\log {\\cal{L}}} { \\partial \\boldsymbol{\\theta}\\partial \\boldsymbol{\\theta}^T} & = &\n\\left[\n  \\begin{array}{cc}\n    -\\phi (\\mathbf{X}^T\\mathbf{X}) & -(\\mathbf{X}^T\\mathbf{X}) (\\boldsymbol{\\beta}- \\hat{\\boldsymbol{\\beta}}) \\\\\n  - (\\boldsymbol{\\beta}- \\hat{\\boldsymbol{\\beta}})^T (\\mathbf{X}^T\\mathbf{X}) & -\\frac{n}{2} \\frac{1}{\\phi^2} \\\\\n  \\end{array}\n\\right] \\\\\n\\textsf{E}[\\frac{\\partial^2 \\log {\\cal{L}}} { \\partial \\boldsymbol{\\theta}\\partial \\boldsymbol{\\theta}^T}] & = &\n\\left[\n  \\begin{array}{cc}\n    -\\phi (\\mathbf{X}^T\\mathbf{X}) & \\mathbf{0}_p \\\\\n  \\mathbf{0}_p^T & -\\frac{n}{2} \\frac{1}{\\phi^2} \\\\\n  \\end{array}\n\\right] \\\\\n& & \\\\\n{\\cal{I}}((\\boldsymbol{\\beta}, \\phi)^T) & = & \\left[\n  \\begin{array}{cc}\n    \\phi (\\mathbf{X}^T\\mathbf{X}) & \\mathbf{0}_p \\\\\n  \\mathbf{0}_p^T & \\frac{n}{2} \\frac{1}{\\phi^2}\n  \\end{array}\n\\right]\n  \\end{eqnarray*}\\]\n\n\\[\\begin{eqnarray*}\n  p_J(\\boldsymbol{\\beta}, \\phi)  & \\propto & |{\\cal{I}}((\\boldsymbol{\\beta}, \\phi)^T) |^{1/2}   \n                =  |\\phi \\mathbf{X}^T\\mathbf{X}|^{1/2} \\left(\\frac{n}{2}\n                 \\frac{1}{\\phi^2} \\right)^{1/2}\n  \\propto    \\phi^{p/2 - 1} |\\mathbf{X}^T\\mathbf{X}|^{1/2} \\\\\n  & \\propto & \\phi^{p/2 - 1}  \n  \\end{eqnarray*}\\]\n\n\nJeffreys’ did not recommend - marginal for \\(\\phi\\) dies not account for dimension \\(p\\)"
  },
  {
    "objectID": "resources/slides/12-priors-regression.html#recommended-independent-jeffreys-prior",
    "href": "resources/slides/12-priors-regression.html#recommended-independent-jeffreys-prior",
    "title": "Lecture 12: Choice of Priors in Regression",
    "section": "Recommended Independent Jeffreys Prior",
    "text": "Recommended Independent Jeffreys Prior\n\nTreat \\(\\boldsymbol{\\beta}\\) and \\(\\phi\\) separately (orthogonal parameterization which implies asymptoptic independence of \\(\\boldsymbol{\\beta}\\) and \\(\\phi\\))\n\\(p_{IJ}(\\boldsymbol{\\beta}) \\propto |{\\cal{I}}(\\boldsymbol{\\beta})|^{1/2}\\) and \\(p_{IJ}(\\phi) \\propto |{\\cal{I}}(\\phi)|^{1/2}\\)\n\n\n\\[\n{\\cal{I}}((\\boldsymbol{\\beta}, \\phi)^T)  =  \\left[\n  \\begin{array}{cc}\n    \\phi (\\mathbf{X}^T\\mathbf{X}) & \\mathbf{0}_p \\\\\n  \\mathbf{0}_p^T & \\frac{n}{2} \\frac{1}{\\phi^2}\n  \\end{array}\n\\right]\n\\]\n\n\n\\[\\begin{align*} p_{IJ}(\\boldsymbol{\\beta}) & \\propto |\\phi \\mathbf{X}^T\\mathbf{X}|^{1/2} \\propto 1 \\\\\n               p_{IJ}(\\phi) & \\propto \\phi^{-1} \\\\\n               p_{IJ}(\\beta, \\phi) & \\propto p_{IJ}(\\boldsymbol{\\beta}) p_{IJ}(\\phi) = \\phi^{-1}\n\\end{align*}\\]\n\n\nTwo group reference prior"
  },
  {
    "objectID": "resources/slides/12-priors-regression.html#formal-posterior-distribution",
    "href": "resources/slides/12-priors-regression.html#formal-posterior-distribution",
    "title": "Lecture 12: Choice of Priors in Regression",
    "section": "Formal Posterior Distribution",
    "text": "Formal Posterior Distribution\n\nUse Independent Jeffreys Prior \\(p_{IJ}(\\beta, \\phi) \\propto p_{IJ}(\\boldsymbol{\\beta}) p_{IJ}(\\phi) = \\phi^{-1}\\)\nFormal Posterior Distribution \\[\\begin{eqnarray*}\n\\boldsymbol{\\beta}\\mid \\phi, \\mathbf{Y}& \\sim & \\textsf{N}(\\hat{\\boldsymbol{\\beta}}, (\\mathbf{X}^T\\mathbf{X})^{-1} \\phi^{-1})  \\\\\n\\phi \\mid \\mathbf{Y}& \\sim& \\textsf{Gamma}((n-p)/2, \\| \\mathbf{Y}- \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\\|^2/2) \\\\\n\\boldsymbol{\\beta}\\mid \\mathbf{Y}& \\sim & t_{n-p}(\\hat{\\boldsymbol{\\beta}}, {\\hat{\\sigma}}^2(\\mathbf{X}^T\\mathbf{X})^{-1})\n\\end{eqnarray*}\\]\nBayesian Credible Sets \\(p(\\boldsymbol{\\beta}\\in C_\\alpha\\mid \\mathbf{Y}) = 1- \\alpha\\) correspond to frequentist Confidence Regions \\[\\frac{\\mathbf{x}^T\\boldsymbol{\\beta}- \\mathbf{x}^T \\hat{\\boldsymbol{\\beta}}} {\\sqrt{{\\hat{\\sigma}}^2\\mathbf{x}^T(\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{x}} }\\sim t_{n-p}\\]\nconditional on \\(\\mathbf{Y}\\) for Bayes and conditional on \\(\\boldsymbol{\\beta}\\) for frequentist"
  },
  {
    "objectID": "resources/slides/12-priors-regression.html#unit-information-prior",
    "href": "resources/slides/12-priors-regression.html#unit-information-prior",
    "title": "Lecture 12: Choice of Priors in Regression",
    "section": "Unit Information Prior",
    "text": "Unit Information Prior\nUnit information prior \\(\\boldsymbol{\\beta}\\mid \\phi \\sim \\textsf{N}(\\hat{\\boldsymbol{\\beta}}, n  (\\mathbf{X}^T\\mathbf{X})^{-1}/\\phi)\\)\n\nBased on a fraction of the likelihood \\(p(\\boldsymbol{\\beta},\\phi) \\propto {\\cal{L}}(\\boldsymbol{\\beta}, \\phi)^{1/n}\\)\n\n\n\\[\\log(p(\\boldsymbol{\\beta}, \\phi) \\propto  \\frac{1}{n}\\frac{n}{2} \\log(\\phi)  - \\frac{\\phi}{2} \\frac{\\| (\\mathbf{I}_n - \\mathbf{P}_\\mathbf{x}) \\mathbf{Y}\\|^2}{n}\n- \\frac{\\phi}{2}(\\boldsymbol{\\beta}- \\hat{\\boldsymbol{\\beta}})^T\\frac{(\\mathbf{X}^T\\mathbf{X})}{n}(\\boldsymbol{\\beta}- \\hat{\\boldsymbol{\\beta}})\\]\n\n``average information’’ in one observation is \\(\\phi \\mathbf{X}^T\\mathbf{X}/n\\) or “unit information”\nPosterior mean \\(\\frac{n}{1 + n} \\hat{\\boldsymbol{\\beta}}+ \\frac{1}{1 + n}\\hat{\\boldsymbol{\\beta}}= \\hat{\\boldsymbol{\\beta}}\\)\nPosterior Distribution \\[\\boldsymbol{\\beta}\\mid \\mathbf{Y}, \\phi \\sim \\textsf{N}\\left( \\hat{\\boldsymbol{\\beta}}, \\frac{n}{1 + n} (\\mathbf{X}^T\\mathbf{X})^{-1}\n\\phi^{-1} \\right)\\]"
  },
  {
    "objectID": "resources/slides/12-priors-regression.html#unit-information-prior-1",
    "href": "resources/slides/12-priors-regression.html#unit-information-prior-1",
    "title": "Lecture 12: Choice of Priors in Regression",
    "section": "Unit Information Prior",
    "text": "Unit Information Prior\n\nAdvantages:\n\nProper\nInvariant to model parameteriztion of \\(\\mathbf{X}\\) (next)\nEquivalent to MLE (no bias) and tighter intervals\n\nDisadvantages\n\ncannot represent prior beliefs;\ndouble use of data!\n\nno shrinkage of \\(\\boldsymbol{\\beta}\\) with noisy data (larger variance than biased estimators)\n\n\n\n\n\n\n\n\n\nExercise for the Energetic Student\n\n\n\nWhat would be a “Unit information prior” for \\(\\phi\\)?\nWhat is the marginal posterior for \\(\\boldsymbol{\\beta}\\) using both unit-information priors?"
  },
  {
    "objectID": "resources/slides/12-priors-regression.html#invariance-and-choice-of-meanprecision",
    "href": "resources/slides/12-priors-regression.html#invariance-and-choice-of-meanprecision",
    "title": "Lecture 12: Choice of Priors in Regression",
    "section": "Invariance and Choice of Mean/Precision",
    "text": "Invariance and Choice of Mean/Precision\n\nthe model in vector form \\(Y \\mid \\beta, \\phi \\sim \\textsf{N}_n (X\\beta, \\phi^{-1} I_n)\\)\nWhat if we transform the mean \\(X\\beta = X H H^{-1} \\beta\\) with new \\(X\\) matrix \\(\\tilde{X} = X H\\) where \\(H\\) is \\(p \\times p\\) and invertible and coefficients \\(\\tilde{\\beta} = H^{-1} \\beta\\).\nobtain the posterior for \\(\\tilde{\\beta}\\) using \\(Y\\) and \\(\\tilde{X}\\)\n\\[ Y \\mid  \\tilde{\\beta}, \\phi \\sim \\textsf{N}_n (\\tilde{X}\\tilde{\\beta}, \\phi^{-1} I_n)\\]\nsince \\(\\tilde{X} \\tilde{\\beta} = X H \\tilde{\\beta} = X \\beta\\) invariance suggests that the posterior for \\(\\beta\\) and \\(H \\tilde{\\beta}\\) should be the same\nplus the posterior of \\(H^{-1} \\beta\\) and \\(\\tilde{\\beta}\\) should be the same\n\n\n\n\n\n\n\n\nExercise for the Energetic Student\n\n\nWith some linear algebra, show that this is true for a normal prior if \\(b_0 = 0\\) and \\(\\Phi_0\\) is \\(k X^TX\\) for some \\(k\\)"
  },
  {
    "objectID": "resources/slides/12-priors-regression.html#zellners-g-prior",
    "href": "resources/slides/12-priors-regression.html#zellners-g-prior",
    "title": "Lecture 12: Choice of Priors in Regression",
    "section": "Zellner’s g-prior",
    "text": "Zellner’s g-prior\n\nPopular choice is to take \\(k = \\phi/g\\) which is a special case of Zellner’s g-prior \\[\\beta \\mid \\phi, g \\sim \\textsf{N}\\left(\\mathbf{b}_0, \\frac{g}{\\phi} (X^TX)^{-1}\\right)\\]\nFull conditional \\[\\beta \\mid \\phi, g \\sim \\textsf{N}\\left(\\frac{g}{1 + g} \\hat{\\beta} + \\frac{1}{1 + g}\\mathbf{b}_0, \\frac{1}{\\phi} \\frac{g}{1 + g} (X^TX)^{-1}\\right)\\]\none parameter \\(g\\) controls shrinkage\ninvariance under linear transformations of \\(\\mathbf{X}\\) with \\(\\mathbf{b}_0 = 0\\) or transform mean \\(\\tilde{\\mathbf{b}}_0 = H^{-1}\\mathbf{b}_0\\)\noften paired with the Jeffereys’ reference prior for \\(\\phi\\)\nallows an informative mean, but keeps the same correlation structure as the MLE"
  },
  {
    "objectID": "resources/slides/12-priors-regression.html#zellners-blocked-g-prior",
    "href": "resources/slides/12-priors-regression.html#zellners-blocked-g-prior",
    "title": "Lecture 12: Choice of Priors in Regression",
    "section": "Zellner’s Blocked g-prior",
    "text": "Zellner’s Blocked g-prior\n\nZellner also realized that different blocks might have different degrees of prior information\nTwo blocks \\(\\mathbf{X}_1\\) and \\(\\mathbf{X}_2\\) with \\(\\mathbf{X}_1^T \\mathbf{X}_2 = 0\\) so Fisher Information is block diagonal\nModel \\(\\mathbf{Y}= \\mathbf{X}_1 \\boldsymbol{\\alpha}+ \\mathbf{X}_2 \\boldsymbol{\\beta}+ \\boldsymbol{\\epsilon}\\)\nPriors \\[\\begin{align}\n\\boldsymbol{\\alpha}\\mid \\phi & \\sim \\textsf{N}(\\boldsymbol{\\alpha}_1, \\frac{g_{\\boldsymbol{\\alpha}}}{\\phi} (\\mathbf{X}_1^T\\mathbf{X}_1)^{-1})\\\\\n\\boldsymbol{\\beta}\\mid \\phi & \\sim \\textsf{N}(\\mathbf{b}_0, \\frac{g_{\\boldsymbol{\\beta}}}{\\phi} (\\mathbf{X}_2^T\\mathbf{X}_2)^{-1})\n\\end{align}\\]\nImportant case \\(\\mathbf{X}_1 = \\mathbf{1}_n\\) corresponding to intercept with limiting case \\(g_{\\boldsymbol{\\alpha}} \\to \\infty\\) \\[p(\\boldsymbol{\\alpha}) \\propto 1\\]"
  },
  {
    "objectID": "resources/slides/12-priors-regression.html#potential-problems",
    "href": "resources/slides/12-priors-regression.html#potential-problems",
    "title": "Lecture 12: Choice of Priors in Regression",
    "section": "Potential Problems",
    "text": "Potential Problems\n\nThe posterior in Jeffereys’ prior(s), the unit information prior, and Zellner’s g-priors depend on \\((\\mathbf{X}^T\\mathbf{X})^{-1}\\) and the MLE \\(\\hat{\\boldsymbol{\\beta}}\\)\nIf \\(\\mathbf{X}^T\\mathbf{X}= \\mathbf{U}\\boldsymbol{\\Lambda}\\mathbf{U}^T\\) is nearly singular (\\(\\lambda_j \\approx 0\\) for one or more eigenvalues), certain elements of \\(\\beta\\) or (linear combinations of \\(\\beta\\)) may have huge posterior variances and the MLEs (and posterior means) are highly unstable!\nthere is no unique posterior distribution if any \\(\\lambda_j = 0\\)! (\\(p &gt; n\\) or non-full rank)\nPosterior Precision and Mean in conjugate prior \\[\\begin{align}\n\\boldsymbol{\\Phi}_n & = \\mathbf{X}^T\\mathbf{X}+ \\boldsymbol{\\Phi}_0 \\\\\n\\mathbf{b}_n & = \\boldsymbol{\\Phi}^{-1} (\\mathbf{X}^T\\mathbf{Y}+ \\boldsymbol{\\Phi}_0 \\mathbf{b}_0)\n\\end{align}\\]\nNeed a proper prior with \\(\\boldsymbol{\\Phi}_0 &gt;0\\) (OK for \\(\\mathbf{b}_0 = 0\\) )\nSimplest case: take \\(\\boldsymbol{\\Phi}_0 = \\kappa \\mathbf{I}_p\\) so that \\(\\boldsymbol{\\Phi}_n = \\mathbf{X}^T\\mathbf{X}+ \\kappa \\mathbf{I}_p = \\mathbf{U}(\\boldsymbol{\\Lambda}+ \\kappa \\mathbf{I}_p) \\mathbf{U}^T &gt; 0\\)"
  },
  {
    "objectID": "resources/slides/12-priors-regression.html#ridge-regression",
    "href": "resources/slides/12-priors-regression.html#ridge-regression",
    "title": "Lecture 12: Choice of Priors in Regression",
    "section": "Ridge Regression",
    "text": "Ridge Regression\nModel: \\(\\mathbf{Y}= \\mathbf{1}_n \\alpha + \\mathbf{X}\\boldsymbol{\\beta}+ \\boldsymbol{\\epsilon}\\)\n\nWLOG assume that \\(\\mathbf{X}\\) has been centered and scaled so that \\(\\mathbf{X}^T\\mathbf{X}= \\textsf{corr}(\\mathbf{X})\\)\ntypically expect the intercept \\(\\alpha\\) to be a different order of magnitude from the other predictors.\n\nAdopt a two block prior with \\(p(\\alpha) \\propto 1\\)\nIf \\(\\mathbf{X}\\) is centered, \\(\\mathbf{1}_n^T \\mathbf{X}= \\mathbf{0}_p\\)\n\nPrior \\(\\boldsymbol{\\beta}\\mid \\phi \\sim \\textsf{N}(\\mathbf{0}_b, \\frac{1} {\\phi \\kappa} \\mathbf{I}_p\\)) implies the \\(\\mathbf{b}\\) are exchangable a priori (i.e. distribution is invariant under permuting the labels and with a common scale and mean)\n\nif different predictors have different variances, rescale \\(\\mathbf{X}\\) to have variance 1\n\nPosterior for \\(\\boldsymbol{\\beta}\\) \\[\\boldsymbol{\\beta}\\mid \\phi, \\kappa, \\mathbf{Y}\\sim\n\\textsf{N}\\left((\\kappa I_p + X^TX)^{-1} X^T Y,  \\frac{1}{\\phi}(\\kappa I_p + X^TX)^{-1}\n\\right)\\]"
  },
  {
    "objectID": "resources/slides/12-priors-regression.html#bayes-ridge-regression",
    "href": "resources/slides/12-priors-regression.html#bayes-ridge-regression",
    "title": "Lecture 12: Choice of Priors in Regression",
    "section": "Bayes Ridge Regression",
    "text": "Bayes Ridge Regression\n\nPosterior mean (or mode) given \\(\\kappa\\) is biased, but can show that there always is a value of \\(\\kappa\\) where the frequentist’s expected squared error loss is smaller for the Ridge estimator than MLE!\nUnfortunately the optimal choice depends on “true” \\(\\boldsymbol{\\beta}\\)!\nrelated to penalized maximum likelihood estimation \\[-\\frac{\\phi}{2}\\left(\\|\\mathbf{Y}- \\mathbf{X}\\boldsymbol{\\beta}\\|^2 + \\kappa \\| \\boldsymbol{\\beta}\\|^2 \\right)\n\\]\nChoice of \\(\\kappa\\) ?\n\nCross-validation (frequentist)\nEmpirical Bayes? (frequentist/Bayes)\nfixed a priori Bayes (and how to choose)\n\nShould there be a common \\(\\kappa\\)? Or a \\(\\kappa_j\\) per variable? (or shared in a group?)"
  },
  {
    "objectID": "resources/slides/12-priors-regression.html#mixture-of-conjugate-priors",
    "href": "resources/slides/12-priors-regression.html#mixture-of-conjugate-priors",
    "title": "Lecture 12: Choice of Priors in Regression",
    "section": "Mixture of Conjugate Priors",
    "text": "Mixture of Conjugate Priors\n\ncan place a prior on \\(\\kappa\\) or \\(\\kappa_j\\) for fully Bayes\nsimilar issue for \\(g\\) in the \\(g\\) priors\noften improved robustness over fixed choices of hyperparameter\nmay not have cloosed form posterior but sampling is still often easy!\nExamples: Bayesian Lasso, Double Laplace, Horseshoe prior, mixtures of \\(g\\)-priors\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#semi-conjugate-priors-in-linear-regression",
    "href": "resources/slides/11-bayes-regression.html#semi-conjugate-priors-in-linear-regression",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Semi-Conjugate Priors in Linear Regression",
    "text": "Semi-Conjugate Priors in Linear Regression\n\nRegression Model (Sampling model) \\[\\mathbf{Y}\\mid \\boldsymbol{\\beta}, \\phi  \\sim \\textsf{N}(\\mathbf{X}\\boldsymbol{\\beta}, \\phi^{-1} \\mathbf{I}_n)\n\\]\nSemi-Conjugate Prior Independent Normal Gamma \\[\\begin{align*}\n\\boldsymbol{\\beta}& \\sim \\textsf{N}(\\mathbf{b}_0, \\boldsymbol{\\Phi}_0^{-1}) \\\\\n\\phi & \\sim \\textsf{Gamma}(\\nu_0/2, \\textsf{SS}_0/2)\n\\end{align*}\\]\n\nConditional Normal for \\(\\boldsymbol{\\beta}\\mid \\phi, \\mathbf{Y}\\) and\nConditional Gamma \\(\\phi \\mid \\mathbf{Y}, \\boldsymbol{\\beta}\\)\nrequires Gibbs sampling or other Metropolis-Hastings algorithms"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#conjugate-priors-in-linear-regression",
    "href": "resources/slides/11-bayes-regression.html#conjugate-priors-in-linear-regression",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Conjugate Priors in Linear Regression",
    "text": "Conjugate Priors in Linear Regression\n\nRegression Model (Sampling model) \\[\\mathbf{Y}\\mid \\boldsymbol{\\beta}, \\phi  \\sim \\textsf{N}(\\mathbf{X}\\boldsymbol{\\beta}, \\phi^{-1} \\mathbf{I}_n)\n\\]\nConjugate Normal-Gamma Model: factor joint prior \\(p(\\boldsymbol{\\beta}, \\phi ) = p(\\boldsymbol{\\beta}\\mid \\phi)p(\\phi)\\) \\[\\begin{align*}\n\\boldsymbol{\\beta}\\mid \\phi & \\sim \\textsf{N}(\\mathbf{b}_0, \\phi^{-1}\\boldsymbol{\\Phi}_0^{-1}) & p(\\boldsymbol{\\beta}\\mid \\phi) & = \\frac{|\\phi \\boldsymbol{\\Phi}_0|^{1/2}}{(2 \\pi)^{p/2}}e^{\\left\\{- \\frac{\\phi}{2}(\\boldsymbol{\\beta}- \\mathbf{b}_0)^T \\boldsymbol{\\Phi}_0 (\\boldsymbol{\\beta}- \\mathbf{b}_0)  \\right\\}}\\\\\n\\phi & \\sim \\textsf{Gamma}(v_0/2, \\textsf{SS}_0/2)  & p(\\phi) & = \\frac{1}{\\Gamma{(\\nu_0/2)}}\n\\left(\\frac{\\textsf{SS}_0}{2} \\right)^{\\nu_0/2}\n\\phi^{\\nu_0/2 - 1}\ne^{- \\phi \\frac{\\textsf{SS}_0}{2}}\\\\\n\\Rightarrow (\\boldsymbol{\\beta}, \\phi) & \\sim \\textsf{NG}(\\mathbf{b}_0, \\boldsymbol{\\Phi}_0, \\nu_o, \\textsf{SS}_0)\n\\end{align*}\\]\nNormal-Gamma distribution indexed by 4 hyperparameters\nNote Prior Covariance for \\(\\boldsymbol{\\beta}\\) is scaled by \\(\\sigma^2 = 1/\\phi\\)"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#finding-the-posterior-distribution",
    "href": "resources/slides/11-bayes-regression.html#finding-the-posterior-distribution",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Finding the Posterior Distribution",
    "text": "Finding the Posterior Distribution\n\nLikelihood: \\({\\cal{L}}(\\beta, \\phi) \\propto \\phi^{n/2} e^{- \\frac{\\phi}{2} (\\mathbf{Y}- \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{Y}- \\mathbf{X}\\boldsymbol{\\beta})}\\)\n\\[\\begin{eqnarray*}\np(\\boldsymbol{\\beta}, \\phi \\mid \\mathbf{Y}) &\\propto&  \\phi^{\\frac {n}{2}}\ne^{- \\frac \\phi 2  (\\mathbf{Y}- \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{Y}- \\mathbf{X}\\boldsymbol{\\beta}) } \\times \\\\\n& & \\phi^{\\frac{\\nu_0}{2} - 1} e^{- \\phi \\frac{\\textsf{SS}_0}{2} }\\times\n\\phi^{\\frac{p}{2}} e^{- \\frac{\\phi}{2} (\\boldsymbol{\\beta}- \\mathbf{b}_0)^T \\boldsymbol{\\Phi}_0 (\\boldsymbol{\\beta}- \\mathbf{b}_0) }\n\\end{eqnarray*}\\]\nQuadratic in Exponential \\[\\exp\\left\\{- \\frac{\\phi}{2} (\\boldsymbol{\\beta}- \\mathbf{b})^T \\boldsymbol{\\Phi}(\\boldsymbol{\\beta}- \\mathbf{b}) \\right\\} = \\exp\\left\\{-\n\\frac{\\phi}{2} (\\boldsymbol{\\beta}^T \\boldsymbol{\\Phi}\\boldsymbol{\\beta}- 2 \\boldsymbol{\\beta}^T \\boldsymbol{\\Phi}\\mathbf{b}+ \\mathbf{b}^T\\boldsymbol{\\Phi}\\mathbf{b})\\right\\}\\]\n\nExpand quadratics and regroup terms\n\nRead off posterior precision from Quadratic in \\(\\boldsymbol{\\beta}\\)\n\nRead off posterior mean from Linear term in \\(\\boldsymbol{\\beta}\\)\n\nwill need to complete the quadratic in the posterior mean due to \\(\\phi\\)"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#expand-and-regroup",
    "href": "resources/slides/11-bayes-regression.html#expand-and-regroup",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Expand and Regroup",
    "text": "Expand and Regroup\n\\[\\begin{eqnarray*}\np(\\boldsymbol{\\beta}, \\phi \\mid \\mathbf{Y}) &\\propto&  \\phi^{\\frac {n}{2}}\ne^{- \\frac \\phi 2 ( \\mathbf{Y}^T\\mathbf{Y}- 2 \\boldsymbol{\\beta}^T \\mathbf{X}^T \\mathbf{Y}+ \\boldsymbol{\\beta}^T \\mathbf{X}^T \\mathbf{X}\\boldsymbol{\\beta})} \\times \\\\\n& & \\phi^{\\frac{\\nu_0}{2} - 1} e^{- \\phi \\frac{\\textsf{SS}_0}{2} }\\times\n\\phi^{\\frac{p}{2}} e^{- \\frac{\\phi}{2} (\\boldsymbol{\\beta}\\boldsymbol{\\Phi}_0\\boldsymbol{\\beta}- 2 \\boldsymbol{\\beta}^T \\boldsymbol{\\Phi}_0 \\mathbf{b}+ \\mathbf{b}_0^T \\boldsymbol{\\Phi}_0 \\mathbf{b}_0) }\n\\end{eqnarray*}\\]\n\n\\[\\begin{eqnarray*}\np(\\boldsymbol{\\beta}, \\phi \\mid \\mathbf{Y}) &\\propto&  \\phi^{\\frac {n + p + \\nu_0}{ 2} - 1}\ne^{- \\frac \\phi 2 (\\textsf{SS}_0 +  \\mathbf{Y}^T\\mathbf{Y}+ \\mathbf{b}_0^T \\boldsymbol{\\Phi}_0 \\mathbf{b}_0) } \\times  \\\\\n& & e^{-\\frac{\\phi}{2} (\\boldsymbol{\\beta}^T(\\mathbf{X}^T\\mathbf{X})\\boldsymbol{\\beta}-2 \\boldsymbol{\\beta}^T\\textcolor{red}{\\mathbf{X}^T\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}}\\mathbf{X}^T\\mathbf{Y}+ \\boldsymbol{\\beta}\\boldsymbol{\\Phi}_0\\boldsymbol{\\beta}- 2 \\boldsymbol{\\beta}^T \\boldsymbol{\\Phi}_0 \\mathbf{b}) }  \n\\end{eqnarray*}\\]\n\n\n\\[\\begin{eqnarray*}\n& = & \\phi^{\\frac {n + p + \\nu_0}{ 2} - 1}\ne^{- \\frac \\phi 2 (\\textsf{SS}_0 +  \\mathbf{Y}^T\\mathbf{Y}+ \\mathbf{b}_0^T \\boldsymbol{\\Phi}_0 \\mathbf{b}_0)} \\times  \\\\\n& &  e^{ -\\frac{\\phi}{2} \\left(  \\boldsymbol{\\beta}^T (\\mathbf{X}^T\\mathbf{X}+ \\boldsymbol{\\Phi}_0) \\boldsymbol{\\beta}\\right) } \\times  \\\\\n& &  e^{  -\\frac{\\phi}{2} \\left( -2 \\boldsymbol{\\beta}^T (\\mathbf{X}^T\\mathbf{X}\\textcolor{red}{\\hat{\\boldsymbol{\\beta}}}  + \\boldsymbol{\\Phi}_0 \\mathbf{b}_0)\n   \\right)}\n\\end{eqnarray*}\\]"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#complete-the-quadratic",
    "href": "resources/slides/11-bayes-regression.html#complete-the-quadratic",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Complete the Quadratic",
    "text": "Complete the Quadratic\n\\[\\begin{eqnarray*}\np(\\boldsymbol{\\beta}, \\phi \\mid \\mathbf{Y}) &\\propto&  \\phi^{\\frac {n + p + \\nu_0}{ 2} - 1}\ne^{- \\frac \\phi 2 (\\textsf{SS}_0 +  \\mathbf{Y}^T\\mathbf{Y}+ \\mathbf{b}_0^T \\boldsymbol{\\Phi}_0 \\mathbf{b}_0\n  )}     \\times \\\\\n& &  e^{ -\\frac{\\phi}{2} \\left(  \\boldsymbol{\\beta}^T \\textcolor{\\red}{(\\mathbf{X}^T\\mathbf{X}+ \\boldsymbol{\\Phi}_0)} \\boldsymbol{\\beta}\n  \\right) }  \\times \\qquad \\qquad  \\qquad \\qquad \\boldsymbol{\\Phi}_n \\equiv \\mathbf{X}^T\\mathbf{X}+ \\boldsymbol{\\Phi}_0  \\\\\n& &  e^{  -\\frac{\\phi}{2} \\left( -2 \\boldsymbol{\\beta}^T  \\textcolor{red}{\\boldsymbol{\\Phi}_n \\boldsymbol{\\Phi}_n^{-1}} (\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}}+ \\boldsymbol{\\Phi}_0 \\mathbf{b}_0)\n   \\right)}  \\times   \\qquad \\qquad  \\mathbf{b}_n \\equiv \\boldsymbol{\\Phi}_n^{-1} (\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}}+ \\boldsymbol{\\Phi}_0 \\mathbf{b}_0) \\\\\n& &  e^{ -\\frac{\\phi}{2} ( \\textcolor{red}{\\mathbf{b}_ n^T \\boldsymbol{\\Phi}_n \\mathbf{b}_n - \\mathbf{b}_n^T \\boldsymbol{\\Phi}_n \\mathbf{b}_n}) }  \n\\end{eqnarray*}\\]\n\n\\[\\begin{eqnarray*}\n& = &\n  \\phi^{\\frac {n +  \\nu_0}{ 2} - 1}\ne^{- \\frac \\phi 2 ( \\textsf{SS}_0   + \\mathbf{Y}^T\\mathbf{Y}+ \\mathbf{b}_0^T \\boldsymbol{\\Phi}_0 \\mathbf{b}_0 - \\mathbf{b}_n^T \\boldsymbol{\\Phi}_n \\mathbf{b}_n)}    \\times  \\\\\n& &   \\textcolor{red}{\\phi^{\\frac p 2}}  e^{ -\\frac{\\phi}{2} \\left(  (\\boldsymbol{\\beta}^T - \\mathbf{b}_n)^T  \\boldsymbol{\\Phi}_n (\\boldsymbol{\\beta}-\n                               \\mathbf{b}_n) \\right) }\n\\end{eqnarray*}\\]\n\n\n\\[\\begin{eqnarray*}\n& \\propto &\n  \\phi^{\\frac {n +  \\nu_0}{ 2} - 1}\ne^{- \\frac \\phi 2 ( \\textsf{SS}_0   + \\mathbf{Y}^T\\mathbf{Y}+ \\mathbf{b}_0^T \\boldsymbol{\\Phi}_0 \\mathbf{b}_0 - \\mathbf{b}_n^T \\boldsymbol{\\Phi}_n \\mathbf{b}_n)}    \\times  \\\\\n& &   \\textcolor{red}{|\\phi \\Phi_n |^{\\frac 1 2}}  e^{ -\\frac{\\phi}{2} \\left(  (\\boldsymbol{\\beta}^T - \\mathbf{b}_n)^T  \\boldsymbol{\\Phi}_n (\\boldsymbol{\\beta}-\n                               \\mathbf{b}_n) \\right) }\n\\end{eqnarray*}\\]"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#posterior-distributions",
    "href": "resources/slides/11-bayes-regression.html#posterior-distributions",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Posterior Distributions",
    "text": "Posterior Distributions\nPosterior density (up to normalizing contants) \\(p(\\boldsymbol{\\beta}, \\phi \\mid \\mathbf{Y}) = p(\\phi \\mid \\mathbf{Y}) p(\\boldsymbol{\\beta}\\mid \\phi \\mathbf{Y})\\) \\[\\begin{eqnarray*}\n   p(\\phi \\mid \\mathbf{Y}) p(\\boldsymbol{\\beta}\\mid \\phi \\mathbf{Y}) & \\propto &\n  \\phi^{\\frac {n +  \\nu_0}{ 2} - 1}\n  e^{- \\frac \\phi 2 ( \\textsf{SS}_0   + \\mathbf{Y}^T\\mathbf{Y}+ \\mathbf{b}_0^T \\boldsymbol{\\Phi}_0 \\mathbf{b}_0 - \\mathbf{b}_n^T \\boldsymbol{\\Phi}_n \\mathbf{b}_n)}  \\times \\\\\n   & & (2 \\pi)^{- \\frac p 2} |\\phi \\Phi_n |^{\\frac 1 2}e^{- \\frac{\\phi}{2} (\\boldsymbol{\\beta}- \\mathbf{b}_n)^T \\boldsymbol{\\Phi}_n (\\boldsymbol{\\beta}-\n   \\mathbf{b}_n) }      \n   \\end{eqnarray*}\\]\n\nMarginal \\[\\begin{eqnarray*}\n   p(\\phi \\mid \\mathbf{Y})  & \\propto &\n  \\phi^{\\frac {n +  \\nu_0}{ 2} - 1}\n  e^{- \\frac \\phi 2 ( \\textsf{SS}_0   + \\mathbf{Y}^T\\mathbf{Y}+ \\mathbf{b}_0^T \\boldsymbol{\\Phi}_0 \\mathbf{b}_0 - \\mathbf{b}_n^T \\boldsymbol{\\Phi}_n \\mathbf{b}_n)}  \\times \\\\\n   & &  \\int_{\\mathbb{R}^p} (2 \\pi)^{- \\frac p 2} |\\phi \\Phi_n |^{\\frac 1 2}e^{- \\frac{\\phi}{2} (\\boldsymbol{\\beta}- \\mathbf{b}_n)^T \\boldsymbol{\\Phi}_n (\\boldsymbol{\\beta}-\n   \\mathbf{b}_n) \\ d\\boldsymbol{\\beta}}   \\\\\n   & =  &\n  \\phi^{\\frac {n +  \\nu_0}{ 2} - 1}\n  e^{- \\frac \\phi 2 ( \\textsf{SS}_0   + \\mathbf{Y}^T\\mathbf{Y}+ \\mathbf{b}_0^T \\boldsymbol{\\Phi}_0 \\mathbf{b}_0 - \\mathbf{b}_n^T \\boldsymbol{\\Phi}_n \\mathbf{b}_n)}\n   \\end{eqnarray*}\\]\n\nConditional Normal for \\(\\boldsymbol{\\beta}\\mid \\phi, \\mathbf{Y}\\) and marginal Gamma for \\(\\phi \\mid \\mathbf{Y}\\)\nNo need for Gibbs sampling!"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#textsfng-posterior-distribution",
    "href": "resources/slides/11-bayes-regression.html#textsfng-posterior-distribution",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "\\(\\textsf{NG}\\) Posterior Distribution",
    "text": "\\(\\textsf{NG}\\) Posterior Distribution\n\\[\\begin{eqnarray*}\n\\boldsymbol{\\beta}\\mid \\phi, \\mathbf{Y}& \\sim &\\textsf{N}(\\mathbf{b}_n, (\\phi \\boldsymbol{\\Phi}_n)^{-1})   \\\\\n\\phi \\mid \\mathbf{Y}&\\sim &\\textsf{Gamma}(\\frac{\\nu_n}{2}, \\frac{\\textsf{SS}_n}{2}) \\\\\n(\\boldsymbol{\\beta}, \\phi) \\mid \\mathbf{Y}& \\sim & \\textsf{NG}(\\mathbf{b}_n, \\boldsymbol{\\Phi}_n, \\nu_n, \\textsf{SS}_n)\n  \\end{eqnarray*}\\]\nHyperparameters: \\[\\begin{align*}\n\\Phi_n & =  \\mathbf{X}^T\\mathbf{X}+  \\boldsymbol{\\Phi}_0   & \\quad\n\\mathbf{b}_n &  =  \\boldsymbol{\\Phi}_n^{-1} (\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}}+ \\boldsymbol{\\Phi}_0 \\mathbf{b}_0)  \\\\\n\\nu_n &  =   n + \\nu_0  & \\quad  \n\\textsf{SS}_n &  =   \\textsf{SS}_0 + \\mathbf{Y}^T\\mathbf{Y}+ \\mathbf{b}_0^T \\boldsymbol{\\Phi}_0 \\mathbf{b}_0 - \\mathbf{b}_n^T \\boldsymbol{\\Phi}_n \\mathbf{b}_n\n\\end{align*}\n\\]\n\n\\[\\begin{align*}\n\\textsf{SS}_n &  = \\textsf{SS}_0 + \\| \\mathbf{Y}- \\mathbf{X}\\mathbf{b}_n \\|^2 +  (\\mathbf{b}_0 - \\mathbf{b}_n)^T \\boldsymbol{\\Phi}_0 (\\mathbf{b}_0 - \\mathbf{b}_n) \\\\\n\n& = \\textsf{SS}_0 + \\| \\mathbf{Y}- \\mathbf{X}\\mathbf{b}_n \\|^2 +  \\| \\mathbf{b}_0 - \\mathbf{b}_n \\|^2_{\\boldsymbol{\\Phi}_0}\n\\end{align*}\\]\n\nInner product induced by prior precision \\(\\langle u, v \\rangle_A \\equiv u^TAv\\)\n\\(\\| \\mathbf{b}_0 - \\mathbf{b}_n \\|^2_{\\boldsymbol{\\Phi}_0}\\) mismatch of prior and posterior mean under prior"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#marginal-distribution",
    "href": "resources/slides/11-bayes-regression.html#marginal-distribution",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Marginal Distribution",
    "text": "Marginal Distribution\n\nTheorem: Student-tLet \\(\\boldsymbol{\\theta}\\mid \\phi \\sim \\textsf{N}(m, \\frac{1}{\\phi} \\boldsymbol{\\Sigma})\\) and \\(\\phi \\sim  \\textsf{Gamma}(\\nu/2, \\nu {\\hat{\\sigma}}^2/2)\\).\nThen \\(\\boldsymbol{\\theta}\\) \\((p \\times 1)\\) has a \\(p\\) dimensional multivariate \\(t\\) distribution \\[\\boldsymbol{\\theta}\\sim t_\\nu( m,\n    {\\hat{\\sigma}}^2\\boldsymbol{\\Sigma})\\] with location \\(m\\), scale matrix \\({\\hat{\\sigma}}^2\\boldsymbol{\\Sigma}\\) and density\n\\[p(\\boldsymbol{\\theta}) \\propto  \\left[ 1 + \\frac{1}{\\nu}  \\frac{ (\\boldsymbol{\\theta}- m)^T\n    \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\theta}- m)}{{\\hat{\\sigma}}^2} \\right]^{- \\frac{p + \\nu}{2}}\\]\n\n\n\nNote - true for prior or posterior given \\(\\mathbf{Y}\\)"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#derivation",
    "href": "resources/slides/11-bayes-regression.html#derivation",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Derivation",
    "text": "Derivation\nMarginal density \\(p(\\boldsymbol{\\theta}) = \\int_0^\\infty p(\\boldsymbol{\\theta}\\mid \\phi) p(\\phi) \\, d\\phi\\)\n\\[\\begin{eqnarray*}\n  p(\\boldsymbol{\\theta}) & \\propto & \\int |  \\boldsymbol{\\Sigma}/\\phi|^{-1/2}\ne^{- \\frac{\\phi}{2} (\\boldsymbol{\\theta}- m)^T\n      \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\theta}- m)}  \\phi^{\\nu/2 - 1} e^{- \\phi \\frac{\\nu\n      {\\hat{\\sigma}}^2}{2}}\\, d \\phi    \\\\\n  & \\propto & \\int \\phi^{p/2} \\phi^{\\nu/2 - 1}\ne^{- \\phi \\frac{(\\boldsymbol{\\theta}- m)^T\n      \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\theta}- m)+  \\nu\n      {\\hat{\\sigma}}^2}{2}}\\, d \\phi    \\\\\n& \\propto & \\int \\phi^{\\frac{p +\\nu}{2} - 1}\ne^{- \\phi \\frac{(\\boldsymbol{\\theta}- m)^T\n      \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\theta}- m)+  \\nu\n      {\\hat{\\sigma}}^2}{2}} \\, d \\phi    \\\\\n& = & \\Gamma((p + \\nu)/2 ) \\left( \\frac{(\\boldsymbol{\\theta}- m)^T\n      \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\theta}- m)+  \\nu\n      {\\hat{\\sigma}}^2}{2} \\right)^{- \\frac{p + \\nu}{2}}    \\\\\n& \\propto &  \\left( (\\boldsymbol{\\theta}- m)^T\n      \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\theta}- m)+  \\nu\n      {\\hat{\\sigma}}^2\\right)^{- \\frac{p + \\nu}{2}}    \\\\\n& \\propto &  \\left( 1 + \\frac{1}{\\nu}  \\frac{(\\boldsymbol{\\theta}- m)^T\n      \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\theta}- m)}{{\\hat{\\sigma}}^2}\n       \\right)^{- \\frac{p + \\nu}{2}}\n\\end{eqnarray*}\\]"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#marginal-posterior-distribution-of-boldsymbolbeta",
    "href": "resources/slides/11-bayes-regression.html#marginal-posterior-distribution-of-boldsymbolbeta",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Marginal Posterior Distribution of \\(\\boldsymbol{\\beta}\\)",
    "text": "Marginal Posterior Distribution of \\(\\boldsymbol{\\beta}\\)\n\\[\\begin{eqnarray*}\n\\boldsymbol{\\beta}\\mid \\phi, \\mathbf{Y}& \\sim & \\textsf{N}( \\mathbf{b}_n, \\phi^{-1} \\boldsymbol{\\Phi}_n^{-1}) \\\\\n\\phi \\mid \\mathbf{Y}& \\sim & \\textsf{Gamma}\\left(\\frac{\\nu_n}{2},  \\frac{\\textsf{SS}_n}{ 2} \\right)\n  \\end{eqnarray*}\\] \n\nLet \\({\\hat{\\sigma}}^2= \\textsf{SS}_n/\\nu_n\\) (Bayesian MSE)\nThe marginal posterior distribution of \\(\\boldsymbol{\\beta}\\) is multivariate Student-t \\[\n\\boldsymbol{\\beta}\\mid \\mathbf{Y}\\sim t_{\\nu_n} (\\mathbf{b}_n, {\\hat{\\sigma}}^2\\boldsymbol{\\Phi}_n^{-1})\n\\] \nAny linear combination \\(\\lambda^T\\boldsymbol{\\beta}\\) has a univariate \\(t\\) distribution with \\(\\mathbf{v}_n\\) degrees of freedom \\[\\lambda^T\\boldsymbol{\\beta}\\mid \\mathbf{Y}\\sim t_{\\nu_n}\n(\\lambda^T\\mathbf{b}_n, {\\hat{\\sigma}}^2\\lambda^T\\Phi_n^{-1}\\lambda)\\]\nuse for individual \\(\\boldsymbol{\\beta}_j\\), the mean of \\(Y\\), \\(\\mathbf{x}^T \\boldsymbol{\\beta}\\), at \\(\\mathbf{x}\\), or predictions \\(Y^* = {\\mathbf{x}^*}^T \\boldsymbol{\\beta}+ \\epsilon_i^*\\)"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#predictive-distributions",
    "href": "resources/slides/11-bayes-regression.html#predictive-distributions",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Predictive Distributions",
    "text": "Predictive Distributions\nSuppose \\(\\mathbf{Y}^* \\mid \\boldsymbol{\\beta}, \\phi \\sim \\textsf{N}_s(\\mathbf{X}^* \\boldsymbol{\\beta}, \\mathbf{I}_s/\\phi)\\) and is conditionally independent of \\(\\mathbf{Y}\\) given \\(\\boldsymbol{\\beta}\\) and \\(\\phi\\)\n\nWhat is the predictive distribution of \\(\\mathbf{Y}^* \\mid \\mathbf{Y}\\)?\nUse the representation that \\(\\mathbf{Y}^* \\mathrel{\\mathop{=}\\limits^{\\rm D}}\\mathbf{X}^* \\boldsymbol{\\beta}+ \\boldsymbol{\\epsilon}^*\\) and \\(\\boldsymbol{\\epsilon}^*\\) is independent of \\(\\mathbf{Y}\\) given \\(\\phi\\)\n\n\n\\[\\begin{eqnarray*}\n\\mathbf{X}^* \\boldsymbol{\\beta}+ \\boldsymbol{\\epsilon}^* \\mid \\phi, \\mathbf{Y}& \\sim & \\textsf{N}(\\mathbf{X}^*\\mathbf{b}_n, (\\mathbf{X}^{*} \\boldsymbol{\\Phi}_n^{-1} \\mathbf{X}^{*T}\n+ \\mathbf{I}_s)/\\phi)   \\\\\n\\mathbf{Y}^* \\mid \\phi, \\mathbf{Y}& \\sim & \\textsf{N}(\\mathbf{X}^*\\mathbf{b}_n, (\\mathbf{X}^{*} \\Phi_n^{-1} \\mathbf{X}^{*T}\n+ \\mathbf{I}_s)/\\phi)  \\\\\n\\phi \\mid \\mathbf{Y}& \\sim & \\textsf{Gamma}\\left(\\frac{\\nu_n}{2},\n  \\frac{{\\hat{\\sigma}}^2\\nu_n}{ 2} \\right)\n\\end{eqnarray*}\\]\n\nUse the Theorem to conclude that \\[\\mathbf{Y}^* \\mid \\mathbf{Y}\\sim  t_{\\nu_n}( \\mathbf{X}^*\\mathbf{b}_n, {\\hat{\\sigma}}^2(\\mathbf{I}+ \\mathbf{X}^* \\boldsymbol{\\Phi}_n^{-1} \\mathbf{X}^T))\\]"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#choice-of-conjugate-or-semi-conjugate-prior",
    "href": "resources/slides/11-bayes-regression.html#choice-of-conjugate-or-semi-conjugate-prior",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Choice of Conjugate (or Semi-Conjugate) Prior",
    "text": "Choice of Conjugate (or Semi-Conjugate) Prior\n\nneed to specify Normal prior mean \\(\\mathbf{b}_0\\) and precision \\(\\boldsymbol{\\Phi}_0\\)\nneed to specify Gamma shape (\\(\\nu_o\\) prior df) and rate (estimate of \\(\\sigma^2\\))\nhard in higher dimensions!\ndefault choices?\n\nJeffreys’ prior\nunit-information prior\nZellner’s g-prior\nridge priors\nmixtures of conjugate priors"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#jeffreys-prior",
    "href": "resources/slides/11-bayes-regression.html#jeffreys-prior",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Jeffreys’ Prior",
    "text": "Jeffreys’ Prior\n\nJeffreys prior is invariant to model parameterization of \\(\\boldsymbol{\\theta}= (\\boldsymbol{\\beta},\\phi)\\) \\[p(\\boldsymbol{\\theta}) \\propto |{\\cal{I}}(\\boldsymbol{\\theta})|^{1/2}\\]\n\\({\\cal{I}}(\\boldsymbol{\\theta})\\) is the Expected Fisher Information matrix \\[{\\cal{I}}(\\theta) = - \\textsf{E}[ \\left[ \\frac{\\partial^2 \\log({\\cal{L}}(\\boldsymbol{\\theta}))}{\\partial\n\\theta_i \\partial \\theta_j} \\right] ]\\]\nlog likelihood expressed as function of sufficient statistics\n\n\n\\[\\log({\\cal{L}}(\\boldsymbol{\\beta}, \\phi))  =  \\frac{n}{2} \\log(\\phi)  - \\frac{\\phi}{2} \\| (\\mathbf{I}_n - \\mathbf{P}_\\mathbf{x}) \\mathbf{Y}\\|^2\n- \\frac{\\phi}{2}(\\boldsymbol{\\beta}- \\hat{\\boldsymbol{\\beta}})^T(\\mathbf{X}^T\\mathbf{X})(\\boldsymbol{\\beta}- \\hat{\\boldsymbol{\\beta}})\\]\n\nprojection matrix \\(\\mathbf{P}_{\\mathbf{X}} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T\\)"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#information-matrix",
    "href": "resources/slides/11-bayes-regression.html#information-matrix",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Information matrix",
    "text": "Information matrix\n\\[\\begin{eqnarray*}\n\\frac{\\partial^2 \\log {\\cal{L}}} { \\partial \\boldsymbol{\\theta}\\partial \\boldsymbol{\\theta}^T} & = &\n\\left[\n  \\begin{array}{cc}\n    -\\phi (\\mathbf{X}^T\\mathbf{X}) & -(\\mathbf{X}^T\\mathbf{X}) (\\boldsymbol{\\beta}- \\hat{\\boldsymbol{\\beta}}) \\\\\n  - (\\boldsymbol{\\beta}- \\hat{\\boldsymbol{\\beta}})^T (\\mathbf{X}^T\\mathbf{X}) & -\\frac{n}{2} \\frac{1}{\\phi^2} \\\\\n  \\end{array}\n\\right] \\\\\n\\textsf{E}[\\frac{\\partial^2 \\log {\\cal{L}}} { \\partial \\boldsymbol{\\theta}\\partial \\boldsymbol{\\theta}^T}] & = &\n\\left[\n  \\begin{array}{cc}\n    -\\phi (\\mathbf{X}^T\\mathbf{X}) & \\mathbf{0}_p \\\\\n  \\mathbf{0}_p^T & -\\frac{n}{2} \\frac{1}{\\phi^2} \\\\\n  \\end{array}\n\\right] \\\\\n& & \\\\\n{\\cal{I}}((\\boldsymbol{\\beta}, \\phi)^T) & = & \\left[\n  \\begin{array}{cc}\n    \\phi (\\mathbf{X}^T\\mathbf{X}) & \\mathbf{0}_p \\\\\n  \\mathbf{0}_p^T & \\frac{n}{2} \\frac{1}{\\phi^2}\n  \\end{array}\n\\right]\n  \\end{eqnarray*}\\]\n\nJeffreys’ Prior (don’t use!) \\[\\begin{eqnarray*}\n  p_J(\\boldsymbol{\\beta}, \\phi)  & \\propto & |{\\cal{I}}((\\boldsymbol{\\beta}, \\phi)^T) |^{1/2}   \n                =  |\\phi \\mathbf{X}^T\\mathbf{X}|^{1/2} \\left(\\frac{n}{2}\n                 \\frac{1}{\\phi^2} \\right)^{1/2}\n  \\propto    \\phi^{p/2 - 1} |\\mathbf{X}^T\\mathbf{X}|^{1/2} \\\\\n  & \\propto & \\phi^{p/2 - 1}  \n  \\end{eqnarray*}\\]"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#recommended-independent-jeffreys-prior",
    "href": "resources/slides/11-bayes-regression.html#recommended-independent-jeffreys-prior",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Recommended Independent Jeffreys Prior",
    "text": "Recommended Independent Jeffreys Prior\n\nTreat \\(\\boldsymbol{\\beta}\\) and \\(\\phi\\) separately (orthogonal parameterization)\n\\(p_{IJ}(\\boldsymbol{\\beta}) \\propto |{\\cal{I}}(\\boldsymbol{\\beta})|^{1/2}\\) and \\(p_{IJ}(\\phi) \\propto |{\\cal{I}}(\\phi)|^{1/2}\\)\n\n\n\\[\n{\\cal{I}}((\\boldsymbol{\\beta}, \\phi)^T)  =  \\left[\n  \\begin{array}{cc}\n    \\phi (\\mathbf{X}^T\\mathbf{X}) & \\mathbf{0}_p \\\\\n  \\mathbf{0}_p^T & \\frac{n}{2} \\frac{1}{\\phi^2}\n  \\end{array}\n\\right]\n\\]\n\n\n\\[\\begin{align*} p_{IJ}(\\boldsymbol{\\beta}) & \\propto |\\phi \\mathbf{X}^T\\mathbf{X}|^{1/2} \\propto 1 \\\\\n               p_{IJ}(\\phi) & \\propto \\phi^{-1} \\\\\n               p_{IJ}(\\beta, \\phi) & \\propto p_{IJ}(\\boldsymbol{\\beta}) p_{IJ}(\\phi) = \\phi^{-1}\n\\end{align*}\\]"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#formal-posterior-distribution",
    "href": "resources/slides/11-bayes-regression.html#formal-posterior-distribution",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Formal Posterior Distribution",
    "text": "Formal Posterior Distribution\n\nUse Independent Jeffreys Prior \\(p_{IJ}(\\beta, \\phi) \\propto p_{IJ}(\\boldsymbol{\\beta}) p_{IJ}(\\phi) = \\phi^{-1}\\)\nFormal Posterior Distribution \\[\\begin{eqnarray*}\n\\boldsymbol{\\beta}\\mid \\phi, \\mathbf{Y}& \\sim & \\textsf{N}(\\hat{\\boldsymbol{\\beta}}, (\\mathbf{X}^T\\mathbf{X})^{-1} \\phi^{-1})  \\\\\n\\phi \\mid \\mathbf{Y}& \\sim& \\textsf{Gamma}((n-p)/2, \\| \\mathbf{Y}- \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\\|^2/2) \\\\\n\\boldsymbol{\\beta}\\mid \\mathbf{Y}& \\sim & t_{n-p}(\\hat{\\boldsymbol{\\beta}}, {\\hat{\\sigma}}^2(\\mathbf{X}^T\\mathbf{X})^{-1})\n\\end{eqnarray*}\\]\nBayesian Credible Sets \\(p(\\boldsymbol{\\beta}\\in C_\\alpha) \\mid \\mathbf{Y}) = 1- \\alpha\\) correspond to frequentist Confidence Regions \\[\\frac{\\mathbf{x}^T\\boldsymbol{\\beta}- \\mathbf{x}^T \\hat{\\boldsymbol{\\beta}}} {\\sqrt{{\\hat{\\sigma}}^2\\mathbf{x}^T(\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{x}} }\\sim t_{n-p}\\]\nconditional on \\(\\mathbf{Y}\\) for Bayes and conditional on \\(\\boldsymbol{\\beta}\\) for frequentist"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#other-priors-next",
    "href": "resources/slides/11-bayes-regression.html#other-priors-next",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Other priors next",
    "text": "Other priors next"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#invariance-and-choice-of-meanprecision",
    "href": "resources/slides/11-bayes-regression.html#invariance-and-choice-of-meanprecision",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Invariance and Choice of Mean/Precision",
    "text": "Invariance and Choice of Mean/Precision\n\nthe model in vector form \\(Y \\mid \\beta, \\phi \\sim \\textsf{N}_n (X\\beta, \\phi^{-1} I_n)\\)\nWhat if we transform the mean \\(X\\beta = X H H^{-1} \\beta\\) with new \\(X\\) matrix \\(\\tilde{X} = X H\\) where \\(H\\) is \\(p \\times p\\) and invertible and coefficients \\(\\tilde{\\beta} = H^{-1} \\beta\\).\nobtain the posterior for \\(\\tilde{\\beta}\\) using \\(Y\\) and \\(\\tilde{X}\\)\n\\[ Y \\mid  \\tilde{\\beta}, \\phi \\sim \\textsf{N}_n (\\tilde{X}\\tilde{\\beta}, \\phi^{-1} I_n)\\]\nsince \\(\\tilde{X} \\tilde{\\beta} = X H \\tilde{\\beta} = X \\beta\\) invariance suggests that the posterior for \\(\\beta\\) and \\(H \\tilde{\\beta}\\) should be the same\nplus the posterior of \\(H^{-1} \\beta\\) and \\(\\tilde{\\beta}\\) should be the same\n\n\n\n\n\n\n\n\nExercise for the Energetic Student\n\n\nWith some linear algebra, show that this is true for a normal prior if \\(b_0 = 0\\) and \\(\\Phi_0\\) is \\(k X^TX\\) for some \\(k\\)"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#zellners-g-prior",
    "href": "resources/slides/11-bayes-regression.html#zellners-g-prior",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Zellner’s g-prior",
    "text": "Zellner’s g-prior\n\nPopular choice is to take \\(k = \\phi/g\\) which is a special case of Zellner’s g-prior \\[\\beta \\mid \\phi, g \\sim \\textsf{N}\\left(0, \\frac{g}{\\phi} (X^TX)^{-1}\\right)\\]\nFull conditional \\[\\beta \\mid \\phi, g \\sim \\textsf{N}\\left(\\frac{g}{1 + g} \\hat{\\beta}, \\frac{1}{\\phi} \\frac{g}{1 + g} (X^TX)^{-1}\\right)\\]\none parameter \\(g\\) controls shrinkage\nif \\(\\phi \\sim \\textsf{Gamma}(v_0/2, s_0/2)\\) then posterior is \\[\\phi \\mid y_1, \\ldots, y_n \\sim \\textsf{Gamma}(v_n/2, s_n/2)\\]\nConjugate so we could skip Gibbs sampling and sample directly from gamma and then conditional normal!"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#ridge-regression",
    "href": "resources/slides/11-bayes-regression.html#ridge-regression",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Ridge Regression",
    "text": "Ridge Regression\n\nIf \\(X^TX\\) is nearly singular, certain elements of \\(\\beta\\) or (linear combinations of \\(\\beta\\)) may have huge variances under the \\(g\\)-prior (or flat prior) as the MLEs are highly unstable!\nRidge regression protects against the explosion of variances and ill-conditioning with the conjugate priors: \\[\\beta \\mid \\phi \\sim \\textsf{N}(0, \\frac{1}{\\phi \\lambda} I_p)\\]\nPosterior for \\(\\beta\\) (conjugate case) \\[\\beta \\mid \\phi, \\lambda, y_1, \\ldots, y_n \\sim\n\\textsf{N}\\left((\\lambda I_p + X^TX)^{-1} X^T Y,  \\frac{1}{\\phi}(\\lambda I_p + X^TX)^{-1}\n\\right)\\]"
  },
  {
    "objectID": "resources/slides/11-bayes-regression.html#bayes-regression",
    "href": "resources/slides/11-bayes-regression.html#bayes-regression",
    "title": "Lecture 11: Conjugate Priors and Bayesian Regression",
    "section": "Bayes Regression",
    "text": "Bayes Regression\n\nPosterior mean (or mode) given \\(\\lambda\\) is biased, but can show that there always is a value of \\(\\lambda\\) where the frequentist’s expected squared error loss is smaller for the Ridge estimator than MLE!\nrelated to penalized maximum likelihood estimation\nChoice of \\(\\lambda\\)\nBayes Regression and choice of \\(\\Phi_0\\) in general is a very important problem and provides the foundation for many variations on shrinkage estimators, variable selection, hierarchical models, nonparameteric regression and more!\nBe sure that you can derive the full conditional posteriors for \\(\\beta\\) and \\(\\phi\\) as well as the joint posterior in the conjugate case!\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#normal-means-model",
    "href": "resources/slides/05-hierarchical-models.html#normal-means-model",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Normal Means Model",
    "text": "Normal Means Model\n\nSuppose we have normal data with \\[Y_i \\mid \\mu_i, \\sigma^2 \\overset{ind}{\\sim} \\textsf{N}(\\mu_i, \\sigma^2)\\]\nseparate mean for each observation!\nQuestion: How can we possibly hope to estimate all these \\(\\mu_i\\)? One \\(y_i\\) per \\(\\mu_i\\) and \\(n\\) observations!\nNaive estimator: just consider only using \\(y_i\\) in estimating and not the other observations.\nMLE \\(\\hat{\\mu}_i = y_i\\)\nHierarchical Viewpoint: Let’s borrow information from other observations!"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#motivation",
    "href": "resources/slides/05-hierarchical-models.html#motivation",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Motivation",
    "text": "Motivation\n\n\n \n \n\nExample \\(y_i\\) is difference in gene expression for the \\(i^{\\text{th}}\\) gene between cancer and control lines\nmay be natural to think that the \\(\\mu_i\\) arise from some common distribution, \\(\\mu_i \\overset{iid}{\\sim} g\\)\nunbiased but high variance estimators of \\(\\mu_i\\) based on one observation!"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#low-variability",
    "href": "resources/slides/05-hierarchical-models.html#low-variability",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Low Variability",
    "text": "Low Variability\n\n\nlittle variation in \\(\\mu_i\\)s so a better estimate might be \\(\\bar{y}\\)\nNot forced to choose either - what about some weighted average between \\(y_i\\) and \\(\\bar{y}\\)?"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#simple-example",
    "href": "resources/slides/05-hierarchical-models.html#simple-example",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Simple Example",
    "text": "Simple Example\n\nData Model \\[Y_i \\mid \\mu_i, \\sigma^2 \\overset{ind}{\\sim} \\textsf{N}(\\mu_i, \\sigma^2)\\]\nMeans Model \\[\\mu_i \\mid \\mu, \\sigma^2_\\mu \\overset{iid}{\\sim} \\textsf{N}(\\mu, \\sigma^2_{\\mu})\\]\nnot necessarily a prior!\nNow estimate \\(\\mu_i\\) (let \\(\\phi = 1/\\sigma^2\\) and \\(\\phi_{\\mu} = 1/\\sigma^2_\\mu\\))\nCalculate the “posterior” \\(\\mu_i \\mid y_i, \\mu, \\phi, \\phi_\\mu\\)"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#hiearchical-estimates",
    "href": "resources/slides/05-hierarchical-models.html#hiearchical-estimates",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Hiearchical Estimates",
    "text": "Hiearchical Estimates\n\nPosterior: \\(\\mu_i \\mid y_i, \\mu, \\phi, \\phi_\\mu \\overset{ind}{\\sim} \\textsf{N}(\\tilde{\\mu}_i, 1/\\tilde{\\phi}_\\mu)\\)\nestimator of \\(\\mu_i\\) weighted average of data and population parameter \\(\\mu\\) \\[\\tilde{\\mu}_i = \\frac{\\phi_\\mu \\mu + \\phi y_i}\n                        {\\phi_\\mu + \\phi} \\qquad \\qquad \\tilde{\\phi}_\\mu = \\phi + \\phi_\\mu\\]\nif \\(\\phi_\\mu\\) is large relative to \\(\\phi\\) all of the \\(\\mu_i\\) are close together and benefit by borrowing information\nin limit as \\(\\sigma^2_\\mu \\to 0\\) or \\(\\phi_\\mu \\to \\infty\\) we have \\(\\tilde{\\mu}_i = \\mu\\) (all means are the same)\nif \\(\\phi_\\mu\\) is small relative to \\(\\phi\\) little borrowing of information\nin the limit as \\(\\phi_\\mu \\to 0\\) we have \\(\\tilde{\\mu}_i = y_i\\)"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#bayes-estimators-and-bias",
    "href": "resources/slides/05-hierarchical-models.html#bayes-estimators-and-bias",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Bayes Estimators and Bias",
    "text": "Bayes Estimators and Bias\n\nNote: you often benefit from a hierarchical model, even if its not obvious that the \\(\\mu_i\\) are related!\nThe MLE for the \\(\\mu_i\\) is just the sample \\(y_i\\).\n\\(y_i\\) is unbiased for \\(\\mu_i\\) but can have high variability!\nthe posterior mean is actually biased.\nUsually through the weighting of the sample data and prior, Bayes procedures have the tendency to pull the estimate of \\(\\mu_i\\) toward the prior or provide shrinkage to the mean.\n\n\n\n\n\n\n\n\nQuestion\n\n\nWhy would we ever want to do this? Why not just stick with the MLE?\n\n\n\n\nMSE or Bias-Variance Tradeoff"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#modern-relevance",
    "href": "resources/slides/05-hierarchical-models.html#modern-relevance",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Modern Relevance",
    "text": "Modern Relevance\n\nThe fact that a biased estimator would do a better job in many estimation/prediction problems can be proven rigorously, and is referred to as Stein’s paradox.\nStein’s result implies, in particular, that the sample mean is an inadmissible estimator of the mean of a multivariate normal distribution in more than two dimensions i.e. there are other estimators that will come closer to the true value in expectation.\nIn fact, these are Bayes point estimators (the posterior expectation of the parameter \\(\\mu_i\\)).\nMost of what we do now in high-dimensional statistics is develop biased estimators that perform better than unbiased ones.\nExamples: lasso regression, ridge regression, various kinds of hierarchical Bayesian models, etc."
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#population-parameters",
    "href": "resources/slides/05-hierarchical-models.html#population-parameters",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Population Parameters",
    "text": "Population Parameters\n\nwe don’t know \\(\\mu\\) (or \\(\\sigma^2\\) and \\(\\sigma^2_\\mu\\) for that matter)\nFind marginal likelihood \\(\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu)\\) by integrating out \\(\\mu_i\\) with respect to \\(g\\) \\[\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu) \\propto \\prod_{i = 1}^n\n\\int \\textsf{N}(y_i; \\mu_i, \\sigma^2)  \\textsf{N}(\\mu_i; \\mu, \\sigma^2_\\mu) \\, d \\mu_i\\]\nProduct of predictive distributions for \\(Y_i \\mid \\mu, \\sigma^2, \\sigma^2_\\mu \\overset{iid}{\\sim} \\textsf{N}(\\mu, \\sigma^2 + \\sigma^2_\\mu)\\)\n\\[\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu) \\propto \\prod_{i = 1}^n (\\sigma^2 + \\sigma^2_\\mu)^{-1/2} \\exp \\left\\{ - \\frac{1}{2} \\frac{\\left(y_i - \\mu \\right)^2}{\\sigma^2 + \\sigma^2_\\mu }\\right\\}\\]\nFind MLE’s"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#mles",
    "href": "resources/slides/05-hierarchical-models.html#mles",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "MLEs",
    "text": "MLEs\n\\[\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu) \\propto  (\\sigma^2 + \\sigma^2_\\mu)^{-n/2} \\exp\\left\\{ - \\frac{1}{2} \\sum_{i=1}^n\\frac{\\left(y_i - \\mu \\right)^2}{\\sigma^2 + \\sigma^2_\\mu }\\right\\}\\]\n\nMLE of \\(\\mu\\): \\(\\hat{\\mu} = \\bar{y}\\)\nCan we say anything about \\(\\sigma^2_\\mu\\)? or \\(\\sigma^2\\) individually?\nMLE of \\(\\sigma^2 + \\sigma^2_\\mu\\) is \\[\\widehat{\\sigma^2 + \\sigma^2_\\mu} = \\frac{\\sum(y_i - \\bar{y})^2}{n}\\]\nAssume \\(\\sigma^2\\) is known (say 1) \\[\\hat{\\sigma}^2_\\mu = \\frac{\\sum(y_i - \\bar{y})^2}{n} - 1\\]"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#empirical-bayes-estimates",
    "href": "resources/slides/05-hierarchical-models.html#empirical-bayes-estimates",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Empirical Bayes Estimates",
    "text": "Empirical Bayes Estimates\n\nplug in estimates of hyperparameters into the prior and pretend they are known\nresulting estimates are known as Empirical Bayes\nEstimates of variances may be negative - constrain to 0 on the boundary\nunderestimates uncertainty\nFully Bayes would put a prior on the unknowns"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#bayes-and-hierarchical-models",
    "href": "resources/slides/05-hierarchical-models.html#bayes-and-hierarchical-models",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Bayes and Hierarchical Models",
    "text": "Bayes and Hierarchical Models\n\nWe know the conditional posterior distribution of \\(\\mu_i\\) given the other parameters, lets work with the marginal likelihood \\(\\cal{L}(\\theta)\\)\nneed a prior \\(\\pi(\\theta)\\) for unknown parameters are \\(\\theta = (\\mu, \\sigma^2, \\sigma^2_\\mu)\\) (details later)\nPosterior \\[\\pi(\\theta \\mid y) = \\frac{\\pi(\\theta) \\cal{L}(\\theta)}\n{\\int_\\Theta \\pi(\\theta) \\cal{L}(\\theta) \\, d\\theta} =\n\\frac{\\pi(\\theta) \\cal{L}(\\theta)}\n{m(y)}\\]\nProblems: Except for simple cases (conjugate models) \\(m(y)\\) is not available analytically"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#large-sample-approximations",
    "href": "resources/slides/05-hierarchical-models.html#large-sample-approximations",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Large Sample Approximations",
    "text": "Large Sample Approximations\n\nAppeal to BvM (Bayesian Central Limit Theorem) and approximate \\(\\pi(\\theta \\mid y)\\) with a Gaussian distribution centered at the posterior mode \\(\\hat{\\theta}\\) and asymptotic covariance matrix \\[V_\\theta = \\left[- \\frac{\\partial^2}{\\partial \\theta \\partial \\theta^T} \\left\\{\\log(\\pi(\\theta)) + \\log(\\cal{L}(\\theta)) \\right\\} \\right]^{-1}\\]\nrelated to Laplace approximation to integral (also large sample)\nUse normal approximation to find \\(\\textsf{E}[h(\\theta) \\mid y]\\)\nIntegral may not exist in closed form (non-linear functions)\nuse numerical quadrature (doesn’t scale up)\nStochastic methods of integration"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#stochastic-integration",
    "href": "resources/slides/05-hierarchical-models.html#stochastic-integration",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Stochastic Integration",
    "text": "Stochastic Integration\n\nStochastic integration \\[\\textsf{E}[h(\\theta) \\mid y] =  \\int_\\Theta h(\\theta) \\pi(\\theta \\mid y) \\, d\\theta \\approx \\frac{1}{T}\\sum_{t=1}^{T} h(\\theta^{(t)}) \\qquad \\theta^{(t)} \\sim \\pi(\\theta \\mid y)\\]\nwhat if we can’t sample from the \\(\\pi(\\theta \\mid y)\\) but can sample from some distribution \\(q()\\) \\[\\textsf{E}[h(\\theta) \\mid y] =  \\int_\\Theta h(\\theta) \\frac{\\pi(\\theta \\mid y)}{q(\\theta)} q(\\theta)\\, d\\theta \\approx \\frac{1}{T}\\sum_{t=1}^{T} h(\\theta^{(t)}) \\frac{\\pi(\\theta^{(t)} \\mid y)} {q(\\theta^{(t)})} \\qquad\\] where \\(\\theta^{(t)} \\sim q(\\theta)\\)\nWithout the \\(m(y)\\) in \\(\\pi(\\theta \\mid y)\\) we just have \\(\\pi(\\theta \\mid y) \\propto \\pi(\\theta) \\cal{L}(\\theta)\\)\nuse twice for numerator and denominator"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#important-sampling-estimate",
    "href": "resources/slides/05-hierarchical-models.html#important-sampling-estimate",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Important Sampling Estimate",
    "text": "Important Sampling Estimate\n\nEstimate of \\(m(y)\\) \\[m(y) \\approx \\frac{1}{T} \\sum_{t=1}^{T}  \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})} \\qquad \\theta^{(t)} \\sim q(\\theta)\\]\nRatio estimator of \\(\\textsf{E}[h(\\theta) \\mid y]\\) \\[\\textsf{E}[h(\\theta) \\mid y] \\approx \\frac{\\sum_{t=1}^{T} h(\\theta^{(t)}) \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}}\n{ \\sum_{t=1}^{T}  \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}}\n\\qquad \\theta^{(t)} \\sim q(\\theta)\\]\nWeighted average with importance weights \\(w(\\theta^{(t)}) \\propto \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}\\) \\[\\textsf{E}[h(\\theta) \\mid y] \\approx \\sum_{t=1}^{T} h(\\theta^{(t)}) w(\\theta^{(t)})/\\sum_{t=1}^T w(\\theta^{(t)}) \\qquad \\theta^{(t)} \\sim q(\\theta)\\]"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#issues",
    "href": "resources/slides/05-hierarchical-models.html#issues",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Issues",
    "text": "Issues\n\nif \\(q()\\) puts too little mass in regions with high posterior density, we can have some extreme weights\noptimal case is that \\(q()\\) is as close as possible to the posterior so that all weights are constant\nEstimate may have large variance\nProblems with finding a good \\(q()\\) in high dimensions \\((d &gt; 20)\\) or with skewed distributions"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#markov-chain-monte-carlo-mcmc",
    "href": "resources/slides/05-hierarchical-models.html#markov-chain-monte-carlo-mcmc",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Markov Chain Monte Carlo (MCMC)",
    "text": "Markov Chain Monte Carlo (MCMC)\n\nTypically \\(\\pi(\\theta)\\) and \\(\\cal{L}(\\theta)\\) are easy to evaluate\n\n\n\n\n\n\n\n\nQuestion\n\n\nHow do we draw samples only using evaluations of the prior and likelihood in higher dimensional settings?\n\n\n\n\nconstruct a Markov chain \\(\\theta^{(t)}\\) in such a way the the stationary distribution of the Markov chain is the posterior distribution \\(\\pi(\\theta \\mid y)\\)! \\[\\theta^{(0)} \\overset{k}{\\longrightarrow} \\theta^{(1)} \\overset{k}{\\longrightarrow} \\theta^{(2)} \\cdots\\]\n\\(k_t(\\theta^{(t-1)} ; \\theta^{(t)})\\) transition kernel\ninitial state \\(\\theta^{(0)}\\)\nchoose some nice \\(k_t\\) such that \\(\\theta^{(t)} \\to \\pi(\\theta \\mid y)\\) as \\(t \\to \\infty\\)\nbiased samples initially but get closer to the target\nMetropolis Algorithm (1950’s)"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#stochastic-sampling-intuition",
    "href": "resources/slides/05-hierarchical-models.html#stochastic-sampling-intuition",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Stochastic Sampling Intuition",
    "text": "Stochastic Sampling Intuition\n\nFrom a sampling perspective, we need to have a large sample or group of values, \\(\\theta^{(1)}, \\ldots, \\theta^{(S)}\\) from \\(\\pi(\\theta \\mid y)\\) whose empirical distribution approximates \\(\\pi(\\theta \\mid y)\\).\nfor any two sets \\(A\\) and \\(B\\), we want \\[\\frac{\\dfrac{\\# \\theta^{(s)} \\in A}{S}}{\\dfrac{\\# \\theta^{(s)} \\in B}{S} } = \\dfrac{\\# \\theta^{(s)} \\in A}{\\# \\theta^{(s)} \\in B} \\approx \\dfrac{\\pi(\\theta \\in A \\mid  y)}{\\pi(\\theta \\in B \\mid  y)}\\]\nSuppose we have a working group \\(\\theta^{(1)}, \\ldots, \\theta^{(s)}\\) at iteration \\(s\\), and need to add a new value \\(\\theta^{(s+1)}\\).\nConsider a candidate value \\(\\theta^\\star\\) that is close to \\(\\theta^{(s)}\\)\nShould we set \\(\\theta^{(s+1)} = \\theta^\\star\\) or not?"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#posterior-ratio.",
    "href": "resources/slides/05-hierarchical-models.html#posterior-ratio.",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Posterior Ratio.",
    "text": "Posterior Ratio.\nlook at the ratio \\[\n\\begin{split}\nM & = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)} = \\frac{\\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y)} } {\\dfrac{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}{p(y)}}\\\\\n\\\\\n&  = \\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}\n\\end{split}\n\\]\n\ndoes not depend on the marginal likelihood we don’t know!"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#metropolis-algorithm",
    "href": "resources/slides/05-hierarchical-models.html#metropolis-algorithm",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Metropolis algorithm",
    "text": "Metropolis algorithm\n\nIf \\(M &gt; 1\\)\n\nIntuition: \\(\\theta^{(s)}\\) is already a part of the density we desire and the density at \\(\\theta^\\star\\) is even higher than the density at \\(\\theta^{(s)}\\).\nAction: set \\(\\theta^{(s+1)} = \\theta^\\star\\)\n\nIf \\(M &lt; 1\\),\n\nIntuition: relative frequency of values in our group \\(\\theta^{(1)}, \\ldots, \\theta^{(s)}\\) “equal” to \\(\\theta^\\star\\) should be \\(\\approx M = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)}\\).\nFor every \\(\\theta^{(s)}\\), include only a fraction of an instance of \\(\\theta^\\star\\).\nAction: set \\(\\theta^{(s+1)} = \\theta^\\star\\) with probability \\(M\\) and \\(\\theta^{(s+1)} = \\theta^{(s)}\\) with probability \\(1-M\\)."
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#proposal-distribution",
    "href": "resources/slides/05-hierarchical-models.html#proposal-distribution",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Proposal Distribution",
    "text": "Proposal Distribution\n\nWhere should the proposed value \\(\\theta^\\star\\) come from?\nSample \\(\\theta^\\star\\) close to the current value \\(\\theta^{(s)}\\) using a symmetric proposal distribution \\(\\theta^\\star \\sim q(\\theta^\\star \\mid \\theta^{(s)})\\)\n\\(q()\\) is actually a “family of proposal distributions”, indexed by the specific value of \\(\\theta^{(s)}\\).\nHere, symmetric means that \\(q(\\theta^\\star \\mid \\theta^{(s)}) = q(\\theta^{(s)} \\mid \\theta^\\star)\\).\nCommon choice \\[\\textsf{N}(\\theta^\\star; \\theta^{(s)}, \\delta^2 \\Sigma)\\] with \\(\\Sigma\\) based on the approximate \\(\\textsf{Cov}(\\theta \\mid y)\\) and \\(\\delta = 2.44/\\text{dim}(\\theta)\\) or \\[\\text{Unif}(\\theta^\\star; \\theta^{(s)} - \\delta, \\theta^{(s)} + \\delta)\\]"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#metropolis-algorithm-recap",
    "href": "resources/slides/05-hierarchical-models.html#metropolis-algorithm-recap",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Metropolis Algorithm Recap",
    "text": "Metropolis Algorithm Recap\nThe algorithm proceeds as follows:\n\nGiven \\(\\theta^{(1)}, \\ldots, \\theta^{(s)}\\), generate a candidate value \\(\\theta^\\star \\sim q(\\theta^\\star \\mid \\theta^{(s)})\\).\nCompute the acceptance ratio \\[\\begin{split}\nM & = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)} = \\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}.\n\\end{split}\\]\nSet \\[\\begin{eqnarray*}\n\\theta^{(s+1)} = \\left\\{ \\begin{array}{ll}\n\\theta^\\star & \\quad \\text{with probability} \\quad \\text{min}(M,1) \\\\\n\\theta^{(s)} & \\quad \\text{with probability} \\quad 1 - \\text{min}(M,1) \\\\\n\\end{array} \\right.\n\\end{eqnarray*}\\] equivalent to sampling \\(u \\sim U(0,1)\\) independently and setting \\[\\begin{eqnarray*}\n\\theta^{(s+1)} = \\left\\{ \\begin{array}{ll}\n\\theta^\\star & \\quad \\text{if} \\quad u &lt; M \\\\\n\\theta^{(s)} & \\quad \\text{if} \\quad \\text{otherwise} \\\\\n\\end{array} \\right. .\n\\end{eqnarray*}\n\\]"
  },
  {
    "objectID": "resources/slides/05-hierarchical-models.html#notes",
    "href": "resources/slides/05-hierarchical-models.html#notes",
    "title": "Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC",
    "section": "Notes",
    "text": "Notes\n\nAcceptance probability is \\[M = \\min \\left\\{ 1, \\frac{\\pi(\\theta^\\star) \\cal{L}(\\theta^\\star)}\n                         {\\pi(\\theta^{(s)}) \\cal{L}(\\theta^{(s)})}\\right\\}\\]\nratio of posterior densities where normalizing constant cancels!\nThe Metropolis chain ALWAYS moves to the proposed \\(\\theta^\\star\\) at iteration \\(s+1\\) if \\(\\theta^\\star\\) has higher target density than the current \\(\\theta^{(s)}\\).\nSometimes, it also moves to a \\(\\theta^\\star\\) value with lower density in proportion to the density value itself.\nThis leads to a random, Markov process that naturally explores the space according to the probability defined by \\(\\pi(\\theta \\mid y)\\), and hence generates a sequence that, while dependent, eventually represents draws from \\(\\pi(\\theta \\mid y)\\) (stationary distribution of the Markov Chain).\n\n\n\n\nhttps://sta702-F23.github.io/website/"
  }
]