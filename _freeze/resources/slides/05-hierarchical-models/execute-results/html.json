{
  "hash": "952cf81858938fc30eaf6842426b4a5a",
  "result": {
    "markdown": "---\ntitle: \"Introduction to Hierarchical Modelling, Empirical Bayes, and MCMC\"\nsubtitle: \"STA702 Lecture 5\"\nauthor: \"Merlise Clyde\"\ninstitute: \"Duke University\"\nformat: \n  revealjs:\n    theme: [simple, custom.scss]\n    slide-number: true\n    incremental: true\n    scrollable: false\n    controls: true\n    fragments: true\n    preview-links: auto\n    logo: ../../img/icon.png\n    footer: <https://sta702-F23.github.io/website/>\n    chalkboard: \n      boardmarker-width: 1\n      chalk-width: 2\n      chalk-effect: 0\n    embed-resources: false\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"    \neditor: \n  markdown: \n    wrap: 72\nexecute: \n  echo: false\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n## Normal Means Model  {.smaller}\n- Suppose we have normal data with \n$$Y_i \\mid \\mu_i, \\sigma^2 \\overset{ind}{\\sim} \\textsf{N}(\\mu_i, \\sigma^2)$$\n \n\n- separate mean for each observation!\n\n \n\n- **Question**: How can we possibly hope to estimate all these $\\mu_i$?  One $y_i$ per $\\mu_i$ and $n$ observations!\n\n \n\n- **Naive estimator**:  just consider only using $y_i$ in estimating and not the other observations.\n\n \n\n- MLE $\\hat{\\mu}_i = y_i$\n\n  \n\n- **Hierarchical Viewpoint**:  Let's borrow information from other observations!\n\n\n## Motivation {.smaller}\n\n:::: {.columns}\n\n::: {.column width=50%}\n\n&nbsp;\n\n&nbsp;\n\n- Example $y_i$ is difference in gene expression for the $i^{\\text{th}}$ gene between cancer and control lines\n\n \n\n- may be natural to think that the $\\mu_i$ arise from some common distribution,\n$\\mu_i \\overset{iid}{\\sim} g$\n\n- unbiased but high variance estimators of $\\mu_i$ based on one observation!\n\n\n:::\n\n\n::: {.column width=50%}\n\n\n\n\n::: {.cell layout-align=\"center\" fig='true'}\n::: {.cell-output-display}\n![](05-hierarchical-models_files/figure-revealjs/randomeffects-1.png){fig-align='center' width=80%}\n:::\n:::\n\n \n:::\n\n::::\n\n\n---\n##  Low Variability\n\n::: {.cell layout-align=\"center\" fig='true'}\n::: {.cell-output-display}\n![](05-hierarchical-models_files/figure-revealjs/means-1.png){fig-align='center' width=50%}\n:::\n:::\n \n\n- little variation in $\\mu_i$s so a better estimate might be $\\bar{y}$\n\n \n\n- Not forced to choose either - what about some weighted average between $y_i$ and $\\bar{y}$?\n\n \n## Simple Example {.smaller}\n\n- Data Model\n$$Y_i \\mid \\mu_i, \\sigma^2 \\overset{ind}{\\sim} \\textsf{N}(\\mu_i, \\sigma^2)$$\n\n \n\n- Means Model \n$$\\mu_i \\mid \\mu, \\sigma^2_\\mu \\overset{iid}{\\sim} \\textsf{N}(\\mu, \\sigma^2_{\\mu})$$ \n \n\n- not necessarily a prior!\n\n \n\n- Now estimate $\\mu_i$   (let $\\phi = 1/\\sigma^2$ and $\\phi_{\\mu} = 1/\\sigma^2_\\mu$)\n\n \n\n- Calculate the \"posterior\"  $\\mu_i \\mid y_i, \\mu, \\phi, \\phi_\\mu$\n\n \n## Hiearchical Estimates  {.smaller}\n\n- Posterior: $\\mu_i \\mid y_i, \\mu, \\phi, \\phi_\\mu \\overset{ind}{\\sim} \\textsf{N}(\\tilde{\\mu}_i, 1/\\tilde{\\phi}_\\mu)$\n \n\n- estimator of $\\mu_i$ weighted average of data and population parameter $\\mu$\n$$\\tilde{\\mu}_i = \\frac{\\phi_\\mu \\mu + \\phi y_i}\n                          {\\phi_\\mu + \\phi} \\qquad \\qquad \\tilde{\\phi}_\\mu = \\phi + \\phi_\\mu$$\n\n\n \n\n- if $\\phi_\\mu$ is large relative to $\\phi$ all of the $\\mu_i$ are close together and benefit by borrowing  information\n\n \n\n- in limit as $\\sigma^2_\\mu \\to 0$ or $\\phi_\\mu \\to \\infty$ we have $\\tilde{\\mu}_i = \\mu$  (all means are the same)\n\n \n\n- if $\\phi_\\mu$ is small relative to $\\phi$ little borrowing of information\n\n \n\n- in the limit as $\\phi_\\mu \\to 0$ we have $\\tilde{\\mu}_i = y_i$\n\n\n\n\n\n \n## Bayes Estimators and Bias {.smaller}\n\n\n- Note: you often benefit from a hierarchical model, even if its not obvious that the $\\mu_i$ are related!\n\n \n\n- The MLE for the $\\mu_i$ is just the sample $y_i$.\n\n \n\n- $y_i$ is unbiased for $\\mu_i$ but can have high variability!\n\n \n\n- the posterior mean is actually biased.\n\n \n\n- Usually through the weighting of the sample data and prior, Bayes procedures have the tendency to pull the estimate of $\\mu_i$ toward the prior  or  provide **shrinkage** to the \nmean.\n\n\n . . . \n\n::: {.callout-note title=\"Question\"}\n\nWhy would we ever want to do this? Why not just stick with the MLE?\n\n:::\n\n\n\n \n\n\n\n-  MSE or Bias-Variance Tradeoff\n\n\n\n\n\n\n \n## Modern Relevance {.smaller}\n\n- The fact that a biased estimator would do a better job in many estimation/prediction problems can be proven rigorously, and is referred to as **Stein's paradox**.\n\n \n\n- Stein's result implies, in particular, that the sample mean is an *inadmissible* estimator of the mean of a multivariate normal distribution in more than two dimensions   i.e. there are other estimators that will come closer to the true value in expectation.\n\n \n\n- In fact, these are Bayes point estimators (the posterior expectation of the parameter $\\mu_i$).\n\n \n\n- Most of what we do now in high-dimensional statistics is develop biased estimators that perform better than unbiased ones.\n\n \n\n- Examples: lasso regression, ridge regression, various kinds of hierarchical Bayesian models, etc.\n\n \n## Population Parameters {.smaller}\n\n\n- we don't know $\\mu$ (or $\\sigma^2$ and $\\sigma^2_\\mu$ for that matter)\n\n \n\n- Find marginal likelihood $\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu)$ by integrating out $\\mu_i$ with respect to $g$\n$$\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu) \\propto \\prod_{i = 1}^n \n\\int \\textsf{N}(y_i; \\mu_i, \\sigma^2)  \\textsf{N}(\\mu_i; \\mu, \\sigma^2_\\mu) \\, d \\mu_i$$\n\n \n\n- Product of predictive distributions for $Y_i \\mid \\mu, \\sigma^2, \\sigma^2_\\mu \\overset{iid}{\\sim} \\textsf{N}(\\mu, \\sigma^2 + \\sigma^2_\\mu)$  \n$$\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu) \\propto \\prod_{i = 1}^n (\\sigma^2 + \\sigma^2_\\mu)^{-1/2} \\exp \\left\\{ - \\frac{1}{2} \\frac{\\left(y_i - \\mu \\right)^2}{\\sigma^2 + \\sigma^2_\\mu }\\right\\}$$\n\n \n\n- Find MLE's\n\n \n## MLEs {.smaller}\n\n$$\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu) \\propto  (\\sigma^2 + \\sigma^2_\\mu)^{-n/2} \\exp\\left\\{ - \\frac{1}{2} \\sum_{i=1}^n\\frac{\\left(y_i - \\mu \\right)^2}{\\sigma^2 + \\sigma^2_\\mu }\\right\\}$$\n\n \n\n\n- MLE of $\\mu$: $\\hat{\\mu} = \\bar{y}$\n\n\n \n\n- Can we say anything about $\\sigma^2_\\mu$?  or $\\sigma^2$ individually?\n\n \n\n\n- MLE of $\\sigma^2 + \\sigma^2_\\mu$ is \n$$\\widehat{\\sigma^2 + \\sigma^2_\\mu} = \\frac{\\sum(y_i - \\bar{y})^2}{n}$$\n\n\n \n\n- Assume $\\sigma^2$ is known (say 1)\n$$\\hat{\\sigma}^2_\\mu = \\frac{\\sum(y_i - \\bar{y})^2}{n} - 1$$\n\n\n \n## Empirical Bayes Estimates\n\n- plug in estimates of hyperparameters into the prior and pretend they are known \n\n \n- resulting estimates are known as Empirical Bayes\n\n\n\n \n\n\n\n \n\n- Estimates of variances may be negative -  constrain to 0 on the boundary\n\n\n \n-  underestimates uncertainty \n\n- Fully Bayes would put a prior on the unknowns\n\n \n##  Bayes and Hierarchical Models {.smaller}\n\n\n\n- We know the conditional posterior distribution of $\\mu_i$ given the other parameters, lets work with the marginal likelihood $\\cal{L}(\\theta)$\n\n \n\n- need a prior $\\pi(\\theta)$ for unknown parameters are  $\\theta = (\\mu, \\sigma^2, \\sigma^2_\\mu)$  (details later)\n\n\n \n\n- Posterior\n$$\\pi(\\theta \\mid y) = \\frac{\\pi(\\theta) \\cal{L}(\\theta)}\n{\\int_\\Theta \\pi(\\theta) \\cal{L}(\\theta) \\, d\\theta} =\n\\frac{\\pi(\\theta) \\cal{L}(\\theta)}\n{m(y)}$$\n\n \n\n- Problems:  Except for simple cases (conjugate models)  $m(y)$ is not available analytically\n\n \n## Large Sample Approximations {.smaller}\n\n- Appeal to BvM (Bayesian Central Limit Theorem) and approximate $\\pi(\\theta \\mid y)$ with a Gaussian distribution centered at the posterior mode $\\hat{\\theta}$  and asymptotic covariance matrix \n$$V_\\theta = \\left[- \\frac{\\partial^2}{\\partial \\theta \\partial \\theta^T} \\left\\{\\log(\\pi(\\theta)) + \\log(\\cal{L}(\\theta)) \\right\\} \\right]^{-1}$$\n\n- related to Laplace approximation to integral (also large sample)\n \n- Use normal approximation  to find $\\textsf{E}[h(\\theta) \\mid y]$\n\n- Integral may not exist in closed form (non-linear functions)\n\n - use numerical quadrature (doesn't scale up)\n\n- Stochastic methods of integration\n \n## Stochastic Integration {.smaller}\n\n\n- Stochastic integration\n$$\\textsf{E}[h(\\theta) \\mid y] =  \\int_\\Theta h(\\theta) \\pi(\\theta \\mid y) \\, d\\theta \\approx \\frac{1}{T}\\sum_{t=1}^{T} h(\\theta^{(t)}) \\qquad \\theta^{(t)} \\sim \\pi(\\theta \\mid y)$$\n \n\n- what if we can't sample from the $\\pi(\\theta \\mid y)$ but can sample from some distribution $q()$\n $$\\textsf{E}[h(\\theta) \\mid y] =  \\int_\\Theta h(\\theta) \\frac{\\pi(\\theta \\mid y)}{q(\\theta)} q(\\theta)\\, d\\theta \\approx \\frac{1}{T}\\sum_{t=1}^{T} h(\\theta^{(t)}) \\frac{\\pi(\\theta^{(t)} \\mid y)} {q(\\theta^{(t)})} \\qquad$$\nwhere $\\theta^{(t)} \\sim q(\\theta)$\n\n \n\n- Without the $m(y)$  in $\\pi(\\theta \\mid y)$ we just have $\\pi(\\theta \\mid y) \\propto  \\pi(\\theta) \\cal{L}(\\theta)$\n\n\n \n\n-  use twice for numerator and denominator\n\n\n \n## Important Sampling Estimate {.smaller}\n\n- Estimate of $m(y)$\n$$m(y) \\approx \\frac{1}{T} \\sum_{t=1}^{T}  \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})} \\qquad \\theta^{(t)} \\sim q(\\theta)$$\n\n- Ratio estimator of $\\textsf{E}[h(\\theta) \\mid y]$\n$$\\textsf{E}[h(\\theta) \\mid y] \\approx \\frac{\\sum_{t=1}^{T} h(\\theta^{(t)}) \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}}\n{ \\sum_{t=1}^{T}  \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}}\n\\qquad \\theta^{(t)} \\sim q(\\theta)$$\n\n- Weighted average with importance weights $w(\\theta^{(t)}) \\propto \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}$\n$$\\textsf{E}[h(\\theta) \\mid y] \\approx \\sum_{t=1}^{T} h(\\theta^{(t)}) w(\\theta^{(t)})/\\sum_{t=1}^T w(\\theta^{(t)}) \\qquad \\theta^{(t)} \\sim q(\\theta)$$ \n\n##  Issues \n\n- if $q()$ puts too little mass in regions with high posterior density,  we can have\nsome extreme weights\n\n- optimal case is that $q()$ is as close as possible to the posterior so that all weights are constant\n\n- Estimate may have large variance\n\n- Problems with finding a good $q()$ in high dimensions $(d > 20)$ or with skewed distributions\n\n## Markov Chain Monte Carlo (MCMC) {.smaller}\n\n\n- Typically $\\pi(\\theta)$ and $\\cal{L}(\\theta)$ are easy to evaluate\n\n \n. . .\n\n::: {.callout-note title=\"Question\"}\nHow do we draw samples  only using evaluations of the prior and likelihood in higher dimensional settings?\n:::\n \n\n- construct a Markov chain $\\theta^{(t)}$ in such a way the the stationary distribution of the Markov chain is the posterior distribution $\\pi(\\theta \\mid y)$!\n$$\\theta^{(0)} \\overset{k}{\\longrightarrow} \\theta^{(1)} \\overset{k}{\\longrightarrow} \\theta^{(2)} \\cdots$$\n \n\n- $k_t(\\theta^{(t-1)} ; \\theta^{(t)})$  transition kernel\n\n \n\n- initial state $\\theta^{(0)}$\n\n \n\n- choose some nice $k_t$ such that $\\theta^{(t)} \\to \\pi(\\theta \\mid y)$ as $t \\to \\infty$\n\n \n\n- biased samples initially but get closer to the target\n\n- Metropolis Algorithm (1950's)\n\n \n\n##  Stochastic Sampling Intuition {.smaller}\n\n- From a sampling perspective, we need to have a large sample or group of values, $\\theta^{(1)}, \\ldots, \\theta^{(S)}$ from $\\pi(\\theta \\mid  y)$ whose empirical distribution approximates $\\pi(\\theta \\mid  y)$.\n\n\n\n-  for any two sets $A$ and $B$, we want\n$$\\frac{\\dfrac{\\# \\theta^{(s)} \\in A}{S}}{\\dfrac{\\# \\theta^{(s)} \\in B}{S} } = \\dfrac{\\# \\theta^{(s)} \\in A}{\\# \\theta^{(s)} \\in B} \\approx \\dfrac{\\pi(\\theta \\in A \\mid  y)}{\\pi(\\theta \\in B \\mid  y)}$$\n\n\n\n- Suppose we have a working group $\\theta^{(1)}, \\ldots, \\theta^{(s)}$ at iteration $s$, and need to add a new value $\\theta^{(s+1)}$.\n\n\n\n- Consider a candidate value $\\theta^\\star$ that is  _close_ to $\\theta^{(s)}$ \n\n\n\n\n- Should we set $\\theta^{(s+1)} = \\theta^\\star$ or not?\n\n\n## Posterior Ratio. {.smaller}\n\n\nlook at  the ratio \n$$\n\\begin{split}\nM & = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)} = \\frac{\\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y)} } {\\dfrac{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}{p(y)}}\\\\\n\\\\\n&  = \\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}\n\\end{split}\n$$\n\n\n\n\n- does not depend on the marginal likelihood we don't know!\n\n\n\n\n\n## Metropolis algorithm {.smaller}\n\n- If $M > 1$\n  + Intuition: $\\theta^{(s)}$ is already a part of the density we desire and the density at $\\theta^\\star$ is even higher than the density at $\\theta^{(s)}$.\n  \n  + Action: set $\\theta^{(s+1)} = \\theta^\\star$\n\n\n\n- If $M < 1$, \n  + Intuition: relative frequency of values in our group $\\theta^{(1)}, \\ldots, \\theta^{(s)}$ \"equal\" to $\\theta^\\star$ should be $\\approx M = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)}$. \n \n\n  + For every $\\theta^{(s)}$, include only a fraction of an instance of $\\theta^\\star$.\n\n\n  + Action: set $\\theta^{(s+1)} = \\theta^\\star$ with probability $M$ and $\\theta^{(s+1)} = \\theta^{(s)}$ with probability $1-M$.\n\n## Proposal Distribution {.smaller}\n\n\n- Where should the proposed value $\\theta^\\star$ come from? \n\n\n\n- Sample $\\theta^\\star$ close to the current value $\\theta^{(s)}$ using a **symmetric proposal distribution** $\\theta^\\star \\sim q(\\theta^\\star \\mid \\theta^{(s)})$\n\n\n\n\n- $q()$ is actually a \"family of proposal distributions\", indexed by the specific value of $\\theta^{(s)}$.\n\n\n\n- Here, symmetric means that $q(\\theta^\\star \\mid \\theta^{(s)}) = q(\\theta^{(s)} \\mid \\theta^\\star)$. \n\n\n\n- Common choice \n$$\\textsf{N}(\\theta^\\star; \\theta^{(s)}, \\delta^2 \\Sigma)$$\n with $\\Sigma$ based on the approximate $\\textsf{Cov}(\\theta \\mid y)$ and $\\delta = 2.44/\\text{dim}(\\theta)$ or \n $$\\text{Unif}(\\theta^\\star; \\theta^{(s)} - \\delta, \\theta^{(s)} + \\delta)$$\n\n\n## Metropolis Algorithm Recap {.smaller}\n\nThe algorithm proceeds as follows:\n\n  1. Given $\\theta^{(1)}, \\ldots, \\theta^{(s)}$, generate a _candidate_ value $\\theta^\\star \\sim q(\\theta^\\star \\mid \\theta^{(s)})$.\n  \n\n  2. Compute the acceptance ratio\n$$\\begin{split}\nM & = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)} = \\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}.\n\\end{split}$$\n\n  3. Set\n$$\\begin{eqnarray*}\n\\theta^{(s+1)} = \\left\\{ \\begin{array}{ll}\n\\theta^\\star & \\quad \\text{with probability} \\quad \\text{min}(M,1) \\\\\n\\theta^{(s)} & \\quad \\text{with probability} \\quad 1 - \\text{min}(M,1) \\\\\n\\end{array} \\right.\n\\end{eqnarray*}$$\nequivalent to sampling $u \\sim U(0,1)$ independently and setting\n $$\\begin{eqnarray*}\n\\theta^{(s+1)} = \\left\\{ \\begin{array}{ll}\n\\theta^\\star & \\quad \\text{if} \\quad u < M \\\\\n\\theta^{(s)} & \\quad \\text{if} \\quad \\text{otherwise} \\\\\n\\end{array} \\right. .\n\\end{eqnarray*}\n$$\n\n\n##  Notes {.smaller}\n\n- Acceptance probability is \n$$M = \\min \\left\\{ 1, \\frac{\\pi(\\theta^\\star) \\cal{L}(\\theta^\\star)}\n                           {\\pi(\\theta^{(s)}) \\cal{L}(\\theta^{(s)})}\\right\\}$$\n                            \n \n\n- ratio of posterior densities where normalizing constant cancels!\n\n\n-  The Metropolis chain ALWAYS moves to the proposed $\\theta^\\star$ at iteration $s+1$ if $\\theta^\\star$ has\nhigher target density than the current $\\theta^{(s)}$.\n\n\n\n- Sometimes, it also moves to a $\\theta^\\star$ value with lower density in proportion to the density value itself. \n\n\n\n- This leads to a random, Markov process that naturally explores the space according to the probability defined by $\\pi(\\theta \\mid y)$, and hence generates a sequence that, while dependent, eventually represents draws from $\\pi(\\theta \\mid y)$ (stationary distribution of the Markov Chain).\n\n\n",
    "supporting": [
      "05-hierarchical-models_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/font-awesome/css/all.min.css\" rel=\"stylesheet\" />\n<link href=\"../../site_libs/font-awesome/css/v4-shims.min.css\" rel=\"stylesheet\" />\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}