{
  "hash": "531546aca6bb04625dab77a8ae6562f2",
  "result": {
    "markdown": "---\ntitle: \"Lecture 6: Metropolis Algorithms and Stochastic Sampling\"\nauthor: \"Merlise Clyde\"\ninstitute: \"Duke University\"\nformat: \n  revealjs:\n    theme: [simple, custom.scss]\n    slide-number: true\n    incremental: true\n    scrollable: false\n    controls: true\n    fragments: true\n    preview-links: auto\n    logo: ../../img/icon.png\n    footer: <https://sta702-F23.github.io/website/>\n    chalkboard: \n      boardmarker-width: 1\n      chalk-width: 2\n      chalk-effect: 0\n    embed-resources: false\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"    \neditor: \n  markdown: \n    wrap: 72\nexecute: \n  echo: false\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n## Last Class: Normal Means Model {.smaller}\n\n- Data Model\n$Y_i \\mid \\mu_i, \\sigma^2 \\overset{ind}{\\sim} \\textsf{N}(\\mu_i, \\sigma^2)$\n\n\n- Means Model \n$\\mu_i \\mid \\mu, \\sigma^2_\\mu \\overset{iid}{\\sim} \\textsf{N}(\\mu, \\sigma^2_{\\mu})$$\n\n\n\n- Found marginal likelihood $\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu)$ by integrating out $\\mu_i$ with respect to $g$\n$$\\cal{L}(\\mu, \\sigma^2, \\sigma^2_\\mu) \\propto (\\sigma^2 + \\sigma^2_\\mu)^{-n/2} \\exp \\left\\{ - \\frac{1}{2} \\frac{\\sum_{i=1}^n\\left(y_i - \\mu \\right)^2}{\\sigma^2 + \\sigma^2_\\mu }\\right\\}$$\n\n\n\n\n\n\n\n- Posterior for $\\theta = \\mu, \\sigma^2_\\mu$ with $\\sigma^2 = 1$\n$$\\pi(\\theta \\mid y) = \\frac{\\pi(\\theta) \\cal{L}(\\theta)}\n{\\int_\\Theta \\pi(\\theta) \\cal{L}(\\theta) \\, d\\theta} =\n\\frac{\\pi(\\theta) \\cal{L}(\\theta)}\n{m(y)}$$\n\n- while we can integrate out $\\mu$, no closed form for  posterior of $\\sigma^2_\\mu$ given $\\sigma^2$\n\n## Important Sampling Estimate {.smaller}\n\n- Estimate of $m(y)$\n$$m(y) \\approx \\frac{1}{T} \\sum_{t=1}^{T}  \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})} \\qquad \\theta^{(t)} \\sim q(\\theta)$$\n\n- Ratio estimator of $\\textsf{E}[h(\\theta) \\mid y]$\n$$\\textsf{E}[h(\\theta) \\mid y] \\approx \\frac{\\sum_{t=1}^{T} h(\\theta^{(t)}) \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}}\n{ \\sum_{t=1}^{T}  \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}}\n\\qquad \\theta^{(t)} \\sim q(\\theta)$$\n\n- Weighted average with importance weights $w(\\theta^{(t)}) \\propto \\frac{\\pi(\\theta^{(t)}) \\cal{L}(\\theta^{(t)})}{q(\\theta^{(t)})}$\n$$\\textsf{E}[h(\\theta) \\mid y] \\approx \\sum_{t=1}^{T} h(\\theta^{(t)}) w(\\theta^{(t)})/\\sum_{t=1}^T w(\\theta^{(t)}) \\qquad \\theta^{(t)} \\sim q(\\theta)$$ \n\n##  Issues {.smaller}\n\n- if $q()$ puts too little mass in regions with high posterior density,  we can have\nsome extreme weights\n\n- optimal case is that $q()$ is as close as possible to the posterior so that all weights are constant\n\n- Estimate may have large variance\n\n- Problems with finding a good $q()$ in high dimensions $(d > 20)$ or with skewed distributions\n\n## Markov Chain Monte Carlo (MCMC) {.smaller}\n\n\n- Typically $\\pi(\\theta)$ and $\\cal{L}(\\theta)$ are easy to evaluate\n\n \n. . .\n\n::: {.callout-note title=\"Question\"}\nHow do we draw samples  only using evaluations of the prior and likelihood in higher dimensional settings?\n:::\n \n\n- construct a Markov chain $\\theta^{(t)}$ in such a way the the stationary distribution of the Markov chain is the posterior distribution $\\pi(\\theta \\mid y)$!\n$$\\theta^{(0)} \\overset{k}{\\longrightarrow} \\theta^{(1)} \\overset{k}{\\longrightarrow} \\theta^{(2)} \\cdots$$\n \n\n- $k_t(\\theta^{(t-1)} ; \\theta^{(t)})$  transition kernel\n\n \n\n- initial state $\\theta^{(0)}$\n\n \n\n- choose some nice $k_t$ such that $\\theta^{(t)} \\to \\pi(\\theta \\mid y)$ as $t \\to \\infty$\n\n \n\n- biased samples initially but get closer to the target\n\n- Metropolis Algorithm (1950's)\n\n \n\n##  Stochastic Sampling Intuition {.smaller}\n\n- From a sampling perspective, we need to have a large sample or group of values, $\\theta^{(1)}, \\ldots, \\theta^{(S)}$ from $\\pi(\\theta \\mid  y)$ whose empirical distribution approximates $\\pi(\\theta \\mid  y)$.\n\n\n\n-  for any two sets $A$ and $B$, we want\n$$\\frac{\\dfrac{\\# \\theta^{(s)} \\in A}{S}}{\\dfrac{\\# \\theta^{(s)} \\in B}{S} } = \\dfrac{\\# \\theta^{(s)} \\in A}{\\# \\theta^{(s)} \\in B} \\approx \\dfrac{\\pi(\\theta \\in A \\mid  y)}{\\pi(\\theta \\in B \\mid  y)}$$\n\n\n\n- Suppose we have a working group $\\theta^{(1)}, \\ldots, \\theta^{(s)}$ at iteration $s$, and need to add a new value $\\theta^{(s+1)}$.\n\n\n\n- Consider a candidate value $\\theta^\\star$ that is  _close_ to $\\theta^{(s)}$ \n\n\n\n\n- Should we set $\\theta^{(s+1)} = \\theta^\\star$ or not?\n\n\n## Posterior Ratio {.smaller}\n\n\nlook at  the ratio \n$$\n\\begin{split}\nM & = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)} = \\frac{\\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y)} } {\\dfrac{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}{p(y)}}\\\\\n\\\\\n&  = \\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}\n\\end{split}\n$$\n\n\n\n\n- does not depend on the marginal likelihood we don't know!\n\n\n\n\n\n## Metropolis Algorithm {.smaller}\n\n- If $M > 1$\n  + Intuition: $\\theta^{(s)}$ is already a part of the density we desire and the density at $\\theta^\\star$ is even higher than the density at $\\theta^{(s)}$.\n  \n  + Action: set $\\theta^{(s+1)} = \\theta^\\star$\n\n\n\n- If $M < 1$, \n  + Intuition: relative frequency of values in our group $\\theta^{(1)}, \\ldots, \\theta^{(s)}$ \"equal\" to $\\theta^\\star$ should be $\\approx M = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)}$. \n \n\n  + For every $\\theta^{(s)}$, include only a fraction of an instance of $\\theta^\\star$.\n\n\n  + Action: set $\\theta^{(s+1)} = \\theta^\\star$ with probability $M$ and $\\theta^{(s+1)} = \\theta^{(s)}$ with probability $1-M$.\n\n## Proposal Distribution {.smaller}\n\n\n- Where should the proposed value $\\theta^\\star$ come from? \n\n\n\n- Sample $\\theta^\\star$ close to the current value $\\theta^{(s)}$ using a **symmetric proposal distribution** $\\theta^\\star \\sim q(\\theta^\\star \\mid \\theta^{(s)})$\n\n\n\n\n- $q()$ is actually a \"family of proposal distributions\", indexed by the specific value of $\\theta^{(s)}$.\n\n\n\n- Here, symmetric means that $q(\\theta^\\star \\mid \\theta^{(s)}) = q(\\theta^{(s)} \\mid \\theta^\\star)$. \n\n\n\n- Common choice \n$$\\textsf{N}(\\theta^\\star; \\theta^{(s)}, \\delta^2 \\Sigma)$$\n with $\\Sigma$ based on the approximate $\\textsf{Cov}(\\theta \\mid y)$ and $\\delta = 2.44/\\text{dim}(\\theta)$ or \n $$\\text{Unif}(\\theta^\\star; \\theta^{(s)} - \\delta, \\theta^{(s)} + \\delta)$$\n\n\n## Metropolis Algorithm Recap {.smaller}\n\nThe algorithm proceeds as follows:\n\n  1. Given $\\theta^{(1)}, \\ldots, \\theta^{(s)}$, generate a _candidate_ value $\\theta^\\star \\sim q(\\theta^\\star \\mid \\theta^{(s)})$.\n  \n\n  2. Compute the acceptance ratio\n$$\\begin{split}\nM & = \\dfrac{\\pi(\\theta^\\star \\mid y)}{\\pi(\\theta^{(s)} \\mid y)} = \\dfrac{p(y \\mid \\theta^\\star) \\pi(\\theta^\\star)}{p(y \\mid \\theta^{(s)}) \\pi(\\theta^{(s)})}.\n\\end{split}$$\n\n  3. Set\n$$\\begin{eqnarray*}\n\\theta^{(s+1)} = \\left\\{ \\begin{array}{ll}\n\\theta^\\star & \\quad \\text{with probability} \\quad \\text{min}(M,1) \\\\\n\\theta^{(s)} & \\quad \\text{with probability} \\quad 1 - \\text{min}(M,1) \\\\\n\\end{array} \\right.\n\\end{eqnarray*}$$\nequivalent to sampling $u \\sim U(0,1)$ independently and setting\n $$\\begin{eqnarray*}\n\\theta^{(s+1)} = \\left\\{ \\begin{array}{ll}\n\\theta^\\star & \\quad \\text{if} \\quad u < M \\\\\n\\theta^{(s)} & \\quad \\text{if} \\quad \\text{otherwise} \\\\\n\\end{array} \\right. .\n\\end{eqnarray*}\n$$\n\n\n##  Notes {.smaller}\n\n- Acceptance probability is \n$$M = \\min \\left\\{ 1, \\frac{\\pi(\\theta^\\star) \\cal{L}(\\theta^\\star)}\n                           {\\pi(\\theta^{(s)}) \\cal{L}(\\theta^{(s)})}\\right\\}$$\n                            \n \n\n- ratio of posterior densities where normalizing constant cancels!\n\n\n-  The Metropolis chain ALWAYS moves to the proposed $\\theta^\\star$ at iteration $s+1$ if $\\theta^\\star$ has\nhigher target density than the current $\\theta^{(s)}$.\n\n\n\n- Sometimes, it also moves to a $\\theta^\\star$ value with lower density in proportion to the density value itself. \n\n\n\n- This leads to a random, Markov process that naturally explores the space according to the probability defined by $\\pi(\\theta \\mid y)$, and hence generates a sequence that, while dependent, eventually represents draws from $\\pi(\\theta \\mid y)$ (stationary distribution of the Markov Chain).\n\n\n\n\n\n \n## Summarizing Samples {.smaller}\n\n- Once we obtain the samples, then we are back to using Monte Carlo approximations for quantities of interest!\n\n  \n\n- we can approximate posterior means, quantiles, and other quantities of interest using the empirical distribution of our sampled values.\n\n  \n\n- easy to compute the posterior distribution of nonlinear functions of parameters!\n$$\\psi^{(s)} = g(\\theta^{(s)})$$\n\n  \n\n- some posterior summaries are hard to calculate based on samples $\\{ \\theta^{(s)}\\}$ \n\n  \n  + mode/MAP (at least for continuous)\n  \n  \n  + marginal likelihood  $m(y) = \\int \\pi(\\theta) p(y \\mid \\theta)\\, d\\theta$\n \n\n \n## Convergence {.smaller}\n\nWe will not cover the convergence theory behind Metropolis chains in detail, but ...\n\n  \n\n- The Markov process generated under this procedure is **ergodic** (irreducible and aperiodic) and has a unique limiting distribution (stationary distribution)\n\n  \n\n  + ergodicity means that the chain can move anywhere at each step, which is ensured, if $q(\\theta^\\star \\mid \\theta^{(s)}) > 0$ everywhere!\n\n  \n\n- By construction, Metropolis chains are **reversible**, so that  $\\pi(\\theta \\mid y)$ is the stationary distribution\n  \n  \n\n  + Think of reversibility as being equivalent to symmetry of the joint density of two consecutive $\\theta^{(s)}$ and $\\theta^{(s+1)}$ in the stationary process (which we get by using a symmetric proposal distribution)  \n  \n  + detailed balance\n  \n\n\n\n\n \n## Example {.smaller}\n\nPriors with $\\sigma^2 = 1$:\n$$p(\\mu) \\propto 1$$\n  \n\n- Use a $\\textsf{Cauchy}(0,1)$ prior on $\\sigma_\\mu$ independent of $\\mu$ and \n\n  \n\n- Symmetric proposal for $\\mu$ and  $\\sigma_\\tau$?    \n\n  \n\n-  Try independent normals $\\frac{2.44^2}{d} \\textsf{Cov}(\\theta)$ where $d$ is the dimension of $\\theta$  (d = 2)\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n \n##  Samples {.smaller}\n\n\n::: {.cell layout-align=\"center\" fig='true'}\n::: {.cell-output-display}\n![](06-metropolis_files/figure-revealjs/joint-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n- Overall Acceptance probability is 0.6   out of 10^{4} samples\n\n  \n\n- Goal is around 0.44 in 1 dimension to 0.23 in higher dimensions\n\n\n \n## Tuning {.smaller}\n\n- Sampled values are correlated\n\n  \n\n- Correlation between samples can be adjusted by selecting an optimal $\\delta$ (i.e., spread of the distribution) in the proposal distribution\n\n  \n\n- $\\delta$ too small leads to $M \\approx 1$ for most proposed values, a high acceptance rate, but very small moves, leading to highly correlated chain.\n\n  \n\n- $\\delta$ too large can get \"stuck\"  because $\\theta^\\star$ may be very far away from high density regions, leading to a very low acceptance rate and again high correlation in the Markov chain.\n\n  \n\n\n- Burn-in and thinning can help!\n\n\n\n \n## Burn-in {.smaller}\n\n- Convergence  occurs regardless of our starting point (in theory),  so we can usually pick any reasonable values in the parameter space as a starting point.\n\n  \n\n- May take a long time to reach high density regions\n\n  \n- Over representation of low density samples given finite iterations\n\n  \n\n- Generally, we throw out a certain number of the first draws, known as the **burn-in**, as an attempt to make our draws closer to the\nstationary distribution and less dependent on any single set of starting values. \n\n  \n\n- However, we don't know exactly when convergence occurs, so it is not always clear how much burn-in we would need.\n\n\n  \n\n- If you run long enough you should not need to discard any samples!  (ergodicity)\n\n\n\n\n##   Example {.smaller}\n\n\n::: {.cell layout-align=\"center\" fig='true'}\n::: {.cell-output-display}\n![](06-metropolis_files/figure-revealjs/joint2-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\n\n\n\n \n## Convergence diagnostics {.smaller}\n\n- Diagnostics available to help decide on number of burn-in & collected samples.\n\n  \n\n- **Note**: no definitive tests of convergence but you should do as many diagnostics as you can, on all parameters in your model.\n\n  \n\n- With \"experience\", visual inspection of trace plots perhaps most useful approach.\n\n  \n\n- There are a number of useful automated tests in R.\n\n  \n\n- **CAUTION**: diagnostics cannot guarantee that a chain has converged, but they can indicate it has not converged.\n\n\n\n \n## Diagnostics in R {.smaller}\n\n\n\n\n- The most popular package for MCMC diagnostics in R is `coda`.\n\n  \n\n- `coda` uses a special MCMC format so you must always convert your posterior matrix into an MCMC object. \n\n  \n\n- For the example, we have the following in R.\n\n. . .\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#library(coda)\ntheta.mcmc <- mcmc(theta,start=1) #no burn-in (simple problem!)\n```\n:::\n\n\n\n\n \n## Diagnostics in R {.smaller}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(theta.mcmc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nIterations = 1:10000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n             Mean     SD Naive SE Time-series SE\nmu       -0.07977 0.1046 0.001046       0.002839\nsigma_mu  0.17550 0.1273 0.001273       0.004397\n\n2. Quantiles for each variable:\n\n              2.5%     25%      50%      75%  97.5%\nmu       -0.283420 -0.1508 -0.08193 -0.00848 0.1337\nsigma_mu  0.007995  0.0758  0.15024  0.25228 0.4693\n```\n:::\n:::\n\n\n- The naive SE is the **standard error of the mean**, which captures simulation error of the mean rather than the posterior uncertainty. \n\n- The time-series SE adjusts the naive SE for **autocorrelation**.\n\n\n\n \n## Effective sample size. {.smaller}\n\n- The **effective sample size** translates the number of MCMC samples $S$ into an equivalent number of independent samples.\n\n  \n\n- It is defined as\n$$\\textrm{ESS} = \\dfrac{S}{1 + 2 \\sum_k \\rho_k},$$\n\n -  $S$ is the sample size and $\\rho_k$ is the lag $k$ autocorrelation.\n  \n  \n\n- For our data, we have\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\neffectiveSize(theta.mcmc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       mu  sigma_mu \n1356.6495  838.2613 \n```\n:::\n:::\n\n\n\n\n  \n\n- So our 10,000 samples are equivalent to 1356.6 independent samples for $\\mu$  and 838.3 independent samples for $\\sigma_\\mu$.\n\n\n\n\n \n## Trace plot for mean\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-metropolis_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n\n\n \n## Trace plot for $\\sigma_\\mu$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-metropolis_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\nOK  (be careful of scaling in plots!)\n\n\n\n \n## Autocorrelation {.smaller}\n\n- Another way to evaluate convergence is to look at the autocorrelation between draws of our Markov chain.\n\n  \n\n- The lag $k$ autocorrelation, $\\rho_k$, is the correlation between each draw and its $k$th lag, defined as\n$$\\rho_k = \\dfrac{\\sum_{s=1}^{S-k}(\\theta_s - \\bar{\\theta})(\\theta_{s+k} - \\bar{\\theta})}{\\sum_{s=1}^{S-k}(\\theta_s - \\bar{\\theta})^2}$$\n\n  \n\n- We expect the autocorrelation to decrease as $k$ increases. \n\n  \n\n- If autocorrelation remains high as $k$ increases, we have slow mixing due to the inability of the sampler to move around the space well.\n\n\n\n \n## Autocorrelation for mean {.smaller}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-metropolis_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\nSo-So\n\n\n \n## Autocorrelation for variance  {.smaller}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-metropolis_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\nworse\n\n\n\n\n \n## Gelman-Rubin  {.smaller}\n\nGelman  & Rubin suggested a diagnostic $R$ based on taking separate  chains with dispersed initial values to test convergence\n\n  \n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-metropolis_files/figure-revealjs/unnamed-chunk-10-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n\n \n## Gelman-Rubin Diagnostic {.smaller}\n\n- Run m > 2 chains of length 2S from overdispersed starting values.\n- Discard the first S draws in each chain.\n-  Calculate the pooled within-chain variance $W$ and between-chain variance $B$.\n$$R = \\frac{\\frac{S-1}{S} W + \\frac{1}{S} B }{W}$$\n\n  \n\n- numerator and denominator are both unbiased estimates of the variance if the two chains have converged\n\n  \n  +  otherwise $W$ is an underestimate (hasn't explored enough)\n  +  numerator will overestimate as $B$ is too large (overdispersed starting points)\n  \n  \n\n- As $S \\to \\infty$ and $B \\to 0$,  $R \\to 1$\n\n  \n\n- version in `R` is slightly different \n\n \n## Gelman-Rubin Diagnostic  {.smaller}\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntheta.mcmc = mcmc.list(mcmc(theta1, start=5000), mcmc(theta2, start=5000))\ngelman.diag(theta.mcmc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPotential scale reduction factors:\n\n         Point est. Upper C.I.\nmu                1          1\nsigma_mu          1          1\n\nMultivariate psrf\n\n1\n```\n:::\n:::\n\n\n  \n\n-  Values of $R > 1.1$ suggest lack of convergence\n\n  \n- Looks OK\n \n  \n\n- See also `gelman.plot`\n\n \n## Geweke statistic {.smaller}\n\n- Geweke proposed taking two non-overlapping parts of a single Markov chain (usually the first 10% and the last 50%) and comparing the mean of both parts, using a difference of means test\n\n  \n\n- The null hypothesis would be that the two parts of the chain are from the same distribution. \n\n  \n\n- The test statistic is a z-score with standard errors adjusted for autocorrelation, and if the p-value is significant for a variable, you need more draws. \n\n- Output in R is the Z score\n\n \n## Geweke Diagnostic  {.smaller}\n\n- The output is the z-score itself (not the p-value).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngeweke.diag(theta.mcmc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n\nFraction in 1st window = 0.1\nFraction in 2nd window = 0.5 \n\n      mu sigma_mu \n -0.7779   0.7491 \n\n\n[[2]]\n\nFraction in 1st window = 0.1\nFraction in 2nd window = 0.5 \n\n      mu sigma_mu \n  0.4454   0.6377 \n```\n:::\n:::\n\n\n\n \n## Practical advice on diagnostics {.smaller}\n\n- There are more tests we can use: Raftery and Lewis diagnostic, Heidelberger and Welch, etc.\n\n  \n\n- The Gelman-Rubin approach is quite appealing in using multiple chains\n\n  \n\n- Geweke (and Heidelberger and Welch) sometimes reject even when the trace plots look good.\n\n  \n\n- Overly sensitive to minor departures from stationarity that do not impact inferences.\n\n  \n\n\n\n- Most common method of assessing convergence is visual examination of trace plots.\n\n\n \n##  Improving {.smaller}\n\n-  more iterations and multiple chains\n\n  \n\n- thinning to reduce correlations and increase ESS\ne.g. if autocorrelation drops to  near zero at say lag 5, keep every 5th draw\n\n  \n\n- change the proposal distribution $q$\n\n\n\n\n",
    "supporting": [
      "06-metropolis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/font-awesome/css/all.min.css\" rel=\"stylesheet\" />\n<link href=\"../../site_libs/font-awesome/css/v4-shims.min.css\" rel=\"stylesheet\" />\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}