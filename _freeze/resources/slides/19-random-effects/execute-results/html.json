{
  "hash": "6178ea3bc9bfed317e77874f6e25ee51",
  "result": {
    "markdown": "---\ntitle: \"Lecture 19: Random Effects\"\nauthor: \"Merlise Clyde\"\nsubtitle: \"STA702\"\ninstitute: \"Duke University\"\nformat: \n  revealjs:\n    theme: [simple, custom.scss]\n    slide-number: true\n    incremental: true\n    scrollable: false\n    controls: true\n    fragments: true\n    preview-links: auto\n    smaller: true\n    logo: ../../img/icon.png\n    footer: <https://sta702-F23.github.io/website/>\n    chalkboard: \n      boardmarker-width: 1\n      chalk-width: 2\n      chalk-effect: 0\n    embed-resources: false\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"    \neditor: \n  markdown: \n    wrap: 72\nexecute: \n  echo: false\nnumber-sections: false\nfilters:\n  - custom-numbered-blocks  \ncustom-numbered-blocks:\n  groups:\n    thmlike:\n      colors: [948bde, 584eab]\n      boxstyle: foldbox.simple\n      collapse: false\n      listin: [mathstuff]\n    todos: default  \n  classes:\n    Theorem:\n      group: thmlike\n    Corollary:\n      group: thmlike\n    Conjecture:\n      group: thmlike\n      collapse: true  \n    Definition:\n      group: thmlike\n      colors: [d999d3, a01793]\n    Feature: default\n    TODO:\n      label: \"To do\"\n      colors: [e7b1b4, 8c3236]\n      group: todos\n      listin: [stilltodo]\n    DONE:\n      label: \"Done\"\n      colors: [cce7b1, 86b754]  \n      group: todos  \n---\n\n\n\n\n\n\n\n## Building Hierarchical Models \n\\usepackage{xcolor}\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\DeclareMathOperator*{\\argmax}{argmax}\n\\DeclareMathOperator{\\sgn}{sgn}\n\\newcommand{\\e}{\\mathbf{e}}\n\\renewcommand{\\P}{\\mathbf{P}}\n\\newcommand{\\F}{\\mathbf{F}}\n\\newcommand{\\R}{\\textsf{R}}\n\\newcommand{\\mat}[1] {\\mathbf{#1}}\n\\newcommand{\\E}{\\textsf{E}}\n\\newcommand{\\SE}{\\textsf{SE}}\n\\newcommand{\\SSE}{\\textsf{SSE}}\n\\newcommand{\\RSS}{\\textsf{RSS}}\n\\newcommand{\\FSS}{\\textsf{FSS}}\n\\renewcommand{\\SS}{\\textsf{SS}}\n\\newcommand{\\MSE}{\\textsf{MSE}}\n\\newcommand{\\SSR}{\\textsf{SSR}}\n\\newcommand{\\Be}{\\textsf{Beta}}\n\\newcommand{\\St}{\\textsf{St}}\n\\newcommand{\\Ca}{\\textsf{C}}\n\\newcommand{\\Exp}{\\textsf{Exp}}\n\\newcommand{\\GDP}{\\textsf{GDP}}\n\\newcommand{\\NcSt}{\\textsf{NcSt}}\n\\newcommand{\\Bin}{\\textsf{Bin}}\n\\newcommand{\\NB}{\\textsf{NegBin}}\n\\renewcommand{\\NG}{\\textsf{NG}}\n\\newcommand{\\N}{\\textsf{N}}\n\\newcommand{\\Ber}{\\textsf{Ber}}\n\\newcommand{\\Poi}{\\text{Poi}}\n\\newcommand{\\Gam}{\\textsf{Gamma}}\n\\newcommand{\\BB}{\\textsf{BB}}\n\\newcommand{\\BF}{\\textsf{BF}}\n\\newcommand{\\Gm}{\\textsf{G}}\n\\newcommand{\\Un}{\\textsf{Unif}}\n\\newcommand{\\Ex}{\\textsf{Exp}}\n\\newcommand{\\DE}{\\textsf{DE}}\n\\newcommand{\\tr}{\\textsf{tr}}\n\\newcommand{\\cF}{{\\cal{F}}}\n\\newcommand{\\cL}{{\\cal{L}}}\n\\newcommand{\\cI}{{\\cal{I}}}\n\\newcommand{\\cB}{{\\cal{B}}}\n\\newcommand{\\cP}{{\\cal{P}}}\n\\newcommand{\\bbR}{\\mathbb{R}}\n\\newcommand{\\bbN}{\\mathbb{N}}\n\\newcommand{\\pperp}{\\mathrel{{\\rlap{$\\,\\perp$}\\perp\\,\\,}}}\n\\newcommand{\\OFP}{(\\Omega,\\cF, \\P)}\n\\newcommand{\\eps}{\\boldsymbol{\\epsilon}}\n\\newcommand{\\1}{\\mathbf{1}_n}\n\\newcommand{\\gap}{\\vspace{8mm}}\n\\newcommand{\\ind}{\\mathrel{\\mathop{\\sim}\\limits^{\\rm ind}}}\n\\newcommand{\\iid}{\\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}}\n\\newcommand{\\simiid}{\\ensuremath{\\mathrel{\\mathop{\\sim}\\limits^{\\rm\niid}}}}\n\\newcommand{\\eqindis}{\\mathrel{\\mathop{=}\\limits^{\\rm D}}}\n\\newcommand{\\SSZ}{S_{zz}}\n\\newcommand{\\SZW}{S_{zw}}\n\\newcommand{\\Var}{\\textsf{Var}}\n\\newcommand{\\corr}{\\textsf{corr}}\n\\newcommand{\\diag}{\\textsf{diag}}\n\\newcommand{\\var}{\\textsf{var}}\n\\newcommand{\\Cov}{\\textsf{Cov}}\n\\newcommand{\\Sam}{{\\cal S}}\n\\def\\H{\\mathbf{H}}\n\\newcommand{\\I}{\\mathbf{I}}\n\\newcommand{\\Y}{\\mathbf{Y}}\n\\newcommand{\\tY}{\\tilde{\\mathbf{Y}}}\n\\newcommand{\\Yhat}{\\hat{\\mathbf{Y}}}\n\\newcommand{\\Yobs}{\\mathbf{Y}_{{\\cal S}}}\n\\newcommand{\\barYobs}{\\bar{Y}_{{\\cal S}}}\n\\newcommand{\\barYmiss}{\\bar{Y}_{{\\cal S}^c}}\n\\def\\bv{\\mathbf{b}}\n\\def\\X{\\mathbf{X}}\n\\def\\tX{\\tilde{\\mathbf{X}}}\n\\def\\x{\\mathbf{x}}\n\\def\\xbar{\\bar{\\mathbf{x}}}\n\\def\\Xbar{\\bar{\\mathbf{X}}}\n\\def\\Xg{\\mathbf{X}_{\\boldsymbol{\\gamma}}}\n\\def\\Ybar{\\bar{\\Y}}\n\\def\\ybar{\\bar{y}}\n\\def\\y{\\mathbf{y}}\n\\def\\Yf{\\mathbf{Y_f}}\n\\def\\W{\\mathbf{W}}\n\\def\\L{\\mathbf{L}}\n\\def\\w{\\mathbf{w}}\n\\def\\U{\\mathbf{U}}\n\\def\\V{\\mathbf{V}}\n\\def\\Q{\\mathbf{Q}}\n\\def\\Z{\\mathbf{Z}}\n\\def\\z{\\mathbf{z}}\n\\def\\v{\\mathbf{v}}\n\\def\\u{\\mathbf{u}}\n\n\\def\\zero{\\mathbf{0}}\n\\def\\one{\\mathbf{1}}\n\\newcommand{\\taub}{\\boldsymbol{\\tau}}\n\\newcommand{\\betav}{\\boldsymbol{\\beta}}\n\\newcommand{\\alphav}{\\boldsymbol{\\alpha}}\n\\newcommand{\\A}{\\mathbf{A}}\n\\def\\a{\\mathbf{a}}\n\\def\\K{\\mathbf{K}}\n\\newcommand{\\B}{\\mathbf{B}}\n\\def\\b{\\boldsymbol{\\beta}}\n\\def\\bhat{\\hat{\\boldsymbol{\\beta}}}\n\\def\\btilde{\\tilde{\\boldsymbol{\\beta}}}\n\\def\\tb{\\boldsymbol{\\theta}}\n\\def\\bg{\\boldsymbol{\\beta_\\gamma}}\n\\def\\bgnot{\\boldsymbol{\\beta_{(-\\gamma)}}}\n\\def\\mub{\\boldsymbol{\\mu}}\n\\def\\tmub{\\tilde{\\boldsymbol{\\mu}}}\n\\def\\muhat{\\hat{\\boldsymbol{\\mu}}}\n\\def\\tb{\\boldsymbol{\\theta}}\n\\def\\tk{\\boldsymbol{\\theta}_k}\n\\def\\tj{\\boldsymbol{\\theta}_j}\n\\def\\Mk{\\boldsymbol{{\\cal M}}_k}\n\\def\\M{\\boldsymbol{{\\cal M}}}\n\\def\\Mj{\\boldsymbol{{\\cal M}}_j}\n\\def\\Mi{\\boldsymbol{{\\cal M}}_i}\n\\def\\Mg{{\\boldsymbol{{\\cal M}_\\gamma}}}\n\\def\\Mnull{\\boldsymbol{{\\cal M}}_{N}}\n\\def\\gMPM{\\boldsymbol{\\gamma}_{\\text{MPM}}}\n\\def\\gHPM{\\boldsymbol{\\gamma}_{\\text{HPM}}}\n\\def\\Mfull{\\boldsymbol{{\\cal M}}_{F}}\n\\def\\tg{\\boldsymbol{\\theta}_{\\boldsymbol{\\gamma}}}\n\\def\\g{\\boldsymbol{\\gamma}}\n\\def\\eg{\\boldsymbol{\\eta}_{\\boldsymbol{\\gamma}}}\n\\def\\G{\\mathbf{G}}\n\\def\\cM{\\cal M}\n\\def\\D{\\Delta}\n\\def \\shat{{\\hat{\\sigma}}^2}\n\\def\\uv{\\mathbf{u}}\n\\def\\l {\\lambda}\n\\def\\d{\\delta}\n\\def\\Sigmab{\\boldsymbol{\\Sigma}}\n\\def\\Phib{\\boldsymbol{\\Phi}}\n\\def\\Lambdab{\\boldsymbol{\\Lambda}}\n\\def\\lambdab{\\boldsymbol{\\lambda}}\n\\def\\Mg{{\\cal M}_\\gamma}\n\\def\\S{{\\cal{S}}}\n\\def\\qg{p_{\\boldsymbol{\\gamma}}}\n\\def\\pg{p_{\\boldsymbol{\\gamma}}}\n\\def\\T{\\boldsymbol{\\Theta}}\n\\def\\Tb{\\boldsymbol{\\Theta}}\n\\def\\t{\\mathbf{t}}\n\n\n\n- Models for Gaussian Data with no Covariates\n$$ y_{ij} \\sim \\, ? \\qquad i = 1, \\ldots n_j; j = 1, \\ldots, J$$ \n\n \n\n- $j$ **blocking variable** - schools, counties, etc (categorical)\n\n \n\n- $i$  observations within a block - students within schools,  households within counties,  etc\n\n \n\n- potentially there may be within block dependence in the observations due to unmeasured covariates\n\n \n\n- structure?\n\n\n## Models\n\n- Naive model (baseline)\n$$ y_{ij} \\overset{iid}{\\sim}  N(\\mu, \\sigma^2) $$\n \n\n- issue: no systematic variation across blocks\n\n \n\n- Fixed Effects model:\n$$  y_{ij} \\overset{ind}{\\sim}  N(\\mu_j, \\sigma^2) $$\n \n\n- Common reparameterization\n$$  y_{ij} \\overset{ind}{\\sim}  N(\\alpha + \\beta_j, \\sigma^2) $$\n\n + $\\mu$ intercept\n\n +  $\\beta_j$ shift for school\n \n \n\n- Identifiability ?\n\n\n\n##  Non-Identifiability\n\n- Example:  $y_{ij} \\sim N(\\alpha + \\beta_j, \\sigma^2)$  overparameterized\n\n\n \n\n- $\\mu_j = \\alpha + \\beta_j$ and $\\sigma^2$ are uniquely estimated, but not $\\alpha$ or $\\beta_j$\n\n \n\n-  $x_{ij} \\in \\{1, \\ldots, J \\}$ factor levels\n$$y_{ij} \\sim N(\\alpha+ \\sum_{j^\\prime}\\beta_j 1(x_{ij^{\\prime}} = j), \\sigma^2)$$\n \n \n \n- $\\mu_j = \\alpha + \\beta_j$ identifiable - $J$ equations but $J + 1$ unknowns\n \n \n \n- Put constraints  on parameters  \n \n  + $\\alpha = 0$\n  + $\\beta_J = 0$ \n  + $\\sum \\beta_j = 0$\n \n \n\n##  Bayesian Notion of Identifiability\n \n - Bayesian Learning\n \n - model is likelihood and prior\n \n \n- the posterior distribution differs from the prior\n \n \n\n\n. . . \n\n::: {.callout-warning}\n## Note:\n\n- Priors may lead to posteriors where parameters are identifiable even if not under likelihood\n\n - Forcing identifiability may involve (complex) constraints that bias parameter estimates \n$$\n\\begin{align}\n\\alpha  & \\sim \\N(0, \\sigma^2_\\alpha) \\\\\n\\beta_j & \\iid \\N(0, \\sigma^2_\\beta)  \\text{ for } j = 1, \\ldots, J-1 \\\\\n\\mu_J & \\sim  \\N(0, \\sigma^2_\\alpha) \\\\\n\\mu_j &\\ iid \\N(0, \\sigma^2_\\alpha + \\sigma^2_\\beta)  \\text{ for } j = 1, \\ldots, J-1 \n\\end{align}\n$$\n\n- sometimes purposely introduce non-identifiability to improve computation  (parameter expansion PX)\n \n\n \n\n- run non-identifiable model and focus on identifiable parameters or functions of them\n\n::: \n\n\n##  Issue with Fixed Effect Approach\n\n- What if $n_i$, number of observations per block, are small?\n\n \n\n- Estimated uncertainty/variances are large based on MLE using group specific means\n\n \n\n- What if blocks might be viewed as a sample from some larger population?   Sample of schools?\n\n \n\n-  May want inference about  the larger population and say things about future blocks (schools) !\n\n\n \n\n- fixed effects do not allow us to say anything about  blocks not in our sample!\n\n \n\n- how to address this?\n\n\n## Random Effects\n\n$$\\begin{align*}\ny_{ij} & = \\alpha + \\beta_i + \\epsilon_{ij}, \\qquad \\epsilon_{ij} \\overset{iid}{\\sim} N(0, \\sigma^2) \\\\\n\\beta_i & \\overset{iid}{\\sim} N(0, \\tau^2)\n\\end{align*}$$\n\n- random effects $\\beta_j$\n\n . . .\n \n::: {.callout-warning}\n## Note: Don't confuse random effect distributions with prior distributions! \n:::\n \n-  Random effect distributions should be viewed as part of the model specification \n\n \n\n- We've specified the likelihood in a hierarchical manner to induce desirable structure\n\n \n\n-  unknown parameters are population parameters $\\alpha$, $\\tau$ and $\\sigma^2$   \n\n \n\n- Bayesians put prior distributions on $\\alpha$, $\\tau$ and $\\sigma^2$; frequentists don't!\n\n\n## Equivalent Model\n\n$$y_{j} = (y_{1j}, y_{2j}, \\ldots, y_{n_j j})$$\n$$y_j  \\mid  \\alpha, \\sigma^2, \\tau^2 \\ind N_{n_j}\\left( \\one_{n_j} \\alpha, \\left(\n\\begin{array}{cccc}\n\\sigma^2 + \\tau^2 & \\tau^2 & \\ldots & \\tau^2 \\\\\n\\tau^2 & \\ddots &    & \\tau^2  \\\\\n\\vdots & & \\ddots & \\vdots \\\\\n\\tau^2 & \\ldots & \\tau^2 & \\sigma^2 + \\tau^2 \\end{array}\\right) \\right)$$\n\n- within-block correlation constant\n\n \n\n- algorithmically we can use either the latent variable model or the collapsed (marginal) model for inferences;  \n\n\n- often latent variable is easier to work with for Bayes!\n\n- MLEs of $\\tau$ on boundary in some cases!\n\n\n##  Simple Gibbs Sampler\n- Reparameterize $\\theta  = (\\alpha, \\phi_\\tau = 1/\\tau^2, \\phi_\\sigma = 1/\\sigma^2, \\beta_1, \\ldots, \\beta_J)$\n\n- Priors (parameters Greek letters, hyperparameters Roman)\n$$\\begin{align*} \n\\alpha & \\sim \\N(a_0, 1/P_0) \\\\\n\\phi_\\tau & \\sim \\Gam(a_\\tau/2, b_\\tau/2) \\\\\n\\phi_\\sigma  & \\sim  \\Gam(a_\\sigma/2, b_\\sigma/2)\n\\end{align*}$$\n\n- Full Conditional for $\\alpha$\n$$\\begin{align*}\\alpha \\mid \\tau^2, \\sigma^2, \\beta_1, \\ldots \\beta_n & \\sim \\N(a_n, 1/P_n) \\\\\nP_n = \\left(P_0 + \\sum_j n_{j} \\phi_\\sigma  \\right) &  \\quad\na_n  = \\frac{a_0 P_0 +  \\sum_j n_j \\bar{y}^*_j }{P_n} \\\\\n \\bar{y}^*_j  & \\equiv \\frac{\\sum_i (y_{ij} - \\beta_j)}{n_j}\n\\end{align*}$$\n\n\n## Full Conditionals Continued\n\n$$\\begin{align*}\n\\phi_\\sigma \\mid \\alpha, \\phi_\\tau, \\beta_1, \\ldots, \\beta_J \\sim  \\Gam \\left(\\frac{a_\\sigma + \\sum_j n_j}{2}, \\frac{b_\\sigma + \\sum_{ij} (y_{ij} - \\alpha - \\beta_j)^2}{2} \\right)\n\\end{align*}$$\n \n. . .\n\n$$\\begin{align*}\\beta_j \\mid \\alpha, \\tau, \\sigma^2  & \\ind \\N( \\hat{b}_j, \\hat{P}_{\\beta_j}^{-1}) \\\\\n\\hat{P}_{\\beta_j} &= \\left(\\phi_\\tau +  n_j \\phi_\\sigma \\right) \\\\\n\\hat{b}_j & = \\frac{\\phi_{\\tau} +  n_j \\phi_\\sigma \\bar{y}^{**}_j }{\\hat{P}_{\\beta_j}} \\\\\n \\bar{y}^{**}_j  & \\equiv \\frac{\\sum_i (y_{ij} - \\alpha)}{n_j}\n\\end{align*}$$\n\n. . .\n\n$$\\begin{align*}\n\\phi_\\tau \\mid \\alpha, \\sigma^2, \\beta_1, \\ldots, \\beta_J \\sim  \\Gam \\left(\\frac{a_\\tau +  J}{2}, \\frac{b_\\tau+ \\sum_j \\beta_j^2}{2} \\right)\n\\end{align*}$$\n\n\n\n\n\n\n\n## Complications Relative to Usual Regression\n\n1. Prior Choice\n \n\n2. Mixing and its dependence on parameterization\n\n \n\n- Early recommendation after Gibbs Sampler used non-informative priors\n$$\\begin{align*}\n\\pi(\\alpha) & \\propto 1 \\\\\n\\pi(\\phi_\\sigma) & \\sim \\Gam(\\epsilon/2, \\epsilon/2) \\qquad \\pi(\\phi_\\sigma ) \\propto 1/\\phi_\\sigma \\text{ as } \\epsilon \\to 0 \\\\\n\\pi(\\phi_\\tau) & \\sim \\Gam(\\epsilon/2, \\epsilon/2)  \\qquad  \\pi(\\phi_\\tau) \\propto 1/\\phi_\\tau  \\text{ as } \\epsilon \\to 0 \n\\end{align*}$$\n\n \n\n- Are full conditionals proper ?\n\n \n\n- Is joint posterior proper ?\n\n \n##  MCMC and Improper Priors\n\n- proper full conditionals even with improper priors\n\n \n\n- but joint is improper !\n\n \n\n-  MCMC won't converge to the stationary distribution  (doesn't exist)\n\n \n\n- may not notice it! \n\n- [Hill (1965)](https://www.jstor.org/stable/2283247) considered the one-way anova model and showed impropriety for $p(\\tau^2) \\propto 1/\\tau^2$\n\n - [Hobart & Casella (1996)](https://www.jstor.org/stable/2291572) provide conditions on improper priors leading to proper posteriors in more general random and mixed effects models\n\n\n## Diffuse But Proper\n\n$$\\begin{align*}\n\\alpha & \\sim N(0, 10^{-6})\\\\\n\\pi(\\phi_\\sigma) & \\sim \\Gam(10^{-6}, 10^{-6} )\\\\\n\\pi(\\phi_\\tau) & \\sim \\Gam(10^{-6}, 10^{-6} )\n\\end{align*}$$\n\n \n\n-  Nearly improper priors may lead to terrible performance!   highly sensitive to just how vague the prior is!  (Domains of attraction)\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](19-random-effects_files/figure-revealjs/unnamed-chunk-1-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n\n## Alternative Priors\n\n$$\\begin{align*}\ny_{ij} \\mid \\alpha, \\beta_1, \\ldots \\beta_J, \\phi_\\sigma^2 & \\ind \\N(\\alpha + \\beta_j, 1/\\phi_\\sigma^2) \\\\\np(\\alpha, \\phi_\\sigma) & \\propto 1/\\phi_\\sigma \\\\\n\\beta_j  \\mid \\tau & \\overset{iid}{\\sim} \\N(0, \\tau^2) \n\\end{align*}$$\n\n- [Gelman 2006](https://projecteuclid.org/journals/bayesian-analysis/volume-1/issue-3/Prior-distributions-for-variance-parameters-in-hierarchical-models-comment-on/10.1214/06-BA117A.full) in a discussion of Browne & Draper paper in Bayesian Analysis recommended priors on random effect standard deviation $\\tau$\n\n \n\n- $\\pi(\\tau ) \\propto 1(\\tau > 0)$  (improper prior on sd)\n\n \n\n- $\\pi(\\tau ) \\propto 1(\\tau > 0)\\N(0,1)$  folded standard normal (half-normal)\n\n \n\n- $\\pi(\\tau ) \\propto 1(\\tau > 0)\\N(0,1/\\psi)  \\qquad \\psi \\sim \\Gam(\\nu/2, \\nu/2)$  leads to a folded t or half t with $\\nu$ degrees of freedom marginally\n \n## Proper Posterior ?\n\nIntegrate out $\\beta_j$ and work with  \n$$\\pi(\\mu, \\tau, \\sigma^2 \\mid y) \\propto \\pi(\\mu, \\tau, \\sigma^2) \\prod_{j=1}^J \\N\\left(y_{j}; \\one_{n_j} \\alpha, \\left(\n\\begin{array}{cccc}\n\\sigma^2 + \\tau^2 & \\tau^2 & \\ldots & \\tau^2 \\\\\n\\tau^2 & \\ddots &    & \\tau^2  \\\\\n\\vdots & & \\ddots & \\vdots \\\\\n\\tau^2 & \\ldots & \\tau^2 & \\sigma^2 + \\tau^2 \\end{array}\\right) \\right)$$\n\n- take $\\pi(\\mu, \\tau, \\sigma^2) \\propto \\sigma^{-2} \\, \\textsf{C}^+(\\tau; 0, 1)$\n\n \n. . .\n\n**OR** \n\n- take $\\pi(\\mu, \\tau, \\sigma^2) \\propto \\sigma^{-2}$ (note prior on standard deviation $\\tau$)\n\n \n\n\n-  Is joint posterior is proper ?   (see Hobart & Casella)  \n\n## Propriety\n\n\n- expression for marginal likelihood requires determinant and inverse of intra-class correlation matrix!   \n\n- Write covariance as $\\sigma^2 \\I_{n_j} + \\tau^2 n_j \\P_{\\one_{n_j}}$ and find spectral decomposition \n$$\\begin{align}\n\\sigma^2 \\I_{n_j} + \\tau^2 n_j \\P_{\\one_{n_j}}  & = \n\\U[\\sigma^2 \\I_{n_j} + \\tau^2 n_j \\text{diag}(1, 0 , \\ldots, 0)] \\U^T\\\\ \n(\\sigma^2 \\I_{n_j} + \\tau^2 n_j \\P_{\\one_{n_j}} )^{-1}  & = \\frac{1}{\\sigma^2} (\\I_{n_j} + \\frac{\\tau^2 n_j}{\\sigma^2 + \\tau^2 n_j} \\P_{\\one_{n_j}})\n\\end{align}$$\n\n- integrate out $\\alpha$  (messy completing the square)!  see [Hill 1965](https://www.jstor.org/stable/2283247) Equation 3.\n\n- consider conditional distributions from $1/\\sigma^2$ and $\\tau$\n\n- determine if integrals are finite (what happens at $\\tau$ near 0 ?)\n\n- look at special case when $n_j$ are all equal\n\n\n## Bayes Estimates of Variances\n\n- Avoids issues when estimate of variance is on the boundary of the parmaeter space\n\n-  Do not have to use asymptotics to construct CI!\n\n- full uncertainty propagation\n\n- predictive distributions for future data\n\n- Gelman (2006) recommends half-t if the number of groups is small or uniform but uniform on the standard deviation $\\tau$ does lead to an improper posterior if $J \\leq 3$\n\n- Hobart & Casella (1996) provides more rigorous conditions with improper priors\n",
    "supporting": [
      "19-random-effects_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/font-awesome/css/all.min.css\" rel=\"stylesheet\" />\n<link href=\"../../site_libs/font-awesome/css/v4-shims.min.css\" rel=\"stylesheet\" />\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}